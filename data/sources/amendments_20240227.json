[
    {
        "uuid":"8909ed4b-897b-4e97-97f8-6786bc806cdc",
        "text":"Having regard to the opinion of the European Central Bank,",
        "title":"Amendment 310: Citation 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"06d23a08-dd96-44b0-aa1c-b835d867c73f",
        "text":"Having regard to the opinion of the European Central Bank,",
        "title":"Amendment 311: Citation 5 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"c5d7c7dd-8cf5-458a-b22e-9aa11e7f3f8b",
        "text":"Having regard to the joint opinion of the European Data Protection Board and the European Data Protection Supervisor,",
        "title":"Amendment 312: Citation 5 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b6606df1-d0f8-4078-a2cb-eb2f7c03e961",
        "text":"(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform minimum legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection. It also ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation, or justified by the need to ensure the protection of the rights and freedoms of natural persons, or the ethical principles advocated by this Regulation",
        "title":"Amendment 313: Recital 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2642ef81-46ce-42da-9586-9be63e45ac8c",
        "text":"(1) The purpose of this Regulation is to ensure a high level of protection of fundamental rights, health, safety and the environment, as well as the Union values enshrined in Article 2 of the Treaty on European Union (TEU), from harmful effects of the use of artificial intelligence systems in the Union while enhancing innovation and improving the functioning of the internal market. This Regulation lays down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the use of artificial intelligence in conformity with Union values and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.",
        "title":"Amendment 314: Recital 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"50fb79c4-17a8-4204-9fa9-edd724a7256a",
        "text":"(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values, the Universal Declaration of Human Rights, the European Convention on Human Rights and the Charter of Fundamental Rights of the EU. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.",
        "title":"Amendment 315: Recital 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"ab5e31ad-d354-415b-bb36-1a75313a7421",
        "text":"(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 of the Treaty on European Union (TEU), and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.",
        "title":"Amendment 316: Recital 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"573054ff-ba6f-4e97-b767-b0e9d2594cf8",
        "text":"(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation and without prejudice to stricter national legislation governing the protection of fundamental rights.",
        "title":"Amendment 317: Recital 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"47f34925-3e89-4752-a24f-c79de0f018b2",
        "text":"(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, environment and fundamental rights, as well as consumer protection and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.",
        "title":"Amendment 318: Recital 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b57363a4-2111-48a2-b8fd-a2044b717584",
        "text":"(1 a) The term “artificial intelligence” (AI) refers to systems developed by humans that can, using different techniques and approaches, generate outputs such as content, predictions, recommendations and decisions. The context they are used in is decisive for how much and what kind of influence they can have, and whether they are perceived by an observer as “intelligent”. The term “automated decision-making” (ADM) has been proposed as it could avoid the possible ambiguity of the term AI. ADM involves a user delegating initially a decision, partly or completely, to an entity by way of using a system or a service. That entity then uses automatically executed decision-making models to perform an action on behalf of a user, or to inform the user’s decisions in performing an action",
        "title":"Amendment 319: Recital 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"53d9317c-a7eb-46a1-84fd-91c7b81e2823",
        "text":"(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems biometric identification in publicly accessible spaces, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.",
        "title":"Amendment 320: Recital 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0332414d-b2cc-410a-ae31-64607aa56733",
        "text":"(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU and to align it with relevant EU legislation such as the GDPR and the EUDPR. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board and to take into consideration the EDPB-EDPS Joint Opinion 5\/2021.",
        "title":"Amendment 321: Recital 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"b8c92f8f-4048-46c4-a0ff-834e04cd160d",
        "text":"(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible and online spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.",
        "title":"Amendment 322: Recital 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c5088cba-395f-4702-813e-9dd55c8676eb",
        "text":"(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A minimum, consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.",
        "title":"Amendment 323: Recital 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"70062840-b253-4e12-99ec-358c9e449b6d",
        "text":"(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). As AI systems rely on the processing of large volumes of data, including personal data, it is appropriate to base this Regulation on Article 16 of the TFEU, which enshrines the right of everyone to the protection of personal data concerning them and provides for the adoption of rules on the protection of individuals with regard to the processing of personal data. In light of the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.",
        "title":"Amendment 324: Recital 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ba384065-cbd2-434b-a37a-24be8ebe14aa",
        "text":"(2 a) However, in line with Article 114(2) TFEU, this Regulation does not affect the rights and interests of employed persons. This Regulation should therefore not affect Community law on social policy and national labour law and practice, that is any legal and contractual provision concerning employment conditions, working conditions, including health and safety at work and the relationship between employers and workers, including information, consultation and participation. This Regulation should not affect the exercise of fundamental rights as recognized in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States, in accordance with national law and\/or practice. Nor should it affect concertation practices, the right to negotiate, to conclude and enforce collective agreement or to take collective action in accordance with national law and\/or practice. It should in any case not prevent the Commission from proposing specific legislation on the rights and freedoms of workers affected by AI systems.",
        "title":"Amendment 325: Recital 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"25fb9d5b-741a-4e4b-b95b-b43ec362e3f5",
        "text":"(2 a) The deployment of artificial intelligence applications across sectors will only accelerate in the years to come. The European Union should therefore consider, in separate legislation, the creation of an Artificial Intelligence Adjustment Fund, which could be beneficial for Member States to cover the accustoming of their labour markets to the new conditions arising from the rapid mass introduction of artificial intelligence systems that could affect specific job sectors.",
        "title":"Amendment 326: Recital 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Maria-Manuel Leitão-Marques, Eva Kaili"
    },
    {
        "uuid":"db620253-ef18-4c46-905a-921adbc0177d",
        "text":"(2 a) This Regulation should not affect the restrictions, prohibitions or enforcement that apply where an artificial intelligence practice infringes another EU law, including EU acquis on data protection, privacy, or the confidentiality of communications, on non discrimination, consumer protection or on competition.",
        "title":"Amendment 327: Recital 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"573bfa01-bd4d-4014-8f96-d2fd68cd3e24",
        "text":"(3 a) The development of AI applications might bring down the costs and increase the volume of services available, e.g. health services, public transport, Farming 4.0, making them more affordable to a wider spectrum of society; that AI applications may also result in the rise of unemployment, pressure on social care systems, and an increase of poverty; in accordance with the values enshrined in Article 3 of the Treaty on European Union, there might be a need to adapt the Union AI transformation to socioeconomic capacities, to create adequate social shielding, support education and incentives to create alternative jobs; the establishment of a Union AI Adjustment Fund building upon the experience of The European Globalisation Adjustment Fund (EGF) or the currently developed Just Transition Fund should be considered;",
        "title":"Amendment 328: Recital 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"e0507c85-430d-49e6-8c06-08f535b47241",
        "text":"(3 a) The deployment of artificial intelligence is critical for European competitiveness and in particular for the success of small and medium-sized enterprises in industrial sectors. AI solutions can support European companies to optimise production processes, predict machinery failures and develop more efficient and smart services. The potential of AI can however only fully materialise if European industry, and in particular SMEs, are provided with a permissive legislative framework which avoids any overregulation that would funnel resources away from R&D towards unnecessary compliance costs.",
        "title":"Amendment 329: Recital 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Tomas Tobé, Arba Kokalari"
    },
    {
        "uuid":"711d6b7b-0345-4c71-a290-ec1dd4ce4d9a",
        "text":"(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.",
        "title":"Amendment 330: Recital 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f53a6c5f-8674-482d-84b6-d6e2ecccf174",
        "text":"(3 a) In order for Member States to reach the carbon neutrality targets, European companies should seek to utilise all available technological advancements that can assist in realising this goal. AI is a well-developed and ready-to-use technology that can be used to process the ever-growing amount of data created during industrial, environmental, health and other processes. To facilitate investments in AI-based analysis and optimisation solutions, this Regulation should provide a predictable and proportionate environment for low-risk industrial solutions.",
        "title":"Amendment 331: Recital 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1329cb0c-19c6-4e45-b37e-66838321a5ac",
        "text":"(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.",
        "title":"Amendment 332: Recital 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9adbf129-ded8-4ca4-83f3-ba38740fb7e0",
        "text":"(3 b) Furthermore, in order for Member States to fight against climate change, to achieve climate-neutrality and to meet the Sustainable Development Goals (SDGs), the European companies should ensure the sustainable design of AI systems to reduce resource usage and energy consumption, thereby limiting the risks to the environment; AI systems have the potential to automatically provide businesses with detailed insight into their emissions, including value chains, and forecast future emissions, thus helping to adjust and achieve the Union's emission targets.",
        "title":"Amendment 333: Recital 3 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a750e753-1b65-4b47-9e21-828d5b57e268",
        "text":"(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law, whether individual, societal, environmental, economic, or to the rule of law and democracy. Such harm might be material or immaterial. Harm should be understood as injury or damage to the life, health, physical integrity and the property of a natural or legal person, economic harm to individuals, damage to their environment, security and other aspects defined in the scope of New Approach directives, complemented by collective harms such as harm to society, the democratic process and the environment, or going against core ethical principles. Immaterial harms should be understood as meaning harm as a result of which the affected person suffers considerable detriment, an objective and demonstrable impairment of his or her personal interests and an economic loss calculated having regard, for example, to annual average figures of past revenues and other relevant circumstances. Such immaterial harm can therefore consist of psychological harm, reputational harm or change in legal status. Harm can be caused (i) by single events and (ii) through exposure over time to harmful algorithmic practices, as well as (iii) through action distributed among a number of actors where the entity causing the harm is not necessarily that which uses the AI or (iv) through uses of AI which are different than intended for the given system.",
        "title":"Amendment 334: Recital 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1333e54d-ca26-4af9-bf4b-904fcdd539c6",
        "text":"(4) At the same time, depending on the circumstances regarding its specific application and use, as well as the level of technological development, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial, including physical, psychological, societal or economic harm.",
        "title":"Amendment 335: Recital 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2585a212-2cd2-4d59-8eff-240aefdb81e9",
        "text":"(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial and might affect one or more persons, a groups of persons or society as a whole, as well as the environment.",
        "title":"Amendment 336: Recital 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1a73c6f7-c3ba-4754-9605-8a89e148d233",
        "text":"(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public and private interests and rights that are protected by Union law. Such harm might be material or immaterial.",
        "title":"Amendment 337: Recital 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"5662897b-3370-4fe6-9146-d47588f149d9",
        "text":"(4 a) In order to ensure the dual green and digital transition, and secure the technological resilience of the EU, to reduce the carbon footprint of artificial intelligence and achieve the objectives of the new European Green Deal, this Regulation should contribute to the promotion of a green and sustainable artificial intelligence and to the consideration of the environmental impact of AI systems throughout their lifecycle. Sustainability should be at the core at the European artificial intelligence framework to guarantee that the development of artificial intelligence is compatible with sustainable development of environmental resources for current and future generations, at all stages of the lifecycle of artificial intelligence products; sustainability of artificial intelligence should encompass sustainable data sources, data centres, resource use, power supplies and infrastructure;",
        "title":"Amendment 338: Recital 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"cac05bc9-3e80-4a61-b102-86c8e509e0a5",
        "text":"(4 a) AI available in the Union market or otherwise affecting people in the Union should be designed human centered, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights what requires a shift towards a Human Centered AI Engineering, also in research and education.",
        "title":"Amendment 339: Recital 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Bettina Vollath"
    },
    {
        "uuid":"51c96f79-782d-4009-9021-02f612522b7a",
        "text":"(4 a) The concept of decision autonomy for machines is at its core in conflict with fundamental notions of our societies, such as human dignity, autonomy, and the rights to private life and the protection of personal data. This Regulation should reconcile the potential benefits to society offered by AI with the primacy of humans over machines;",
        "title":"Amendment 340: Recital 4 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f6df38f5-ffe1-4230-8511-edb92fcdd393",
        "text":"(4 a) Given the major impact that artificial intelligence can have on society and the need to build trust, it is vital for artificial intelligence systems to respect the principles of fairness, accountability, transparency and accountability, privacy and security, and social benefit.",
        "title":"Amendment 341: Recital 4 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b2d4dab5-8beb-44c2-b3a3-ef36df53765c",
        "text":"(4 b) Despite the high potential of solutions to the environmental and climate crisis offered by artificial intelligence, the design, training and execution of algorithms imply a high energy consumption and, consequently, high levels of carbon emissions. Artificial intelligence technologies and data centres have a high carbon footprint due to increased computational energy consumption, and high energy costs due to the volume of data stored and the amount of heat, electric and electronic waste generated, thus resulting in increased pollution. These environmental and carbon footprints are expected to increase overtime as the volume of data transferred and stored and the increasing development of artificial intelligence applications will continue to grow exponentially in the years to come. It is therefore important to minimise the climate and environmental footprint of artificial intelligence and related technologies and that AI systems and associated machinery are designed sustainably to reduce resource usage and energy consumption, thereby limiting the risks to the environment.",
        "title":"Amendment 342: Recital 4 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"cca56cad-c03a-479a-923c-cfc808438e8a",
        "text":"(4 c) To promote the sustainable development of AI systems and in particular to prioritise the need for sustainable, energy efficient data centres, requirements for efficient heating and cooling of data centres should be consistent with the long-term climate and environmental standards and priorities of the Union and comply with the principle of 'do no significant harm' within the meaning of Article 17 of Regulation (EU) 2020\/852 on the establishment of a framework to facilitate sustainable investment, and should be fully decarbonised by January 2050. In this regard, Member States and telecommunications providers should collect and publish information relating to the energy performance and environmental footprint for artificial intelligence technologies and date centres including information on the energy efficiency of algorithms to establish a sustainability indicator for artificial intelligence technologies. A European code of conduct for datacentre energy efficiency can establish key sustainability indicators to measure four basic dimensions of a sustainable data centre, namely, how efficiently it uses energy, the proportion of energy generated from renewable energy sources, the reuse of any waste and heat, and the usage of fresh water.",
        "title":"Amendment 343: Recital 4 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e23aaa6f-a0a1-49c4-8497-e97a6027171e",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. These rules should be supportive to new innovative solutions and robust in protecting fundamental rights of all the actors. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council, and it ensures the protection of ethical principles, as specifically requested. One of the fundamental principles of this legislative framework is that there is no doubt between the protection of fundamental rights or the support of innovation, since this Regulation provides rules that adequately address both of mentioned priorities.",
        "title":"Amendment 344: Recital 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"d0d911ab-7ded-46b6-a142-d7aae4baf219",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety, the protection of fundamental rights, as recognised and protected by Union law, the environment and the Union values enshrined in Article 2 TEU. To achieve that objective, rules regulating the development, the placing on the market, and the putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 345: Recital 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e65f3ef4-70af-4947-b260-96e88f9c48e4",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. Furthermore, clear rules supporting the application and design of AI systems should be laid down, thus enabling a European ecosystem of public and private actors creating AI systems in line with European values. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 346: Recital 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"602851e4-934e-4139-9aa0-40dd6f9b7ca8",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time guarantees a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law as well as the environment, society, rule of law and democracy, economic interests and consumer protection. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 347: Recital 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7247a090-d9f6-4dee-a74a-7aff4ed87b97",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules as well as measures in support of innovation with a particular focus on SMEs and start-ups, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 348: Recital 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"ef62846b-5f45-4a3a-8146-4787990ddd68",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of promoting the \"AI made in Europe\" and being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 349: Recital 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"b6d21d63-9e52-41ed-928d-88cdd9509e8e",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as the protection of fundamental rights, health and safety, as recognised and protected by Union law. To achieve that objective, rules regulating the development, the placing on the market, putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 350: Recital 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"f7de9cca-0a94-4833-8eb2-27a823f7b82f",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and the environment and the protection of fundamental rights and values, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 351: Recital 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0d3eb50b-33f3-4c25-bc11-bc0f61a5db20",
        "text":"(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public and private interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) – Conclusions, EUCO 13\/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020\/2012(INL).",
        "title":"Amendment 352: Recital 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"31971fd7-1d45-4d80-9aec-bdfdd5395f98",
        "text":"(5 a) Furthermore, in order to foster the development of artificial intelligence in line with Union values, the Union needs to address the main gaps and barriers blocking the potential of the digital transformation including the shortage of digitally skilled workers, cybersecurity concerns, lack of investment and access to investment, and existing and potential gaps between large companies, SME’s and start-ups. Special attention should be paid to ensuring that the benefits of AI and innovation in new technologies are felt across all regions of the Union and that sufficient investment and resources are provided especially to those regions that may be lagging behind in some digital indicators.",
        "title":"Amendment 353: Recital 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1f9576a9-652b-4f65-b267-5a04d8ba2436",
        "text":"(5 a) The regulatory framework addressing artificial intelligence should be without prejudice to existing and future Union laws concerning data protection, privacy, and protection of fundamental rights. In this regard, requirements of this Regulation should be consistent with the aims and objectives of, among others, the GDPR and the EUDPR. Where this Regulation addresses automated processing within the context of article 22 of the GDPR, the requirements contained in that article should continue to apply, ensuring the highest levels of protection for European citizens over the use of their personal data.",
        "title":"Amendment 354: Recital 5 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"7c0b90ee-7312-4743-a84a-2e16ac855595",
        "text":"(5 a) The Union legal framework for AI should respect existing sector specific legislations and create legal certainty by avoiding duplication and additional administrative burden;",
        "title":"Amendment 355: Recital 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"a68dc331-a1e3-4951-b671-8d74b23322ab",
        "text":"(5 b) To ensure the development of secure, trustworthy and ethical AI, the European Commission established the High-Level Expert Group on Artificial Intelligence. In formulating both Ethics guidelines for Trustworthy AI and a corresponding Assessment List for Trustworthy Artificial Intelligence, this independent group solidified the foundational ambition for ‘Trustworthy AI’. As noted by the group, Trustworthiness is a prerequisite for people, societies and companies to develop, deploy and use AI systems. Without AI systems – and the human beings behind them – being demonstrably worthy of trust, serious and unwanted consequences may ensue and the uptake of AI might be hindered, preventing the realisation of the potentially vast social and economic benefits that trustworthy AI systems can bring. This approach should be seen as the basis of a European approach to both ensure and scale AI that is innovative and ethical.",
        "title":"Amendment 356: Recital 5 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ff20c5d7-0773-432b-b5e5-cd17d24c51ed",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. This definition should be in line with definitions that have found international acceptance. Moreover, it should be based on the key functional characteristics of artificial intelligence distinguishing it from more classic software systems and modelling approaches such as logistic regression and other techniques that are similarly transparent, explainable and interpretable. For the purposes of this Regulation, the definition should be based on the key functional characteristics of the AI system, in particular its ability, for a given set of human-defined objectives, to make predictions, recommendations, or decisions that influence real or virtual environments, whereby it uses machine and\/or human-based data and inputs to (i) perceive real and\/or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (e.g. with machine learning), or manually; and (iii) use model inference to formulate options for outcomes. AI systems are designed to operate with varying levels of autonomy and can be used on a stand-alone software system, integrated into a physical product (embedded), used to serve the functionality of a physical product without being integrated therein (non-embedded) or used as a subsystem of a software\/physical\/hybrid system of systems. If an AI system is used as a subsystem of a system of systems, then all parts including their interfaces to other parts of the system of systems that would be obsolete if the AI functionality were turned off or removed are essential parts of the AI system thus fall directly under this regulation. Any parts of the system of systems to which this does not hold true are not covered by this regulation and the obligations listed in this regulation do not apply to them. This is to ensure that the integration of AI systems into existing systems is not blocked by this regulation.",
        "title":"Amendment 357: Recital 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cc52ceab-674f-4cc7-8063-b6e19112f6bc",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. Therefore, the term AI system should be defined in line with internationally accepted definitions. The definition should be based on the key functional characteristics of AI systems, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence their physical or digital environment. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In order to ensure alignment of definitions on an international level, the European Commission should engage in a dialogue with international organisations such as the Organisation for Economic Cooperation and Development (OECD), should their definitions of the term ‘AI system’ be adjusted.",
        "title":"Amendment 358: Recital 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-"
    },
    {
        "uuid":"3002e583-899a-4bb5-a993-8419629a8bcd",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to perceive, reason and act on machine and\/or human-based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded).",
        "title":"Amendment 359: Recital 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"ca089cdb-5add-47f8-bc3e-d61c42950a3f",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). AI systems can be developed through various techniques using learning, reasoning or modelling, such as: machine learning approaches, including supervised, unsupervised and reinforcement learning, using a wide variety of methods including deep learning; logic- and knowledge-based approaches, including knowledge representation, inductive (logic) programming, knowledge bases, inference and deductive engines, (symbolic) reasoning and expert systems; statistical approaches, Bayesian estimation, search and optimization methods.",
        "title":"Amendment 360: Recital 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8535a8d0-e010-465b-961e-74f360ea1e9e",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of objectives or parameters which have human control at their origin, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. These delegated acts should consist only of additions to the list of techniques used.",
        "title":"Amendment 361: Recital 6  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"f97a0316-5c47-41df-bd8e-7634f4761a1f",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the system, in particular the ability, for a given set of objectives, to generate outputs such as content, predictions, recommendations, or decisions. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.",
        "title":"Amendment 362: Recital 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0231ffae-82e5-4ada-96c8-7d148709d149",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate existing harmless applications and future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.",
        "title":"Amendment 363: Recital 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"6fab6283-0c8d-4cb0-84a3-3d2362967e33",
        "text":"(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be aligned with internationally accepted approach. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. The Commission should engage in dialogue with key international organizations, so that the common international standards could be achieved to the highest possible extent.",
        "title":"Amendment 364: Recital 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"0161e0cd-18ff-4353-9a82-a6ebc8674b0f",
        "text":"(6 a) Defining AI systems is an ongoing process that should take into account the context in which AI operates, keep pace with societal developments in this field and not lose sight of the link between the ecosystem of excellence and the ecosystem of trust. The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to–date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In the drafting process of these delegated acts, the Commission shall insure the input of all relevant stakeholders including the technical experts and developers of AI systems. This consultation can take place through existing bodies such as the High Level Expert Group on AI or a newly established similar advisory body that is closely included in the work of the European Artificial Intelligence Board. Should the definition of ‘AI system’ from the OECD be adjusted in the coming years, the European Commission should engage in dialogue with these organisations to ensure alignment between the two definitions. Should the AI Act still be undergoing legislative procedure, the co-legislators should consider these latest developments during the legislative process, so as to ensure alignment, legal clarity and broad international acceptance of the AI Act Definition of ‘AI Systems’.",
        "title":"Amendment 365: Recital 6 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2188d9df-8836-4048-8569-4047175672c4",
        "text":"(6 b) Taking into account the work of International Standardisation Organisations, it is important to highlight the differences as well as the connection between Automation, Heteronomy and Autonomy. Experts speak of an automated system with different levels of automation instead of levels of autonomy. Autonomy is understood as the highest level of automation. An autonomous AI system would be capable to change its scope or its goals independently. However, today's AI technologies do not allow full autonomy yet and are not self-governing. Instead, they operate based on algorithms and otherwise obey the commands of operators. A fully autonomous AI system would be a genuine General or Super AI. Despite these restrictions, this Regulation will use the term “autonomy” as it is a key element of international accepted definitions.",
        "title":"Amendment 366: Recital 6 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8cd4133c-43c2-4c51-bb6b-ee10525fc45b",
        "text":"(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016\/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018\/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016\/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018\/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45\/2001 and Decision No 1247\/2002\/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016\/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008\/977\/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).",
        "title":"Amendment 367: Recital 7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"66e003c3-23f1-4d30-83fc-8f16ae00fd15",
        "text":"(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016\/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018\/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016\/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018\/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45\/2001 and Decision No 1247\/2002\/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016\/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008\/977\/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).",
        "title":"Amendment 368: Recital 7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1cca33ab-13b0-46b5-bb93-04dba3d87980",
        "text":"(7) The notion of biometric data used in this Regulation is the same as that defined in Article 4(14) of Regulation (EU) 2016\/679 of the European Parliament and of the Council35.' '35 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).",
        "title":"Amendment 369: Recital 7  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ec627e12-0cba-4f1d-8d6b-81ff5b406134",
        "text":"(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016\/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018\/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016\/680 of the European Parliament and of the Council37 . The notion of “biometrics-based data” is broader, covering situations where the data in question may not, of itself, confirm the unique identification of an individual.' '35 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018\/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45\/2001 and Decision No 1247\/2002\/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016\/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008\/977\/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).",
        "title":"Amendment 370: Recital 7  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"819acb48-74b9-4576-8a07-5e7956f19324",
        "text":"(8) The notion of biometric identification system as used in this Regulation should be defined functionally, as an AI system performing automated recognition of physical, physiological, behavioural, and psychological human features, for the purpose of identification of natural persons through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used.",
        "title":"Amendment 371: Recital 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0169f850-ea57-4942-bdfc-39a46cad1405",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used.",
        "title":"Amendment 372: Recital 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"b4a80010-6e5f-45c9-81c4-a1686300f15b",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Because remote biometric identification relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the remote biometric identification system, and is not de facto annulled by pre-enrolment.",
        "title":"Amendment 373: Recital 8  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Patrick Breyer"
    },
    {
        "uuid":"7fd7e6b0-e617-4d29-aa86-8a9b99294a26",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises.",
        "title":"Amendment 374: Recital 8  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"991d2a1a-aa67-4040-a63e-f6452dfea037",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include authentification and verification systems whose purpose is to confirm, based on prior consent, that a specific natural person is the person he or she claims to be or to confirm the identity of a natural person for the purpose of having access to a service, a device or premises.",
        "title":"Amendment 375: Recital 8  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0232822e-4be7-4629-ab03-d136d83bcaff",
        "text":"(8) The notion of biometric identification system, including remote biometric identification system as used in this Regulation, should be defined functionally, as an AI system intended for the identification of natural persons including at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification\/ authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.",
        "title":"Amendment 376: Recital 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"65bdc143-ebe7-4c56-8951-9ded1ea34906",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a database data repository, excluding verification\/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.",
        "title":"Amendment 377: Recital 8  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Eugen Jurzyca, Adam Bielan"
    },
    {
        "uuid":"2e4567d3-c8d4-4e2c-90c9-cb1e48317d1f",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used. The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online \/ virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.",
        "title":"Amendment 378: Recital 8  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e49aa875-d827-4c0a-88fd-e51dfe284435",
        "text":"(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.",
        "title":"Amendment 379: Recital 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"43c2708d-9cc1-45ff-96cb-481eed8e7fb6",
        "text":"(9) For the purposes of this Regulation the notion of publicly accessible physical or virtual space should be understood as referring to any physical or virtual place that is accessible to the public, on a temporary or permanent basis, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion covers places that are both private in nature, used for private purposes only, accessed completely voluntarily and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes and private clubs. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, sports grounds, virtual gaming environments, schools, universities, hospitals, amusement parks, festivals, shops and shopping centres, offices, warehouses and factories are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.",
        "title":"Amendment 380: Recital 9  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fb981ea7-4e2b-4870-822b-cdd062227a1c",
        "text":"(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. Online spaces are not covered either, as they are not physical spaces. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis by the competent judicial or administrative authority, having regard to the specificities of the individual situation at hand.",
        "title":"Amendment 381: Recital 9  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"282bf1a0-91c7-48b8-b742-ac928bbf3326",
        "text":"(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.",
        "title":"Amendment 382: Recital 9  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e8587635-e85c-42d4-b798-f90be7d48a5f",
        "text":"(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.",
        "title":"Amendment 383: Recital 9  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"88f1ccfc-e57e-4116-b3ed-22ee5f4a6074",
        "text":"(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to online and public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.",
        "title":"Amendment 384: Recital 9  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"492417f8-cb86-4f10-82e8-55f467c93e5c",
        "text":"(9 a) In order to ensure the rights of individuals and groups, and the growth of trustworthy AI, certain principles should be guaranteed across all AI systems, such as transparency, the right to an explanation and the right to object to a decision. This requires that discrimination, and detrimental power and information imbalances be prevented, control and oversight guaranteed, and that compliance is demonstrable and subject to ongoing monitoring. Decision-making by, or supported by, AI systems, should be subject to specific transparency rules, as regards the logic and parameters on which decisions are made.",
        "title":"Amendment 385: Recital 9 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"040a9b3d-2424-462c-98cc-d3ca7e7ad5eb",
        "text":"(9 b) Requirements on transparency and on the explicability of AI decision-making should contribute to countering the deterrent effects of digital asymmetry, power and information imbalance, and so-called ‘dark patterns’ targeting individuals and their informed consent.",
        "title":"Amendment 386: Recital 9 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"df476d37-ca0e-4110-abd2-89c850508094",
        "text":"(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to deployers of AI systems established within the Union. This Regulation and the rules it establishes should take into account different development and business models and the fact that standard implementations, or Free and Open Source software development and licensing models might entail less knowledge about and little to no control over further use, modification, and deployment within an AI system.",
        "title":"Amendment 387: Recital 10  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f4a921a6-37eb-4dc1-ad4b-5e6f7cd4482a",
        "text":"(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union and on international level, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to users of AI systems established within the Union.",
        "title":"Amendment 388: Recital 10  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"7d269464-990f-478e-84e9-30fd9013d660",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.",
        "title":"Amendment 389: Recital 11  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"fd110921-9477-41e1-bd25-fade0be3f932",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.",
        "title":"Amendment 390: Recital 11  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"81e831bd-f269-4b5e-9a16-a713b3c20187",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or it affects natural persons within the Union.",
        "title":"Amendment 391: Recital 11  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b3b91aa4-ba30-450d-9425-deba993dbda9",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and deployers of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or affects people in the Union.",
        "title":"Amendment 392: Recital 11  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ef27f9aa-ede8-4527-9186-1f2510a8f4a8",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union. Nonetheless, to take into account existing arrangements and special needs for cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations. This exception should nevertheless be limited to trusted countries and international organizations that share the Union’s values.",
        "title":"Amendment 393: Recital 11  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"72754946-8a79-4c9b-8c96-9a0cc30505b0",
        "text":"(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is intended for use in the Union. Nonetheless, to take into account existing arrangements and special needs for future cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations.",
        "title":"Amendment 394: Recital 11  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4fb5d219-8091-4d3e-b4a8-0f45be06e07f",
        "text":"(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000\/31\/EC of the European Parliament and of the Council [as amended by the Digital Services Act].",
        "title":"Amendment 395: Recital 12  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"03988454-1de0-4313-8053-523be6a98b21",
        "text":"(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000\/31\/EC of the European Parliament and of the Council [as amended by the Digital Services Act].",
        "title":"Amendment 396: Recital 12  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst"
    },
    {
        "uuid":"31ed0022-6861-43e7-877f-752e5e7f88fb",
        "text":"(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or deployer of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000\/31\/EC of the European Parliament and of the Council [as amended by the Digital Services Act].",
        "title":"Amendment 397: Recital 12  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"179c181a-d759-40bd-8c56-766f018dd999",
        "text":"(12) This Regulation should also apply to the institutions, bodies, offices and agencies of the Union. AI systems exclusively developed or used for military purposes should be excluded from the scope of this Regulation. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000\/31\/EC of the European Parliament and of the Council [as amended by the Digital Services Act].",
        "title":"Amendment 398: Recital 12  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"9fb9409f-f6cf-4030-a782-6e2506883080",
        "text":"(12 a) This Regulation should not undermine research and development activity and should respect freedom of science. It is therefore necessary to exclude from its scope AI systems specifically developed and put into service for the sole purpose of scientific research and development and to ensure that the Regulation does not otherwise affect scientific research and development activity on AI systems. As regards product oriented research activity by providers, the provisions of this Regulation should apply insofar as such research leads to or entails placing of an AI system on the market or putting it into service. Under all circumstances, any research and development activity should be carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 399: Recital 12 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"2761567c-5d35-4d79-afac-24b2d5a222ef",
        "text":"(12 a) This Regulation should also ensure harmonisation and consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.",
        "title":"Amendment 400: Recital 12 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"8de950ed-cf2d-47e4-a0d1-d439cba3b556",
        "text":"(12 a) This Regulation should also ensure harmonisation consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.",
        "title":"Amendment 401: Recital 12 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"23f14a47-ab35-4bd0-ad62-b86c69799ead",
        "text":"(12 a) AI systems developed or used exclusively for military purposes should be excluded from the scope of this Regulation where that use falls under the exclusive remit of the Common Foreign and Security Policy regulated under Title V TEU. However, AI systems which are developed or used for military purposes but can also be used for civil purposes, falling under the definition of “dual use items” pursuant to Regulation (EU) 2021\/821 of the European Parliament and of the Council1ashould fall into the scope of this Regulation.' '1a Regulation (EU) 2021\/821 of the European Parliament and of the Council of 20 May 2021 setting up a Union regime for the control of exports, brokering, technical assistance, transit and transfer of dual-use items (OJ L 206 11.6.2021, p. 1).",
        "title":"Amendment 402: Recital 12 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e154343d-0dd2-4f0b-82e2-40603f3a8469",
        "text":"(12 a) In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document parameters including but not limited to resource consumption, resulting from the design, data management and training, the underlying infrastructures of the AI system, and of the methods to reduce such impact for any AI system.",
        "title":"Amendment 403: Recital 12 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"417495a9-a0dd-4525-9c8f-4358caf49c13",
        "text":"(12 b) Given the complexity of the value chain for AI systems, it is essential to clarify the role of persons who may contribute to the development of AI systems covered by this Regulation, without being providers and thus being obliged to comply with the obligations and requirements established herein. It is necessary to clarify that general purpose AI systems - understood as AI systems that are able to perform generally applicable functions such as image\/speech recognition, audio\/video generation, pattern detection, question answering, translation etc. - should not be considered as having an intended purpose within the meaning of this Regulation, unless those systems have been adapted to a specific intended purpose that falls within the scope of this Regulation. Initial providers of general purpose AI systems should therefore only have to comply with the provisions on accuracy, robustness and cybersecurity as laid down in Art. 15 of this Regulation. If a person adapts a general purpose AI application to a specific intended purpose and places it on the market or puts it into service, it shall be considered the provider and be subject to the obligations laid down in this Regulation. The initial provider of a general purpose AI application shall, after placing it on the market or putting it to service, and without compromising its own intellectual property rights or trade secrets, provide the new provider with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.",
        "title":"Amendment 404: Recital 12 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"60cf8b8e-2a49-4e02-8da8-033c83324cb0",
        "text":"(12 b) This Regulation should not affect the provisions aimed at improving working conditions in platform work set out in Directive 2021\/762\/EC.",
        "title":"Amendment 405: Recital 12 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"59a762aa-1380-440a-ab87-a123bfd774da",
        "text":"(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments. In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document (i) parameters including, but not limited to, resource consumption resulting from the design, data management, training and from the underlying infrastructures of the AI system; as well as (ii) the methods to reduce such impact.",
        "title":"Amendment 406: Recital 13  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f3edbd4b-1045-4215-8c40-cf7c6adec3f5",
        "text":"(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, the environment and fundamental rights, and values, common normative standards for AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter), the European Green Deal (The Green Deal), the Joint Declaration on Digital Rights of the Union (the Declaration) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High-Level Expert Group on Artificial Intelligence (AI HLEG), and should be non-discriminatory and in line with the Union’s international commitments.",
        "title":"Amendment 407: Recital 13  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"aa1a055f-aba2-4fed-9e3c-c93e09af28fe",
        "text":"(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of Fundamental Rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.",
        "title":"Amendment 408: Recital 13  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1e604a1d-be79-49e7-acc2-3d38cf829f8a",
        "text":"(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, the environment and the Union values enshrined in Article 2 TEU, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.",
        "title":"Amendment 409: Recital 13  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9a5753ef-9891-40df-b7fa-869cd1aa35d8",
        "text":"(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, minimum common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international commitments.",
        "title":"Amendment 410: Recital 13  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"54e9bf0b-edfd-40cb-8cd7-6826150ee52f",
        "text":"(13 a) AI systems and related ICT technology require significant natural resources, contribute to waste production, and have a significant overall impact on the environment. It is appropriate to design and develop in particular high-risk AI systems with methods and capabilities that measure, record, and reduce resource use and waste production, as well as energy use, and that increase their overall efficiency throughout their entire lifecycle. The Commission, the Member States and the European AI Board should contribute to these efforts by issuing guidelines and providing support to providers and deployers.",
        "title":"Amendment 411: Recital 13 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6a6f6b4c-e4a1-4c19-b2db-8988faea17a4",
        "text":"(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems. It is also necessary to establish the criteria and conditions which determinine the category to which an AI system belongs.",
        "title":"Amendment 412: Recital 14  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"ec895a9a-d30f-4325-90ec-e0af0e6b13de",
        "text":"(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate for individuals and society, rather than depend on the type of technology. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.",
        "title":"Amendment 413: Recital 14  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"d1c20f5b-2733-406d-8ae2-475ba08d4f27",
        "text":"(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.",
        "title":"Amendment 414: Recital 14  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"5486f4f1-3b4e-4e57-87a1-4799c6954197",
        "text":"(15) AI systems can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict Union values of respect for human dignity, freedom, equality, democracy and the rule of law and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child. All uses of AI systems which interfere with the essence of the fundamental rights of individuals should in any case be prohibited. The prohibitions listed in this Regulation should apply notwithstanding existing Union law and do not provide a new legal basis for the development placing on the market, deployment or use of AI systems. To keep up with rapid technological development and to ensure future-proof regulation, the Commission should keep the list of prohibited and high-risk AI systems under constant review.",
        "title":"Amendment 415: Recital 15  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0710f082-bde7-40ca-a747-67be50c44f49",
        "text":"(15) Aside from the many beneficial uses of artificial intelligence, that technology can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict the values of respect for human dignity, freedom, equality, democracy and the rule of law, which are protected values under EU law, and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child.",
        "title":"Amendment 416: Recital 15  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"1d08ce5d-5d1b-4390-95af-8b3487712313",
        "text":"(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality, to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems, and to ensure respect for privacy of persons with disabilities. Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019\/882.",
        "title":"Amendment 417: Recital 15 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"13dd4ef0-1671-4f01-bde3-cd4efb62f4df",
        "text":"(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).",
        "title":"Amendment 418: Recital 15 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ec0c1433-e8c2-4235-89fb-f99f7e4c6a16",
        "text":"(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).",
        "title":"Amendment 419: Recital 15 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4cf55344-abf6-4761-a914-e97b3cb6e21a",
        "text":"(15 a) The European Union and its Member States as signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD) are obliged to protect persons with disabilities from discrimination and to promote their equality. They are obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and to ensure respect for the fundamental rights, including that of privacy, of persons with disabilities.",
        "title":"Amendment 420: Recital 15 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia"
    },
    {
        "uuid":"f0388ced-28e8-4241-8550-3f0d0c371a4c",
        "text":"(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (UNCRPD), the European Union and all Member States should protect persons with disabilities from discrimination and promote their equality, ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and ensure respect for privacy of persons with disabilities.",
        "title":"Amendment 421: Recital 15 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"26b578ff-9b54-445d-ab5a-0307dbd2ff07",
        "text":"(15 b) Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019\/882. Union law should be further developed, including through this Regulation, so that no one is left behind as result of digital innovation.",
        "title":"Amendment 422: Recital 15 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"65306e5d-df6e-41a5-98a8-4f25afd0f4b0",
        "text":"(15 b) Providers of AI systems should ensure that these systems are designed in accordance with the accessibility requirements set out in Directive (EU) 2019\/882 and guarantee full, equal, and unrestricted access for everyone potentially affected by or using AI systems, including persons with disabilities.",
        "title":"Amendment 423: Recital 15 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia"
    },
    {
        "uuid":"59176f22-1fbd-4dc9-8963-be670b08df07",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems materially distorting human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components that persons cannot perceive or those systems otherwise exploit vulnerabilities of a specific group of persons due to their age, disability within the meaning of Directive (EU) 2019\/882, or social or economic situation. Such systems can be placed on the market, put into service or used with the objective to or the effect of materially distorting the behaviour of a person and in a manner that causes or is reasonably likely to cause physical or psychological harm to that or another person or groups of persons, including harms that may be accumulated over time. The intention to distort the behaviour may not be presumed if the distortion results from factors external to the AI system which are outside of the control of the provider or the user meaning factors that may not be reasonably foreseen and mitigated by the provider or the user of the AI system. In any case, it is not necessary for the provider or the user to have the intention to cause the physical or psychological harm, as long as such harm results from the manipulative or exploitative AI-enabled practices. The prohibitions for such AI practices is complementary to the provisions contained in Directive [Unfair Commercial Practice Directive 2005\/29\/EC, as amended by Directive (EU) 2019\/216], notably that unfair commercial practices leading to economic or financial harms to consumers are prohibited under all circumstances, irrespective of whether they are put in place through AI systems or otherwise.",
        "title":"Amendment 424: Recital 16  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e52c27bc-3c76-4d7d-80c7-9d95ec7d3304",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby physical, economic or psychological harms to individuals or society are likely to occur, should be forbidden. This includes AI systems that deploy subliminal components that individuals may not be able to perceive or understand, or exploit vulnerabilities of individuals. They materially distort the behaviour of a person, including in a manner that causes or is likely to cause physical, psychological or economic harm to that or another person, or to society, or lead them to make decisions they would not otherwise have taken. Manipulation may not be presumed if the distortion of human behaviour clearly results from factors external to the AI system which are outside of the control of the provider or the user and are not reasonably foreseeable at or during the deployment of the AI system. Research for legitimate purposes in relation to such AI systems should not be unduly limited by the prohibition, if such research does not amount to use of the AI system in non-supervised human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research. If necessary, further flexibilities in order to foster research, and thereby European innovation capacities, should be introduced by Member States under controlled circumstances only and with all relevant safeguards to protect health and safety, fundamental rights, environment, society, rule of law and democracy.",
        "title":"Amendment 425: Recital 16  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1e486d62-3e9b-495b-8ac9-052cae7137dc",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of people such as children or people who are vulnerable due to their age, physical or mental incapacities, or other traits. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations with uninformed or non-consenting third parties that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 426: Recital 16  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"621d955e-222f-4f75-90d9-547130bd81ee",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby material or non-material harm, including physical, psychological or economic harms are likely to occur, should be forbidden. This limitation should be understood to include neuro-technologies assisted by AI systems that are used to monitor, use, or influence neural data gathered through brain-computer interfaces. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the effect of materially distorting the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 427: Recital 16  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"c697cf0d-855e-4dd8-b43a-82e64a207cc4",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. In particular, AI systems that deploy subliminal components that natural persons cannot perceive, that exploit the vulnerabilities of any groups,or that use purposefully manipulative techniques with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person or to their rights or to the values of the Union should be prohibited. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 428: Recital 16  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"9a4c1444-4f5a-41fa-a70e-99d53620986f",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive, access brain or brain-generated data without consent, or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 429: Recital 16  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Maria-Manuel Leitão-Marques, Eva Kaili"
    },
    {
        "uuid":"16a24a5a-9ec7-48a7-ae03-0bf3d88c420d",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems with the objective to or the effect of distorting human behaviour, whereby physical or psychological harms are reasonably likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of specific groups of persons due to their age, disabilities, social or economic situation. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 430: Recital 16  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Abir Al-Sahlani, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"208745e0-2810-4706-a573-4382d1bee896",
        "text":"(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby with due diligence it could be predicted that physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",
        "title":"Amendment 431: Recital 16  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"c4eb822a-6b17-4106-b686-682eac6eb002",
        "text":"(17) AI systems providing social scoring of natural persons are, by definition, discriminatory. They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems leads to the detrimental or unfavourable treatment of natural persons or whole groups. Such AI systems should be therefore prohibited.",
        "title":"Amendment 432: Recital 17  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"659c859b-ba28-4380-9476-d5811dde81d9",
        "text":"(17) AI systems providing social scoring of natural persons for general purpose by private or public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. Such AI systems should be therefore prohibited.",
        "title":"Amendment 433: Recital 17  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"83a6316f-cd26-4e4c-8d83-141be98c9114",
        "text":"(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics using trustworthiness, good citizenship, patriotism, deviancy, or any other such metric as a proxi. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. This detrimental treatment can also be effected by providing undue and unjustified privileges to groups of people based on their social score. Such AI systems should be therefore prohibited.",
        "title":"Amendment 434: Recital 17  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c19a7820-37bf-4b61-bf86-2d53243f0f0b",
        "text":"(17) AI systems that evaluate, classify, rate or score the trustworthiness or social standing of natural persons may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness or social standing of natural persons based on multiple data points related to their social behaviour in multiple contexts or known, inferred or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.",
        "title":"Amendment 435: Recital 17  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4c70ef5e-8f10-4a67-bbdc-d42e40feb117",
        "text":"(17) AI systems providing social scoring of natural persons for general purpose may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.",
        "title":"Amendment 436: Recital 17  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"5a894496-b612-40ea-98f3-edb7c940b0c9",
        "text":"(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.",
        "title":"Amendment 437: Recital 17  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"48f89dfc-eae7-461a-a487-d4b35d6e348c",
        "text":"(17 a) The placing on the market, putting into service or use of certain AI systems that can be used or foreseeably misused for intrusive monitoring and flagging to identify or deter rule-breaking or fraud should be forbidden. The use of such intrusive monitoring and flagging in a relationship of power, such as the use of e-proctoring software by education institutions to monitor students and pupils, or the use of surveillance- or monitoring software by employers on workers poses an unacceptable risk to the fundamental rights of workers, students and pupils, including minors. Notably, these practices affect the right to private life, data protection and human dignity of students and pupils, including minors.",
        "title":"Amendment 438: Recital 17 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f8d0c50f-20f8-4098-b590-7dc061895c5b",
        "text":"(17 a) AI systems that are intended for use to protect consumers and prevent fraudulent activities should not necessarily be considered high-risk under this Regulation. As set by Article 94 of the Directive (EU) 2015\/2366, payment systems and payment service providers should be allowed to process data to safeguard the prevention, investigation and detection of payment fraud. Therefore AI systems used to process data to safeguard the prevention, investigation and detection of fraud may not be considered as high-risk AI systems for the purpose of this Regulation.",
        "title":"Amendment 439: Recital 17 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a1d866ea-8b30-46b3-a2c5-e4d224c9cc01",
        "text":"(17 a) AI systems used by law enforcement authorities or on their behalf to make predictions, profiles or risk assessments based on data analysis or profiling of natural groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour, hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.",
        "title":"Amendment 440: Recital 17 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4440a5ab-d495-4f42-b364-5148edc5b22a",
        "text":"(17 a) AI systems used in law enforcement and criminal justice contexts based on predictive methods, profiling and risk assessment pose an unacceptable risk to fundamental rights and in particular to the right of non-discrimination, insofar as they contradict the fundamental right to be presumed innocent and are reflective of historical, systemic, institutional and societal discrimination and other discriminatory practices. These AI systems should therefore be prohibited;",
        "title":"Amendment 441: Recital 17 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"27cf0da2-d63c-4096-8e0a-1ec17fd932a7",
        "text":"(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual or place-based risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.",
        "title":"Amendment 442: Recital 17 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6a384c98-a51e-4e85-96cb-9d7ada3faf35",
        "text":"(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.",
        "title":"Amendment 443: Recital 17 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"c901ee8a-bf82-4967-8d09-aeb43b6dbdf4",
        "text":"(17 b) Insofar as such systems could ever function as intended, AI-based emotion recognition systems carry unacceptable risk for the essence of fundamental rights, such as human dignity and freedom of expression and must be prohibited. Exceptions for therapeutic tools or assistive technologies for personal use only could, nonetheless, be envisaged. However, this should only be permitted if the scientific basis and clinical validity of such systems have been demonstrated, where it can be shown that affected groups were active participants in the development process, and where the rights of everyone that is likely to be affected by the system, and not just the deployer , are clearly respected. Such systems should always be subject to careful oversight and transparency.",
        "title":"Amendment 444: Recital 17 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2cafe001-4666-4401-9b0d-7ed87ff41af5",
        "text":"(17 c) Similarly, ostensible truth-detection technologies, such as polygraphs, have a long and unsuccessful history of abuse, misselling, miscarriages of justice and failure. The problems underlying these failures are exacerbated in the field of migration, which thusfar has been tarnished by new failings due to, inter alia to incorrect cultural assumptions. Such technologies therefore cannot be used while protecting the essence of all relevant fundamental rights.",
        "title":"Amendment 445: Recital 17 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"40cc3f63-19a9-42ed-a81e-5f767df21aef",
        "text":"deleted",
        "title":"Amendment 446: Recital 18  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"b52de24f-9834-409a-96cf-134347dd960a",
        "text":"(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces, as well as online spaces, for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. In addition, whether such systems are used in 'real-time' or post factum, there is little difference on the impact and the heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The placing or making available on the market, the putting into service or use of those systems should therefore be prohibited.",
        "title":"Amendment 447: Recital 18  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6a8ba636-61b7-4ee7-99ad-b31edcef4788",
        "text":"(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces is particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Such systems should therefore be prohibited.",
        "title":"Amendment 448: Recital 18  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"4b2694e5-b0f4-4fe9-94b0-30d0dc60b9a8",
        "text":"(18) The use of AI systems for biometric identification of natural persons in publicly accessible spaces is particularly corrosive to the rights and freedoms of the concerned persons and can ultimately affect the private life of a large part of the population, leave society with a justifiable feeling of constant surveillance, give parties deploying biometric identification in publicly accessible spaces a position of uncontrollable power and indirectly dissuade individuals from the exercise of their freedom of assembly and other fundamental rights the core to the Rule of Law. Biometric identification not carried out in real time carries different but equally problematic risks. Due to the increase in pervasiveness, functionality and memory capacities of relevant devices, this would amount to a \"surveillance time machine\", which could be used to track movements and social interactions stretching back an indeterminate period into the past.",
        "title":"Amendment 449: Recital 18  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"52cdc889-0662-45b7-bd8f-b0af8ceaa9ee",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.",
        "title":"Amendment 450: Recital 18  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und Hohenstein, Vlad-Marius Botoş, Samira Rafaela, Monica Semedo, Salima Yenbou, Sophia in t Veld, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"4ca28b87-7123-4eff-a79e-d42d6b6101ec",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.",
        "title":"Amendment 451: Recital 18  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"670544fb-a7fd-4740-a606-d4c0400dc8a8",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. Such AI systems should be therefore prohibited.",
        "title":"Amendment 452: Recital 18  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9c8f78c7-7a31-457b-b9bb-fd90b7d6fdb3",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.",
        "title":"Amendment 453: Recital 18  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a80731ac-c4b7-40c3-9b63-b97b4120a355",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.",
        "title":"Amendment 454: Recital 18  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"9dfd5264-9d67-4a8e-ad7d-71925679b55c",
        "text":"(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it affects the private life of a large part of the population, constitutes constant surveillance and indirectly dissuades the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.",
        "title":"Amendment 455: Recital 18  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"aaa2a85f-939a-4856-b098-d57b97138ea4",
        "text":"(18 a) Despite progress regarding biometric identification technologies, the accuracy of the results still varies across technologies and depends on contextual factors. Even the relatively well-established fingerprint identification applications face challenges, in particular at the stage of the collection of biometric data (related to, for example, subject's age). The reliability of face recognition technologies in 'real world' settings is highly dependent on the quality of the images captured and on the quality of the algorithms used for biometric matching. During enrolment, poor quality images taken at e-gates or through a CCTV camera under variable environmental conditions may result in less accurate results. As in the case of automated fingerprint identification, changes in a person's physical characteristics over time may also affect the accuracy of facial recognition technologies. Research has found a considerable degradation in performance for face recognition algorithms on children as compared to the performance obtained on adults. In light of this, the placing or making available on the market, the putting into service or use of remote biometric identification systems should be prohibited.",
        "title":"Amendment 456: Recital 18 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0c9e0031-f687-4cde-b224-379635f0cace",
        "text":"(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online \/ virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.",
        "title":"Amendment 457: Recital 18 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"12901ee5-afa2-42f6-954c-4a8d06794dbd",
        "text":"(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scanmultiple persons in its field of view (or the equivalent generalised scanning of online \/ virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not defacto annulled by pre-enrollment.",
        "title":"Amendment 458: Recital 18 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"de677e0b-3692-4ccb-a235-45fe739bb60e",
        "text":"(18 a) The use of data collected or generated by practices prohibited under this Regulation should also be prohibited. Within the framework of judicial and administrative proceedings, the responsible authorities should establish that data collected or generated by practices prohibited under this regulation should not be admissible.",
        "title":"Amendment 459: Recital 18 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b16ba50c-d8a5-4e5c-bbfe-55ac65e40ce4",
        "text":"(18 b) There are serious concerns about the scientific basis of AI systems aiming to detect emotions from facial expressions. Facial expressions and perceptions thereof vary considerably across cultures and situations, and even within a single person. Among the key shortcomings of such technologies are the limited reliability (emotion categories are neither reliably expressed through, nor unequivocally associated with, a common set of facial movements), the lack of specificity (facial expressions do not perfectly match emotion categories) and the limited generalisability (the effects of context and culture are not sufficiently considered). Reliability issues may also arise when deploying the system in real-life situations, for example, when dealing with subjects who actively seek (and train themselves) to fool the system. Therefore, the placing on the market, putting into service, or use of AI systems intended to be used as polygraphs and similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person, should be prohibited.",
        "title":"Amendment 460: Recital 18 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b4f71929-038d-4c49-94f5-dd30e9794e02",
        "text":"(18 b) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male\/female, suspicious\/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).",
        "title":"Amendment 461: Recital 18 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5536c520-db07-4282-b2b0-6d2f86540772",
        "text":"deleted",
        "title":"Amendment 462: Recital 19  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"511d6ea8-e272-4f77-851f-d50af6d038be",
        "text":"deleted",
        "title":"Amendment 463: Recital 19  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0d3be7d1-5288-4013-80dd-adc6f0edf6ed",
        "text":"deleted",
        "title":"Amendment 464: Recital 19  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"8619888a-cf3a-4f5b-af17-c609a47abc33",
        "text":"deleted",
        "title":"Amendment 465: Recital 19  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"a78794cf-02a7-41b4-8c69-f931e5b2dd35",
        "text":"deleted",
        "title":"Amendment 466: Recital 19  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"7d84e501-5ef4-4cc6-b595-b0f9fd1fea55",
        "text":"deleted",
        "title":"Amendment 467: Recital 19  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"618eb957-00b7-454c-bcd8-63a5bd31e905",
        "text":"(19) The use of those systems for the purpose of law enforcement must therefore be prohibited, with the exception of border control and in the context of the fight against terrorism.",
        "title":"Amendment 468: Recital 19  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"b9b9fb72-e420-490d-b1a6-5cdb96e50c5d",
        "text":"(19) The use of those systems for the purpose of law enforcement should therefore be prohibited.",
        "title":"Amendment 469: Recital 19  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bdfeb1aa-ccc1-4d03-b7b6-b2acb8b761bd",
        "text":"(19) The use of AI systems for remote biometric identification of individuals should therefore be prohibited",
        "title":"Amendment 470: Recital 19  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"b2024215-0262-47b5-b7cd-9c1a145f9af5",
        "text":"(19) The use of those systems for the purpose of law enforcement should therefore be prohibited, except in three exhaustively listed and narrowly defined situations, where the use is ad hoc and strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for potential victims of crime, including missing children; certain threats to the life or physical safety of natural persons or of a terrorist attack; and the detection, localisation, identification or prosecution of perpetrators or suspects of criminal offences if they are punishable by a custodial sentence or a detention order for a maximum period of at least ten years in the Member State concerned. Such threshold for the custodial sentence or detention order in accordance with national law contributes to ensure that the offence should be serious enough to potentially justify the use of ‘real-time’ remote biometric identification systems. The nature of the offences deemed sufficiently serious to justify a penalty up to this threshold is a matter for the national legislation of each Member State in accordance with its own criminal law.",
        "title":"Amendment 471: Recital 19  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"c5bce109-bce1-41ff-9884-4ecc9b8aae4b",
        "text":"deleted",
        "title":"Amendment 472: Recital 20  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"00e70f23-581c-4980-a0a3-d53e37fa32dc",
        "text":"deleted",
        "title":"Amendment 473: Recital 20  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b803ccbe-7fa8-43f0-98ae-f1dc7ff56c11",
        "text":"deleted",
        "title":"Amendment 474: Recital 20  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"284d614c-e8e2-44ab-9967-ef595bc89a09",
        "text":"deleted",
        "title":"Amendment 475: Recital 20  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"120dee10-28ae-4680-839f-7f183813aa78",
        "text":"deleted",
        "title":"Amendment 476: Recital 20  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"1f0a21af-4c85-42d3-bf7d-473929feba10",
        "text":"deleted",
        "title":"Amendment 477: Recital 20  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"f2fd8775-f756-4055-80ed-e734fca9de64",
        "text":"deleted",
        "title":"Amendment 478: Recital 20  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"a9d02be3-d166-4a43-b02c-8addbd93e736",
        "text":"(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use.",
        "title":"Amendment 479: Recital 20  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"161fe94d-5200-4038-90ff-59ef23750338",
        "text":"(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each of those three exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use. In addition, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement should be subject to appropriate limits in time and space, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The reference database of persons should be appropriate for each use case in each of the three situations mentioned above.",
        "title":"Amendment 480: Recital 20  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"97e81cd2-dead-4c29-a256-51a2494b8383",
        "text":"deleted",
        "title":"Amendment 481: Recital 21  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"215e1c67-385d-4d94-8bea-4a8565420e52",
        "text":"deleted",
        "title":"Amendment 482: Recital 21  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e94ed2b5-4687-4469-9856-7fc096e41d11",
        "text":"deleted",
        "title":"Amendment 483: Recital 21  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"883a0eb8-c9d7-4a51-a479-d4a4480a72e4",
        "text":"deleted",
        "title":"Amendment 484: Recital 21  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"bf20b49a-564a-4c77-8438-5f07d0474d57",
        "text":"deleted",
        "title":"Amendment 485: Recital 21  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"59577729-8371-44fa-9f9b-d224eb802833",
        "text":"deleted",
        "title":"Amendment 486: Recital 21  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"e2e8bcab-09f0-47ee-ba18-96069d29b98a",
        "text":"deleted",
        "title":"Amendment 487: Recital 21  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"89f3441d-30a0-4701-9022-533a9507a014",
        "text":"(21) Each use of a ‘real-time’ remote biometric identification system in publicly accessible or online spaces for the purpose of law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.",
        "title":"Amendment 488: Recital 21  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d0abf9d3-cf8c-4a93-b175-e2d0729a8f7e",
        "text":"(21) Use of a ‘real-time’ remote biometric identification system in publicly accessible spaces for the purpose of law enforcement should be subject to authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.",
        "title":"Amendment 489: Recital 21  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"8b6f8f61-3437-41b0-8824-3bb030f5233d",
        "text":"deleted",
        "title":"Amendment 490: Recital 22  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"16652477-49d3-4b82-ab87-df960819a46e",
        "text":"deleted",
        "title":"Amendment 491: Recital 22  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"8f53f6bc-b33d-4cf9-91a7-4e3d15d00581",
        "text":"deleted",
        "title":"Amendment 492: Recital 22  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"957d87b2-bd15-419c-9721-b127b55c5dcb",
        "text":"deleted",
        "title":"Amendment 493: Recital 22  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c08d04fd-1eb0-43fd-928a-e7c137019044",
        "text":"deleted",
        "title":"Amendment 494: Recital 22  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"6bf6d162-999e-4503-8137-24d4d12703dd",
        "text":"deleted",
        "title":"Amendment 495: Recital 22  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"15ee3671-27ab-4032-bd1e-109f9a4564df",
        "text":"(22) Furthermore, it is appropriate to provide that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State in question has decided to expressly provide for the possibility to authorise such use in its detailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide limited possibilities in this regard.",
        "title":"Amendment 496: Recital 22  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"2ec768d1-0673-4a63-a5e5-e559901627d7",
        "text":"deleted",
        "title":"Amendment 497: Recital 23  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"5400046d-1b33-4dc7-8a53-3f39f50f214f",
        "text":"deleted",
        "title":"Amendment 498: Recital 23  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"610b31ce-ffd8-4a6a-bc6c-6f50fcd8d783",
        "text":"deleted",
        "title":"Amendment 499: Recital 23  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0566d250-cef4-488e-8e2f-6f01e59379a4",
        "text":"deleted",
        "title":"Amendment 500: Recital 23  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"84cab0f5-ef3b-4d32-b929-1335c7091e2d",
        "text":"deleted",
        "title":"Amendment 501: Recital 23  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"269f2a5c-2910-4c74-bed3-258d604b3c32",
        "text":"(23) The use of AI systems for biometric identification of natural persons in publicly accessible spaces necessarily involves the processing of biometric and biometrics-based data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016\/680 and Article 9 of Regulation 2016\/679, thus regulating such use and the processing of biometric data involved in an exhaustive manner.",
        "title":"Amendment 502: Recital 23  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"a6578691-6672-49c3-a72a-01fdec51aef1",
        "text":"(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016\/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it. The lex specialis nature of the prohibition on RBI does not provide a legal basis for law enforcement uses of RBI, nor does it weaken existing protections of biometric data under the Data Protection Law Enforcement Directive (LED) or national implementations of the LED.",
        "title":"Amendment 503: Recital 23  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"81501518-3c71-4e1d-a86a-f13e5a9c24b8",
        "text":"(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement necessarily involves the processing of biometric data. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016\/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016\/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.",
        "title":"Amendment 504: Recital 23  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c73ca96f-390a-4312-b146-b4d8e4543e8f",
        "text":"(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016\/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016\/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016\/680. The use of biometric identification systems, including ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should be covered by the framework set by this Regulation, with the exception of customs formalities and individual authentication.",
        "title":"Amendment 505: Recital 23  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"a2f93687-24ee-430c-b4a3-00ef5a07a486",
        "text":"(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016\/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016\/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016\/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.",
        "title":"Amendment 506: Recital 23  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"9f2eb5e8-9219-410e-a6ca-b4a29e899305",
        "text":"(23 a) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male\/female, suspicious\/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).",
        "title":"Amendment 507: Recital 23 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f8c4af20-29ee-41fd-a451-d9d8cb4470fd",
        "text":"deleted",
        "title":"Amendment 508: Recital 24  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"eecdef45-3f2e-4004-bb85-703b7d142b98",
        "text":"deleted",
        "title":"Amendment 509: Recital 24  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"394e6952-4836-4b88-bc3d-1621e8c6d5d3",
        "text":"(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016\/679, Article 10(1) of Regulation (EU) 2018\/1725 and Article 10 of Directive (EU) 2016\/680, as applicable.",
        "title":"Amendment 510: Recital 24  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"62229802-5bda-42de-88f9-891e51882a85",
        "text":"(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016\/679, Article 10(1) of Regulation (EU) 2018\/1725 and Article 10 of Directive (EU) 2016\/680, as applicable.",
        "title":"Amendment 511: Recital 24  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"b901c918-4d29-4728-a55e-62a8948e7e04",
        "text":"(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016\/679, Article 10(1) of Regulation (EU) 2018\/1725 and Article 10 of Directive (EU) 2016\/680, as applicable.",
        "title":"Amendment 512: Recital 24  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8bef4cf4-7ca4-4200-b90c-8c327c1b45f2",
        "text":"(24) Any processing of biometric data, biometrics-based data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of biometric identification systems in publicly accessible spaces as regulated by this Regulation, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016\/679, Article 10(1) of Regulation (EU) 2018\/1725 and Article 10 of Directive (EU) 2016\/680, as applicable.",
        "title":"Amendment 513: Recital 24  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"9d095ffd-78ae-4035-8b44-d9546c3af82e",
        "text":"(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement as regulated by this Regulation, including where those systems are used by competent authorities in publicly accessible or online spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016\/679, Article 10(1) of Regulation (EU) 2018\/1725 and Article 10 of Directive (EU) 2016\/680, as applicable.",
        "title":"Amendment 514: Recital 24  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4b57d7c4-f453-491b-a031-4df5b6fc71bf",
        "text":"(24 a) Fundamental rights in the digital sphere have to be guaranteed to the same extent as in the offline world. The right to privacy needs to be ensured, amongst others through end-to-end encryption in private online communication and the protection of private content against any kind of general or targeted surveillance, be it by public or private actors. Therefore, the use of AI systems violating the right to privacy in online communication services should be prohibited.",
        "title":"Amendment 515: Recital 24 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"d3394037-dddf-4988-8753-86328d6ccbec",
        "text":"(25) In accordance with Article 6a of Protocol No 21 on the position of the United Kingdom and Ireland in respect of the area of freedom, security and justice, as annexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU, where Ireland is not bound by the rules governing the forms of judicial cooperation in criminal matters or police cooperation which require compliance with the provisions laid down on the basis of Article 16 of the TFEU.",
        "title":"Amendment 516: Recital 25  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"98fb0e98-9f4d-4f13-95a4-496353b7ebe0",
        "text":"(26) In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark, annexed to the TEU and TFEU, Denmark is not bound by rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU, or subject to their application, which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU.",
        "title":"Amendment 517: Recital 26  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"f7d572c0-b668-4822-baf0-ec2f0ba531c3",
        "text":"(26 a) AI systems capable of reading facial expressions to infer emotional states hold no scientific basis, while at the same time running a high risk of inaccuracy, in particular for certain groups of individuals whose facial traits are not easily readable by such systems, as several examples have shown. Therefore, due to the particular risk of discrimination, these systems should be prohibited.",
        "title":"Amendment 518: Recital 27  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"059f042a-234f-4cf1-b665-01b759943b39",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be classified as such when they have a significant harmful impact on the health, safety, economic status and fundamental rights of individuals in the Union, and also on the environment, society, rule of law, democracy or consumer protection. Given the rapid path of technological development, but also given the potential changes in the use and the aim of authorised AI systems, regardless of whether they are high-risk or lower risk, the limited list of high-risk systems and areas of high risk systems in Annex III should nonetheless be subject to permanent review through the exercise of regular assessment as provided in Title III of this Regulation.",
        "title":"Amendment 519: Recital 27  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"27d70c0e-90bf-4214-916b-cbbb1a90c2de",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation, provided it is delivered with the information on its accuracy or other relevant methodical aspects necessary for the decision making. A human intervention is required to convert this recommendation into an action.",
        "title":"Amendment 520: Recital 27  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"e8d1ae3e-6036-46e4-a8ce-7977a3afda5d",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017\/745 on Medical Devices and Regulation (EU) 2017\/746 on In Vitro Diagnostic Devices and Directive 2006\/42\/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 521: Recital 27  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Deirdre Clune, Axel Voss, Andreas Schwab"
    },
    {
        "uuid":"c87e32b8-4329-446b-806a-f96c84f8aa99",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017\/745 on Medical Devices and Regulation (EU) 2017\/746 on In Vitro Diagnostic Devices and Directive 2006\/42\/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 522: Recital 27  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"37c0ed41-0560-44cc-bea9-8cf75004c9e5",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation and a human intervention is required to convert this recommendation into an action.",
        "title":"Amendment 523: Recital 27  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"db3f0c92-0966-4e96-b169-9793b191ee00",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not breach the Union values enshrined in Article 2 TEU or the principles applicable to all AI systems as per this Regulation. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the fundamental rights of persons, their health and safety and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 524: Recital 27  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e7f272f8-9234-410f-8cd2-02d0b4227f02",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service or used if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not contravene the Union values enshrined in Article 2 TEU. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and the fundamental rights of persons in the Union or the environment and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 525: Recital 27  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"fb8364a0-8d24-45f3-9067-79f806b6447e",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union, as well as the public order and national security of the Member States, and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 526: Recital 27  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"3db1501d-dd0a-409a-a7e4-3951bd2e725e",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union or to Union values as enshrined in Article 2 TEU and such limitation minimises any potential restriction to international trade, if any.",
        "title":"Amendment 527: Recital 27  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"30f8d80b-a57a-48d5-b58b-18a08c63398b",
        "text":"(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a harmful impact on the health, safety and fundamental rights of persons, but also on the environment, democracy and the rule of law in the Union..",
        "title":"Amendment 528: Recital 27  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"73c6f5d1-2ee3-4902-9925-a1906f8c98b8",
        "text":"(28) AI systems could produce adverse outcomes to health and safety of persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. Conversely, industrial robots used in manufacturing processes that operate within a predefined and restricted area entail considerably lower safety risks and are already subject to harmonised safety legislation. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause, including in relation to the health and safety of persons.",
        "title":"Amendment 529: Recital 28  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"8497768c-456a-4ed7-b756-8c416cc1ce21",
        "text":"(28) AI systems could have an adverse impact on persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause.",
        "title":"Amendment 530: Recital 28  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7a55fc7d-1b36-41a8-a428-c28ac0834b1d",
        "text":"(28 a) The risk-assessment of AI systems as regards their environmental impact and use of resources should not only focus on sectors related to the protection of the environment, but be common to all sectors, as environmental impacts can stem from any kind of AI systems, including those not originally directly related to the protection of the environment, in terms of energy production and distribution, waste management and emissions control.",
        "title":"Amendment 531: Recital 28 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d0ecda03-4115-449e-86ae-d060bcd6974b",
        "text":"(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300\/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167\/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168\/2013 of the European Parliament and of the Council41 , Directive 2014\/90\/EU of the European Parliament and of the Council42 , Directive (EU) 2016\/797 of the European Parliament and of the Council43 , Regulation (EU) 2018\/858 of the European Parliament and of the Council44 , Regulation (EU) 2018\/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019\/2144 of the European Parliament and of the Council46, Regulation (EU) 2017\/745 of the European Parliament and of the Council, and Regulation (EU) 2017\/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment, market surveillance and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300\/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320\/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167\/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168\/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014\/90\/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96\/98\/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016\/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018\/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715\/2007 and (EC) No 595\/2009 and repealing Directive 2007\/46\/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018\/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111\/2005, (EC) No 1008\/2008, (EU) No 996\/2010, (EU) No 376\/2014 and Directives 2014\/30\/EU and 2014\/53\/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552\/2004 and (EC) No 216\/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922\/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019\/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018\/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78\/2009, (EC) No 79\/2009 and (EC) No 661\/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631\/2009, (EU) No 406\/2010, (EU) No 672\/2010, (EU) No 1003\/2010, (EU) No 1005\/2010, (EU) No 1008\/2010, (EU) No 1009\/2010, (EU) No 19\/2011, (EU) No 109\/2011, (EU) No 458\/2011, (EU) No 65\/2012, (EU) No 130\/2012, (EU) No 347\/2012, (EU) No 351\/2012, (EU) No 1230\/2012 and (EU) 2015\/166 (OJ L 325, 16.12.2019, p. 1).",
        "title":"Amendment 532: Recital 29  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"afab6ef3-ef51-4aa3-8d6f-d23b7d397b49",
        "text":"(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300\/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167\/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168\/2013 of the European Parliament and of the Council41 , Directive 2014\/90\/EU of the European Parliament and of the Council42 , Directive (EU) 2016\/797 of the European Parliament and of the Council43 , Regulation (EU) 2018\/858 of the European Parliament and of the Council44 , Regulation (EU) 2018\/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019\/2144 of the European Parliament and of the Council46 , Regulation (EU)2017\/745 of the European Parliament and of the Council, and Regulation (EU)2017\/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300\/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320\/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167\/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168\/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014\/90\/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96\/98\/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016\/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018\/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715\/2007 and (EC) No 595\/2009 and repealing Directive 2007\/46\/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018\/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111\/2005, (EC) No 1008\/2008, (EU) No 996\/2010, (EU) No 376\/2014 and Directives 2014\/30\/EU and 2014\/53\/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552\/2004 and (EC) No 216\/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922\/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019\/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018\/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78\/2009, (EC) No 79\/2009 and (EC) No 661\/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631\/2009, (EU) No 406\/2010, (EU) No 672\/2010, (EU) No 1003\/2010, (EU) No 1005\/2010, (EU) No 1008\/2010, (EU) No 1009\/2010, (EU) No 19\/2011, (EU) No 109\/2011, (EU) No 458\/2011, (EU) No 65\/2012, (EU) No 130\/2012, (EU) No 347\/2012, (EU) No 351\/2012, (EU) No 1230\/2012 and (EU) 2015\/166 (OJ L 325, 16.12.2019, p. 1).",
        "title":"Amendment 533: Recital 29  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Deirdre Clune, Axel Voss, Andreas Schwab"
    },
    {
        "uuid":"6011a4d3-10c8-4641-b984-ae37f18796c6",
        "text":"(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation, it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure in order to ensure compliance with essential safety requirements with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.",
        "title":"Amendment 534: Recital 30  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard,"
    },
    {
        "uuid":"cc8bccc5-a728-4728-ac8b-3698965b9ec0",
        "text":"(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation (as specified in Annex II), it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.",
        "title":"Amendment 535: Recital 30  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cd35aed6-a7e3-4251-afd4-142171c1b8f7",
        "text":"(31) The classification of an AI system as high-risk pursuant to this Regulation should not necessarily mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017\/745 of the European Parliament and of the Council47 and Regulation (EU) 2017\/746 of the European Parliament and of the Council48, where a third-party conformity assessment is provided for medium-risk and high-risk products. However, the classification of an AI system as high risk for the sole purpose of this Regulation will apply to all products which use that AI system or which are themselves AI systems, irrespective of their classification under the sector-specific harmonisation legislation of the Union under which they are otherwise covered.' '47 Regulation (EU) 2017\/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001\/83\/EC, Regulation (EC) No 178\/2002 and Regulation (EC) No 1223\/2009 and repealing Council Directives 90\/385\/EEC and 93\/42\/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017\/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98\/79\/EC and Commission Decision 2010\/227\/EU (OJ L 117, 5.5.2017, p. 176).",
        "title":"Amendment 536: Recital 31  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b6068a29-c673-4797-a9bc-4725b43689e9",
        "text":"(31) The classification of an AI system as high-risk pursuant to this Regulation shall not mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017\/745 of the European Parliament and of the Council47 and Regulation (EU) 2017\/746 of the European Parliament and of the Council48.' '47 Regulation (EU) 2017\/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001\/83\/EC, Regulation (EC) No 178\/2002 and Regulation (EC) No 1223\/2009 and repealing Council Directives 90\/385\/EEC and 93\/42\/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017\/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98\/79\/EC and Commission Decision 2010\/227\/EU (OJ L 117, 5.5.2017, p. 176).",
        "title":"Amendment 537: Recital 31  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3652086a-8053-4e7a-a0f7-7ef3951a19d8",
        "text":"(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, safety or the fundamental rights of persons or to Union values as enshrined in Article 2 TEU, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such systems should be classified as high-risk only insofar as they are built and operated with biometric, biometrics-based, or personal data or they influence decisions of natural persons or make decisions or influence decisions affecting natural persons. This ensures that, when referencing AI systems in pre-defined areas of human activity, this Regulation does not inadvertently apply to AI systems that can have no impact on the health, safety, fundamental rights of natural persons or the values of the Union as enshrined in Article 2 TEU.",
        "title":"Amendment 538: Recital 32  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"4737dc02-bc93-475e-a7e1-b51987ef9109",
        "text":"(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a significant risk of harm to the health and safety or the fundamental rights of persons, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such classification should take place before the placing onto the market but also during the life-cycle of an AI system.",
        "title":"Amendment 539: Recital 32  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8ad8d51b-26f7-426d-bdc6-59f90912d60c",
        "text":"(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose or reasonably foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.', '(This amendment should apply throughout the text, i.e. any occurrence of \"intended purpose\" should be followed by \"or reasonably foreseeable uses\")",
        "title":"Amendment 540: Recital 32  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c97da29b-3b06-44d7-b4fd-df9cc8c91549",
        "text":"(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, natural environment, and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.",
        "title":"Amendment 541: Recital 32  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"b0947b26-910c-4b82-985a-1d4319e55d79",
        "text":"(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.",
        "title":"Amendment 542: Recital 32  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"454b2d70-cbfd-40ad-b3c1-cb074cd20bbf",
        "text":"(32 a) In the light of the nature and complexity of the value chain for AI systems, it is essential to consider the foreseeable high-risks they can create when combined. Particular attention should be paid to the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses.",
        "title":"Amendment 543: Recital 32 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ff04811f-076f-4170-8e3e-8177ee0a8ee5",
        "text":"deleted",
        "title":"Amendment 544: Recital 33  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6602cf6a-cbfa-445f-9f54-43a79d31c24f",
        "text":"deleted",
        "title":"Amendment 545: Recital 33  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"f729f33f-a88c-4ddf-b3cb-c4a1b12056cd",
        "text":"(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.",
        "title":"Amendment 546: Recital 33  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Dita Charanzová,"
    },
    {
        "uuid":"a1304a13-0e91-43b7-a9ac-737b879092fb",
        "text":"(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for the purpose of remote client on-boarding or verification of a user through a device. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.",
        "title":"Amendment 547: Recital 33  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"8abe6933-e108-4f83-ab01-6f64541a4edc",
        "text":"(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.",
        "title":"Amendment 548: Recital 33  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"ceac2f3d-8376-4574-b15d-738caf8b690e",
        "text":"(33) Technical inaccuracies of AI systems intended for the biometric identification of natural persons, including remote biometric identification, can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems , including remote biometric identification, should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.",
        "title":"Amendment 549: Recital 33  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"6a3b70f1-30fe-4131-ba01-81b09fc11da6",
        "text":"(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be prohibited.",
        "title":"Amendment 550: Recital 33  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7de1bc87-bc4e-47f3-92b4-992ee4bfc0eb",
        "text":"(33) Technical inaccuracies, as well as conscious or subconscious design decisions, and the use of training data which codify and reinforce structural inequalities, mean that AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. As a result, ‘real-time’ and ‘post’ remote biometric identification systems undermine the essence of fundamental rights and therefore must be prohibited.",
        "title":"Amendment 551: Recital 33  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick"
    },
    {
        "uuid":"8d73eac6-dd78-423a-bfe5-b8cd424ab78e",
        "text":"(33 a) Human oversight should target high-risk AI systems as a priority, with the aim of serving human-centric objectives. The individuals to whom human oversight is assigned shall be provided with adequate education and training on the functioning of the application, its capabilities to influence or make decisions, and to have harmful effects, notably on fundamental rights. The persons in charge of the assignment of these individuals shall provide them with relevant staff and psychological support.",
        "title":"Amendment 552: Recital 33 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"74dfad58-8531-4b4b-afb2-29a28d3e4240",
        "text":"(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety or security components in the management and operation of road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may infringe the security and integrity of such critical infrastructure and thus put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.",
        "title":"Amendment 553: Recital 34  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6cad858e-959e-4efb-b6e0-545bedf76965",
        "text":"(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, and internet, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.",
        "title":"Amendment 554: Recital 34  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0ebfd70e-8857-467c-998b-316b0331ce32",
        "text":"(34) It is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of critical infrastructure such as road traffic or the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.",
        "title":"Amendment 555: Recital 34  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"0547f056-34d4-4e25-b442-f76d2b4f2f5c",
        "text":"(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination. Therefore, AI systems in education shall be prohibited to be used by public authorities in education of underaged children to meet the requirement in this regulation, to not exploit any of the vulnerabilities of the group of persons due to their age.",
        "title":"Amendment 556: Recital 35  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"72d7111e-7ad4-4d44-a311-818f41e6d7d8",
        "text":"(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. AI systems that are designed to constantly monitor individuals are particuarly intrusive and violate the right to education and training, the right not to be discriminated against and perpetuate historical patterns of discrimination and should therefore be prohibited.",
        "title":"Amendment 557: Recital 35  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6dad522e-30d6-4a4f-a88a-73cc17c29ada",
        "text":"(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against.",
        "title":"Amendment 558: Recital 35  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"ced7716a-5f4a-405b-801b-f6abf924c371",
        "text":"(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate or monitor persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination.",
        "title":"Amendment 559: Recital 35  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6b46c37c-28fc-405d-9b54-b8decb97d0bd",
        "text":"(36) AI systems used in employment, workers management and access to self-employment, notably affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters should be high risk. Particularly AI affecting recruitment and selection of persons, for making decisions on promotion and for task allocation, for measuring and monitoring of performance or for evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. AI systems used for constant monitoring of workers pose an unacceptable risk to their fundamental rights, and should be therefore prohibited. Relevant work-related contractual relationships should meaningfully involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also undermine the essence of their fundamental rights to data protection and privacy. This Regulation applies without prejudice to Union and Member State competences to provide for more specific rules for the use of AI-systems in the employment context.",
        "title":"Amendment 560: Recital 36  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e4610fce-edf1-404c-b356-32d0b962aa9d",
        "text":"(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for personalised task allocation based on personal or biometric data, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",
        "title":"Amendment 561: Recital 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"56828da1-a892-49d5-be76-1e625e0a2e69",
        "text":"(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, in so far as such use does not correspond to practices prohibited by this Regulation, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may lead to discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",
        "title":"Amendment 562: Recital 36  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"66636881-40ea-42af-8d06-24020a7a4883",
        "text":"(36) AI systems used for making autonomous decisions or materially influencing decisions in employment, workers management and access to self-employment, notably for the selection of persons, for making decisions on promotion and termination and for monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",
        "title":"Amendment 563: Recital 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"51b63d88-eb19-4b60-b372-48801e9491f7",
        "text":"(36) AI systems used in employment, workers management and access to self-employment, notably but not limited to, for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems impact future career prospects, livelihoods of these persons and workers’ rights. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",
        "title":"Amendment 564: Recital 36  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"7ca2fd58-96a5-46b1-8a7b-8bd4fa28aba2",
        "text":"(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",
        "title":"Amendment 565: Recital 36 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0c270754-2b6b-40b7-9840-14101e6330ba",
        "text":"(36 a) In line with Article 114 (2) TFEU, this Regulation does not in any way affect the rights and interests of employed persons. This Regulation is without prejudice to Community law on social policy and national labour law and practice.",
        "title":"Amendment 566: Recital 36 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"0737089e-fdf5-4740-941c-58380d99f2db",
        "text":"(36 b) Given the significance of Artificial Intelligence impact assessments according to the usage Artificial Intelligence applications in the workplace, the EU will consider a corresponding directive with specific provisions for an impact assessment to ensure the protection of the rights and freedoms of workers affected by AI systems through collective agreements of national legislation.",
        "title":"Amendment 567: Recital 36 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0db9d5d2-941d-4493-a19e-28e211dc8c36",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Infact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 568: Recital 37  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"b9aefd91-b157-415b-9806-73011bbe4828",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 569: Recital 37  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"33340483-c2a6-411f-ad81-5c614d142394",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 570: Recital 37  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"decdc521-cb12-47c4-8b8c-c688f332a5f4",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose lead to an unacceptably high risk of discrimination against persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they have a significant impact on persons’ livelihood and infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be prohibited. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 571: Recital 37  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1f7a0175-6d09-40c8-b04d-ddc73a323a78",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of movables do not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. . Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 572: Recital 37  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"052a962d-f888-4267-8e84-24b5672bd99c",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. In fact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 573: Recital 37  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"0a5aadb1-af91-41f3-a6af-4941a474c9a9",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of moveables does not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 574: Recital 37  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Eugen Jurzyca"
    },
    {
        "uuid":"b0e769fc-341f-41f6-af3d-49267cea9939",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, in so far as such use does not correspond to practices prohibited by this Regulation, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they will have a significant impact on persons’ livelihood and will infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should allow for experimentation in the public administration, in a regulatory sandbox, with innovative approaches which would stand to benefit from a wider use of compliant and safe AI systems, in accordance with the established rules. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should be prohibited as they make decisions in very critical situations for the life and health of persons and their property, and such ethical choices should not be given over to computer systems.",
        "title":"Amendment 575: Recital 37  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"b410e7f9-5613-4ecf-97c9-d380a12ff3d0",
        "text":"(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by SMEs and start-ups for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",
        "title":"Amendment 576: Recital 37  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"7c99a265-9790-486d-822a-aab16be12531",
        "text":"(37 a) Given the speed at which AI applications are being developed around the world, it is not feasible to compile an exhaustive listing of applications that should be prohibited or considered high-risk. What is needed is a clear and coherent governance model guaranteeing both the fundamental rights of individuals and legal clarity for operators, considering the continuous evolution of technology. Nevertheless, given the role and responsibility of police and judicial authorities, and the impact of decisions they take for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, the use of AI applications has to be categorised as high-risk in instances where there is the potential to significantly affect the lives of individuals.",
        "title":"Amendment 577: Recital 37 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"fdba577e-9bce-41d0-82c2-6af3df63684c",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. In addition, some applications, such as to make predictions, profiles, or risk assessments based on data analysis or profiling of groups or individuals for the purpose of predicting the occurrence or recurrence of actual or potential offences or rule-breaking undermine the essence of fundamental rights and should be prohibited. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as prohibited a number of AI systems intended to be used in the law enforcement context as well as for crime analytics regarding natural persons.",
        "title":"Amendment 578: Recital 38  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a3377a1e-85ac-4ce7-a3aa-0cc63d4dab42",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its performance, including its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",
        "title":"Amendment 579: Recital 38  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"becb4fac-0929-426c-953d-e7a69f4cbe02",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. AI systems intended to assess or rank the reliability of natural persons, to identify natural persons based on biometric data, to serve as polygraphs or similar tools, to detect the emotional state of natural persons, to predict the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons or to assess personality traits of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, shall be prohibited except in the three specific cases provided for in this Regulation. AI systems other than the aforementioned and intended to be used in a law enforcement context where accuracy, reliability and transparency is particularly important shall be classed as high-risk AI systems to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, or assessing characteristics or past criminal behaviour of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",
        "title":"Amendment 580: Recital 38  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"6de25005-9f51-4ada-a2fd-8dc8ec8bed33",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities or on their behalf to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",
        "title":"Amendment 581: Recital 38  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"61ef715c-90e8-4c7a-91e2-d3512c5c7faf",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",
        "title":"Amendment 582: Recital 38  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"88f23b9c-3889-4e1c-ae13-f4bc1758fefe",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",
        "title":"Amendment 583: Recital 38  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8ca0660b-5983-4b6b-81d3-96e53383f6dc",
        "text":"(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented and where a redress procedure is not foreseen. It is therefore appropriate to prohibit some AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress, including the availability of redress-by-design mechanisms and procedures. In view of the nature of the activities in question and the risks relating thereto, those prohibited systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons, or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, for profiling in the course of detection, investigation or prosecution of criminal offences. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be included in such a ban.",
        "title":"Amendment 584: Recital 38  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"774ed5e8-fcc9-4170-8922-644ab0b75992",
        "text":"(38 a) The use of AI tools by law enforcement and judicial authorities should not become a factor of inequality, social fracture or exclusion. The impact of the use of AI tools on the defence rights of suspects should not be ignored, notably the difficulty in obtaining meaningful information on their functioning and the consequent difficulty in challenging their results in court, in particular by individuals under investigation.",
        "title":"Amendment 585: Recital 38 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"028ac99b-1cb6-4bdd-9c1c-ee52ef8455c9",
        "text":"(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013\/32\/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810\/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013\/32\/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810\/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).",
        "title":"Amendment 586: Recital 39  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ffa3df86-2ac4-43db-ba8a-eab8fd68d81d",
        "text":"(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013\/32\/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810\/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013\/32\/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810\/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).",
        "title":"Amendment 587: Recital 39  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"5c99f65c-d03d-440f-a69e-4f475d9c3c58",
        "text":"(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management; for verifying the authenticity of the relevant documents of natural persons; AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013\/32\/EU of the European Parliament and of the Council, the Regulation (EC) No 810\/2009 of the European Parliament and of the Council and other relevant legislation.",
        "title":"Amendment 588: Recital 39  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"5d2f23a2-ea90-484a-a1ab-d83f5d554698",
        "text":"(39) AI systems used in migration, asylum and border control management affect people who are often in a particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013\/32\/EU of the European Parliament and of the Council, the Regulation (EC) No 810\/2009 of the European Parliament and of the Council and other relevant legislation",
        "title":"Amendment 589: Recital 39  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke"
    },
    {
        "uuid":"7893ae87-de4b-4f99-b203-6a8e95692d4c",
        "text":"(39) AI systems used in migration, asylum and border control management affect people who are sometimes in a vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably, and where applicable, their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as polygraphs and similar tools or to detect the emotional state of a natural person; for assessing certain risks posed by natural persons entering the territory of a Member State or applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013\/32\/EU of the European Parliament and of the Council49, the Regulation (EC) No 810\/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013\/32\/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810\/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).",
        "title":"Amendment 590: Recital 39  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"0aabc156-0f8b-4338-8fe6-3ca2a8164e0c",
        "text":"(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;",
        "title":"Amendment 591: Recital 39 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke"
    },
    {
        "uuid":"78c16dcc-9bbe-473c-8c92-9a9dd31ee774",
        "text":"(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;",
        "title":"Amendment 592: Recital 39 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"5eecab30-2270-466f-a80c-3c94fa913638",
        "text":"(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;",
        "title":"Amendment 593: Recital 39 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e7cd3961-449d-4575-a617-80b6ddc1cc2b",
        "text":"(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;",
        "title":"Amendment 594: Recital 39 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"41418376-654c-4e81-8d02-3ac80ed3a095",
        "text":"(39 a) The use of AI systems in migration, asylum and border management should however not, at any point, be used by Member States or by the institutions or agencies of the Union to infringe on the principle of non-refoulement, the right to asylum or to circumvent international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967.",
        "title":"Amendment 595: Recital 39 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Abir Al-Sahlani, Svenja Hahn, Samira Rafaela, Monica Semedo"
    },
    {
        "uuid":"4794b141-2fcc-486c-bf9a-597263375084",
        "text":"(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. The use of Artificial Intelligence tools can support, but should not interfere with the decision-making power of judges or judicial independence, as the final decision-making must remain a human-driven activity and decision. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources",
        "title":"Amendment 596: Recital 40  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"19506d5d-6f4f-47fa-a686-86bbf2936f15",
        "text":"(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching facts and the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.",
        "title":"Amendment 597: Recital 40  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"b4326248-de3b-4850-81d2-622ce806f7cc",
        "text":"(40) Certain AI systems intended for the administration of justice and democratic processes should be prohibited, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to prohibit the use of AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.",
        "title":"Amendment 598: Recital 40  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"1d504640-a1b9-429a-bbe0-b57e07891b56",
        "text":"(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in interpreting facts or the law for applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.",
        "title":"Amendment 599: Recital 40  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-"
    },
    {
        "uuid":"37074e80-5c27-4dcf-a610-e32246e11041",
        "text":"(40 a) Another area in which the use of AI systems deserves special consideration is the use for health-related purposes, including healthcare. Next to medical devices (as per EU regulation 2017\/745), other health-related AI systems also bring about risks which should be regulated. These include systems that influence individual’s health outcomes but do not meet the criteria for a medical device, systems that influence population health outcomes or health equality, systems that impact the distribution of healthcare resources and systems used by pharmaceutical and medical technology companies in research and development, pharmacovigilance, market optimisation and pharmaceutical marketing. Bias and errors in health-related AI systems can have major and immediate consequences for individuals’ and populations’ health and wellbeing. Further, many systems will use sensitive and personal data, which needs to be justified, and about which patients need to be properly informed. What is more, systems that work on hospital, health system, or population level may have a major effect on societal health because they influence the distribution of healthcare resources and health policy design. For these reasons, there is a need for trustworthy AI in healthcare, meaning people must be able to trust that systems used in healthcare are scientifically, technically and clinically valid, safe and accountable, and safeguard individuals’ autonomy and privacy.",
        "title":"Amendment 600: Recital 40 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d0db20a7-d0ec-42e7-9472-9b335f42abda",
        "text":"(40 a) Certain AI systems should at the same time be subject to transparency requirements and be classified as high-risk AI systems, given their potential to deceive and cause both individual and societal harm. In particular, AI systems that generate deep fakes representing existing persons have the potential to both manipulate the natural persons that are exposed to those deep fakes and harm the persons they are representing or misrepresenting, while AI systems that, based on limited human input, generate complex text such as news articles, opinion articles, novels, scripts and scientific articles have the potential to manipulate, to deceive, or to expose natural persons to built-in biases or inaccuracies. These should not include AI systems intended to translate text, or cases where the content forms part of an evidently artistic, creative or fictional cinematographic and analogous work.",
        "title":"Amendment 601: Recital 40 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"ef19d17c-518d-429f-9d0a-9e2b16d760c2",
        "text":"(40 a) When the “deep fake” content forms part of an evidently artistic, creative, or fictional cinematographic and analogous work, or when the “AI authors” generate content that undergoes human review and for the publication of which a natural or legal person established in the Union is liable or holds editorial responsibility, the AI systems should not be considered high-risk but should nevertheless be subject to adequate transparency requirements, where appropriate.",
        "title":"Amendment 602: Recital 40 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"3fc27a1e-dde3-44fc-9761-7bab8cf602a9",
        "text":"(40 a) Certain AI-systems used in the area of healthcare that are not covered by Regulation (EU) 2017\/745 (Regulation on Medical Devices) should be high-risk. Uses such as software impacting diagnostics, treatments or medical prescriptions and access to health insurance can clearly impact health and safety, but also can also obstruct access to health services, impact the right to health care and cause physical harm in the long run.",
        "title":"Amendment 603: Recital 40 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"39c27dba-b687-46c0-868d-7b581c0390e4",
        "text":"(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme.",
        "title":"Amendment 604: Recital 40 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"c4b008fc-7bc2-497d-b83a-2b34a662f960",
        "text":"(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional and analogous work or programme.",
        "title":"Amendment 605: Recital 40 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"a84a0fcf-600d-45db-9ab4-9d2be12574e6",
        "text":"(40 b) Subliminal techniques are techniques that expose natural persons to sensorial stimuli that the natural persons cannot consciously perceive but that are assumed to register in the brain unconsciously, such as flashing images or text for fractions of a second or playing sounds outside the range of perceptible hearing. AI systems deploying such techniques should be prohibited, because these techniques are by their very nature intended to be manipulative. Nevertheless, exceptions are warranted for AI systems using subliminal techniques for research and therapeutical purposes, based on the consent of the natural persons that are being exposed to them. In such limited cases, the AI systems should be considered high-risk and comply with the requirements for high-risk AI systems as set forth in this Regulation.",
        "title":"Amendment 606: Recital 40 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"69a60b11-8e5f-4544-b48d-4b91530b09c4",
        "text":"(40 b) Certain AI-systems used in the area of media, particularly in the area of social media, due to their potentially large reach and the specific risk of large scale spread of disinformation and exacerbation of societal polarisation should be high-risk due to their potential impact on individuals’ rights, but also on society and democracy at large.",
        "title":"Amendment 607: Recital 40 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e8ce4c04-dc44-4926-8ec6-e7df27959f35",
        "text":"(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data.",
        "title":"Amendment 608: Recital 41  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f5f194ed-c285-47e5-b671-4ce42fa848b5",
        "text":"(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.",
        "title":"Amendment 609: Recital 41  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"821bd33f-71cd-4b39-977a-9b9b6cfa0dda",
        "text":"(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.",
        "title":"Amendment 610: Recital 41  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5a9ace2f-bb66-4156-abd4-cae7c224149e",
        "text":"(41) The fact that an AI system is compliant with the requirements for high-risk AI under this Regulation should not be interpreted as indicating that the use of the system is necessarily unlawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. As far as is applicable and proportionate, this Regulation may, where duly justified, be understood as providing for the legal ground for processing of personal data where relevant.",
        "title":"Amendment 611: Recital 41  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ed19eb08-ba32-41bc-8a6a-6afd41facf51",
        "text":"(41 a) AI systems do not operate in a lawless world. A number of legally binding rules at European, national and international level already apply or are relevant to AI systems today. Legal sources include, but are not limited to EU primary law (the Treaties of the European Union and its Charter of Fundamental Rights), EU secondary law (such as the General Data Protection Regulation, the Product Liability Directive, the Regulation on the Free Flow of Non-Personal Data, anti-discrimination Directives, consumer law and Safety and Health at Work Directives), the UN Human Rights treaties and the Council of Europe conventions (such as the European Convention on Human Rights), and numerous EU Member State laws. Besides horizontally applicable rules, various domain-specific rules exist that apply to particular AI applications (such as for instance the Medical Device Regulation in the healthcare sector).",
        "title":"Amendment 612: Recital 41 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"52b3cb2b-a6da-4a29-a558-4c6de0b870c6",
        "text":"(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system and according to the risk management system to be established by the provider. These requirements should be objective-driven, fit to purpose, reasonable and effective, without adding undue regulatory burdens or costs on operators.",
        "title":"Amendment 613: Recital 42  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"d369d39b-77f2-470c-9a49-caf0dd3cdae1",
        "text":"(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system, level of reliance of the user or business user on the output of the AI system for the final decision or outcome and according to the risk management system to be established by the provider.",
        "title":"Amendment 614: Recital 42  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5adc1003-ffca-40e0-96ee-5e39733f769c",
        "text":"(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for deployers and AI subjects, certain mandatory requirements should apply, taking into account the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and should be in accordance with the risk management system to be established by the provider.",
        "title":"Amendment 615: Recital 42  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fbacf8ae-9b22-40df-aa53-302b64131f10",
        "text":"(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose or reasonably foreseeable use of the system and according to the risk management system to be established by the provider.",
        "title":"Amendment 616: Recital 42  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"75ef3af0-da26-41db-b61c-bfa6c67b380a",
        "text":"(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the foreseeable uses of the system and according to the risk management system to be established by the provider.",
        "title":"Amendment 617: Recital 42  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f0441930-f8f7-46b6-8d95-18b298e08698",
        "text":"(43) Requirements should apply to high-risk AI systems as regards the quality and relevance of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and security. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, as applicable in the light of the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.",
        "title":"Amendment 618: Recital 43  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"921ddefe-2e53-437e-b287-32ec407de0a6",
        "text":"(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 TEU, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.",
        "title":"Amendment 619: Recital 43  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"18d201e4-eebc-4570-a11f-dd08778aea11",
        "text":"(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.",
        "title":"Amendment 620: Recital 43  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f53bccd5-2999-4afb-a901-4045b2bba8bc",
        "text":"(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the foreseeable uses of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.",
        "title":"Amendment 621: Recital 43  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"047bdec0-001c-4f5b-94b9-b07a22ae7f1d",
        "text":"(43 a) Fundamental rights impact assessments for high-risk AI systems may include a clear outline of the intended purpose for which the system will be used, a clear outline of the intended geographic and temporal scope of the system’s use, categories of natural persons and groups likely to be affected by the use of the system or any specific risk of harm likely to impact marginalised persons or groups at risk of discrimination, or increase societal inequalities;",
        "title":"Amendment 622: Recital 43 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"ccbf7dcf-8ae6-4a01-b0bf-369ef5926eef",
        "text":"(44) High data quality and having simple and accessible data plays a vital role in providing structure and ground truth for AI and are essential for purpose-ready data analytics and the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. To achieve simple access to and usability of high quality data for AI, the Commission should examine ways to facilitate the lawful processing of personal data to train legitimate AI systems by appropriate amendments to applicable laws. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, machine learning validation and testing data sets should be sufficiently relevant and representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, machine learning validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. If it is necessary for the aforementioned purpose to use existing sets of data that includes personal data originally collected and stored for a different purpose, their use for the aforementioned purpose should be deemed compatible with the original purpose so long as the personal data is not transferred to any third party. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 623: Recital 44  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"60bfeca7-ef93-4fb9-82b8-9937e6efb1dd",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.",
        "title":"Amendment 624: Recital 44  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"fbde1925-906c-4664-8613-295898364a79",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative as complete and close to zero error as possible. A procedure to check data and completeness in view of the intended purpose of the system should be implemented. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the unfair bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the unfair bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 625: Recital 44  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"7869e519-9339-4f53-b5a6-be01404e3960",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the foreseeable uses of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their foreseeable uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should ensure the bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 626: Recital 44  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b90a02c2-e2a5-49d2-8398-0a01b453df06",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose or reasonably foreseeable use of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose or reasonably foreseeable use , the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended or foreseeable to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 627: Recital 44  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e4fb533f-c309-4c7b-8a8d-2fed669a2220",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become a source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors, statistically complete and relevant in view of the intended purpose of the system and the context of its use. They should also have the appropriate statistical properties, including as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent necessary in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. Solely in order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process special categories of personal data, as a matter of substantial public interest, in order to ensure bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 628: Recital 44  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6b187331-215a-42dc-8114-c2a79cea869f",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training datasets, and where applicable, validation and testing datasets, including the labels, shall be relevant, representative, up-to-date, and to the best extent possible, free of errors and complete. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, data sets should take into account, to the extent required by the intended purpose, the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.",
        "title":"Amendment 629: Recital 44  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7eb91b11-8ea4-4e1e-8ee1-e56f661ecd66",
        "text":"(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.",
        "title":"Amendment 630: Recital 44  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"c6e989cb-21aa-435c-b461-453194ba99ec",
        "text":"(44 a) Biases can be inherent in underlying datasets, especially when historical data is being used, introduced by the developers of the algorithms, or generated when the systems are implemented in real world settings. Any result provided by an AI system is necessarily influenced by the quality of the data used, and such inherent biases are inclined to gradually increase and thereby perpetuate and amplify existing discrimination, in particular for persons belonging to certain ethnic groups or racialised communities.",
        "title":"Amendment 631: Recital 44 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1779c754-fef5-4b7e-88ba-e719f71c2093",
        "text":"(45) For the development of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission, developed and operated by European actors and which do not transfer any data outside the territory or legal jurisdiction of the European Union, and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.",
        "title":"Amendment 632: Recital 45  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"af9f8e33-8040-40f5-9074-5361b3e30af7",
        "text":"(45) For the development and assessment of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.",
        "title":"Amendment 633: Recital 46  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"44636972-6333-4aba-a0ed-71487d7a40dd",
        "text":"(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date. The required technical documentation may contain trade secrets in accordance with Directive (EU) 2016\/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure. Possible trade secrets in the required documentation must be treated and kept in accordance with national legislation put in place in accordance with mentioned directive.",
        "title":"Amendment 634: Recital 46  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"79431ec1-6638-492b-8ad4-ab1a3df0f01e",
        "text":"(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date throughout the entire lifecycle of the AI system.",
        "title":"Amendment 635: Recital 46  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"cb6bead7-1ec1-486b-a11c-f7087d3e5608",
        "text":"(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements, while preserving trade secrets. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.",
        "title":"Amendment 636: Recital 46  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"db92492c-a39b-43aa-8eda-027f4adb44ae",
        "text":"(47) To address the opacity that may make certain AI systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high-risk AI systems. Deployers should be able to interpret the system’s goals, priorities and output and use it appropriately. High-risk AI systems should therefore be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to possible risks to fundamental rights and discrimination, where appropriate. Where individuals are passively subject to AI systems (AI subjects), information to ensure an appropriate type and degree of transparency should be made publicly available, with full respect to the privacy, personality, and related rights of subjects.",
        "title":"Amendment 637: Recital 47  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fd9f0c2e-0172-4c50-82bc-a1c9cb84cb67",
        "text":"(47 a) It is vital to ensure that the development, deployment and use of AI systems for the judiciary and law enforcement comply with fundamental rights, and are trusted by citizens, as well as in order to ensure that results generated by AI algorithms can be rendered intelligible to users and to those subject to these systems, and that there is transparency on the source data and how the system arrived at a certain conclusion. To this aim, law enforcement or judiciary authorities in the Union should use only such AI systems whose algorithms and logic are auditable and accessible at least to the police and the judiciary, as well as independent auditors, to allow for their evaluation, auditing and vetting, and such systems should not be closed or labelled as proprietary by the vendors.",
        "title":"Amendment 638: Recital 47 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"45f665a3-cd98-4995-bfbb-c7548fcb85dc",
        "text":"(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art and technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017\/745 and Regulation (EU) 2017\/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.",
        "title":"Amendment 639: Recital 48  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fb924d49-e1a5-4068-a170-1bec2705c275",
        "text":"(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017\/745 and Regulation (EU) 2017\/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.",
        "title":"Amendment 640: Recital 48  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Deirdre Clune, Axel Voss, Andreas Schwab"
    },
    {
        "uuid":"e6157584-3d53-4d05-9e05-1fe2f7d5881a",
        "text":"(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings a proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.",
        "title":"Amendment 641: Recital 48  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki"
    },
    {
        "uuid":"13a8acf2-4803-40e2-914a-4314ca166b27",
        "text":"(48) High-risk AI systems should be designed and developed in such a way that natural persons can actually oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself, that it cannot make decisions without approval by the human operator, that it is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.",
        "title":"Amendment 642: Recital 48  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2a0725a0-d769-4948-b9b0-58cf071f80b0",
        "text":"(48) High-risk AI systems should be designed and developed in such a way that natural persons can meaningfully oversee and regulate their functioning or investigate in case of an accident. For this purpose, appropriate human oversight measures should be ensured by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.",
        "title":"Amendment 643: Recital 48  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b8062436-11c8-4021-ba98-8121c9dafac6",
        "text":"(48 a) In order to protect natural persons that are developers or users of AI systems against retaliation from their employers and colleagues, and to prevent misconduct or breaches of this Regulation and other relevant Union law, they should have the right to rely on the whistleblower protections set in Directive (EU) 2019\/1937 of the European Parliament and of the Council.",
        "title":"Amendment 644: Recital 48 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"d1c1d96d-b370-4b4e-aea3-840e23648375",
        "text":"(49) High-risk AI systems should perform consistently throughout their lifetime and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the users. While standardisation organisations exist to establish standards, coordination on benchmarking is needed to establish how these standards should be met and measured. The European Artificial Intelligence Board should bring together national metrology and benchmarking authorities and provide guidance to address the technical aspects of how to measure the appropriate levels of accuracy and robustness. Their work should not be seen as a replacement of the standardisation organisations, but as a complementary function to provide specific technical expertise on measurement.",
        "title":"Amendment 645: Recital 49  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"87b089a8-3df0-4dc5-83e8-a8a6e93cefd7",
        "text":"(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be defined by standards or common technical specifications and communicated to the users. The European Commission should be able to decide on such standards or common technical specifications or to adopt existing ones developed by third parties such as suppliers, stakeholders or standardisation bodies.",
        "title":"Amendment 646: Recital 49  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"69e20a07-2ef6-435e-be1c-f0865c3e098c",
        "text":"(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness, reliability and security in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the deployers.",
        "title":"Amendment 647: Recital 49  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ab134225-2ee6-453c-9cd5-1b1006c56df9",
        "text":"(50) Technical robustness is a key requirement for high-risk AI systems. They should be resilient against risks connected to the limitations of the system (e.g. errors, faults, inconsistencies, unexpected situations) as well as adequately protected against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behaviour. Failure to protect against these risks could lead to safety impacts or negatively affect fundamental rights, for example due to erroneous decisions or wrong or biased outputs generated by the AI system.",
        "title":"Amendment 648: Recital 50  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5616c780-aa5d-4fe7-80a1-5dc0facd8841",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, state-of-the-art measures should therefore be taken into account by the providers of high-risk AI systems but also by the national competent authorities, market surveillance authorities and notified bodies that are accessing the data of providers of high-risk AI systems, next to appropriate underlying ICT infrastructure. It should be further taken into account that AI in the form of machine learning is a critical defence against malware representing a legitimate interest of the AI user.",
        "title":"Amendment 649: Recital 51  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7c09f7df-e010-4ab2-846c-ef9dcff30d11",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.",
        "title":"Amendment 650: Recital 51  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo"
    },
    {
        "uuid":"b0314b00-be47-4056-84b6-e857294a09fb",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities, also taking into account as appropriate the underlying ICT infrastructure.",
        "title":"Amendment 651: Recital 51  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a70c7602-9a31-4724-ae8f-01f00f15a4c5",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the competent public authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.",
        "title":"Amendment 652: Recital 51  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"c141e2d6-8f92-447d-aa2e-a7c420aabca2",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can target AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.",
        "title":"Amendment 653: Recital 51  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f0ea00a5-4e74-4c4c-82b8-d2698f29f020",
        "text":"(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account the underlying ICT infrastructure.",
        "title":"Amendment 654: Recital 51  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c928ddd0-1c05-4dac-9658-7809f7172614",
        "text":"(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market or putting into service of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system, without prejudice to the right of a provider to take action against the manufacturer of that system.",
        "title":"Amendment 655: Recital 53  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"f576625c-6a48-468c-9f04-f086a3b906d1",
        "text":"(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market, putting into service or deploying of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system.",
        "title":"Amendment 656: Recital 53  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"956b0e6f-4393-45e7-bf79-9649d2660a3e",
        "text":"(54) The provider and, where applicable, deployer should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question. Deployers should have strategies in place to ensure that the data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data during the deployment lifetime of high-risk AI systems, complies with applicable rules and ensure regulatory compliance, in particular regarding modifications to the high-risk AI systems.",
        "title":"Amendment 657: Recital 54  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"39ab7c87-8cb8-44d9-a6f9-39f54bef188f",
        "text":"(54) The provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation in the language of the Member State concerned and establish a robust post-market monitoring system. All elements, from design to future development, must be transparent for the user. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.",
        "title":"Amendment 658: Recital 54  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"ceb9c0e5-1a2e-4903-9b0d-d3f70fd1146b",
        "text":"(54) Unless the provider has already implemented a risk management system warranting quality and conformity, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.",
        "title":"Amendment 659: Recital 54  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"d9fa49d2-0720-401d-835c-3895b2deb30f",
        "text":"(54) In case there are no risk management systems already in place, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.",
        "title":"Amendment 660: Recital 54  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"8dcca392-5c66-4663-af48-b2de429bb3e1",
        "text":"(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to placing any AI system on the Union market, putting it into service or using it, where an importer cannot be identified, operators established outside the Union should, by written mandate, appoint a legal representative established in the Union. The legal representative should act on behalf of the operator and may be addressed by any competent authorities for the purpose of this Regulation. The designation of such a legal representative does not affect the responsibility or liability of the operator under this Regulation. Such a legal representative should perform its tasks according to the mandate received from the operator, including cooperating with the national supervisory authorities with regard to any action taken to ensure compliance with this Regulation. The designated legal representative should be subject to enforcement proceedings in the event of non-compliance by the operator.",
        "title":"Amendment 661: Recital 56  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6f215804-bc45-4783-a202-ea262574c9a0",
        "text":"(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to making their AI systems available in the Union, providers established outside the Union shall, by written mandate, appoint an authorised representative established in the Union.",
        "title":"Amendment 662: Recital 56  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"0abeda95-8d3b-4192-be7a-ec201a061aac",
        "text":"(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate. Given the potential impact and the need for democratic oversight and scrutiny, users of high-risk AI systems that are public authorities or Union institutions, bodies, offices and agencies should be required to conduct a fundamental rights impact assessment prior to commencing the use of a high-risk AI system should be required to register the use of any high-risk AI systems in a public database.",
        "title":"Amendment 663: Recital 58  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"19a5aab2-db98-4e31-9bcc-34728ef7d21b",
        "text":"(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems for the purpose for which they were intended and in accordance with the instructions of use, to that end high-risk AI systems should structurally limit, to the greatest extent possible, the technical possibility for a user to use these AI systems in another way, and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate.",
        "title":"Amendment 664: Recital 58  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e746c529-c8cd-42da-930b-e28233af83a7",
        "text":"(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping and quality management, as appropriate.",
        "title":"Amendment 665: Recital 58  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7bd4590f-aa2c-4e71-adad-c214306c41a3",
        "text":"(58 a) Whilst risks related to AI systems can generate from the way such systems are designed, risks can as well stem from how such AI systems are used. Users of high-risk AI system therefore play a critical role in ensuring that fundamental rights are protected, complementing the obligations of the provider when developing the AI system. Users are best placed to understand how the high-risk AI system will be used concretely and can therefore identify potential risks that were not foreseen in the development phase, thanks to a more precise knowledge of the context of use, the people or groups of people likely to be affected, including marginalised and vulnerable groups. In order to efficiently ensure that fundamental rights are protected, the user of high-risk AI systems should therefore carry out a fundamental rights impact assessment on how it intends to use such AI systems, and prior to putting it into use. The impact assessment should be accompanied by a detailed plan describing the measures or tools that will help mitigating the risks to fundamental rights identified. When performing this impact assessment, the user should notify the national supervisory authority, the market surveillance authority as well as relevant stakeholders. It should also involve representatives of groups of persons likely to be affected by the AI system in order to collect relevant information which is deemed necessary to perform the impact assessment.",
        "title":"Amendment 666: Recital 58 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"df2490a3-9956-45b9-8843-5328cd18b735",
        "text":"(58 a) To ensure that fundamental rights, the environment and the public interest are effectively protected where an AI-system is classified as high-risk under Annex III, both producers and deployers before each deployment should perform a fundamental rights impact assessment of the systems’ impact in the context of use throughout the entire lifecycle and include measures to mitigate any impact on fundamental rights, the environment or the public interest. The fundamental rights impact assessment should be registered in the public EU database for stand-alone high-risk AI systems and be publicly accessible. The supervisory authority should have the power to review these fundamental rights impact assessments.",
        "title":"Amendment 667: Recital 58 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"95f3caed-9d1f-4077-a95e-b8b09a997e90",
        "text":"(58 a) Risks for people affected by AI systems often arise from uses of an AI system in a specific context and with respect to a specific group of people, and might not always be foreseeable for the provider. Therefore, prior to putting a high-risk AI system into use, the user should conduct an assessment of the system’s impact on the fundamental rights in particular, within the context of use, and publish the results.",
        "title":"Amendment 668: Recital 58 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"012b96f9-71f6-42da-a007-cb7b59d66e4a",
        "text":"(59) It is appropriate to envisage that the user of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated.",
        "title":"Amendment 669: Recital 59  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c9b48488-5444-48a5-9d68-496d58b8f054",
        "text":"(59) It is appropriate to envisage that the deployer of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated except where the use is made in the course of a personal non-professional activity.",
        "title":"Amendment 670: Recital 59  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5c0d544d-40b0-4390-ac49-738ff6027b94",
        "text":"(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and users to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation. This provision shall qualify as a legal obligation in the context of the processing of personal data where necessary for the cooperation between the relevant providers.",
        "title":"Amendment 671: Recital 60  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"41f01522-7f18-4dd5-bae8-b35c374c7520",
        "text":"(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and deployers to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation.",
        "title":"Amendment 672: Recital 60  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0f84bc30-3377-4046-8c83-0da9ff4741df",
        "text":"(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation, in particular as regards the levels and metrics of accuracy and robustness for high-risk AI systems. The Commission should be able to adopt common technical specifications in areas where no harmonised standards exist or where they are insufficient. The Commission should also be able to adopt standards or common technical specifications developed by third parties such as suppliers, stakeholders or standardisation bodies. Compliance with the common technical specifications adopted by the Commission should be a means for suppliers to demonstrate compliance with the requirements of this Regulation. Compliance with other harmonised standards set out in Regulation (EU) No 1025\/2012 of the European Parliament and of the Council54 should also help to demonstrate suppliers’ compliance with the requirements of this Regulation, without having the same probative value as the common technical specifications adopted by the Commission.' '54 Regulation (EU) No 1025\/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89\/686\/EEC and 93\/15\/EEC and Directives 94\/9\/EC, 94\/25\/EC, 95\/16\/EC, 97\/23\/EC, 98\/34\/EC, 2004\/22\/EC, 2007\/23\/EC, 2009\/23\/EC and 2009\/105\/EC of the European Parliament and of the Council and repealing Council Decision 87\/95\/EEC and Decision No 1673\/2006\/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).",
        "title":"Amendment 673: Recital 61  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"36e69b4d-3dfe-4cb3-9731-f8f3ab003fb5",
        "text":"(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025\/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, the Commission could adopt common technical specifications in areas where no harmonised standards exist and are not expected to be published within a reasonable period or where they are insufficient, only after consulting the Artificial Intelligence Board, the European standardisation organisations as well as the relevant stakeholders. The Commission should duly justify why it decided not to use harmonised standards.' '54 Regulation (EU) No 1025\/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89\/686\/EEC and 93\/15\/EEC and Directives 94\/9\/EC, 94\/25\/EC, 95\/16\/EC, 97\/23\/EC, 98\/34\/EC, 2004\/22\/EC, 2007\/23\/EC, 2009\/23\/EC and 2009\/105\/EC of the European Parliament and of the Council and repealing Council Decision 87\/95\/EEC and Decision No 1673\/2006\/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).",
        "title":"Amendment 674: Recital 61  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"4f49720e-7c68-4f3b-be07-68b0fcd2d4d6",
        "text":"(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025\/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, in exceptional cases, where industry and technical experts consider that pressing and specific safety or fundamental rights concerns cannot be addressed by established standardisation processes, the Commission may adopt common technical specifications in areas where no harmonised standards exist or where they are evidently insufficient.' '54 Regulation (EU) No 1025\/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89\/686\/EEC and 93\/15\/EEC and Directives 94\/9\/EC, 94\/25\/EC, 95\/16\/EC, 97\/23\/EC, 98\/34\/EC, 2004\/22\/EC, 2007\/23\/EC, 2009\/23\/EC and 2009\/105\/EC of the European Parliament and of the Council and repealing Council Decision 87\/95\/EEC and Decision No 1673\/2006\/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).",
        "title":"Amendment 675: Recital 61  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"6a04e478-a2e7-4c2a-bb88-cd7262b69556",
        "text":"(61 a) As part of the new legal framework on corporate sustainable reporting and due diligence, minimum common standards for the reporting of businesses on the societal and environmental impacts of the AI systems that they develop, sell or distribute should be established and used at an early stage of the development and life-cycle of AI systems. Such common standard obligations should notably consist of mandatory human rights due diligence rules, thus enabling a level-playing field among European businesses and non-European businesses operating in the EU.",
        "title":"Amendment 676: Recital 61 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"22e704f6-22bb-4d9a-8f90-3dd856a5c302",
        "text":"(61 a) Striving for regulatory alignment on AI with likeminded global partners is key to fostering mutual innovation and cross-border partnerships within the field of AI. Coordination with international standardisation bodies is therefore of great importance.",
        "title":"Amendment 677: Recital 61 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Tomas Tobé, Arba Kokalari"
    },
    {
        "uuid":"6bcf9ab2-e495-47f8-b067-e15c5c88d1ea",
        "text":"(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a conformity assessment prior to their placing on the market or putting into service. AI systems, including general purpose AI systems, that may not necessarily be high-risk, are frequently used as components of other AI or non-AI software systems. In order to increase trust in the value chain and to give certainty to businesses about the performance of their systems, providers may voluntarily apply for a third-party conformity assessment.",
        "title":"Amendment 678: Recital 62  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c2de3808-84d1-4953-ac6e-77ed3025eed8",
        "text":"(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a third party conformity assessment prior to their placing on the market or putting into service.",
        "title":"Amendment 679: Recital 62  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"94f54f88-a4d9-4ed0-8c97-b6f7a72bedb4",
        "text":"(63) It is appropriate that, in order to minimise the burden on operators and avoid any possible duplication, for high-risk AI systems related to products which are covered by existing Union harmonisation legislation following the New Legislative Framework approach, the compliance of those AI systems with the requirements of this Regulation should be assessed as part of the conformity assessment already foreseen under that legislation. The applicability of the requirements of this Regulation should thus not affect the specific logic, methodology or general structure of conformity assessment under the relevant specific New Legislative Framework legislation. This approach is fully reflected in the interplay between this Regulation and the [Machinery Regulation]. While safety risks of AI systems ensuring safety functions in machinery are addressed by the requirements of this Regulation, certain specific requirements in the [Machinery Regulation] will ensure the safe integration of the AI system into the overall machinery, so as not to compromise the safety of the machinery as a whole. The [Machinery Regulation] applies the same definition of AI system as this Regulation. However, should this Regulation and another legislative act of the European Union both cover the same product or component of a product and provide diverging definitions or impose different safety requirements, the applicable text shall be the one with the definition or safety requirements offering the best protection for people, Member States, society and fundamental rights.",
        "title":"Amendment 680: Recital 63  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"eba7b937-41bd-400e-838e-85db02d73310",
        "text":"deleted",
        "title":"Amendment 681: Recital 64  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"73695a9a-5747-4d41-abb3-541686db2511",
        "text":"(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to allow them to carry out a conformity assessment for AI systems, including high-risk AI systems, as qualified bodies, to the extent that these systems are not prohibited.",
        "title":"Amendment 682: Recital 64  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"6e94c333-12a4-4f4e-9c1f-2f7f408aeb67",
        "text":"(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the exception of AI systems intended to be used for the remote biometric identification of persons and AI systems intended to be used to make inferences on the basis of biometric data that produce legal effects or affect the rights and freedoms of natural persons. For those types of AI systems the involvement of a notified body in the conformity assessment should be foreseen, to the extent they are not prohibited..",
        "title":"Amendment 683: Recital 64  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"ced2be61-96b4-43b4-aaec-c082b7565f4f",
        "text":"(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is essential to ensure, particularly in the period before application of this Regulation, the development of adequate capacity for the application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility.",
        "title":"Amendment 684: Recital 64  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0e09ff34-c145-4bc9-9953-8093e2a8fee9",
        "text":"(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the only exception of AI systems intended to be used for the remote biometric identification of persons, for which the involvement of a notified body in the conformity assessment should be foreseen.",
        "title":"Amendment 685: Recital 64  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"1371be14-cade-43bc-a056-db2da1a2c8eb",
        "text":"deleted",
        "title":"Amendment 686: Recital 65  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4bf186b3-6494-4ebe-9677-6bec549be790",
        "text":"(65) In order to carry out third-party conformity assessment for AI systems intended to be used for the remote biometric identification of persons, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence, absence of conflicts of interests and minimum cybersecurity requirements.",
        "title":"Amendment 687: Recital 65  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"7ee04b2b-e533-4534-8066-ffbb396c6c16",
        "text":"(65) In order to carry out third-party conformity assessments when so required, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.",
        "title":"Amendment 688: Recital 65  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"749932ac-c2ed-4aa1-b80e-617be2c9e78a",
        "text":"(65) In order to carry out third-party conformity assessment for AI systems intended to be used for any of the use-cases listed in Annex III, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.",
        "title":"Amendment 689: Recital 65  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"f20d1270-b134-41d7-82ae-57b42c7f134b",
        "text":"(65 a) Third party conformity assessments for products listed in Annex III are essential as a precautionary measure and to ensure that trust is not lost in AI products, to the detriment of innovation, competition and growth. Due to the particularly sensitive nature of the tasks at hand, third party conformity assessments in the fields of law enforcement, asylum and immigration should be carried out by the market surveillance authority.",
        "title":"Amendment 690: Recital 65 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"06024716-7781-48d1-bdb8-813a7de6fa10",
        "text":"(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may create a new or increased risk and significantly affect the compliance of the system with this Regulation or when the intended purpose of the system changes. If such a case materialises, the provider should follow a clear procedure with fixed deadlines, transparency requirements and reporting duties involving, where appropriate and applicable, external oversight by notified bodies or, where it is covered already under the relevant sectoral legislation, post market monitoring if that is needed. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been considered by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification. In addition, it should not be considered a substantial modification if the user trains an AI system. In this situation, the user should clearly delimit the effects that the learning can have for the AI system. The notion of substantial modification should be assessed in light of the essential requirements set in this Regulation and be left to the manufacturer to determine if a modification is deemed to be substantial.",
        "title":"Amendment 691: Recital 66  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6980a831-bc45-4083-9934-6a897af739cb",
        "text":"(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary that changes to the algorithm and its performance that constitute substantial modifications are subject to new conformity assessments, including in cases where the substantial modifications have been pre-determined by the provider and assessed at the moment of the initial conformity assessment.",
        "title":"Amendment 692: Recital 66  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b0261435-10f8-4fc8-9091-014b496ad329",
        "text":"(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose or reasonably foreseeable use of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.",
        "title":"Amendment 693: Recital 66  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"436cc037-167c-4596-8723-744573775542",
        "text":"(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new third party conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.",
        "title":"Amendment 694: Recital 66  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"fc135375-5812-47ab-9d08-911566e31f30",
        "text":"(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the foreseeable uses of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.",
        "title":"Amendment 695: Recital 66  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"50e8ced8-06a3-4f2d-b885-1d221c4b00ef",
        "text":"(66 a) To prevent any deterioration in the expected safety of the algorithm subject to significant changes independent of the providers control, a clearly developed plan to address such significant changes should be subject to oversight by the relevant competent authorities or notified bodies when it is already addressed in principle in the respective sectoral Union harmonisation legislation regarding post-market monitoring",
        "title":"Amendment 696: Recital 66 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5dc24e9c-034b-4410-9bef-53d68fc88a1b",
        "text":"(67) High-risk AI systems should bear the CE marking to indicate their conformity with this Regulation so that they can move freely within the internal market. Member States should not create obstacles to the placing on the market or putting into service of high-risk AI systems that comply with the requirements laid down in this Regulation and bear the CE marking.",
        "title":"Amendment 697: Recital 67  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"7e80f4e4-4108-423d-9af7-276b11974df2",
        "text":"deleted",
        "title":"Amendment 698: Recital 68  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"04c5c8a1-a016-4572-828b-0641a206c213",
        "text":"deleted",
        "title":"Amendment 699: Recital 68  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1954ae8f-f0f1-465e-98d1-982a435eef73",
        "text":"deleted",
        "title":"Amendment 700: Recital 68  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"0b45fed7-52c5-4317-bacb-7ad13ce78b05",
        "text":"deleted",
        "title":"Amendment 701: Recital 68  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d3503d37-fbb1-4b6e-9696-d4507d8cec11",
        "text":"(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. Certain AI systems listed in Article 52 (1b) and (2) and uses thereof shall be registered in the EU database. In order to facilitate this, users shall request information listed in Annex VIII point 2(g) from providers of AI systems. Any uses of AI systems by public authorities or on their behalf shall also be registered in the EU database. In order to facilitate this, public authorities shall request information listed in Annex VIII point 3(g) from providers of AI systems. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018\/1725 of the European Parliament and of the Council. In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.",
        "title":"Amendment 702: Recital 69  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f49edace-18b1-4bb1-9e6e-65949d781bd8",
        "text":"(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018\/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.' '55 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).",
        "title":"Amendment 703: Recital 69  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d150456a-512f-45c2-a166-87ef7e7e606e",
        "text":"(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, both providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. Users who are public authorities or European Union institutions, bodies, offices and agencies or users acting on their behalf should also register in the EU database before putting into service or using any AI system. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018\/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).",
        "title":"Amendment 704: Recital 69  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c6c5263c-1d81-44a4-8ead-24bee6e9dcc2",
        "text":"(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and deployers of high-risk AI systems should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018\/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).",
        "title":"Amendment 705: Recital 69  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b4a1d71a-59c7-4f05-b60f-a2e9200c0d34",
        "text":"(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards regulators, providers of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018\/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016\/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95\/46\/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).",
        "title":"Amendment 706: Recital 69  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"70f1dc29-743b-4173-a20b-820177a55960",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation, deception or EU principles and values irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio, text, script, or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Besides, recommendation systems, in particular automated decision-making algorithms that disseminate and order cultural and creative content displayed to users, should be designed in such a way that their personalised suggestions are explainable and non-discriminatory. A clear explanation of the parameters used for the personalised suggestions should be easily accessible and understandable to the users. Natural persons should have a right to opt out of recommended and personalised services without affecting their right to use the core service.",
        "title":"Amendment 707: Recital 70  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"b8e386b4-6c26-457c-a8ae-c2dea718953c",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audio-visual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.",
        "title":"Amendment 708: Recital 70  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"8e912557-546c-4290-808f-44da3400bc27",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audiovisual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.",
        "title":"Amendment 709: Recital 70  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"eea6ad05-121c-4aac-bb42-f4b54203b561",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content forms part of an evidently creative, satirical, artistic or fictional cinematographic, video game visuals or analogous work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose in an appropriate, clear and visible manner that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.",
        "title":"Amendment 710: Recital 70  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"32ff5ae6-28d3-4c2c-8a17-5d86aaf0875e",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, deployers, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Additionally, the use of an AI system to generate or manipulate image, audio or video content that appreciably resembles a natural person should be permitted only when used for freedom of expression and artistic purposes and while respecting the limits of these purposes, or with the explicit consent of that person.",
        "title":"Amendment 711: Recital 70  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"29d04501-1a2b-4a81-b8e8-714b279c2f49",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.",
        "title":"Amendment 712: Recital 70  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e97dc233-6d75-493c-9af3-534b37a72006",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content is part of an obviously artistic, creative or fictional cinematographic work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose, in an appropriate, clear and visible manner, that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.",
        "title":"Amendment 713: Recital 70  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"072a28ee-e565-4ac4-ba7a-3ba55d0a4677",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.",
        "title":"Amendment 714: Recital 70  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"66da0a21-0ce9-407b-808a-c0509b398731",
        "text":"(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, AI systems used to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should systematically contain an indication on the content generated that the content has been artificially created or manipulated, and users who use such AI systems or reuse the content generated should not be allowed to remove or conceal that indication.",
        "title":"Amendment 715: Recital 70  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"d4679836-0bf2-46a9-bca9-bf21d25c1899",
        "text":"(70 a) In light of the nature and complexity of the value chain for AI systems, it is essential to clarify the role of humans who may contribute to the development of AI systems covered by this Regulation, without being providers, no longer being providers or when other natural or legal persons have also become providers. Therefore, it is particularly important to clarify the legal situation when it comes to general purpose AI systems. Those AI system are able to perform generally applicable functions such as image\/speech recognition, audio\/video generation, pattern detection, question answering or translation in a plurality of contexts. Every natural or legal person can become a new provider by adapting a general purpose AI system, already placed on the market or put into service, to a specific intended purpose. Due to their peculiar nature and in order to ensure a fair sharing of responsibilities along the AI value chain, such general purpose AI system should however already be subject to proportionate and tailored requirements and obligations under this Regulation even before placing it on the Union market or putting it into service. The original provider of a general purpose AI system should furthermore cooperate, as appropriate, with the new provider to enable its compliance with the relevant obligations under this Regulation.",
        "title":"Amendment 716: Recital 70 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2aaaa10a-5058-47c9-b24e-c861267f112d",
        "text":"(70 a) Suppliers of general purpose AI systems and, as relevant, other third parties that may supply other software tools and components, including pre-trained models and data, should cooperate, as appropriate, with providers that use such systems or components for an intended purpose under this Regulation in order to enable their compliance with applicable obligations under this Regulation and their cooperation, as appropriate, with the competent authorities established under this Regulation. In such cases, the provider may, by written agreement, specify the information or other assistance that such supplier will furnish in order to enable the provider to comply with its obligations herein.",
        "title":"Amendment 717: Recital 70 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"afa0309b-7479-4023-925d-bdbb9d0a575a",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe and fully controlled space for experimentation, while ensuring responsible innovation and integration of appropriate ethical safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Regulatory sandboxes involving activities that may impact health, safety and fundamental rights, democracy and the rule of law or the environment should be developed in accordance with redress-by-design principles. Any significant risks identified during the development and testing of such systems should result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place. The legal basis of such sandboxes should comply with the requirements established in the existing data protection framework and should be consistent with the Charter of fundamental rights of the European Union.",
        "title":"Amendment 718: Recital 71  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2942be67-3ae9-4b55-814c-09946098183a",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that benefits from clear rules and legal certainty, and requires regulatory oversight. In order to fulfill its potential to benefit society, a safe space for controlled experimentation, ensuring respect for Union law and the protection of fundamental rights, can help foster responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that promotes sustainable innovation, is future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to cooperate in establishing artificial intelligence regulatory sandboxes to facilitate the development and testing of AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.",
        "title":"Amendment 719: Recital 71  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c854f204-5b2c-48dc-92cc-571978070a41",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Member States should ensure that the regulatory sandboxes have the adequate financial and human resources for their proper functioning.",
        "title":"Amendment 720: Recital 71  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8303bbda-1426-49cb-8eee-c1da2ab21bbf",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. All other relevant actors should be encouraged to do so as well.",
        "title":"Amendment 721: Recital 71  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"90cb65c2-639f-4d31-8c6d-184b1bb0f6a2",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that safeguards fundamental rights and is innovation-friendly, future-proof and resilient to disruption, national supervisory authorities from one or more Member States could establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.",
        "title":"Amendment 722: Recital 71  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"9766f9cd-f347-4011-bfc7-ff1c1e569a52",
        "text":"(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.",
        "title":"Amendment 723: Recital 71  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"1891af2a-10d2-4ff9-91ce-a5195d90aa0f",
        "text":"(72) The objectives of the regulatory sandboxes should be to foster AI innovation for the benefit of society by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring respect for and protection of fundamental rights, compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Personal data that had originally been collected for different purposes should be processed in a sandbox only under specified conditions and within the limits of Regulation (EU) 2016\/679. Such further processing should be considered as for statistical purposes in the meaning of Article 5(1)(b) of that Regulation. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide over the suspending or banning them from participating in the sandbox, or whether to impose an administrative fine under Article 83(2) of Regulation 2016\/679 and Article 57 of Directive 2016\/680. This Regulation should also provide the legal basis for the use of data protected by intellectual property or trade-secrets for developing certain AI systems in the public interest within the AI regulatory sandbox, without prejudice to Directive (EU) 2019\/790 and to Directive (EU) 2016\/943. The authorised use of data protected by intellectual property or trade-secrets under Article 54 of this Regulation should be covered by Article 4 of Directive (EU) 2019\/790.",
        "title":"Amendment 724: Recital 72  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"651d25b1-dba8-473a-bf0f-e3eba5d0e96c",
        "text":"(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a strictly controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation, as well as with the Charter of Fundamental Rights of the European Union and the General Data Protection Regulation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, to provide safeguards needed to build trust and reliance on AI systems, to accelerate access to markets, including by removing barriers for the public sector, small and medium enterprises (SMEs) and start-ups; and to contribute to the development of ethical, socially responsible and environmentally sustainable AI systems. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. This Regulation should provide the legal basis for the use of personal data collected for other purposes for developing certain AI systems in the public interest within the AI regulatory sandbox, in line with Article 6(4) of Regulation (EU) 2016\/679, and Article 6 of Regulation (EU) 2018\/1725, and without prejudice to Article 4(2) of Directive (EU) 2016\/680. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016\/679 and Article 57 of Directive 2016\/680.",
        "title":"Amendment 725: Recital 72  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"85afd496-fa66-4b8c-a5bd-fe213e2effef",
        "text":"(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016\/679 and Article 57 of Directive 2016\/680.",
        "title":"Amendment 726: Recital 72  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"82030136-a76a-4bd9-8e0e-e3935f67b358",
        "text":"(72) The objectives of the regulatory sandboxes should be to foster AI innovation, while safeguarding fundamental rights and the values enshrined in Article 2 TFEU, by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the national supervisory authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the national supervisory authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the national supervisory authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016\/679 and Article 57 of Directive 2016\/680.",
        "title":"Amendment 727: Recital 72  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b05d82b2-34f3-4570-826a-99fbf7ec77a0",
        "text":"(72 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support and promote research and development of AI in support of socially and environmentally beneficial outcomes by allocating sufficient resources, including public and Union funding, and giving priority access to regulatory sandboxes to projects led by civil society. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts on inequality and non-discrimination, accessibility, consumer, environmental, and digital rights, as well as academics.",
        "title":"Amendment 728: Recital 72 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"f6ffa21d-e4ff-43dc-b3f7-1f0fc4e02c35",
        "text":"(73) In order to promote and protect innovation, it is important that the interests of SME providers and users of AI systems are taken into particular account. To this objective, AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high-risk, nor be prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of industry to create and roll out solutions designed to combat fraud across the Union. Furthermore, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SME providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users. Member States should also be encouraged to do the same for small and medium enterprises, which may sometimes lack the requisite administrative and legal resources to ensure proper understanding and compliance with the provisions under this act. In the event that Member States request it, the Commission may also provide assistance in this regard.",
        "title":"Amendment 729: Recital 73  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0f98a851-9e06-4bf7-a236-b397a2348068",
        "text":"(73) In order to promote and protect innovation, it is important that the interests of small-scale providers, like SMEs, micro-enterprises and users of AI systems are taken into particular account. SMEs are the backbone of the European economy and they face more challenges adapting to new legislations therefore measures should be foreseen to support them to cope with the new obligations or to exclude them from certain requirements. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.",
        "title":"Amendment 730: Recital 73  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"075aaeac-294e-40ab-a7ed-4888e56c0de3",
        "text":"(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale.",
        "title":"Amendment 731: Recital 73  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"a433a735-ad33-420f-8dea-aa6666be823a",
        "text":"(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication, and including the cooperation across borders. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers.",
        "title":"Amendment 732: Recital 73  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7b491bba-201d-4221-bb7e-503c91ec690b",
        "text":"(73) In order to promote and protect innovation, it is important that the interests of start-ups and SME providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SMEs and start-ups shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.",
        "title":"Amendment 733: Recital 73  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"511ffd14-09a1-434e-8bdf-2e9211103f46",
        "text":"(73 a) AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high risk, nor prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of the industry to create and roll out solutions designed to combat fraud across the European Union.",
        "title":"Amendment 734: Recital 73 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"a98c30d9-43c0-410b-b21b-9979d67980cb",
        "text":"(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, Member States should utilise existing dedicated channels for communication with SMEs and start-ups. Such existing channels could include but are not limited to ENISA’s Computer Security Incident Response Teams, National data protection agencies, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.",
        "title":"Amendment 735: Recital 74  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"46437c54-de07-4072-a485-70cc4456fb5f",
        "text":"(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level, as well as the ENISA, the EU Agency for Fundamental Rights, EIGE, and the European Data Protection Supervisor should constantly contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.",
        "title":"Amendment 736: Recital 74  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3fb710a4-f707-4198-9097-b4e4f179ee1d",
        "text":"(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level should contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.",
        "title":"Amendment 737: Recital 74  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"581d8f05-89ef-4417-90c7-64066296e34e",
        "text":"(76) In order to facilitate a smooth, effective and consistent implementation of this Regulation an independent European Artificial Intelligence Board should be established. The Board should be responsible for a number of tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence, including on possible amendments of the annexes, in particular the annex listing high-risk AI systems. To contribute to the effective and harmonised enforcement of this Regulation, the Board should also be able to adopt binding decisions for the settlement of cases involving two or more Member States in which the national supervisory authorities are in disagreement or when it is not clear who the lead national supervisory authority is. The Board should also be able to adopt a binding decision in those cases when a national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection.",
        "title":"Amendment 738: Recital 76  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"546f72b9-f37d-4b9e-a1d7-65a4649230cb",
        "text":"(76) In order to ensure an effective and harmonised implementation of this Regulation, to achieve a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU across the Union with regards to artificial intelligence systems, to actively support Member States, Union institutions, bodies, offices and agencies in matters pertaining to this Regulation, to reduce the fragmentation of the internal market, and to increase the uptake of artificial intelligence throughout the Union, an European Union Artificial Intelligence Office should be established. The AI Office should have legal personality, should act in full independence, and should be adequately funded and staffed. Member States should provide the strategic direction and control of the AI Office through the management board of the AI Office, alongside the Commission, the EDPS, and the FRA. An executive director should be responsible for the coordination of the AI Office’s operations and for the implementation of its work programme. Industry,start-ups and SMEs, and civil society should formally participate in the work of the AI Office through an advisory forum that should ensure varied stakeholder representation and should advise the AI Office on matters pertaining to this Regulation.",
        "title":"Amendment 739: Recital 76  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Karen Melchior, Alin Mituța"
    },
    {
        "uuid":"69f8421c-e972-42d9-bcf4-3d5e051bbd71",
        "text":"(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established. The Board should be independent and responsible for a number of advisory and enforcement tasks, including issuing decisions, opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence. In order to ensure a consistent and appropriate enforcement vis-à-vis very large undertakings, the Board should be the supervisory authority for undertakings that meet the criteria of 'community dimension' as defined in Article 1(3) of Regulation 139\/200 (Merger Regulation). The Board should have a secretariat with sufficient resources and expertise to be able to fulfil its role. In this respect, the secretariat should establish a European Centre of Excellence for Artificial Intelligence (ECE-AI).",
        "title":"Amendment 740: Recital 76  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ee4a763c-845d-47ce-b586-c5c165c1dc5a",
        "text":"(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established as a body of the Union and should have legal personality. The Board should be responsible for a number of advisory tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission and the national competent authorities on specific questions related to artificial intelligence.",
        "title":"Amendment 741: Recital 76 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"3935e4c3-3dfd-4091-a2ad-a1248a987ded",
        "text":"(76 a) An AI advisory council(‘the Advisory Council’) should be established as a sub-group of the Board consisting of relevant representatives from industry, research, academia, civil society, standardisation organisations, relevant common European data spaces, and other relevant stakeholders, including social partners, where appropriate depending on the subject matter discussed, representing all Member States to maintain geographical balance. The Advisory Council should support the work of the Board by providing advice relating to the tasks of the Board. The Advisory Council should nominate a representative to attend meetings of the Board and to participate in its work.",
        "title":"Amendment 742: Recital 76 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Radosław Sikorski,"
    },
    {
        "uuid":"3f7cfdf6-a871-4a4e-b72e-87d006f30f8c",
        "text":"(76 a) The Commission should re-establish the High Level Expert Group or a similar body with a new and balanced membership comprising an equal number of experts from SMEs and start-ups, large enterprises, academia and Research, and civil society. This new High Level Expert Group should not only act as advisory body to the Commission but also to the Board. At least every quarter, the new High Level Expert Group must have the chance to share its practical and technical expertise in a special meeting with the Board.",
        "title":"Amendment 743: Recital 76 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"10bc7b09-e840-4f1e-97d5-91ed08edae75",
        "text":"(77) Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities for the purpose of supervising the application and implementation of this Regulation. In order to increase organisation efficiency on the side of Member States and to set an official point of contact vis-à-vis the public and other counterparts at Member State and Union levels, in each Member State one national authority should be designated as national supervisory authority. In order to avoid duplication and combine expertise and competences, this should be a supervisory authority established under Regulation (EU) 2016\/679 (General Data Protection Regulation). The supervisory authorities should have sufficient investigative and corrective powers.",
        "title":"Amendment 744: Recital 77  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9f542822-2521-4f4a-be78-bb5eba5fd05d",
        "text":"(77) Each Member State should establish or designate a single national supervisory authority to act as the lead authority and be responsible for ensuring the effective coordination between the national competent authorities regarding the implementation of this Regulation. It should also represent its Member State on the Board. Each national supervisory authority should act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.",
        "title":"Amendment 745: Recital 77  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"cc263dd4-172f-49e1-b211-d6f5c2e94eb6",
        "text":"(77 a) The national supervisory authorities should monitor the application of the provisions pursuant to this Regulation and contribute to its consistent application throughout the Union. For that purpose, the national supervisory authorities should cooperate with each other, with the market surveillance authorities and with the Commission, without the need for any agreement between Member States on the provision of mutual assistance or on such cooperation.",
        "title":"Amendment 746: Recital 77 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"99e104f1-c52c-4a49-9a13-ebf2426a671f",
        "text":"(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. In view of the sensitive nature of high-risk AI systems, this post-market monitoring system should not be able to automatically send data or error reports to the supplier via the AI system. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.",
        "title":"Amendment 747: Recital 78  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"aa3fcaa6-e673-4f46-a81f-5c4dfa6e9bde",
        "text":"(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law, including those protecting fundamental rights and consumer rights, resulting from the use of their AI systems.",
        "title":"Amendment 748: Recital 78  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ac9c560b-cba8-44ed-b737-37036fc2f652",
        "text":"(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.",
        "title":"Amendment 749: Recital 78  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"906f9d21-a842-46bc-b9c2-0077062ae065",
        "text":"(79) In order to ensure an appropriate and effective enforcement of the requirements and obligations set out by this Regulation, which is Union harmonisation legislation, the system of market surveillance and compliance of products established by Regulation (EU) 2019\/1020 should apply in its entirety. Where necessary for their mandate, national public authorities or bodies, which supervise the application of Union law protecting fundamental rights, including equality bodies, should also have access to any documentation created under this Regulation. A reasonable suspicion of breach of fundamental rights, which may arise from a complaint from an individual or a notification of a breach submitted by a civil society organisation, should be deemed as a sufficient reason for the commencement of an evaluation of an AI system at national level.",
        "title":"Amendment 750: Recital 79  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ea5f8c38-9ef8-4688-832c-66e6af5c0f4f",
        "text":"(79 a) As the rights and freedoms of individuals can be seriously undermined by AI systems, it is essential that affected individuals have meaningful access to reporting and redress mechanisms. They should be able to report infringements of this Regulation to their national supervisory authority and have the right to be heard and to be informed about the outcome of their complaint and the right to a timely decision. In addition, they should have the right to an effective remedy against competent authorities who fail to enforce these rights and the right to redress. Where applicable, deployers should provide internal complaints mechanisms to be used by affected individuals and should be liable for pecuniary and non-pecuniary damages in cases of breaches of individuals’ or groups’ rights. Collective representation of affected individuals must be possible.",
        "title":"Amendment 751: Recital 79 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ec0061e0-b1fe-49e9-b4b2-bf69711d3739",
        "text":"(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013\/36\/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013\/36\/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013\/36\/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits .' '56 Directive 2013\/36\/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002\/87\/EC and repealing Directives 2006\/48\/EC and 2006\/49\/EC (OJ L 176, 27.6.2013, p. 338).",
        "title":"Amendment 752: Recital 80  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"99034bff-4373-499f-b637-c5a11875bf3e",
        "text":"(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013\/36\/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013\/36\/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013\/36\/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits.' '56 Directive 2013\/36\/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002\/87\/EC and repealing Directives 2006\/48\/EC and 2006\/49\/EC (OJ L 176, 27.6.2013, p. 338).",
        "title":"Amendment 753: Recital 80  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"26f924c0-0c5d-40b2-b494-079177ddafcd",
        "text":"(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013\/36\/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013\/36\/EU.' '56 Directive 2013\/36\/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002\/87\/EC and repealing Directives 2006\/48\/EC and 2006\/49\/EC (OJ L 176, 27.6.2013, p. 338).",
        "title":"Amendment 754: Recital 80  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e147e826-6767-487c-8c98-ceb046be0cb4",
        "text":"(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the competent authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the competent authorities as defined in Directive 2013\/36\/EU of the European Parliament and of the Council, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, excluding market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013\/36\/EU of the European Parliament and of the Council56, it is also appropriate to integrate certain aspects of the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013\/36\/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013\/36\/EU.' '56 Directive 2013\/36\/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002\/87\/EC and repealing Directives 2006\/48\/EC and 2006\/49\/EC (OJ L 176, 27.6.2013, p. 338).",
        "title":"Amendment 755: Recital 80  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1a048d44-e068-4b0f-9d77-0405ded96241",
        "text":"(80 a) Where the national market surveillance authority has not taken measures against an infringement to this Regulation, the Commission should be in possession of all the necessary resources, in terms of staffing, expertise, and financial means, for the performance of its tasks instead of the national market surveillance authority under this Regulation. In order to ensure the availability of the resources necessary for the adequate investigation and enforcement measures that the Commission could undertake under this Regulation, the Commission should charge fees on national market surveillance authorities, the level of which should be established on a case-by-case basis. The overall amount of fees charged should be established on the basis of the overall amount of the costs incurred by the Commission to exercise its investigation and enforcement powers under this Regulation. Such an amount should include costs relating to the exercise of the specific powers and tasks connected to Chapter 4 of Title VIII of this Regulation. The external assigned revenues resulting from the fees could be used to finance additional human resources, such as contractual agents and seconded national experts, and other expenditure related to the fulfilment of these tasks entrusted to the Commission by this Regulation.",
        "title":"Amendment 756: Recital 80 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"379ecb92-e8b9-4885-8d31-1ee1200deead",
        "text":"(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy, and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.",
        "title":"Amendment 757: Recital 81  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"ff7a0cd0-48d1-4972-95bd-2466821a19fe",
        "text":"(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.",
        "title":"Amendment 758: Recital 81  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Christel Schaldemose"
    },
    {
        "uuid":"f0007c3e-88c1-451f-adf8-22e30bdb7cfc",
        "text":"(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems or risk-appropriate codes of conduct that sufficiently increase trust in the underlying technology that is not high-risk. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.",
        "title":"Amendment 759: Recital 81  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"894248d0-400d-4219-bbb6-7f001c85c097",
        "text":"(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to energy efficiency, resource use and waste production, and environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity, equal representation and gender-balance of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.",
        "title":"Amendment 760: Recital 81  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"04de2418-4fa2-45ad-8e26-e9c46517781a",
        "text":"(82) It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out for high-risk AI systems are nevertheless safe when placed on the market or put into service. To contribute to this objective, the Directive 2001\/95\/EC of the European Parliament and of the Council57 would apply as a safety net.' '57 Directive 2001\/95\/EC of the European Parliament and of the Council of 3 December 2001 on general product safety (OJ L 11, 15.1.2002, p. 4).",
        "title":"Amendment 761: Recital 82  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1ea86895-7a7b-421d-98ea-98c7c17d9d6c",
        "text":"(83) In order to ensure trustful and constructive cooperation of competent authorities on Union and national level, all parties involved in the application of this Regulation should aim for transparency and openness. Where necessary for individual cases and internal deliberations, they should also respect the confidentiality of information and data obtained in carrying out their tasks.",
        "title":"Amendment 762: Recital 83  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fe966a5b-6295-4d5e-b560-7b06c3f4ed55",
        "text":"(84) Member States should take all necessary measures to ensure that the provisions of this Regulation are implemented, including by laying down effective, proportionate and dissuasive penalties for their infringement. For certain specific infringements, Member States should take into account the margins and criteria set out in this Regulation. The European Data Protection Supervisor should have the power to impose fines on Union institutions, agencies and bodies falling within the scope of this Regulation. The penalties and litigation costs under this Regulation should not be subject to contractual clauses or any other arrangements.",
        "title":"Amendment 763: Recital 84  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"d9832677-eb11-4b0a-8a81-0824bec4dd18",
        "text":"(84 a) In order to strengthen and harmonise administrative penalties for infringements of this Regulation, each national supervisory authority should have the power to impose administrative fines. This Regulation should indicate infringements and the upper limit for setting the related administrative fines, which should be determined by the national supervisory authority in each individual case, taking into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and the measures taken to ensure compliance with the obligations under this Regulation and to prevent or mitigate the consequences of the infringement.",
        "title":"Amendment 764: Recital 84 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4925d838-be3a-41cd-a745-b2b89fb51275",
        "text":"(84 a) An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf. To this end, Directive 2020\/1828\/EC on Representative Actions for the Protection of the Collective Interests of Consumers should be amended to include this Regulation among the provisions of Union law falling under its scope.",
        "title":"Amendment 765: Recital 84 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"06d8739b-9543-45f4-b55b-59bb0ba65e1e",
        "text":"(84 a) Union legislation on the protection of whistleblowers (Directive (EU) 2019\/1937) has full application to academics, designers, developers, project contributors, auditors, product managers, engineers and economic operators acquiring information on breaches of Union law by a provider of AI system or its AI system, even if they are not explicitly mentioned in Article 4(1)a-4(1)d of that Directive.",
        "title":"Amendment 766: Recital 84 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9c42649c-48cc-4503-b228-1834bbeae807",
        "text":"(84 b) Natural persons, affected by an AI system falling within the scope of this Regulation, should have the right to lodge a complaint against the providers or users of such AI system with a national supervisory authority, if they consider that their fundamental rights, health or safety have been breached. An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf.",
        "title":"Amendment 767: Recital 84 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"27d8fe9b-ec69-4c8b-b046-5b1e08dc7354",
        "text":"(84 b) Union legislation on consumer protection(notably Directives (EU) 2019\/2161, 2005\/29\/EC,2011\/83\/EU) applies to AI systems to the extent determined in these legislations, regardless of whether these systems are categorized as high-risk.",
        "title":"Amendment 768: Recital 84 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9b32fd8c-719e-41b9-a9eb-d925f07a4dc0",
        "text":"(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. As the purpose of delegating that power is to allow this Regulation to be adapted to technical advancements, the Commission should only be able to adopt such delegated acts to include non-restrictive additions or clarifications in the lists in those Annexes, whereas deletions, restrictive clarifications or amendments to the definitions of the items in those Annexes should only result from the adoption of amending regulations. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016 p.1.",
        "title":"Amendment 769: Recital 85  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"cbf7d41d-8825-4f2b-b440-ce8450276982",
        "text":"(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II and the content of the EU declaration of conformity in Annex V. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.",
        "title":"Amendment 770: Recital 85  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"1dbd791b-bc62-4f18-9762-fa3706ea3c9d",
        "text":"(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . These consultations should involve the participation of a balanced selection of stakeholders, including consumer organisations, associations representing affected persons, businesses representatives from different sectors and sizes, as well as researchers and scientists. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.",
        "title":"Amendment 771: Recital 85  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7699e3f5-ce9e-4625-95e5-d921d18c30ea",
        "text":"(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V and the provisions regarding the conformity assessment procedures in Annex VI and VII. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.",
        "title":"Amendment 772: Recital 85  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"184892d5-ed56-418c-92d4-e5cf9dc6d1dc",
        "text":"(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including with industry, civil society, other stakeholders, and at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.",
        "title":"Amendment 773: Recital 85  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"f4461962-ee3d-48e1-968d-d6613fd5d864",
        "text":"(86 a) Given the rapid technological developments and the required technical expertise in conducting the assessment of high-risk AI systems, the Commission should regularly review Annex III, at least every six months, while consulting with the relevant stakeholders, including ethics experts and anthropologists, sociologists, mental health specialists and any relevant scientists and researchers.",
        "title":"Amendment 774: Recital 86 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6c394c2b-9439-419d-a7c3-699275456c7f",
        "text":"(86 a) In order to ensure uniform conditions for the implementation of this Regulation, it should be accompanied by the publication of guidelines to help all stakeholders to interpret key concepts covered by the Regulation, such as prohibited or high-risk AI cases and the precise means and implementation rules of the Regulation by national competent authorities;",
        "title":"Amendment 775: Recital 86 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"13db4f74-93c5-4b8d-8dd3-5c07b57d327d",
        "text":"(86 b) When adopting delegated or implementing acts concerning high-risk sectors of AI development, notably those raising concerns with respect to ethical principles or entailing risks to the health or safety of humans, animals or plants, or the protection of the environment, Member States should also assume greater responsibility in the decision-making process. In particular, the abstentions of Member States representatives’ should be counted within a qualified majority, each Member State representative should give substantive reasons for votes and abstentions, each of their vote and abstention should be accompanied by a detailed justification, on the basis of Regulation XX\/XX amending Regulation (EU) No 182\/2011.",
        "title":"Amendment 776: Recital 86 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ca4c2d41-7034-4b2c-b90e-e61f5bf2f09a",
        "text":"(87 a) As reliable information on the resource and energy use, waste production and other environmental impact of AI systems and related ICT technology, including software, hardware and in particular data centres, is limited, the Commission should evaluate the impact and effectiveness of this Regulation regarding these criteria and further evaluate bringing legislation for the sector to contribute to EU climate strategy and targets.",
        "title":"Amendment 777: Recital 87 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b51a3400-f6e3-46ed-833d-21b4d5c21ed6",
        "text":"(89) The European Data Protection Supervisor and the European Data Protection Board were consulted in accordance with Article 42(2) of Regulation (EU) 2018\/1725 and delivered an opinion on 18.6.2021”.",
        "title":"Amendment 778: Recital 89  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1ab40ca5-a4bb-4276-b6c8-5147bcad24e0",
        "text":"1 Aim and subject matter",
        "title":"Amendment 779: Article 1 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"69809cac-6b53-4dcd-8401-086d058306d1",
        "text":"-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 TEU from harmful effects of artificial intelligence systems in the Union while promoting innovation.",
        "title":"Amendment 780: Article 1 – paragraph -1 (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9e464390-b33f-46fe-a074-19422025b0da",
        "text":"-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, fundamental rights and the environment, from harmful effects of artificial intelligence systems (\"AI systems\") in the Union, while enhancing innovation.",
        "title":"Amendment 781: Article 1 – paragraph -1 (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0a2c7f1f-460d-490a-8cf4-b67975861762",
        "text":"-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, and fundamental rights from harmful effects of artificial intelligence systems (\"AI systems\") in the Union, while enhancing innovation.",
        "title":"Amendment 782: Article 1 – paragraph -1 (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"24c55b77-e76a-415d-887a-04152dda678d",
        "text":"1.The purpose of this Regulation is to ensure a high level of protection of public interests, such as health, safety, fundamental rights, the environment and democracy from harmful effects of artificial intelligence systems (\"AI systems\") in the Union, whether individual, societal or environmental, while enhancing innovation.Its provisions are underpinned by the precautionary principle.', 'This Regulation lays down:",
        "title":"Amendment 783: Article 1 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"eb3e8b5c-95c7-441e-afb2-85ab8352c5c8",
        "text":"The purpose of this Regulation is to ensure a high level of protection of fundamental rights, health, safety and the environment from harmful effects of the use of artificial intelligence systems in the Union while enhancing innovation. This Regulation lays down:",
        "title":"Amendment 784: Article 1 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"271b0c2f-770d-466f-a732-e92002d3cfc5",
        "text":"(a) harmonised minimum rules for the development of human-centric AI in the Union through the placing on the market, putting into service and use of artificial intelligence systems (‘AI systems’);",
        "title":"Amendment 785: Article premier – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"214e9da7-432f-436c-ab50-c2d938e32fab",
        "text":"(a) harmonised rules for the placing on the market, the development, the putting into service, the deployment and the use of human-centric and trustworthy artificial intelligence systems (‘AI systems’) in the Union;",
        "title":"Amendment 786: Article 1 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4fcad55d-f9a7-4d03-a401-c99a5e7086de",
        "text":"(a) harmonised rules for the placing on the market, the putting into service and the use of safe and trustworthy artificial intelligence systems (‘AI systems’) in the Union;",
        "title":"Amendment 787: Article 1 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"03d068e9-5e82-4078-8df1-89af2aee1d83",
        "text":"(a) harmonised rules for the development, placing on the market, the putting into service and the use of artificial intelligence systems (‘AI systems’) in the Union;",
        "title":"Amendment 788: Article 1 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d4c1e480-b650-48cd-bb0d-453c323a492a",
        "text":"(a) harmonised rules for the development, placing on the market, the putting into service and the use of artificial intelligence systems (‘AI systems’) in the Union;",
        "title":"Amendment 789: Article 1 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"e2af298b-139f-4958-bf91-f1b1f6ebcdc1",
        "text":"(a a) principles applicable to all AI systems;",
        "title":"Amendment 790: Article 1 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"d3981dd4-86ff-4c85-b051-5539debbccef",
        "text":"(c) specific requirements for high-risk AI systems and obligations for operators of such systems, unless these systems are already covered by sector-specific regulation;",
        "title":"Amendment 791: Article 1 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e8af5900-0e35-4af3-81ef-f71ef492c197",
        "text":"(c a) harmonised rules on high-risk AI systems to ensure a high level of trustworthiness and protection of fundamental rights, health and safety, the Union values enshrined in Article 2 TEU and the environment;",
        "title":"Amendment 792: Article 1 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"79a20bf6-8379-4a4c-a5e3-79915bd4c29b",
        "text":"(c a) harmonised rules on high-risk AI systems to ensure a high level of trustworthiness and protection of fundamental rights, health and safety",
        "title":"Amendment 793: Article 1 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"0834eca0-fa8a-40de-8e42-0eed28b5ed51",
        "text":"(d) harmonised transparency rules for AI systems;",
        "title":"Amendment 794: Article 1 – paragraph 1 – point d  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"7b2174e5-a5b5-4a8d-af00-0fb3b8196824",
        "text":"(d) harmonised transparency rules for AI systems;",
        "title":"Amendment 795: Article 1 – paragraph 1 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"44dcda6e-9a27-4778-b721-6455fb541e97",
        "text":"(d) harmonised transparency rules for certain AI systems;",
        "title":"Amendment 796: Article 1 – paragraph 1 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"2db646bd-3d40-491a-bd40-df413075bb67",
        "text":"(e) rules on market monitoring, market surveillance and governance;', '.",
        "title":"Amendment 797: Article 1 – paragraph 1 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"35d5f201-892f-4182-9ea7-957fc0a7974e",
        "text":"(e) rules on market monitoring, market surveillance and enforcement.",
        "title":"Amendment 798: Article 1 – paragraph 1 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"922a37d4-54ad-4244-9e2a-7ebed283a5c9",
        "text":"(e) rules on market monitoring, market surveillance and governance;",
        "title":"Amendment 799: Article 1 – paragraph 1 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d43f6888-8f6a-4b51-8d9f-3182677568a5",
        "text":"(e a) measures in support of innovation with a particular focus on SMEs and start-ups, including but not limited to setting up regulatory sandboxes and targeted measures to reduce the compliance burden on SME’s and start-ups;",
        "title":"Amendment 800: Article 1 – paragraph 1 – point e a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7e9d7e31-634b-4487-b924-483fa6d369c8",
        "text":"(e a) measures to support innovation and provide for a level playing field for European providers of AI systems on international level, in particular for small-scale providers like SMEs.",
        "title":"Amendment 801: Article 1 – paragraph 1 – point e a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"cb1f4039-8ab3-48d7-9426-7b48013a8233",
        "text":"(e a) measures in support of innovation with a particular focus on SMEs and start-ups, including the setting up of regulatory sandboxes and the reduction of regulatory burdens.",
        "title":"Amendment 802: Article 1 – paragraph 1 – point e a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten"
    },
    {
        "uuid":"4fccde3e-4382-482e-8d45-d3b2da6cb68b",
        "text":"(e a) rules for the establishment and functioning of the European Union Artificial Intelligence Office;",
        "title":"Amendment 803: Article 1 – paragraph 1 – point e a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b7cad993-b749-49d5-8ec2-55f57953fd82",
        "text":"(e a) measures in support of innovation particularly focusing on SMEs and start-ups.",
        "title":"Amendment 804: Article 1 – paragraph 1 – point e a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"5db2fd6e-56a6-4e74-8934-496ebadde78f",
        "text":"(e b) measures in support of innovation, including the setting up of regulatory sandboxes, and measures to reduce the regulatory burden on SMEs and start-ups.",
        "title":"Amendment 805: Article 1 – paragraph 1 – point e b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"3227a873-8087-46c3-88fb-81c09ea95c42",
        "text":"(e b) the establishment of an independent ‘European Artificial Intelligence Board’ and its activities supporting the enforcement of this Regulation.",
        "title":"Amendment 806: Article 1 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bbc2ee63-320d-446c-9cfc-a33d773f7ac7",
        "text":"This Regulation is based on the principle that it is for developers, importers, distributors and users to ensure that they develop, place on the market or use AI systems that do not adversely affect health, safety, or fundamental rights. Its provisions are underpinned by the precautionary principle.",
        "title":"Amendment 807: Article 1 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"1cb7d8a0-93d0-4c9e-89b7-0b05ae28e394",
        "text":"When justified by significant risks to fundamental rights of persons, including the protection of consumer rights, Member States may introduce regulatory solutions ensuring a higher level of protection of persons than offered in this Regulation.",
        "title":"Amendment 808: Article 1 – paragraph 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"963e9a67-4d17-4c06-8f39-6bb75998eeab",
        "text":"The purpose of this Regulation is to ensure protection of health, safety, fundamental rights and the environment, from harmful effects of artificial intelligence systems in the Union, while supporting innovation.",
        "title":"Amendment 809: Article 1 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a92dc68d-b3ae-4595-a9f7-56cec57a5d45",
        "text":"These provisions shall apply to AI systems as a product, service or practice, or as part of a product, service or practice.",
        "title":"Amendment 810: Article 1 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5f0890b4-9a91-4fa3-b3e3-79ef3ffbdd89",
        "text":"This Regulation shall be applied taking due account of the precautionary principle.",
        "title":"Amendment 811: Article 1 – paragraph 1 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"ec6ec526-ea31-4ee2-905c-5a9ce6c16727",
        "text":"This Regulation is based on the principle that it is for developers, importers, distributors and downstream users to ensure that they develop, place on the market or use artificial intelligence that does not adversely affect health, safety, fundamental rights, and the environment. Its provisions are underpinned by the precautionary principle.",
        "title":"Amendment 812: Article 1 – paragraph 1 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e0b2be37-bd32-4130-bc15-9d308c014cc4",
        "text":"This Regulation is based on the principle that it is for developers, importers, distributors and downstream users to ensure that they develop, place on the market or use artificial intelligence that does not adversely affect health, safety, fundamental rights, or the environment. Its provisions are underpinned by the precautionary principle.",
        "title":"Amendment 813: Article 1 – paragraph 1 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c77aee77-dbfd-4bcd-88b6-2c2ca6c714bc",
        "text":"Any processing of personal data for the purposes of this Regulation shall take place in accordance with Union legislation for the protection of personal data, in particular Regulation 2016\/679, Directive 2016\/680, Regulation 2018\/1725 and Directive 2002\/58.",
        "title":"Amendment 814: Article 1 – paragraph 1 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"613b7394-661a-4133-bf8e-836055b68016",
        "text":"(a) providers placing on the market, developing, putting into service or deploying AI systems in the Union, irrespective of whether those providers are established within the Union or in a third country;",
        "title":"Amendment 815: Article 2 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"60f85da8-b528-496e-8f14-bee8718df4f3",
        "text":"(a) operators placing on the market or putting into service AI systems in the Union, irrespective of whether those operators are established within the Union or in a third country;",
        "title":"Amendment 816: Article 2 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4552404d-b2df-4c5e-89f9-1af66343b78c",
        "text":"(a a) providers of AI systems that have their main establishment in the EU;",
        "title":"Amendment 817: Article 2 – paragraph 1 – point a a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"52d02cd5-4764-4846-9ff9-083ac0f5339f",
        "text":"(b) users of AI systems who are physically present or established within the Union;",
        "title":"Amendment 818: Article 2 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0833b6ad-6604-4f6e-9b47-10d0e71d53d8",
        "text":"(b) deployers of AI systems located or established within the Union;",
        "title":"Amendment 819: Article 2 – paragraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"e9b8d8de-99e7-4f5f-8904-2bc49a872ab0",
        "text":"(b) users of AI systems who are established within the Union;",
        "title":"Amendment 820: Article 2 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-"
    },
    {
        "uuid":"5233ddaf-c23d-41a5-9877-3a9ddfbd1b8c",
        "text":"(b) users of AI systems that are located within the Union;",
        "title":"Amendment 821: Article 2 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"036494f3-d80a-49bd-aa8e-de014a2d0362",
        "text":"(b) users of AI systems using the AI system in the Union;",
        "title":"Amendment 822: Article 2 – paragraph 1 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"0e5875dc-cdd8-4138-a4a2-a6f0b5b91a28",
        "text":"(b a) natural persons affected by the use of AI systems;",
        "title":"Amendment 823: Article 2 – paragraph 1 – point b a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"03c9739a-f15f-4424-a49f-30f3178a45cf",
        "text":"(c) providers and users of AI systems that are located in a third country, where the output, meaning predictions, recommendations or decisions, produced by the AI system and influencing the environment it interacts with, is intended for use in the Union and puts at risk the health, safety or fundamental rights of natural persons physically present in the Union, insofar as the provider has permitted, is aware or can reasonably expect such use;",
        "title":"Amendment 824: Article 2 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5ae494fd-c0f0-46bf-ab21-df1905d766a0",
        "text":"(c) providers and users of AI systems that are located in a third country, where the output produced by the system is used in the Union or affects natural persons within the Union;",
        "title":"Amendment 825: Article 2 – paragraph 1 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3bee60c5-1809-4c4d-a72b-d75701ff10c7",
        "text":"(c) providers and users of AI systems that are located in a third country, where the output produced by the system is used in the Union or has effects in the Union;",
        "title":"Amendment 826: Article 2 – paragraph 1 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"1fd579a5-81fd-4469-a916-094ae632fcdb",
        "text":"(c) providers and users of AI systems who are established in a third country, where the output produced by the system is used in the Union;",
        "title":"Amendment 827: Article 2 – paragraph 1 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"fdf97083-2883-47c4-9e1f-00fcca201587",
        "text":"(c a) public authorities in a third country or to international organisations where those authorities or organisations use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.",
        "title":"Amendment 828: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"65baaf06-6936-4ff1-8e65-5a1632d0d35e",
        "text":"(c a) importers, distributors, and authorised representatives of providers of AI systems;",
        "title":"Amendment 829: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"fa6a7b73-61f1-4100-9283-e2569655a2f4",
        "text":"(c a) importers, distributors and authorised representatives of providers of AI-systems.",
        "title":"Amendment 830: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e75cba28-b333-4a7f-ab01-f912e0c77d14",
        "text":"(c a) natural persons, affected by the use of an AI system, who are in the Union;",
        "title":"Amendment 831: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9947a3c0-a05f-48ca-a7b0-94f1aa965f22",
        "text":"(c a) natural persons, affected by the use of an AI system, who are in the Union;",
        "title":"Amendment 832: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"242916cd-335d-4bda-a4bc-0ff299b21126",
        "text":"(c a) importers and distributors of AI systems;",
        "title":"Amendment 833: Article 2 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"550f313d-cf51-465a-956e-eefae2c2d4f1",
        "text":"(c b) product placing on the market or putting into service an AI system together with their product and under their own name or trademark;",
        "title":"Amendment 834: Article 2 – paragraph 1 – point c b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"11695b90-51d0-46fb-a9d8-9d9c97058721",
        "text":"(c b) providers placing on the market or putting into service AI systems outside the Union where the provider is located within the Union;",
        "title":"Amendment 835: Article 2 – paragraph 1 – point c b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0a240edc-491e-48b9-a5d5-6e272dcafa41",
        "text":"(c b) AI systems as a product, service or practice, or as part of a product, service or practice.",
        "title":"Amendment 836: Article 2 – paragraph 1 – point c b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"be2db461-ebdf-4b85-8c8e-48495a25dbb0",
        "text":"(c c) authorised representatives of providers, which are established in the Union.",
        "title":"Amendment 837: Article 2 – paragraph 1 – point c c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"c9462e88-e4da-4c71-bb06-11a5b60a96b1",
        "text":"1 a. providers placing on the market or putting into service AI systems in a third country where the provider or distributor of such AI systems originates from the Union;",
        "title":"Amendment 838: Article 2 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2dda2797-346e-4f56-8278-a68aab40a3bf",
        "text":"1 a. This Regulation shall also apply to Union institutions, offices and agencies where they develop, deploy or otherwise make use of AI systems.",
        "title":"Amendment 839: Article 2 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"897dc06a-e95c-4977-9479-18a6d5f5a3a2",
        "text":"1 a. This Regulation shall apply to Union institutions, offices, bodies and agencies when acting as an operator of an AI system.",
        "title":"Amendment 840: Article 2 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e558cf6c-d565-4eb4-84e4-1425c82ea623",
        "text":"deleted",
        "title":"Amendment 841: Article 2 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"35c8a862-00a6-4df4-8cfe-05074764eada",
        "text":"2. In order to ensure legal certainty, preserve the existing legislation and avoid duplication, only Article 84 of this Regulation shall apply for high-risk AI systems that are safety components of products or systems, or which are themselves products or systems, falling within the scope of the following acts:",
        "title":"Amendment 842: Article 2 – paragraph 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"a2620ee3-ae5f-488c-8a39-b86efa7b33f9",
        "text":"2. For high-risk AI systems that are safety components of products or systems, or which are themselves products or Systems and that fall within the scope of the listed Acts in Annex II - Section B, only Article 84 of this Regulation shall apply.",
        "title":"Amendment 843: Article 2 – paragraph 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2357a5a1-641b-40bf-b8fb-ef34d0c49432",
        "text":"2. For AI systems classified as high-risk AI in accordance with Article 6 related to products covered by Union harmonisation legislation listed in Annex II, section B only Article 84 of this Regulation shall apply.",
        "title":"Amendment 844: Article 2 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"25507501-a562-48d1-acb8-f536e9b5ca9f",
        "text":"deleted",
        "title":"Amendment 845: Article 2 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"bf2b0333-fd63-406f-878a-b89928733f57",
        "text":"deleted",
        "title":"Amendment 846: Article 2 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"841cb144-8eac-4f32-ad25-499ce80f3ae9",
        "text":"deleted",
        "title":"Amendment 847: Article 2 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"1c0296c8-9c6b-48ab-b334-c7c45a892451",
        "text":"deleted",
        "title":"Amendment 848: Article 2 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6c964b22-8f89-42d3-8357-093ea93cc93a",
        "text":"deleted",
        "title":"Amendment 849: Article 2 – paragraph 2 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"2607b4cd-8c2c-4673-be90-eb7666985c7f",
        "text":"deleted",
        "title":"Amendment 850: Article 2 – paragraph 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"19d1a4fd-5d5a-4aec-bda6-a59f919bdfc6",
        "text":"deleted",
        "title":"Amendment 851: Article 2 – paragraph 2 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"5754d879-e2d3-47c5-b950-130d5bae2b12",
        "text":"deleted",
        "title":"Amendment 852: Article 2 – paragraph 2 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"18cc8fc0-fb7a-4156-8a86-2dd7a28908c4",
        "text":"deleted",
        "title":"Amendment 853: Article 2 – paragraph 2 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"96b8b824-2ec6-4af9-a00a-172a7089d18f",
        "text":"deleted",
        "title":"Amendment 854: Article 2 – paragraph 2 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2c5b0613-9584-4aff-ab8f-d412670dcf25",
        "text":"deleted",
        "title":"Amendment 855: Article 2 – paragraph 2 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"94d1334c-54e8-4046-accd-049c640ff906",
        "text":"deleted",
        "title":"Amendment 856: Article 2 – paragraph 2 – point f  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"604ef0c6-3dc8-427b-aa29-5a43aefe7c68",
        "text":"deleted",
        "title":"Amendment 857: Article 2 – paragraph 2 – point g  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"56e21fe4-aa4c-4747-846f-e32ea5bbfadb",
        "text":"deleted",
        "title":"Amendment 858: Article 2 – paragraph 2 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"97c04fd8-50ca-4686-903a-1f534a68fbcc",
        "text":"deleted",
        "title":"Amendment 859: Article 2 – paragraph 2 – point h  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c3d6ab2e-ff70-41f2-8e80-bdd36fa3a39e",
        "text":"deleted",
        "title":"Amendment 860: Article 2 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"21acbd3e-508c-4f35-bab6-b4e15338955d",
        "text":"2 a. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of scientific research and development.",
        "title":"Amendment 861: Article 2 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"30635cf3-12cd-44a8-9c11-8920291c2f9c",
        "text":"2 a. AI systems likely to interact with or impact on children shall be considered high-risk for this group;",
        "title":"Amendment 862: Article 2 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Milan Brglez, Hilde Vautmans, Catharina Rinzema"
    },
    {
        "uuid":"11561e23-e466-44c9-b870-5d2ab8355ebe",
        "text":"2 b. This Regulation shall not apply to any research and development activity regarding AI systems in so far as such activity does not lead to or entail placing an AI system on the market or putting it into service.",
        "title":"Amendment 863: Article 2 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"4d3082e9-3a36-4b48-ae74-50e618b27da4",
        "text":"deleted",
        "title":"Amendment 864: Article 2 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"286850e0-ebfa-4f9a-9fe4-2a9e245b6598",
        "text":"deleted",
        "title":"Amendment 865: Article 2 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"48b26e60-f274-4057-a346-40e67e8ded2a",
        "text":"deleted",
        "title":"Amendment 866: Article 2 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"02a7ddc1-4246-46d0-b8ca-3dcdf3f09987",
        "text":"3. This Regulation shall not apply to AI systems developed or used exclusively for military purposes.', 'However, this Regulation shall apply to AI systems which are developed or used as dual-use items, as defined in Article 2, point (1) of Regulation (EU) 2021\/821 of the European Parliament and of the Council1a.' '1a Regulation (EU) 2021\/821 of the European Parliament and of the Council of 20 May 2021 setting up a Union regime for the control of exports, brokering, technical assistance, transit and transfer of dual-use items (OJ L 206, 11.6.2021, p. 1).",
        "title":"Amendment 867: Article 2 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"20e5cc16-7080-4261-8d73-5bf0865fa452",
        "text":"3. This Regulation shall not apply to AI systems developed or used exclusively for military purposes, unless the AI system is subsequently used for non-military purposes.",
        "title":"Amendment 868: Article 2 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"0d04a336-e99f-467f-b719-05e7d9a4478f",
        "text":"3. This Regulation shall not apply to AI systems developed or used exclusively for military or national security purposes",
        "title":"Amendment 869: Article 2 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"39bfced8-a1b0-4a89-8217-2cb21ff71775",
        "text":"3. This Regulation shall not apply to AI systems designed, modified, developed or used exclusively for military purposes.",
        "title":"Amendment 870: Article 2 – paragraph 3  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo"
    },
    {
        "uuid":"92004af2-612a-46aa-b608-dfbfc7ccab14",
        "text":"3. This Regulation shall not apply to AI systems developed or used for military purposes.",
        "title":"Amendment 871: Article 2 – paragraph 3  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"dd7fbf34-b68f-4938-9553-7a685447ed5e",
        "text":"3 a. Union law on the protection of personal data, privacy and the confidentiality of communications applies to personal data processed in connection with the rights and obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU) 2016\/679, (EU) 2018\/1725 or Directives 2002\/58\/EC and (EU) 2016\/680.",
        "title":"Amendment 872: Article 2 – paragraph 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4c979f8b-e624-42f8-bfaf-f1b90685cf8c",
        "text":"3 a. Any exemptions from the application of this Act to AI systems used exclusively by Member States for national security purposes will be without prejudice to the application of Union law to any activity carried out by the Union or by a Member State that is subject to Union law.",
        "title":"Amendment 873: Article 2 – paragraph 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"29b0e1d1-989e-42c4-8728-4e6314dab2da",
        "text":"3 a. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of research and development.",
        "title":"Amendment 874: Article 2 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e45953b4-77a6-4020-bbf5-4a14f926d7aa",
        "text":"3 a. Title III of this Regulation shall not apply to AI systems that are used in a business-to-business environment and do not directly impact natural persons.",
        "title":"Amendment 875: Article 2 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3b948dff-63e6-4e00-8433-aa3e2b803f2c",
        "text":"3 a. This Regulation shall apply to Union institutions, offices, bodies and agencies when acting as an operator of an AI system.",
        "title":"Amendment 876: Article 2 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8e183fd3-5b4a-4439-8f46-b1eec3355e42",
        "text":"deleted",
        "title":"Amendment 877: Article 2 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"0dbe8ee2-e415-435d-a759-65e6782e17c8",
        "text":"deleted",
        "title":"Amendment 878: Article 2 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8f4e6647-1604-4367-882c-d4b65160eda5",
        "text":"deleted",
        "title":"Amendment 879: Article 2 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"64eea284-4cb3-46eb-a387-561de4b13ae7",
        "text":"deleted",
        "title":"Amendment 880: Article 2 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"96d00330-48c7-4345-ba8b-76f4827b8cd0",
        "text":"deleted",
        "title":"Amendment 881: Article 2 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"beb5ca76-e4cc-4693-be9e-d52b3b5d9dd8",
        "text":"deleted",
        "title":"Amendment 882: Article 2 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"183f8fbf-197a-4077-95d6-5704eb817d89",
        "text":"4. This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States and are subject of a decision of the Commission adopted in accordance with Article 36 of Directive (EU)2016\/680 or Article 45 of Regulation 2016\/679 (‘adequacy decision’) or are part of an international agreement concluded between the Union and that third country or international organisation pursuant to Article 218 TFEU adducing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals;",
        "title":"Amendment 883: Article 2 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"6571bcfb-1e4e-40ca-84ae-c7e80f8406b1",
        "text":"4. This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international cooperation or agreements for law enforcement and judicial cooperation or in the context of border checks, asylum and immigration related activities with the Union or with one or more Member States.",
        "title":"Amendment 884: Article 2 – paragraph 5 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki"
    },
    {
        "uuid":"3965b1c1-15fd-4305-8079-2fe35f252083",
        "text":"5 a. The use of any AI-system that is in line with this Regulation, should also continue to comply with the European Charter on Fundamental Rights, secondary Union law and national law. This Regulation shall not provide the legal ground for unlawful AI development, deployment or use.",
        "title":"Amendment 885: Article 2 – paragraph 5 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7608807d-e343-4b2d-bb86-549fe8ec7037",
        "text":"5 a. An AI-system or practice that is in line with this Regulation, should also continue to comply with the European Charter on Fundamental Rights, existing and new secondary Union law and national law.",
        "title":"Amendment 886: Article 2 – paragraph 5 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0823c788-56c8-4b87-9ed7-0e046eeb74c8",
        "text":"5 a. This Regulation shall not apply to AI systems, including their output, specifically developed or used exclusively for scientific research and development purposes.",
        "title":"Amendment 887: Article 2 – paragraph 5 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"966c95fa-bfb7-44a2-ac03-ed580691847f",
        "text":"5 a. This Regulation shall not affect any research, testing and development activity regarding an AI system prior to this system being placed on the market or put into service.",
        "title":"Amendment 888: Article 2 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d8c49e7d-d2b8-4436-a6cb-dee2ab0bd19b",
        "text":"5 a. This Regulation shall not provide a legal basis for the development, deployment or use of AI systems that is unlawful under Union or national law;",
        "title":"Amendment 889: Article 2 – paragraph 5 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"aadd34fd-e300-487b-a7ed-4a9f961afb45",
        "text":"5 a. This Regulation shall not affect community law on social policy.",
        "title":"Amendment 890: Article 2 – paragraph 5 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"fb583be7-8c5e-4086-916c-38fa0b191f98",
        "text":"5 b. This Regulation shall not affect national labour law and practice or collective agreements, and it shall not preclude national legislation to ensure the protection of workers’ rights in respect of the use of AI systems by employers, including where this implies introducing more stringent obligations than those laid down in this Regulation.",
        "title":"Amendment 891: Article 2 – paragraph 5 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"50425e54-a218-4ad5-87b8-b8debd91620e",
        "text":"5 b. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of scientific research, testing and development. The Commission may adopt delegated acts that clarify this exemption.",
        "title":"Amendment 892: Article 2 – paragraph 5 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6c6dd933-7c5c-4c21-a525-3997fdba5a65",
        "text":"5 b. This Regulation is without prejudice to the rules laid down by other Union legal acts regulating the protection of personal data, in particular Regulation (EU) 2016\/679, Directive (EU) 2016\/680, Regulation (EU) 2018\/1725, and Directive 2002\/57\/EC;",
        "title":"Amendment 893: Article 2 – paragraph 5 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"5bda5d4a-647d-4663-808c-50d098d3de83",
        "text":"5 b. Member States may adopt or maintain in force more stringent provisions, compatible with the Treaty in the field covered by this Directive, to ensure a higher level of protection of health, safety and fundamental rights.",
        "title":"Amendment 894: Article 2 – paragraph 5 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"53dc0ef1-9a39-4d3c-9017-11fea11137a6",
        "text":"5 b. This Regulation shall not affect any research and development activity regarding AI systems in so far as such activity does not lead to placing an AI system on the market or putting it into service.",
        "title":"Amendment 895: Article 2 – paragraph 5 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"b232fd7e-de2d-4490-ab7c-31823ff06874",
        "text":"5 b. This Regulation shall be without prejudice to Regulation (EU) 2016\/679.",
        "title":"Amendment 896: Article 2 – paragraph 5 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c1e06ebc-a4c7-4719-bfb2-89ea6130df2c",
        "text":"5 c. This Regulation is without prejudice to the rules laid down by other Union legal acts regulating other aspects of AI systems as well as the national rules aimed at enforcing or, as the case may be, implementing these acts, in particular Union law on consumer protection and product safety, including Regulation (EU)2017\/2394, Regulation (EU) 2019\/1020, Directive 2001\/95\/EC on general product safety and Directive 2013\/11\/EU.",
        "title":"Amendment 897: Article 2 – paragraph 5 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"fd6aa651-7218-4b55-ac1d-ae2e1f809713",
        "text":"5 c. This Regulation is without prejudice to the rules laid down by other Union legal acts relating to consumer protection and product safety, including Regulation (EU) 2017\/2394, Regulation (EU) 2019\/1020 and Directive 2001\/95\/EC on general product safety and Directive 2013\/11\/EU.",
        "title":"Amendment 898: Article 2 – paragraph 5 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"66cd0c93-b2f8-4ee1-b3d1-67990e2a40f9",
        "text":"5 c. This Regulation shall be without prejudice to Community law on social policy.",
        "title":"Amendment 899: Article 2 – paragraph 5 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"dd7ddc77-2e1c-449a-910f-d2165d7c498c",
        "text":"5 d. This Regulation shall be without prejudice to national labour law and practice, that is any legal or contractual provision concerning employment conditions, working conditions, including health and safety at work and the relationship between employers and workers, including information, consultation and participation",
        "title":"Amendment 900: Article 2 – paragraph 5 d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4f48d6a9-48bc-4e0a-8684-96da324f66a4",
        "text":"5 e. This Regulation shall not in any way affect the exercise of fundamental rights as recognised in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States, in accordance with national law and\/or practice. Nor does it affect the right to negotiate, to conclude and enforce collective agreements, or to take collective action in accordance with national law and\/or practice.",
        "title":"Amendment 901: Article 2 – paragraph 5 e (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"27de6f33-d63f-47ab-9575-4322d880a6e6",
        "text":"Article 2 a', 'Metaverse environments', '1. This regulation shall apply, mutatis mutandis, to operators of AI systems operating in virtual environments that can be accessed by natural persons in the Union that fulfil all the following criteria (‘metaverse environments’):', '(i) they require natural persons to have a uniquely identifiable and permanent representation within the virtual environment that is legally and economically connected to them via an official identity document, a digital identity, a digital wallet, or equivalent;', '(ii) they are built for social and economic interaction on a large scale;', '(iii) they allow natural persons to behave and interact virtually in manners that are consistent with their real-world behaviours and interactions and that can be analysed to infer real-world characteristics, including personal data;', '(iv) they allow natural persons to engage in real-world financial transactions, including through blockchain-backed digital currencies and non-fungible tokens;', '(v) they allow for such interactions between natural persons as to make possible risks to the health, safety, or fundamental rights of natural persons or to bring prejudice to the values of the Union as enshrined in Article 2 TEU.",
        "title":"Amendment 902: Article 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"6bda3705-8e0e-469e-a15b-25113bb0e961",
        "text":"(1) ‘artificial intelligence system’ (AI system) refers to systems designed by humans that, given a complex goal, act in the physical or digital world by perceiving their environment, interpreting the collected structured or unstructured data, reasoning on the knowledge derived from this data and deciding the best action(s) to take (according to pre-defined parameters) to achieve the given goal. AI systems can also be designed to learn to adapt theirbehaviour by analysing how the environment is affected by their previous actions. As a scientific discipline, AI includes several approaches and techniques, such as machine learning (of which deep learning and reinforcement learning are specific examples), machine reasoning (which includes planning, scheduling, knowledge representation and reasoning, search, and optimization), and robotics(which includes control, perception, sensors and actuators, as well as the integration of all other techniques into cyber-physical systems);",
        "title":"Amendment 903: Article 3 – paragraph 1 – point 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"91ace324-8d3b-4be4-83de-c19f6d19edcb",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a system that combines these three criteria:', '(i) receives machine and\/or human-based data and inputs,', '(ii) infers how to achieve a given set of human-defined objectives using learning, reasoning or modelling implemented with the techniques and approaches listed in Annex I, and', '(iii) generates outputs in the form of content (generative AI systems), predictions, recommendations or decisions, which influence the environments it interacts with;",
        "title":"Amendment 904: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"57a0897d-31dd-4c0b-a1b7-0906c25b4c0a",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that display intelligent behaviour by analysing their environment and taking actions – with some degree of autonomy – to achieve specific goals, which:', '(a) receives machine and\/or human-based data and inputs;', '(b) infers how to achieve a given set of human-defined objectives using data-driven models created through learning or reasoning implemented with the techniques and approaches listed in Annex I, and', '(c) generates outputs in the form of content (generative AI systems), predictions, recommendations or decisions, which influence the environments it interacts with;",
        "title":"Amendment 905: Article 3 – paragraph 1 – point 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar"
    },
    {
        "uuid":"d3b0a9ab-1e70-4992-8961-73e66e15325e",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a machine-based system that is developed with one or more of the techniques and approaches listed in Annex I and is capable of influencing the environment by producing an output(predictions, recommendations, or decisions) for a given set of objectives. It uses machine and\/or human-based data and inputs to (i) perceive real and\/or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (e.g. with machine learning), or manually; and (iii) use model inference to formulate options for outcomes. AI systems are designed to operate with varying levels of autonomy;",
        "title":"Amendment 906: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"91c6958e-049d-4cb7-9f9f-c076f8b9f6ab",
        "text":"(1) 'artificial intelligence' (AI) systems are software (and also hardware) systems designed by humans that, given a complex goal, act in the physical or digital dimension by perceiving their environment through data acquisition, interpreting the collected structured or unstructured data, reasoning on the knowledge, or processing the information, derived from this data and deciding the best action(s) to take to achieve the given goal. AI systems can either use symbolic rules or learn a numeric model, and they can also adapt their behaviour by analysing how the environment is affected by their previous actions;",
        "title":"Amendment 907: Article 3 – paragraph 1 – point 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"a88c2001-d187-4b56-a41b-da3a9c44a6df",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a system that', '(I) receives machine and\/or human-based data and inputs,', '(II) infers how to achieve a given set of human-defined objectives using learning, reasoning or modelling implemented with the techniques and approaches listed in Annex I, and', '(III) generates outputs in the form of content, predictions, recommendations or decisions, which influence the environments it interacts with;",
        "title":"Amendment 908: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"06e754ac-8314-4362-b8bb-3524d039e119",
        "text":"(1) ‘artificial intelligence (AI)' means computer systems that act in the physical or digital world and that, in an automated manner:\", '(i) decide on action(s) to take according to predefined parameters by perceiving their environment and analysing the collected structured or unstructured information from that environment;and\/or', '(ii) can adapt their decisions by analysing how the environment is affected by their previous actions.",
        "title":"Amendment 909: Article 3 – paragraph 1 – point 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"15ed4b03-b634-4070-abe5-1447dd0333de",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a system that operates with varying degrees of autonomy, uses one or more of the techniques and approaches listed in Annex I and can, for human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with and that cannot be fully predicted by the natural person developing the system;",
        "title":"Amendment 910: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"66d8f23b-ed5d-4bc8-8d27-bea98a624377",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions real or virtual environments",
        "title":"Amendment 911: Article 3 – paragraph 1 – point 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Carlo Fidanza"
    },
    {
        "uuid":"9b559b8d-a839-45fe-a26d-1c97fb3ded1a",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that can, for a given set of human-defined objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments; AI systems can be designed to operate with varying levels of autonomy and can be developed with one or more of the techniques and approaches listed in Annex I;",
        "title":"Amendment 912: Article 3 – paragraph 1 – point 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-"
    },
    {
        "uuid":"7fe7cb70-e3c8-4ed9-870c-eb7f2d0713fe",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a system based on machine or human-based data and input that infers how to achieve a given set of human-defined objectives using one or more of the techniques and approaches listed in Annex I and generates outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",
        "title":"Amendment 913: Article 3 – paragraph 1 – point 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"677e4bc9-b612-4dd4-97a5-5261ae2a1d01",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives, indispensably with some degree of autonomy, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",
        "title":"Amendment 914: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"10fb9358-ff79-4bc9-93c8-a49a94c4ca95",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of objectives or parameters subject to human command, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",
        "title":"Amendment 915: Article 3 – paragraph 1 – point 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b10fd2e8-589a-4782-bf0d-760e0ba75f5e",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives and with varying levels of autonomy, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",
        "title":"Amendment 916: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"8784ef33-d6b5-49ab-918d-c99662123316",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of inputs and objectives, generate outputs such as content, predictions, recommendations, or decisions;",
        "title":"Amendment 917: Article 3 – paragraph 1 – point 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"ac06269e-2864-4bf3-81cd-2bad33eb381f",
        "text":"(1) ‘artificial intelligence system’ (AI system) means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments and is designed to operate with varying levels of autonomy;",
        "title":"Amendment 918: Article 3 – paragraph 1 – point 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"30d91de9-aed8-428f-9231-a0201420a12a",
        "text":"(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",
        "title":"Amendment 919: Article 3 – paragraph 1 – point 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2b251efb-be0f-4217-af07-2503c605d7a7",
        "text":"(1) ‘artificial intelligence system’(AI system) means software that can perceive, learn, reason or model based on machine and\/or human based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions influencing the real or virtual environments they interact with;",
        "title":"Amendment 920: Article 3 – paragraph 1 – point 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2509bd22-9a43-4908-bad2-6aab49bc76b1",
        "text":"(1) 'artificial intelligence system’ (AI system) means software that can for example perceive, learn, reason or model based on machine and\/or human based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions influencing the real or virtual environments they interact with;",
        "title":"Amendment 921: Article 3 – paragraph 1 – point 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"dd3e766c-fa8b-4816-9a88-a46173a8a010",
        "text":"(1a) ‘human-centric AI’ means an approach which strives to ensure that human values are central to the development, deployment, use and monitoring of AI systems, by ensuring respect for fundamental rights, including those set out in the Treaties of the European Union and the Charter of Fundamental Rights of the European Union, all of which are united by reference to a common foundation rooted in respect for human dignity, in which every human being enjoys a unique and inalienable moral status, which also entails consideration of the natural environment and of other living beings that are part of the human ecosystem, as well as a sustainable approach enabling the flourishing of future generations;",
        "title":"Amendment 922: Article 3 – paragraph 1 – point 1 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b2ff112f-896a-4ae7-8033-73dc0cbcd048",
        "text":"(1 a) 'autonomy' means that to some degree an AI system operates by interpreting certain input and by using a set of pre-determined objectives, without being limited to such instructions, even when the system’s behaviour was initially constrained by, and targeted at, fulfilling the goal it was given and other relevant design choices made by its developer;",
        "title":"Amendment 923: Article 3 – paragraph 1 – point 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"565a0c5a-0173-4e39-aeb3-2bc65262a1ea",
        "text":"(1 a) ‘machine learning’ means an AI system that gives computers the ability to find patterns in data without being explicitly programmed for a given task;",
        "title":"Amendment 924: Article 3 – paragraph 1 – point 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fc0fd235-5cca-41c8-94d8-82ad7e1363e5",
        "text":"(1 b) 'general purpose AI system' means an AI system that - irrespective of the modality in which it is placed on the market or put into service including as open source software - is able to perform generally applicable functions such as image or speech recognition, audio or video generation, pattern detection, question answering, translation or others; a general purpose AI system may be used in a plurality of contexts and may be integrated in a plurality of other AI systems;",
        "title":"Amendment 925: Article 3 – paragraph 1 – point 1 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9b21268c-d84b-4944-afd7-60e6b18fc6bf",
        "text":"(1 b) 'general purpose AI system’ means an AI system that is able to perform generally applicable functions for multiple potential purposes, such as image or speech recognition, audio or video generation, pattern detection, question answering, and translation, is largely customizable and often open source software;",
        "title":"Amendment 926: Article 3 – paragraph 1 – point 1 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Sophia in t Veld, Moritz Körner, Jan-"
    },
    {
        "uuid":"ad064b08-43c1-470c-af8c-a0230fd7e4cd",
        "text":"(1 c) ‘autonomous’ means an AI-system that operates by interpreting certain input and results and by using a set of pre-determined objectives, without being limited to such instructions, despite the system’s behaviour being constrained by, and targeted at, fulfilling the goal it was given and other relevant design choices made by its provider;",
        "title":"Amendment 927: Article 3 – paragraph 1 – point 1 d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f9707353-5bd2-48a3-882a-ef460bc454df",
        "text":"(1 d) ‘risk’ means the combination of the probability of occurrence of a harm and the severity of that harm;",
        "title":"Amendment 928: Article 3 – paragraph 1 – point 1 d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c296896a-85f9-4f72-86f3-641f5fe7e7d5",
        "text":"(1 e) ‘harm’ means an adverse impact affecting the health, safety or fundamental rights of a natural person;",
        "title":"Amendment 929: Article 3 – paragraph 1 – point 1 e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"40239507-3dd3-40ea-8167-90f4af6dd22d",
        "text":"(2) 'developer' means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places it on the market or puts it into service under its own name or trademark, whether for payment or free of charge or that adapts general purpose AI systems to a specific intended purpose;",
        "title":"Amendment 930: Article 3 – paragraph 1 – point 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"4bf26cc9-0c81-4bc9-b4ea-12ba7292b73d",
        "text":"(2) ‘provider’ means a natural or legal person, public authority, agency or other body that places an AI system on the market or puts it into service under its own name or trademark, whether for payment or free of charge or that adapts general purpose AI systems to an intended purpose;",
        "title":"Amendment 931: Article 3 – paragraph 1 – point 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"469f471e-f031-4fae-944d-39e7db00e396",
        "text":"(2) ‘provider’ means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places that system on the market or puts it into service under its own name or trademark, whether for payment or free of charge;",
        "title":"Amendment 932: Article 3 – paragraph 1 – point 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"7094f719-8ad1-4c31-bbb2-48c07e32afa4",
        "text":"(2) ‘provider’ means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places that system on the market or puts it into service under its own name or trademark, whether for payment or free of charge;",
        "title":"Amendment 933: Article 3 – paragraph 1 – point 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"761a4a92-d8b9-45bd-9ea9-b6aca9fc5d07",
        "text":"(2 a) ‘new provider’ means a natural or legal person that becames provider for the purposes of this Regulation due to one of the circumstances referred to in Art 23a(1).",
        "title":"Amendment 934: Article 3 – paragraph 1 – point 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"af754ea5-1853-40c3-bab0-2e2e2cc2feeb",
        "text":"(2 b) ‘former provider’ means a provider that initially placed the AI system on the market or put it into service but is according to Art 23a(2) no longer considered a provider for the purposes of this Regulation;",
        "title":"Amendment 935: Article 3 – paragraph 1 – point 2 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c25199ea-c797-4383-b4f3-4abfd5b5581a",
        "text":"(2 c) ‘original provider’ means a provider of a general purpose AI system, who has made available the AI system to a natural or legal person that itself became a provider by giving an intended purpose to the general purpose AI system;",
        "title":"Amendment 936: Article 3 – paragraph 1 – point 2 c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5aab495c-7278-44c4-89eb-b71409aa6634",
        "text":"deleted",
        "title":"Amendment 937: Article 3 – paragraph 1 – point 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"d157084e-8bb4-49a3-a2c1-ebda65b3d1d6",
        "text":"deleted",
        "title":"Amendment 938: Article 3 – paragraph 1 – point 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f200e75e-3cf7-4eac-b17f-0745ba95ab5c",
        "text":"(3 a) ‘risk’ means the combination of the probability of occurrence of a harm and the severity of that harm;",
        "title":"Amendment 939: Article 3 – paragraph 1 – point 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Samira Rafaela,"
    },
    {
        "uuid":"54f3fc5f-75c6-4cd0-ae72-7658a0dc1426",
        "text":"(3 b) ‘significant harm‘ means a material harm to a person's life, health and safety or fundamental rights or entities or society at large whose severity is exceptional. The severity is in particular exceptional when the harm is hardly reversible, the outcome has a material adverse impact on health or safety of a person or the impacted person is dependent on the outcome;",
        "title":"Amendment 940: Article 3 – paragraph 1 – point 3 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"ffed0d96-da87-42cc-ae77-f19d70afd80a",
        "text":"(4) ‘user’ means any natural or legal person, public authority, agency or other body using an AI system under its authority;",
        "title":"Amendment 941: Article 3 – paragraph 1 – point 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"dcf7763c-dabc-4b79-aba2-389ee069515d",
        "text":"(4) ‘user’ means any natural or legal person, public authority, agency or other body using an AI system under its authority;",
        "title":"Amendment 942: Article 3 – paragraph 1 – point 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"323abb3e-266a-401a-bbe5-a8bc1f4ed1d6",
        "text":"(4) ‘user’ means any natural or legal person, data subject, public authority, agency or other body using an AI system under its authority and on its own responsibility, except where the AI system is used in the course of a personal non-professional activity;",
        "title":"Amendment 943: Article 3 – paragraph 1 – point 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c583795f-c34a-4a6e-8302-44a545bfca7a",
        "text":"(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;",
        "title":"Amendment 944: Article 3 – paragraph 1 – point 4  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"e098676d-12aa-4a46-b057-70894bf42f76",
        "text":"(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;",
        "title":"Amendment 945: Article 3 – paragraph 1 – point 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"186ab425-1407-4c73-9c07-18576c19fa94",
        "text":"(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;",
        "title":"Amendment 946: Article 3 – paragraph 1 – point 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c9403ad2-acec-43f4-b7fe-5018a8abafff",
        "text":"(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;",
        "title":"Amendment 947: Article 3 – paragraph 1 – point 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"890554fb-dcb7-4111-a2fa-f1699383c77c",
        "text":"(4 a) ‘AI subject’ means any natural or legal person that is subject to a decision based on or assisted by an AI system, or subject to interaction with an AI system or treatment of data relating to them by an AI system, or otherwise subjected to analysis by an AI or otherwise impacted or affected by an AI system;",
        "title":"Amendment 948: Article 3 – paragraph 1 – point 4 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"eae1568e-3c00-427e-bec1-ae31af37dc69",
        "text":"(4 a) ‘end user’ means any natural person who, in the context of employment or contractual agreement with the user, uses or deploys the AI system under the authority of the user;",
        "title":"Amendment 949: Article 3 – paragraph 1 – point 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"1a1e23ec-87a4-4299-8918-8109060ab10e",
        "text":"(4 a) 'End-user' means any natural person who, in the framework of employment, contract or agreement with the deployer, uses the AI system under the authority of the deployer;",
        "title":"Amendment 950: Article 3 – paragraph 1 – point 4 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2f8ffd05-c9a2-449a-b7de-ac13d5b302ec",
        "text":"(4 a) ‘affected person’ means the natural or legal person who is ultimately directly or indirectly affected by the deployment of an AI system.",
        "title":"Amendment 951: Article 3 – paragraph 1 – point 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"685dbbb7-017c-4abe-8950-ccd02c39d29a",
        "text":"(5) ‘authorised representative’ means any natural or legal person physically present or established in the Union who has received and accepted a written mandate from a provider of an AI system to, respectively, perform and carry out on its behalf the obligations and procedures established by this Regulation;",
        "title":"Amendment 952: Article 3 – paragraph 1 – point 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"770bda10-f774-41cd-9dbb-44a5c0db2817",
        "text":"(5) ‘legal representative’ means any natural or legal person established in the Union who has received a written mandate from a provider of an AI system to, respectively, perform and carry out on its behalf any of the obligations and procedures established by this Regulation;",
        "title":"Amendment 953: Article 3 – paragraph 1 – point 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1b56495a-d29c-4d96-840c-177bb72832c5",
        "text":"(5 a) ‘product manufacturer’ means a manufacturer within the meaning of any of the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 954: Article 3 – paragraph 1 – point 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"93fe542c-f8a0-45ee-b27a-aa0afeba4eec",
        "text":"(6) ‘importer’ means any natural or legal person physically present or established in the Union that places on the market an AI system that bears the name or trademark of a natural or legal person established outside the Union;",
        "title":"Amendment 955: Article 3 – paragraph 1 – point 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"10be2441-ae4f-4014-ad38-1b5c7c7e7f41",
        "text":"(7 a) ‘economic operator’ means the provider, the authorised representative, the importer and the distributor;",
        "title":"Amendment 956: Article 3 – paragraph 1 – point 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f74d050d-a657-40ae-a797-fbec25c286e7",
        "text":"(8) ‘operator’ means the economic operator and the user;",
        "title":"Amendment 957: Article 3 – paragraph 1 – point 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f267120c-a0b7-4a68-bbf1-6f7a3438d692",
        "text":"(8) ‘operator’ means the provider, the deployer, the authorised representative, the importer and the distributor;",
        "title":"Amendment 958: Article 3 – paragraph 1 – point 8  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"2043c844-e7db-41c4-b509-e15b78e889eb",
        "text":"(8) ‘operator’ means the provider, the user, the legal representative, the importer and the distributor;",
        "title":"Amendment 959: Article 3 – paragraph 1 – point 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"01619aa9-5dc1-42ca-94e8-5994f1e237a6",
        "text":"(8 a) ‘affected person’ means any natural person or a group of persons who are subjects to or affected by an AI system",
        "title":"Amendment 960: Article 3 – paragraph 1 – point 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1fd7753c-1e51-4d62-91b2-e56d1fdeae90",
        "text":"(8 a) ‘affected person’ means any natural person or group of persons who are subject to or affected by an AI system;",
        "title":"Amendment 961: Article 3 – paragraph 1 – point 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"c9caa75c-5177-4fb8-b212-baa74c042f58",
        "text":"(11) ‘putting into service’ means the supply of an AI system for first use directly to the user or for own use on the Union market for its intended purpose or reasonably foreseeable use ;",
        "title":"Amendment 962: Article 3 – paragraph 1 – point 11  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"e0908473-8ae2-4a15-b51a-ada8e9459771",
        "text":"(11) ‘putting into service’ means the supply of an AI system for first use directly to the deployer or for own use on the Union market for its intended purpose;",
        "title":"Amendment 963: Article 3 – paragraph 1 – point 11  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"b43d3624-6b0a-460c-9e6c-08426851292b",
        "text":"(11) ‘putting into service’ means the supply of an AI system for first use directly to the user or for own use on the Union market for its foreseeable uses;",
        "title":"Amendment 964: Article 3 – paragraph 1 – point 11  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"840c5576-d37b-4cc5-8629-e2f5fff0d4b5",
        "text":"(11a) ‘testing’ means making the AI system available to a limited and restricted group of users before it is placed on the market or put into service;",
        "title":"Amendment 965: Article 3 – paragraph 1 – point 11 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"8116d45a-2719-45b7-b678-711a58f3b97c",
        "text":"(12) ‘intended purpose’ means the specific use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation; general purpose AI systems shall not be considered as having an intended purpose within the meaning of this Regulation;",
        "title":"Amendment 966: Article 3 – paragraph 1 – point 12  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"13e6cd66-79e4-451f-9ea6-5ca15fb0a07e",
        "text":"(12) ‘foreseeable uses’ means uses that can reasonably be expected to be made of an AI system, including but not limited to the use for which the AI system is intended for consumers or the likely use by consumers under reasonably foreseeable conditions;",
        "title":"Amendment 967: Article 3 – paragraph 1 – point 12  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"a5f4b3d5-1202-40fb-9b6e-d1d78f868e04",
        "text":"(12) ‘reasonably foreseeable purpose’ means the use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation;",
        "title":"Amendment 968: Article 3 – paragraph 1 – point 12  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"3213fbb6-3ab6-4108-8b7c-0168351ff7b8",
        "text":"i) 'Reasonably foreseeable use' means the use of an AI system in a way that is or should be reasonably foreseeable and that addresses the risks to health, safety and fundamental rights that it can cause.",
        "title":"Amendment 969: Article 3 – paragraph 1 – point 12 – point i (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"413936bd-644f-4fb2-a727-4d812f57997f",
        "text":"(12 a) ‘foreseeable uses’ means uses that can reasonably be expected to be made of an AI system, including but not limited to the use for which the AI system is intended for consumers or the likely use by consumers under reasonably foreseeable conditions;",
        "title":"Amendment 970: Article 3 – paragraph 1 – point 12 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"113a66e7-2bd6-4861-bd90-f1b001406d1f",
        "text":"(12 a) 'reasonably foreseeable use' means the use of an AI system in a way that is or should be reasonably foreseeable;",
        "title":"Amendment 971: Article 3 – paragraph 1 – point 12 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6d6ff7e3-6842-45eb-bbba-a7829e606e79",
        "text":"deleted",
        "title":"Amendment 972: Article 3 – paragraph 1 – point 13  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"cafad3f1-be2c-4759-9540-b45a04c28696",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose and with the specific context and conditions of use established by the provider, but which may result from reasonably foreseeable human behaviour or interaction with other systems;",
        "title":"Amendment 973: Article 3 – paragraph 1 – point 13  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c44640e8-21ed-4908-b427-d13c3c402ab2",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system within its intended purpose, but not in accordance with the specific context and conditions of use established by the provider and in a way which may result from reasonably foreseeable human behaviour or interaction with other systems;",
        "title":"Amendment 974: Article 3 – paragraph 1 – point 13  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"6d529b88-c8e6-40bc-984b-575a937e0eae",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its purpose as indicated in instruction for use or technical specification, but which may result from reasonably foreseeable human behaviour or interaction with other systems;",
        "title":"Amendment 975: Article 3 – paragraph 1 – point 13  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"23f85f86-237f-4fd4-a3f5-5eb32635513b",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, including other AI systems;",
        "title":"Amendment 976: Article 3 – paragraph 1 – point 13  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3b1ec110-62fe-4006-bd26-b876b2b87c6c",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, and with other AI systems;;",
        "title":"Amendment 977: Article 3 – paragraph 1 – point 13  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"52328bbe-4729-4d73-8722-1114960729e2",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, and with other AI systems;",
        "title":"Amendment 978: Article 3 – paragraph 1 – point 13  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"65533c91-03c1-4caf-96e7-0b8c6dd76941",
        "text":"(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from known and reasonably foreseeable human behaviour;",
        "title":"Amendment 979: Article 3 – paragraph 1 – point 13  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"7bbb1868-e2ac-43d1-981d-3b92c0049adf",
        "text":"(13 a) ‘harmful subliminal technique’ means a measure whose existence and operation are entirely imperceptible by those on whom it is used, and which has the purpose and direct effect to induce actions leading to that person’s physical or psychological harm.",
        "title":"Amendment 980: Article 3 – paragraph 1 – point 13 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"96f17383-16ff-4283-bf78-cbdae1e572fb",
        "text":"(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety function for that product or system or the failure or malfunctioning of which endangers the health and safety of persons or property, but which is not necessary in order for the product or system to function;",
        "title":"Amendment 981: Article 3 – paragraph 1 – point 14  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"7ba10337-9c3e-4213-89c0-61da80fccdaf",
        "text":"(14) ‘safety component of a product or system’ means, in line with the relevant Union harmonisation legislation listed in Annex II, a component of a product or of a system which fulfils a direct and critical safety function for that product or system so that its malfunction endagers the health and safety of persons;",
        "title":"Amendment 982: Article 3 – paragraph 1 – point 14  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f796a277-e0b7-4c2b-b2e9-6c1e11f3f14d",
        "text":"(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety or security function for that product or system or the failure or malfunctioning of which endangers the fundamental rights, health or safety of persons, or which damages property or the environment;",
        "title":"Amendment 983: Article 3 – paragraph 1 – point 14  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"4d765475-f4d0-4dcb-bf7d-2dc20f060dc1",
        "text":"(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety or security function for that product or system or the failure or malfunctioning of which endangers the health, safety, fundamental rights of persons or which damages property, or the environment;",
        "title":"Amendment 984: Article 3 – paragraph 1 – point 14  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4ab03b22-9bac-4662-9acb-1d8d2eb0370d",
        "text":"(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a direct or indirect safety function for that product or system or the failure or malfunctioning of which endangers the health and safety of persons or property;",
        "title":"Amendment 985: Article 3 – paragraph 1 – point 14  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"80d33062-6f8e-472f-97df-3becb97de9ca",
        "text":"(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety function for that product or system so that its malfunctioning endangers the health and safety of persons or property;",
        "title":"Amendment 986: Article 3 – paragraph 1 – point 14  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"6606618e-10ed-49f1-a16a-1b689370cc9f",
        "text":"(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s intended purpose and proper use,",
        "title":"Amendment 987: Article 3 – paragraph 1 – point 15  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b09c8159-3a68-4cd2-8444-e06b4faf0028",
        "text":"(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s intended purpose or reasonably foreseeable use and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended or foreseeable to be used;",
        "title":"Amendment 988: Article 3 – paragraph 1 – point 15  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"af1ecf49-eacf-44ff-8fbb-6bffd6435cc8",
        "text":"(15) ‘instructions for use’ means the information provided by the provider to inform the deployer of in particular an AI system’s intended purpose and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used;",
        "title":"Amendment 989: Article 3 – paragraph 1 – point 15  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"061e90bc-ec53-4f8b-8416-bd5277d25121",
        "text":"(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s foreseeable uses and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used;",
        "title":"Amendment 990: Article 3 – paragraph 1 – point 15  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"b03da4af-1d9a-49af-b791-778008898d7a",
        "text":"(16) ‘recall of an AI system’ means any measure aimed at achieving the return to the provider or taking it out of service or disable the use of an AI system made available to users;",
        "title":"Amendment 991: Article 3 – paragraph 1 – point 16  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"eb714572-634a-4989-bc99-3ebb176eccf2",
        "text":"(16) ‘recall of an AI system’ means any measure aimed at achieving the return to the provider of an AI system made available to deployers;",
        "title":"Amendment 992: Article 3 – paragraph 1 – point 16  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"87662c8b-ec55-42e4-9c38-cff92624ad77",
        "text":"(17) ‘withdrawal of an AI system’ means any measure aimed at preventing an AI system in the supply chain being made available on the market;",
        "title":"Amendment 993: Article 3 – paragraph 1 – point 17  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ee250a7e-8773-4b28-97ab-873779da6a0c",
        "text":"(18) ‘performance of an AI system’ means the ability of an AI system to achieve its intended purpose or reasonably foreseeable use ;",
        "title":"Amendment 994: Article 3 – paragraph 1 – point 18  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"55d36b4a-5f71-4a90-b682-b224d3c5aa51",
        "text":"(18) ‘performance of an AI system’ means the ability of an AI system to achieve its foreseeable uses;",
        "title":"Amendment 995: Article 3 – paragraph 1 – point 18  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"d3b1c1e8-fdb3-4b23-81d8-cbc278109fab",
        "text":"(18a) ‘lifecycle of AI’ means the process of developing, deploying and using an AI system, including the research, design, data supply, training, limited-scale deployment, implementation and withdrawal stages;",
        "title":"Amendment 996: Article 3 – paragraph 1 – point 18 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"75bc47c5-e092-4522-af07-5308abf0735a",
        "text":"(20) ‘conformity assessment’ means the process of verification by an independent third party whether the principles and requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;",
        "title":"Amendment 997: Article 3 – paragraph 1 – point 20  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"26604958-f590-4bcf-9abb-7e71f63b9934",
        "text":"(20) ‘conformity assessment’ means the process of demonstrating whether the requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;",
        "title":"Amendment 998: Article 3 – paragraph 1 – point 20  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"dd93f8f8-6918-45b0-af19-71759038a33f",
        "text":"(20) ‘conformity assessment’ means the process of demonstrating whether the requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;",
        "title":"Amendment 999: Article 3 – paragraph 1 – point 20  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"3c21076d-c815-4a2e-aae9-6ace20801b87",
        "text":"(22) ‘notified body’ means a conformity assessment body notified in accordance with Art 32 of this Regulation and with other relevant Union harmonisation legislation;",
        "title":"Amendment 1000: Article 3 – paragraph 1 – point 22  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8e6a188a-aaf4-46d6-a5e5-98a0ee1bd5a6",
        "text":"(23) ‘substantial modification’ means a change to a high-risk AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation such as a new training with a completely different dataset with respect to the one used to begin with or the addition of a further AI module into the AI system or results in a modification to the intended purpose for which the AI system has been assessed; Supplementary and periodic training of an AI algorithm by the AI user or provider using their own data to ensure that the system remains accurate and\/or is working as intended does not amount to a ‘substantial modification’ under this Regulation. The periodic retraining of models due to new data with same structure shall not constitute a substantial modification. For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been predetermined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification;",
        "title":"Amendment 1001: Article 3 – paragraph 1 – point 23  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"5f9cd117-f161-4065-8472-dde98f47b6dc",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service, which is not foreseen or planned by the provider and as a result of which the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation is affected or which results in a modification to the intended purpose for which the AI system has been assessed. A substantial modification is given if the remaining risk is increased by the modification of the AI system under the application of all necessary protective measures;",
        "title":"Amendment 1002: Article 3 – paragraph 1 – point 23  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"5e482b56-b71a-4f3d-a8fd-6819eb3ab1b0",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed or to its performance, including modifications of the intended purpose of an AI system which is not classified as high-risk and is already placed on the market or put into service;",
        "title":"Amendment 1003: Article 3 – paragraph 1 – point 23  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9bc7b271-272e-465a-9821-7123d6e7f30a",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed including the use of an AI system beyond its reasonably foreseeable purpose;",
        "title":"Amendment 1004: Article 3 – paragraph 1 – point 23  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"e68c4175-3262-49ac-bece-2c9f2fc00b28",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the foreseeable uses for which the AI system has been assessed, health and safety requirements are to be covered;",
        "title":"Amendment 1005: Article 3 – paragraph 1 – point 23  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"ba987195-b8cf-4864-866b-73d1f0a8bd60",
        "text":"(23) ‘substantial modification’ means a change, including a change based on ‘learning’, to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed;",
        "title":"Amendment 1006: Article 3 – paragraph 1 – point 23  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"20a475c5-c7e1-48ba-bb09-bfb503fb1ba3",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service, not foreseen by the provider, which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed;",
        "title":"Amendment 1007: Article 3 – paragraph 1 – point 23  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f9d05607-f4f0-4d48-ae78-34045dec9d3f",
        "text":"(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose or reasonably foreseeable use for which the AI system has been assessed;",
        "title":"Amendment 1008: Article 3 – paragraph 1 – point 23  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"9b9e13b2-ad32-46e7-ba02-995ea182e56a",
        "text":"(24) ‘CE marking of conformity’ (CE marking) means a physical or digital marking by which a provider indicates that an AI system or a product with an embedded AI system is in conformity with the requirements set out in Title III, Chapter 2 of this Regulation and other applicable Union legislation harmonising the conditions for the marketing of products (‘Union harmonisation legislation’) providing for its affixing;",
        "title":"Amendment 1009: Article 3 – paragraph 1 – point 24  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"86149959-480e-4bab-9300-993588836f5c",
        "text":"(24) ‘CE marking of conformity’ (CE marking) means a physical or electronic marking by which a provider indicates that an AI system is in conformity with the requirements set out in Title III, Chapter 2 of this Regulation and other applicable Union legislation harmonising the conditions for the marketing of products (‘Union harmonisation legislation’) providing for its affixing as well as the GDPR;",
        "title":"Amendment 1010: Article 3 – paragraph 1 – point 24  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3b44e788-09ac-4400-906d-f3b0e8227bc3",
        "text":"(25) ‘post-market monitoring’ means all activities carried out by providers of AI systems to proactively collect and review experience gained from the use of AI systems they place on the market or put into service for the purpose of identifying any need to immediately apply any necessary corrective or preventive actions, whereby such activities may not consist in the AI system automatically sending data or error reports to the provider;",
        "title":"Amendment 1011: Article 3 – paragraph 1 – point 25  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"7e96bae9-f294-4424-9b87-b035648c2c74",
        "text":"(28) ‘common specifications’ means a document comprising a set of technical specifications, other than a standard, providing a means to comply with certain requirements and obligations established under this Regulation;",
        "title":"Amendment 1012: Article 3 – paragraph 1 – point 28  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e43d4dcc-a878-4d09-a35d-b44bd7c51d9e",
        "text":"(28a) ‘sandbox’, in connection with the development of AI systems, means an isolated operating and experimental environment enabling certain actions to be carried out using an AI system while protecting the user from any harm resulting from computer bias, damage or compromise;",
        "title":"Amendment 1013: Article 3 – paragraph 1 – point 28 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"094759d6-2d2d-40bc-b4e1-950d6e2c50b0",
        "text":"(29) ‘training data’ means data used for training an AI system to fit its learnable parameters;",
        "title":"Amendment 1014: Article 3 – paragraph 1 – point 29  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d1d006eb-e367-4bea-a26a-4413a71f327c",
        "text":"(29) ‘training data’ means data used for training an AI system through fitting its learnable parameters;",
        "title":"Amendment 1015: Article 3 – paragraph 1 – point 30  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"6eb3b6b7-d1b0-43dd-902d-86eee68e3fba",
        "text":"(30) ‘validation data’ means data used for providing an evaluation of the trained AI system. The process evaluates whether the model is under-fitted or overfitted; The validation dataset should be a separate dataset of the training set for the evaluation to be unbiased. If there is only one available dataset, this is divided into two parts, a training set and a validation set. Both sets should still comply with Article 10(3) to ensure appropriate data governance and management practices.",
        "title":"Amendment 1016: Article 3 – paragraph 1 – point 30  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c9f6f968-f612-4103-865e-cfdb3d4a8b48",
        "text":"(30) ‘validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, whereas the validation dataset can be a separate dataset or part of the training dataset, either as a fixed or variable split;",
        "title":"Amendment 1017: Article 3 – paragraph 1 – point 30  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"be497e2a-4228-4491-9246-e71910db4db8",
        "text":"(30) ‘machine learning validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, among other things, in order to prevent overfitting; whereas the validation dataset can be a separate dataset or part of the training dataset, either as a fixed or variable split;",
        "title":"Amendment 1018: Article 3 – paragraph 1 – point 30  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1ad6202b-9ab8-4ee6-bc67-f21c80b257a8",
        "text":"(30) ‘validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, among other things, in order to prevent underfitting or overfitting; whereas the validation dataset is a separate dataset or part of the training dataset, either as a fixed or variable split;",
        "title":"Amendment 1019: Article 3 – paragraph 1 – point 30  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"b218e9a3-b29d-4195-b68b-f048cef7f93a",
        "text":"(31) ‘testing data’ means data used for providing an independent evaluation of the trained and validated AI system to confirm the expected performance of that system before its placing on the market or putting into service. Similar to Article 3(30), the testing dataset should be a separate dataset from the training set and validation set. This set should also comply with Article 10(3) to ensure appropriate data governance and management practices.",
        "title":"Amendment 1020: Article 3 – paragraph 1 – point 31  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a7d47a5e-5e24-4ae5-b491-56279dc8b4e4",
        "text":"(31) ‘testing data’ means data used for providing an independent evaluation of the trained and validated AI system in order to confirm the expected performance of that system before its placing on the market or putting into service. The testing data must be a separate dataset;",
        "title":"Amendment 1021: Article 3 – paragraph 1 – point 31  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"353adaea-e251-487c-9ff8-99fe7ab040cb",
        "text":"(33) ‘biometric data’ means personal data as defined in Article 4, point (14) of Regulation (EU) 2016\/679;",
        "title":"Amendment 1022: Article 3 – paragraph 1 – point 33  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"be2d2819-11f1-4457-8f4b-98fd227749e5",
        "text":"(33) ‘biometric data’ means personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, such as facial images or dactyloscopic data;",
        "title":"Amendment 1023: Article 3 – paragraph 1 – point 33  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"93699304-ac27-4081-a86a-62c158d4bf5a",
        "text":"(33) ‘biometric data’ means personal data resulting from specific technical processing relating to the physical or physiological characteristics of a natural person, which allow or confirm the unique identification of that natural person, such as facial images or dactyloscopic data;",
        "title":"Amendment 1024: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"eb6c20f4-b9b5-4b70-81bc-cda063f68c79",
        "text":"(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological or behavioural signals of a natural person which may or may not allow or confirm the unique identification of a natural person;",
        "title":"Amendment 1025: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bf06314a-6c61-4678-9b04-b45929d5936c",
        "text":"(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological or behavioural signals of a natural person which may or may not allow or confirm the unique identification of a natural person",
        "title":"Amendment 1026: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"19e61256-9e24-4708-acb4-5d1757d6235c",
        "text":"(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological, or behavioural features, signals, or characteristics of a natural person;",
        "title":"Amendment 1027: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c1635f02-d7a6-4eda-904f-7683dd338ebb",
        "text":"(33 a) ‘subliminal techniques’ means techniques that use sensorial stimuli such as images, text, or sounds, that are below the limits of conscious human sensorial perception;",
        "title":"Amendment 1028: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"db0558f1-ced9-4c45-b503-5db4428b51ed",
        "text":"(33 a) “special categories of personal data” means the categories of personal data referred to in Article 9(1) of Regulation (EU)2016\/679;",
        "title":"Amendment 1029: Article 3 – paragraph 1 – point 33 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar, Paul Tang, Maria Grapini"
    },
    {
        "uuid":"fb9604b9-f3e4-4ce5-8750-0212c7b11534",
        "text":"(33 b) ‘biometric identification’ means the use of AI-systems for the purpose of the automated recognition of physical, physiological, behavioural, and psychological human features such as the face, eye movement, facial expressions, body shape, voice, speech, gait, posture, heart rate, blood pressure, odour, keystrokes, psychological reactions (anger, distress, grief, etc.) for the purpose of verification of an individual’s identity by comparing biometric data of that individual to stored biometric data of individuals in a database (one-to-many identification);",
        "title":"Amendment 1030: Article 3 – paragraph 1 – point 33 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"223bcf79-9fab-4873-9923-dfe8fbc120b0",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind (such as ‘deception’, ‘trustworthiness’ or ‘truthfulness’) or intentions of natural persons on the basis of their biometric data or other biometrics-based data;",
        "title":"Amendment 1031: Article 3 – paragraph 1 – point 34  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"fb3a2cf7-5627-48ae-a060-401cd5235981",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind (such as ‘deception’, ‘trustworthiness’ or ‘truthfulness’)or intentions of natural persons on the basis of their biometric data or biometrics-based data;",
        "title":"Amendment 1032: Article 3 – paragraph 1 – point 34  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6934a057-4540-44c4-823e-16bab4f8450c",
        "text":"(34) ‘emotion recognition system’ means an AI system capable of identifying, categorizing or inferring emotions, thoughts, states of mind (such as 'deception', 'trustworthiness', or 'trustfulness') or intentions of natural persons on the basis of their biometric data;",
        "title":"Amendment 1033: Article 3 – paragraph 1 – point 34  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"f1298d51-eb64-47d3-a55d-ea1f04642fd9",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions or intentions of natural persons on the basis of their biometric or behavioural data or by means of biological or brain implants;",
        "title":"Amendment 1034: Article 3 – paragraph 1 – point 34  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"f4d53535-7e64-4d9c-b3cb-b270da7c2a82",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions or intentions of natural persons on the basis of their biometric or other data obtained, read or interpreted from an individual;",
        "title":"Amendment 1035: Article 3 – paragraph 1 – point 34  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"f9916ad9-6a5b-4131-9708-3480db52d683",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions thoughts, states of mind or intentions of individuals or groups on the basis of their biometric and biometric-based data;",
        "title":"Amendment 1036: Article 3 – paragraph 1 – point 34  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Paul Tang, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"716af715-0a54-4261-a5cb-2c0f890403ba",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts or intentions of natural persons on the basis of their biometric or biometrics-based data;",
        "title":"Amendment 1037: Article 3 – paragraph 1 – point 34  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"00d51943-5cc2-4569-b219-03ed57f2815a",
        "text":"(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind or intentions of natural persons;",
        "title":"Amendment 1038: Article 3 – paragraph 1 – point 35  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"b1633dd4-4638-4c28-919c-e8a83a45ce30",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as gender, sex, age, hair colour, eye colour, tattoos, ethnic or social origin, health, mental or physical ability, behavioural or personality traits, language, religion, or membership of a national minority, or sexual or political orientation, on the basis of their biometric or biometric-based data, or which can be reasonably inferred from such data.",
        "title":"Amendment 1039: Article 3 – paragraph 1 – point 35  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"f6d5421b-2b07-4e10-ae77-bc4e20ca1db6",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as gender, sex, age, hair colour, eye colour, tattoos, ethnic or social origin, health, mental or physical ability,behavioural or personality traits, language, religion, or membership of a national minority, or sexual or political orientation, on the basis of their biometric or biometric-based data, or which can be reasonably inferred from such data;",
        "title":"Amendment 1040: Article 3 – paragraph 1 – point 35  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6e85192f-f118-4cf5-8868-0309034f893d",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as sex, age, hair colour, eye colour, health, mental ability, personality traits, tattoos, ethnic origin or sexual or political orientation, on the basis of their biometric data or biometrics-based data;",
        "title":"Amendment 1041: Article 3 – paragraph 1 – point 35  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"5aefb50f-28a5-496d-9445-be7d7aced0fc",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as sex, age, hair colour, eye colour, tattoos, health, ethnic origin or sexual or political orientation, on the basis of their biometric data;",
        "title":"Amendment 1042: Article 3 – paragraph 1 – point 35  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"b920466a-184a-48f4-96a1-efc5ea831776",
        "text":"(35) ‘biometric categorisation system’ means an AI system that uses biometric or biometrics-based data for the purpose of assigning natural persons to specific categories, or inferring their characteristics and attributes ;",
        "title":"Amendment 1043: Article 3 – paragraph 1 – point 35  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"82aa5c89-596d-41d4-bcad-64373dff6380",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories or inferring their characteristics and attributes on the basis of their biometric or biometrics-based data;",
        "title":"Amendment 1044: Article 3 – paragraph 1 – point 35  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"6d0d6627-a9f2-4aad-b700-ce0ce3e386a2",
        "text":"(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories or inferring their characteristics and attributes on the basis of their biometric data or biometrics-based data;",
        "title":"Amendment 1045: Article 3 – paragraph 1 – point 35  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"aa02f5dc-3285-4f13-bf80-79c718e169fa",
        "text":"(35) ‘biometric categorisation system’ means an AI system that uses biometric data, or other physical, physiological or behavioral data, capable of assigning natural persons to specific categories or inferring their characteristics and attributes;",
        "title":"Amendment 1046: Article 3 – paragraph 1 – point 35  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"4556dc2a-d6d9-4a86-a83d-b794bc5f1f53",
        "text":"(35 a) ‘remote biometric categorisation system’ means a biometric categorisation system capable of categorising natural persons at a distance;",
        "title":"Amendment 1047: Article 3 – paragraph 1 – point 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"dcea3f82-c912-4c0a-ab0a-96e7dc3c7da6",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified; this does not include biometric identification systems used for remote customer onboarding as proscribed under Article 13(1) of Directive (EU) 2018\/843 of the European Parliament and of the Council, nor the use for authentication as defined under Articles 4(29) & 4(30) of Directive (EU) 2015\/2366 of the European Parliament and of the Council;",
        "title":"Amendment 1048: Article 3 – paragraph 1 – point 36  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"376906c6-1091-4fb7-b5b7-665660ded1d5",
        "text":"(36) ‘biometric identification system’ means an AI system, including remote biometric identification, for the purpose of identifying natural persons including at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification\/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises; , and without prior knowledge of the user of the AI system whether the person will be present and can be identified;",
        "title":"Amendment 1049: Article 3 – paragraph 1 – point 36  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"63aa7d4e-dbf6-4244-8fbc-ff2fb3a35a76",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons, at a physical distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification\/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises; and without prior knowledge of the user of the AI system whether the person will be present and can be identified;",
        "title":"Amendment 1050: Article 3 – paragraph 1 – point 36  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Eugen Jurzyca"
    },
    {
        "uuid":"42009a99-5d39-4c01-abf1-8ffd8432f36c",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified, , excluding authentification and verification systems whose sole purpose is to confirm, based on prior consent, that a specific natural person is the person he or she claims to be or to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;",
        "title":"Amendment 1051: Article 3 – paragraph 1 – point 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"1da8ec78-3d9c-4271-9d5c-8e9f9227942d",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified, excluding verification\/authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;",
        "title":"Amendment 1052: Article 3 – paragraph 1 – point 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"b7794757-9c2b-40fb-af1e-1bb76e52839e",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database.",
        "title":"Amendment 1053: Article 3 – paragraph 1 – point 36  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"866d7f46-1e6a-462f-9fd4-452cc3474471",
        "text":"(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;",
        "title":"Amendment 1054: Article 3 – paragraph 1 – point 36  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a0e66b8b-efb3-4c3d-bb78-757b0df5027f",
        "text":"(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;",
        "title":"Amendment 1055: Article 3 – paragraph 1 – point 36  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"750caadb-ff11-45f7-a888-d95bc77897a4",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;",
        "title":"Amendment 1056: Article 3 – paragraph 1 – point 36  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"801848c7-abbe-4ce4-bc92-e12bb5cdfbf5",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;",
        "title":"Amendment 1057: Article 3 – paragraph 1 – point 36  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d9eba275-04f8-47ed-a17f-5944f18dbb47",
        "text":"(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database or data repository;",
        "title":"Amendment 1058: Article 3 – paragraph 1 – point 36  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f12ecdf6-849d-429e-aee0-f91cded9f9fc",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a physical distance through a “one to many” comparison where the persons identified do not claim to have a particular identity but where the identity is otherwise established - without the conscious cooperation of these persons - by matching live templates with templates stored in a template database;",
        "title":"Amendment 1059: Article 3 – paragraph 1 – point 36  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"d039a6d6-9119-4485-9fd2-cc554bc2b61c",
        "text":"(36) ‘remote biometric identification system’ means an AI system for the purpose, after a unique process, of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;",
        "title":"Amendment 1060: Article 3 – paragraph 1 – point 36  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"14ac66b8-4a9e-4daa-8a69-27b02581ca90",
        "text":"(36) ‘remote biometric identification system’ means an AI system capable of categorizing natural persons at a distance through the comparison of a person’s biometric data or other physical, physiological or behavioral data, with this data contained in a reference database;",
        "title":"Amendment 1061: Article 3 – paragraph 1 – point 36  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"566dfe60-a4a8-4c97-9804-f2f6888bd608",
        "text":"(36 a) ‘at a distance’ means the process of identification, verification or authentication in physical distance with indirect interaction with the data subject or without;",
        "title":"Amendment 1062: Article 3 – paragraph 1 – point 36 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"c9284730-eac2-4fe7-9d7b-9d4230ba7187",
        "text":"deleted",
        "title":"Amendment 1063: Article 3 – paragraph 1 – point 37  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Patrick Breyer"
    },
    {
        "uuid":"3ca4f5e4-8ffe-4c64-8eca-8379158c18da",
        "text":"(37) biometric identification system’ means a remote biometric identification system whereby the capturing of biometric data, the comparison and the identification occur on a continuous or large-scale basis over a period of time and without limitation to a particular past incident.",
        "title":"Amendment 1064: Article 3 – paragraph 1 – point 37  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"e4b751b3-c08a-4a16-b983-27dd59d8d899",
        "text":"deleted",
        "title":"Amendment 1065: Article 3 – paragraph 1 – point 38  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9fe1a89a-750b-4930-a7db-37d99a582eeb",
        "text":"(38) ‘‘post’ remote biometric identification system’ means a remote biometric identification system other than a ‘real-time’ remote biometric identification system, regardless of whether the acquired data is hosted in a separate system prior to the comparison and identification;",
        "title":"Amendment 1066: Article 3 – paragraph 1 – point 38  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"d82353ac-18d9-4cd5-a67f-1824084d96a2",
        "text":"(38 a) 'deepfakes' means manipulated or synthetic audio or video which appears to be authentic, and which feature people, without their consent\/awareness, or events that are false and\/or misleading, produced using artificial intelligence techniques, including machine learning and deep learning;",
        "title":"Amendment 1067: Article 3 – paragraph 1 – point 38 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"89e7ae41-4027-40ae-bcfa-926d5611f3ce",
        "text":"(39) ‘publicly accessible space’ means any publicly or privately owned physical place accessible to an undetermined number of natural persons, regardless of whether certain conditions or circumstances for access have been predetermined, and regardless of the potential capacity restrictions;",
        "title":"Amendment 1068: Article 3 – paragraph 1 – point 39  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"f510d46e-fe7a-480b-884f-cb4dea59b304",
        "text":"(39) ‘publicly accessible space’ means any place accessible to the public, or fulfilling a public function, regardless of whether certain conditions for access may apply;",
        "title":"Amendment 1069: Article 3 – paragraph 1 – point 39  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"25ec9719-c35a-478c-b074-68d870aebd8f",
        "text":"(40) ‘law enforcement authority’ means any public authority competent for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;",
        "title":"Amendment 1070: Article 3 – paragraph 1 – point 40 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"3f55e14e-8cd4-4737-a3ec-b371b8e8e801",
        "text":"deleted",
        "title":"Amendment 1071: Article 3 – paragraph 1 – point 40 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"5940a7e5-9350-40c6-a7db-7e3ec49e4688",
        "text":"(a a) any other authority competent for law enforcement, including courts and the judiciary;",
        "title":"Amendment 1072: Article 3 – paragraph 1 – point 40 – point a a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e9bb37d6-b025-47d1-9f3f-ac3ff295a02c",
        "text":"deleted",
        "title":"Amendment 1073: Article 3 – paragraph 1 – point 40 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"de92a782-26ae-4f28-a9db-b593b7d5ff9c",
        "text":"(41) ‘law enforcement’ means', 'i) activities carried out by law enforcement authorities for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security; and', 'ii) activities carried out by any other authority that is part of the criminal justice system, including the judiciary;",
        "title":"Amendment 1074: Article 3 – paragraph 1 – point 41  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"723374d9-369c-4520-8775-67c545937734",
        "text":"(41) ‘law enforcement’ means activities carried out by law enforcement authorities or on their behalf for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;",
        "title":"Amendment 1075: Article 3 – paragraph 1 – point 41  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"3fc5bc90-c3b7-432b-b73f-5fb1800bfcbb",
        "text":"(41) ‘law enforcement’ means activities carried out by law enforcement authorities solely for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;",
        "title":"Amendment 1076: Article 3 – paragraph 1 – point 41  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"227e2426-528e-4674-9e1b-d79407f22391",
        "text":"(42) ‘national supervisory authority’ means an independent public authority to which a Member State assigns the responsibility for the implementation and application of this Regulation, for coordinating the activities entrusted to that Member State, for acting as the single contact point for the Commission, and for representing the Member State at the European Artificial Intelligence Board;",
        "title":"Amendment 1077: Article 3 – paragraph 1 – point 42  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e3a44a1e-019e-4782-bf1c-eee336302135",
        "text":"(42) ‘national supervisory authority’ means the authority to which a Member State assigns the responsibility for the implementation and application of this Regulation, for coordinating the activities entrusted to that Member State, for acting as the single contact point for the Commission, and for representing the Member State in the management board of the AI Office;",
        "title":"Amendment 1078: Article 3 – paragraph 1 – point 42  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"30002c61-7c9a-4e8a-b8b1-6e7232f4c1db",
        "text":"deleted",
        "title":"Amendment 1079: Article 3 – paragraph 1 – point 43  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e6f79378-29ee-41b6-982d-aa3a663790fd",
        "text":"(43) ‘national competent authority’ means the notifying authority and the market surveillance authority;",
        "title":"Amendment 1080: Article 3 – paragraph 1 – point 43  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ea98bafc-a75f-4b86-be3f-8262e318ae79",
        "text":"(43) ‘competent authority’ means the EDPS, the national supervisory authority, the notifying authority and the market surveillance authority;",
        "title":"Amendment 1081: Article 3 – paragraph 1 – point 43  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4825b805-f262-4c2d-b979-fc0f2747aef8",
        "text":"(44) ‘serious incident’ means any incident or malfunctioning that directly or indirectly leads, might have led or might lead to any of the following:",
        "title":"Amendment 1082: Article 3 – paragraph 1 – point 44 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"dd972a3d-e4b1-4de7-874f-3375e5228912",
        "text":"(44) ‘serious incident’ means any incident that directly or indirectly leads to any of the following:",
        "title":"Amendment 1083: Article 3 – paragraph 1 – point 44 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"655a28dc-022a-485b-aabd-0f43ff9363a7",
        "text":"(44) ‘serious incident’ means any incident that directly or indirectly leads to any of the following:",
        "title":"Amendment 1084: Article 3 – paragraph 1 – point 44 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"5f7e5fe3-6b3b-47b2-b486-15198a5392e4",
        "text":"(a) the death of a person or serious damage to a person’s physical health, mental health or wellbeing, to property or the environment,",
        "title":"Amendment 1085: Article 3 – paragraph 1 – point 44 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"142806af-6acb-422a-95dd-bb186f7008dc",
        "text":"(a) the death of a person or serious damage to a person’s physical health, mental health or wellbeing, to property or the environment",
        "title":"Amendment 1086: Article 3 – paragraph 1 – point 44 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b1bf3500-cd17-4467-b1c9-dfb141988c69",
        "text":"(a) the death of a person or damage to a person’s health or wealth, to property or the environment,",
        "title":"Amendment 1087: Article 3 – paragraph 1 – point 44 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"5cf65f45-9623-46bb-bd81-0107cd5c25cf",
        "text":"(a) the death of a person or serious damage to a person’s health,",
        "title":"Amendment 1088: Article 3 – paragraph 1 – point 44 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0008b349-6852-4f07-8cec-4fd26eca3d69",
        "text":"(a) the death of a person or damage to a person’s health, to property or the environment,",
        "title":"Amendment 1089: Article 3 – paragraph 1 – point 44 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"3d95ee0f-06da-4c92-bd90-32fd5d570ddf",
        "text":"(a a) a breach of fundamental rights defined by The Charter of Fundamental Rights of the European Union;",
        "title":"Amendment 1090: Article 3 – paragraph 1 – point 44 – point a b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"428b8804-acd0-451e-9578-e543f084aa71",
        "text":"(a b) systematic, mass or serious breach of other rights;",
        "title":"Amendment 1091: Article 3 – paragraph 1 – point 44 – point a b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4c00bff0-af64-4da0-9aa2-14e6f8fffd52",
        "text":"(a c) damage to democracy, the rule of law or the environment",
        "title":"Amendment 1092: Article 3 – paragraph 1 – point 44 – point a c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"85e070b0-32cc-4ec7-8779-e33c462c7d1a",
        "text":"(b) a serious disruption of the management and operation of critical infrastructure,",
        "title":"Amendment 1093: Article 3 – paragraph 1 – point 44 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"38f0e4cd-a3e9-4ca8-b3cf-abdb54f314a5",
        "text":"(ba) a breach of obligations under national law or Union law intended to protect fundamental rights.",
        "title":"Amendment 1094: Article 3 – paragraph 1 – point 44 – point b a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b0901b24-6277-438f-b58f-8f6fb38d248b",
        "text":"(b a) a breach of obligations under Union law intended to protect fundamental rights;",
        "title":"Amendment 1095: Article 3 – paragraph 1 – point 44 – point b a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a84c4971-c72d-4f07-a823-b36e3375e412",
        "text":"(b a) breach of obligations under Union law intended to protect personal data",
        "title":"Amendment 1096: Article 3 – paragraph 1 – point 44 – point b a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"59ee37dc-60e6-46c7-9cab-d84865aff101",
        "text":"(b a) a serious violation of an individual’s fundamental rights;",
        "title":"Amendment 1097: Article 3 – paragraph 1 – point 44 – point b a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4e85bc90-a8ce-433b-9b94-f77dc7dcf80d",
        "text":"(44 a) ‘AI systems presenting a risk’ means an AI system having the potential to affect adversely fundamental rights, health and safety of persons in general, including in the workplace, protection of consumers, the environment, public security, the values enshrined in Article 2 TEU and other public interests, that are protected by the applicable Union harmonisation legislation, to a degree which goes beyond that considered reasonable and acceptable in relation to its intended purpose or under the normal or reasonably foreseeable conditions of use of the system concerned, including the duration of use and, where applicable, its putting into service, installation and maintenance requirements.",
        "title":"Amendment 1098: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8e9cc35b-9d84-475e-a53c-da29c63758a4",
        "text":"(44 a) ‘regulatory sandbox’ means a framework which, by providing a structured context for experimentation, enable where appropriate in a real-world or digital environment the testing of innovative technologies, products, services or approaches for a limited time and in a limited part of a sector or area under regulatory supervision ensuring that appropriate safeguards are in place;",
        "title":"Amendment 1099: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"aa5531b4-9c7d-43d6-b609-d85c4971e5ae",
        "text":"(44 a) ‘Recommender system’ means a fully or partially automated system used by an online platform to suggest or prioritise in its online interface specific information to recipients of the service, including as a result of a search initiated by the recipient of the service or otherwise determining the relative order or prominence of information displayed.",
        "title":"Amendment 1100: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f30c4e3a-d87b-4e4a-8da0-7cbe8659f47b",
        "text":"(44 a) 'critical infrastructure' means an asset, system or part thereof which is necessary for the delivery of a service that is essential for the maintenance of vital societal functions or economic activities within the meaning of Article 2(4) and (5) of Directive (…) on the resilience of critical entities;",
        "title":"Amendment 1101: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"ae9e4435-2d7e-4f32-991e-ab65a78edcf7",
        "text":"(44a) ‘bias’ means any inclination of prejudice towards or against a person, object or position, whether voluntary or involuntary, that may arise as a result of the design, data supply, interactions, personalisation or configuration of an IA system;",
        "title":"Amendment 1102: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"72e4815c-59d6-4999-a2fc-57b45eb90bb2",
        "text":"(44 a) ‘regulatory sandbox’ means a facility that provides a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan;",
        "title":"Amendment 1103: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"612074cc-516f-427f-ab03-46faab04fdf8",
        "text":"(44 a) ‘unfair bias’ means an inclination of prejudice towards or against a natural person that can result in discriminatory and\/or unfair treatment of some natural persons with respect to others;",
        "title":"Amendment 1104: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"d9bddc5d-f848-4e63-99f8-666a0112f781",
        "text":"(44 a) ´scientific research and development´ means any scientific development, experimentation, analysis, testing or validation carried out under controlled conditions.",
        "title":"Amendment 1105: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"de9e6032-9011-4ec9-aa6b-c669fa48bd50",
        "text":"(44 a) scientific research and development means: any scientific development, experimentation, analysis, testing or validation carried out under controlled conditions.",
        "title":"Amendment 1106: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"231b2f8e-2a8e-47bb-abee-4f388daf0e77",
        "text":"(44 a) 'near miss' means any incident that, if the circumstances were slightly different, would have resulted in a 'serious incident';",
        "title":"Amendment 1107: Article 3 – paragraph 1 – point 44 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ce6f18dc-1ffd-4b21-ac29-d515f0647505",
        "text":"(44 b) ‘social scoring’ means the evaluation or categorisation of EU citizens based on their behavior or (personality) characteristics, where one or more of the following conditions apply:', '(i) the information is not reasonably relevant for the evaluation or categorisation;', '(ii) the information is generated or collected in another domain than that of the evaluation or categorisation;', '(iii) the information is not necessary for or proportionate to the evaluation or categorisation;', '(iv) the information contains or reveals special categories of personal data.",
        "title":"Amendment 1108: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"efd3382f-d7ee-4091-93c5-ae8d56b151b8",
        "text":"(44 b) ‘social scoring’ means the evaluation or categorisation of persons based on their behaviour or (personality) characteristics, where one or more of the following conditions apply:', '(i) the information is not reasonably relevant for the evaluation or categorisation;', '(ii) the information is generated or collected in another domain than that of the evaluation or categorisation;', '(iii) the information is not necessary for or proportionate to the evaluation or categorisation;', '(iv) the information contains or reveals special categories of personal data.",
        "title":"Amendment 1109: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b00b309a-dea7-4343-890d-ed5be6e01599",
        "text":"(44 b) ‘deep fake’ means manipulated or synthetic audio, image or video content that would falsely appear to be authentic or truthful, and which features depictions of persons appearing to say or do things they did not say or do, without their consent, produced using AI techniques, including machine learning and deep learning;",
        "title":"Amendment 1110: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"28847951-da06-4762-bc28-4504b73fab11",
        "text":"(44 b) ‘deep fake’ means an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful.",
        "title":"Amendment 1111: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"41b80337-2961-40fa-9483-838e5eeb6a88",
        "text":"(44 b) ‘artificial intelligence system with indeterminate uses’ means an artificial intelligence system without specific and limited provider-defined purposes;",
        "title":"Amendment 1112: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"5dd7c274-302a-4a49-8c6b-dba86377c1d0",
        "text":"(44b) ‘auditability’ means the ability of an AI system to undergo an assessment of the system’s algorithms, data and design processes;",
        "title":"Amendment 1113: Article 3 – paragraph 1 – point 44 b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"bef33f9f-2f64-453c-ae66-e1d5892f2123",
        "text":"(44 b) ‘child’ means any person below the age of 18 years.",
        "title":"Amendment 1114: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"93cfb0b1-d350-4fbf-85d2-01de932e1dc0",
        "text":"(44c) ‘reproducibility’ means the ability of an AI system to exhibit the same behaviour when an experiment is repeated under the same conditions;",
        "title":"Amendment 1115: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"614d5f97-fd20-4948-9ec4-e41e6c915f39",
        "text":"(44 c) ‘affectee(s)’ mean(s) any natural or legal person or group of natural or legal persons affected by the use or outcomes of, or a combination of, AI system(s);",
        "title":"Amendment 1116: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c741e9ea-0eb0-45a1-ae1e-7e4bd8042767",
        "text":"(44 c) ‘profiling’ means any form of automated processing of personal data as defined point (4) of Article 4 of Regulation (EU) 2016\/679;",
        "title":"Amendment 1117: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"49fffb92-426a-467e-a6ff-d7d7a3c71fde",
        "text":"(44 c) ‘incident’ means a faulty operation of an AI system;",
        "title":"Amendment 1118: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b7f58e3b-ea81-4f18-b324-923b218cada9",
        "text":"(44 c) “child” is any person under the age of 18.",
        "title":"Amendment 1119: Article 3 – paragraph 1 – point 44 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1190bac5-6c99-4af7-970b-96adfe3d1ffa",
        "text":"(44 d) ‘artificial intelligence system within determinate uses’ means an artificial intelligence system without specific and limited provider-defined purposes;",
        "title":"Amendment 1120: Article 3 – paragraph 1 – point 44 d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"70456243-600b-427b-b7ca-72d8558904f7",
        "text":"(44 d) ‘personal data’ means data as defined in point (1) of Article 4 of Regulation (EU) 2016\/679;",
        "title":"Amendment 1121: Article 3 – paragraph 1 – point 44 d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f8d35c61-1594-416e-9481-b5ff2df51fe8",
        "text":"(44 e) 'deep fake' means generated or manipulated image, audio or video content produced by an AI system that appreciably resembles existing persons, objects, places or other entities or events and falsely appears to a person to be authentic or truthful;",
        "title":"Amendment 1122: Article 3 – paragraph 1 – point 44 e (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"499c2780-71aa-4fc4-8003-66face3df225",
        "text":"(44 e) ‘non-personal data’ means data other than personal data as defined in point (1) of Article 4 of Regulation (EU) 2016\/679;",
        "title":"Amendment 1123: Article 3 – paragraph 1 – point 44 e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f3986fa2-a5a4-4ce2-8a76-a26c7c03b769",
        "text":"(44 f) ‘critical infrastructure’ means an asset, system or part thereof which is neccesary for the delivery of a service that is essential for the maintenance of vital societal functions or economic activities within the meaning of Article 2 (4) and (5) of Directive of the European Parliament and of the Council on the resilience of critical entities (2020\/0365 (COD));",
        "title":"Amendment 1124: Article 3 – paragraph 1 – point 44 f (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f5660bb2-5867-4df3-95f4-f109ecbc98ee",
        "text":"(44 f) 'redress by design' means technical mechanisms and\/or operational procedures, established from the design phase, in order to be able to effectively detect, audit, rectify the consequences and implications of wrong predictions by an AI system and improve it.",
        "title":"Amendment 1125: Article 3 – paragraph 1 – point 44 g (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f6e03868-55db-40fb-ad8b-b52531a1ce79",
        "text":"(44 g) ‘harmful subliminal technique’ means a measure whose existence and operation is entirely imperceptible by a natural person on whom it is used, and which has the purpose and direct effect to induce actions leading to that persons physical or phychological harm;",
        "title":"Amendment 1126: Article 3 – paragraph 1 – point 44 g (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d0a14401-442c-45e2-bb44-7a75d7ff52b4",
        "text":"(44 h) 'unfair bias' means an inclination of prejudice towards or against a natural person that can result in discriminatory and\/or unfair treatment of some natural persons with respect to others.",
        "title":"Amendment 1127: Article 3 – paragraph 1 – point 44 h (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ce5f6591-9cc2-4578-bf78-072231e68a24",
        "text":"Social scoring' means the evaluation or categorization of an individual natural person, or a group, based on their behaviour or (personality) characteristics, where one or more of the following conditions apply: (1) the information is not reasonably relevant, necessary for, or proportionate to the evaluation or categorization; (2) the information is generated or collected in another domain than that of the evaluation or categorization; (3) the information contains or reveals special categories.",
        "title":"Amendment 1128: Article 3 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"b60b9127-8e04-4d14-b518-f6e48dbfb99d",
        "text":"Article 3 a', 'General Purpose AI', '1. General purpose AI applications shall not be considered as having an intended purpose within the meaning of this Regulation unless those systems have been adapted to a specific intended purpose that falls within the scope of this Regulation.', '2. Any natural or legal person that adapts a general purpose AI application to a specific intended purpose and places it on the market or puts it into service shall be considered the provider and be subject to the obligations laid down in this Regulation.', '3.The initial provider of a general purpose AI application shall comply with Article 15 of this Regulation at all times. After placing it on the market or putting it to service, and without compromising its own intellectual property rights or trade secrets, provide the new provider referred to in paragraph 2 with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '4. The initial provider of a general purpose AI application shall only be responsible for the accuracy of the provided information and compliance with Article 15 of this Regulation towards the natural or legal person that adapts the general purpose AI application to a specific intended purpose.",
        "title":"Amendment 1129: Article 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-"
    },
    {
        "uuid":"98562806-486a-49fb-8746-3950ee1d67b1",
        "text":"deleted",
        "title":"Amendment 1130: Article 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky"
    },
    {
        "uuid":"0ead957a-1583-409e-a7c6-8f184e740cfe",
        "text":"deleted",
        "title":"Amendment 1131: Article 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1cf81981-ace9-4f0d-953c-74a805729138",
        "text":"deleted",
        "title":"Amendment 1132: Article 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"f9e6592e-8060-4d26-a7b1-138c2ac6868b",
        "text":"deleted",
        "title":"Amendment 1133: Article 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"a2830b94-c903-4d20-97f2-d94dbee4b0c7",
        "text":"deleted",
        "title":"Amendment 1134: Article 4 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"d4fb375d-5dc7-460a-a3cc-ceb3d760bef6",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73, after ensuring adequate consultation with relevant stakeholders, to amend the list of techniques and approaches listed in Annex I within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of transparent criteria.', 'Every time the list of techniques and approaches listed in Annex I is amended, providers and users of AI systems, which become in scope of the Regulation shall have 24 months to apply the relevant requirements and obligations. Article 83 shall apply for AI systems already placed on the market before delegated acts are published.",
        "title":"Amendment 1135: Article 4 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"38673174-1aff-4656-81b9-1d25a0f34804",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73, after an adequate and transparent consultation process involving the relevant stakeholders, to amend the list of techniques and approaches listed in Annex I within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of transparent characteristics. Providers and users of AI systems should be given 24 months to comply with any amendment to Annex I.",
        "title":"Amendment 1136: Article 4 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"b9baa11b-dd67-438e-b402-4c9dfa2fdde8",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of characteristics and hazards that are similar to the techniques and approaches listed therein.",
        "title":"Amendment 1137: Article 4 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"5a77a1dc-d316-45f5-aa54-d6a194376ca1",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments on the basis of characteristics that are similar to the techniques and approaches listed therein. As an adequate transitional period, two years shall be applied to each amendment.",
        "title":"Amendment 1138: Article 4 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"29bc98ee-8f9f-4d37-89ca-a1aae02b16d9",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments by means of additions or non-restrictive precisions on the basis of characteristics that are similar to the techniques and approaches listed therein.",
        "title":"Amendment 1139: Article 4 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"8c57eba3-1afb-441e-bef1-d7ce638361bf",
        "text":"The Commission is empowered to adopt delegated acts in accordance with Article 73 after consulting relevant stakeholders to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments on the basis of characteristics that are similar to the techniques and approaches listed therein.",
        "title":"Amendment 1140: Article 4 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"42487d2f-0f4b-4f64-8bf7-c132af74e8a8",
        "text":"Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1.Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle.To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2.Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or deploy, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3.Operators shall commit to transparency and responsible disclosure regarding AI systems.To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to enable those affected by an AI system to understand the outcome, and', '(d) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’)', '4.Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they functionappropriately and do not pose unreasonable risk.Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of art.', 'Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5.Operators shall proactively engage in pursuit of beneficial outcomes for people, socieites and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’)', '6. Operators should be motivated to follow a human-centric approach. AI available in the Union market or otherwise affecting people in the Union should be designed human centered, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights what requires a shift towards a Human Centered AI Engineering, also in research and education.",
        "title":"Amendment 1141: Article 4 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Bettina Vollath"
    },
    {
        "uuid":"775f6e18-a3f6-4800-b941-a070ee2ce856",
        "text":"The techniques and approaches listed in Annex I may only be amended by an amending regulation if the amendment concerns a withdrawal, a restrictive precision or a change in the definition of those techniques and approaches.",
        "title":"Amendment 1142: Article 4 – paragraph 1 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"18e5bebb-8c42-4798-b3cc-4da8b184cf75",
        "text":"Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1. Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle. To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2. Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or use, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3. Operators shall commit to transparency and responsible disclosure regarding AI systems. To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of the art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to make affected persons aware about their rights conferred in this Regulation,', '(d) to enable those affected by an AI system to understand the outcome, and', '(e) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’).', '4. Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose unreasonable risk. Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of the art. Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5. Operators shall proactively engage in pursuit of beneficial outcomes for people, societies and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’).",
        "title":"Amendment 1143: Article 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"7004d0e1-852a-436b-a294-242d132076cf",
        "text":"Article 4 a', 'Trustworthy AI systems', '1. The principles set out in this Article establish a high-level framework for a coherent and coordinated human-centric European approach on trustworthy AI systems that respect and promote the values on which the Union is founded. This Regulation takes those principles into account by establishing certain requirements for high-risk AI systems listed in Article 8 to 15.', '• ‘human agency and oversight’ means that AI systems shall be developed and used as a tool that serves people, respects human dignity and personal autonomy, and that is functioning in a way that can be controlled and overseen by humans in a manner that is appropriate to the circumstances of the case.', '• ‘technical robustness and safety’ means that AI systems shall be developed and used in a way to minimize unintended and unexpected harm as well as being robust in case of problems and being resilient against attempts to alter the use or performance of the AI system by malicious third parties.', '• ‘privacy and data governance’ means that AI systems shall be developed and used in compliance with existing privacy and data protection rules, while processing data that meets high standards in terms of quality and integrity.', '• ‘transparency’ means that AI systems shall be developed and used in a way that allows appropriate traceability and explainability, while making humans Aware that they communicate or interact with an AI system as well as duly informing users of the capabilities and limitations of that AI system.', '• ‘diversity, non-discrimination and fairness’ means that AI systems shall be developed and used in a way that includes diverse actors and promotes equal access, while avoiding discriminatory impacts that are prohibited by Union or Member States law.', '• ‘social and environmental well-being’ means that AI systems shall be developed and used in a sustainable and environmentally friendly manner as well as in away to benefit all human beings, while monitoring and assessing the long-term impacts on the individual, society and democracy.', '• ‘accountability’ means that AI systems shall be developed or used in a way that facilitates auditability and accountability pursuant to applicable Union and Member States law, while making clear who is legally responsible in case the AI system causes negative impacts.', '2. Paragraph 1 is without prejudice to obligations set up by existing Union and Member States legislation and does not create any additional obligations for providers or users.', '3. European Standardisation Organisations shall understand the principles referred to in paragraph 1 as outcome-based objectives when developing the appropriate harmonised standards for high risk AI systems as referred to in Article 40(2b). For all other AI systems, the voluntary application on the basis of harmonised standards, technical specifications and codes of conducts as referred to in Article 69(1a) is encouraged.",
        "title":"Amendment 1144: Article 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"57653e64-e6d2-4804-83ce-c176aa6a49ee",
        "text":"Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1. Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle. To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2. Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or deploy, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3. Operators shall commit to transparency and responsible disclosure regarding AI systems. To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to enable those affected by an AI system to understand the outcome, and', '(d) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’)', '4. Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose unreasonable risk. Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of art.', 'Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5. Operators shall proactively engage in pursuit of beneficial outcomes for people, socieites and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’)",
        "title":"Amendment 1145: Article 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar"
    },
    {
        "uuid":"82bd5e37-f0a8-4eb2-a608-30fd1e330397",
        "text":"Article 4 a', 'Transparency Rights', '1. Providers and deployers of AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an AI system.', '2. The information referred to in paragraph 1 shall include a clear and concise indication about the provider or deployer and the purpose of the AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.', '3. This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', '4. This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016\/679 [GDPR], Directive 2016\/680 [LED], Regulation 2022\/XXX [DSA].', '5. AI subjects will have the right not to be subject to a high-risk AI system.",
        "title":"Amendment 1146: Article 4 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3494f233-7cb2-41c8-91a1-c66251c89618",
        "text":"Article 4 a', 'Notification about the use of an AI system', '1. Users of AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an AI system.', '2. The information referred to in paragraph 1 shall include a clear and concise indication of the user and the purpose of the AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.', '3. This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', '4. This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016\/679, Directive 2016\/680, Regulation 2022\/XXX.",
        "title":"Amendment 1147: Article 4 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"ccd226f9-6054-4a34-9089-527de14472f7",
        "text":"Article 4 b', 'Accessibility Requirements for providers and users of AI systems', '1. Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882 prior to those systems being placed on the market or put into service.', '2. Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882.', '3. Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019\/882. Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public in an accessible manner for persons with disabilities and be kept for as long as the AI system is in use.', '4. Without prejudice to the rights of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, obligations to ensure consistent and meaningful public transparency under this Regulation, providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in such a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019\/882.', '5. Users of AI systems shall ensure that procedures are in place so that the use of AI systems remains in conformity with the applicable accessibility requirements. Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user.', '6. In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements. When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements.', '7. Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken. They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements.', '8. AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019\/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements.', '9. AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive (EU) 2019\/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.",
        "title":"Amendment 1148: Article 4 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"214d5a02-44eb-4824-ba32-104006b372b0",
        "text":"Article 4 b', 'Explanation of individual decision-making', '1. A decision made by or with the assistance of a high risk AI system which produces legal effects concerning a person, or which similarly significantly affects that person, shall be accompanied by a meaningful, relevant explanation of at least:', '(a) the role of the AI system in the decision-making process;', '(b) the input data relating to the affected person, including the indication of his or her personal data on the basis of which the decision was made;', '(c) for high-risk AI systems, the link to the entry in the EU database referred to in Article 60;', '(d) the information about the person’s rights under this Regulation, including the right to lodge a complaint with the national supervisory authority.', 'For information on input data under point b) to be meaningful it must include an easily understandable description of inferences drawn from other data.', '2. Paragraph 1 shall not apply to the use of AI systems:', '(a) that are authorised by law to detect, prevent, investigate and prosecute criminal offences or other unlawful behaviour under the conditions laid down in Article 3(41) and Article 52 of this Regulation, if not explaining the decision is necessary and proportionate for detection, prevention, investigation and prosecution of a specific of-fence;', '(b) for which exceptions from, or restrictions to, the obligation under paragraph 1 follow from Union or Member State law, which lays down appropriate other safeguards for the affected person’s rights and freedoms and legitimate interests.', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person and shall be provided in a clear, easily understandable, and intelligible way, accessible for persons with disabilities.', '4. If the affected person believes that the decision produced legal effects or similarly significantly affects him or her, but the deployer has not provided the explanation, he or she may request it. The deployer shall inform the affected person within 7 days about how he assessed the request and if it is accepted, the explanation shall be provided without undue delay. If the request is refused, the deployer shall in-form the affected person of the right to complain to the national supervisory authority.",
        "title":"Amendment 1149: Article 4 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2d3afdf4-9c69-4652-b4f0-6b52fcc3ddc7",
        "text":"Article 4 b', 'Principles applicable to all AI systems', '1. Providers and deployers of AI systems shall respect the following principles:', '(a) AI systems must be used in a fair and transparent manner in relation to AI subjects;', '(b) AI subjects shall have a right to automatically receive an explanation in accordance with Article 4c;', '(c) AI subjects shall have the right to object to a decision taken solely by an AI system, or relying to a significant degree on the output of an AI system, which produces legal effects concerning him or her, or similarly significantly affects him or her. This paragraph is without prejudice to Article 22 of Regulation 2016\/679;', '(d) AI systems shall not be used to exploit power and information asymmetries to the detriment of AI subjects, regardless of whether such asymmetries already exist or may be created or aggravated by the use of AI systems themselves. In particular, AI systems may not be used to discriminate against AI subjects on the basis of the characteristics listed in Article 21 of the European Charter of Fundamental Rights, on the basis of biometrics-based data, as well as on the basis of economic factors;', '(e) AI systems must be safe and secure, ensuring a performance that is reliable, accurate, and robust throughout their lifecycle;', '(f) AI systems intended to interact with AI subjects shall be designed and developed in such a way that natural individuals are informed that they are interacting with an AI system, especially where its outputs or behaviour may be reasonably mistaken for that of a human being;', '2. Providers of AI systems shall be responsible for, and be able to demonstrate compliance with, the principles established in paragraph 1. This requirement shall apply accordingly to deployers where they have substantially influenced the intended purpose or the manner of operation of the AI system;', '3. The functioning of AI systems shall be regularly monitored and assessed to ensure they respect the rights and obligations set out in Union law;', '4. These principles shall apply without prejudice to existing obligations relating to transparency, explanation or motivation of decision-making under Member State or Union law.",
        "title":"Amendment 1150: Article 4 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"43c584bf-1161-471f-9ff0-6a7c079252c9",
        "text":"Article 4 b', 'A right to explanation of individual decision-making', '1. A decision which is taken by the user on the basis of the output from an AI system and which produces legal effects on an affected person, or which similarly significantly affects that person, shall be accompanied by a meaningful explanation of:', '(a) the role of the AI system in the decision-making process;', '(b) the logic involved, the main parameters of the decision-making, and their relative weight; and', '(c) the input data relating to the affected person and each of the main parameters on the basis of which the decision was made.', 'For information on input data under point c) to be meaningful, it must include an easily understandable description of inferences drawn from other data, if it is the inference that relates to the main parameter.', '2. For the purpose of Paragraph 1, it shall be prohibited for the law enforcement authorities or the judiciary in the Union to use AI systems that are considered closed or labelled as proprietary by the providers or the distributors;', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person.",
        "title":"Amendment 1151: Article 4 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"575ae953-0c3c-48ed-996a-d010b4c3dbe8",
        "text":"Article 4 c', 'Explanation of individual decision-making', '1. A decision made by or with the assistance of an AI system which produces legal effects concerning an AI subject, or which similarly significantly affects an AI subject, shall be accompanied by a meaningful, relevant explanation of at least:', '(a) the role of the AI system in the decision-making process and the extent to which the output produced by the AI system influenced the decision in this case;', '(b) the logic involved, the main parameters of decision-making, and their relative weight;', '(c) the input data relating to the AI subject, including the indication of his or her personal data, and each of the parameters on the basis of which the decision was made. For the information on input data to be meaningful it must include an easily understandable description of inferences drawn from other data;', '(d) if applicable, the category or group into which the AI subject has been classified;', '(e) whether the same decision was taken in relation to other persons in similar circumstances and if not – an explanation why the AI subject was treated differently, without prejudice to the protection of personal data;', '(f) for high-risk AI systems, the link to the entry in the EU database referred to in Article 60;', '(g) the information about the person’s rights under this Regulation, including the right to lodge a complaint with a supervisory authority;', '2. Paragraph 1 shall not apply to the use of AI systems:', '(a) that are authorised by law to detect, prevent, investigate and prosecute criminal offences or other unlawful behaviour under the conditions laid down in Article 3(41) and Article 52 of this Regulation, if not explaining the decision is necessary and proportionate for detection, prevention, investigation and prosecution of a specific offence;', '(b) for which exceptions from, or restrictions to, the obligation under paragraph 1 follow from Union or Member State law, which lays down appropriate other safeguards for the affected person’s rights and freedoms and legitimate interests;', '3. The explanation within the meaning of paragraph 1 shall be provided by default at the same time when the decision is communicated to the AI subject and shall be provided in a clear, easily understandable, and intelligible way, accessible for persons with disabilities;', '4. If an AI subject has not received an explanation by default, AI subjects have the right to request it. The deployer shall inform the affected person within 7 days. If the request is refused, the deployer shall inform the AI subject of the right to complain to the national supervisory authority.",
        "title":"Amendment 1152: Article 4 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f384692d-64b1-4eea-96da-e6e99d88c0e9",
        "text":"Article 4 c', 'Right to receive an explanation of individual decision-making', '1. A decision which is taken by the user on the basis of the output from an AI system and which produces legal effects on an affected person, or which similarly significantly affects that person, shall be accompanied by a meaningful explanation of', '(a) the role of the AI system in the decision-making process;', '(b) the logic involved, the main parameters of the decision-making, and their relative weight; and', '(c) the input data relating to the affected person and each of the main parameters on the basis of which the decision was made.', 'For information on input data under point c) to be meaningful, it must include an easily understandable description of inferences drawn from other data, if it is the inference that relates to the main parameter.', '2. For the purpose of Paragraph 1, it shall be prohibited for the law enforcement authorities or the judiciary in the Union to use AI systems that are considered closed or labelled as proprietary by the providers or the distributors;', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person.",
        "title":"Amendment 1153: Article 4 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6e1187bb-7e04-4298-9268-0069d4d3639c",
        "text":"Article 4 d', 'Right not to be subject to non-compliant AI systems', 'Natural persons shall have the right not to be subject to AI systems that:', '(a) pose an unacceptable risk pursuant to Article 5, or', '(b) otherwise do not comply with the requirements of this Regulation.",
        "title":"Amendment 1154: Article 4 d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"70f1af09-bdc5-477e-90c2-6d79ffece83f",
        "text":"5 -1. Any practices related to artificial intelligence and AI systems whose development, deployment or use, or reasonably foreseeable misuse, that adversely affect, or are likely to adversely affect, the essence of any fundamental right shall be prohibited.",
        "title":"Amendment 1155: Article 5 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c474df40-6a5e-45ea-b7f9-f92632adc0c8",
        "text":"1. In addition to paragraph -1, the following artificial intelligence practices shall be prohibited:",
        "title":"Amendment 1156: Article 5 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"cdee6563-a5b7-416b-b619-e5cc193277b1",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys techniques with the effect or likely effect of materially distorting a person’s behaviour by appreciably impairing the persons’ ability to make an informed decision, thereby causing the person to take a decision that they would not have taken otherwise, in a manner that causes or is likely to cause that person or another person, or a group of persons material or non-material harm, including physical, psychological or economic harm;",
        "title":"Amendment 1157: Article 5 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"038ccd4f-59dd-40da-a164-4917b6ccec2d",
        "text":"(a) the development, the placing on the market, putting into service, deployment or use of an AI system that deploys techniques with the effect or likely effect of materially distorting a person’s or a group's behaviour, including by impairing the person’s ability to make an informed decision, thereby causing the person to take a decision that they would not otherwise have taken, in a manner that causes or is likely to cause any person or society at large physical, economic or psychological harm;",
        "title":"Amendment 1158: Article 5 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"93c75952-377f-49d1-8c71-68338cf314ce",
        "text":"(a) the placing on the market, putting into service or use of an AI system deployed, aimed at, or used for manipulation, deception or distorting a person’s behaviour or exploit a person’s characteristics, in a manner that causes, or is likely to cause, harm to:', '(i) that person’s, another person’s or group of persons’ fundamental rights, including their physical or psychological health and safety, and\/or', '(ii) democracy, the rule of law, or society at large;",
        "title":"Amendment 1159: Article 5 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"dfe3987e-bfe3-466c-9449-f251c86b63d4",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys techniques with the effect or the likely effect of materially distorting the behaviour of a person by impairing their ability to make an autonomous decision, thereby causing them to take a decision that they would not have taken otherwise, in a manner that causes or is likely to cause that person or other persons material or non-material harm, including physical, psychological or economic harm;",
        "title":"Amendment 1160: Article 5 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ca41bd7b-d1b8-4d2f-8cf6-425200b92a35",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to distort a person’s behaviour;",
        "title":"Amendment 1161: Article 5 – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"f76f080c-15e1-4e81-bd91-8653c3c11b73",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys manipulative, including subliminal, techniques beyond a person’s consciousness;",
        "title":"Amendment 1162: Article 5 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c9bf996a-db17-4373-aab1-1bff9d405c93",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques, with the exception of AI systems using such techniques for scientific research and for approved therapeutical purposes on the basis of explicit consent of the natural persons that are exposed to them, which systems shall be classified as high risk for the purposes of this Regulation;",
        "title":"Amendment 1163: Article 5 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"196d490c-020d-43fe-ae41-dc29a3061c86",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour;",
        "title":"Amendment 1164: Article 5 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"af3a8eee-b1ee-44e6-94fc-51ec6cdfd5ea",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm that could be predicted with due diligence;",
        "title":"Amendment 1165: Article 5 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"855eaa4a-016a-4d62-9223-fe170d0e3eea",
        "text":"(a) the placing on the market, putting into service or use of an AI system with the objective to significantly and materially distorting a person’s behaviour or directly causing that person or another person significant harm;",
        "title":"Amendment 1166: Article 5 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0ec3e458-dbc3-4b31-939e-f094505bfe5d",
        "text":"(a) the placing on the market, putting into service, or use of an AI system that deploys harmful subliminal techniques beyond a person’s consciousness with the objective to materially distort a person’s behavior in a manner that causes or, that foreseeably may cause that person or another person material, physical or psychological harm;",
        "title":"Amendment 1167: Article 5 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"c80c9457-8547-4f02-9725-4facafa0edcf",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner intended that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1168: Article 5 – paragraph 1 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"0df28218-953c-4ec5-a677-26faeca10996",
        "text":"(a) the placing on the market, putting into service or use of an AI system with the objective to or the effect of materially distorting a person’s behaviour in a manner that causes or is reasonably likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1169: Article 5 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"10a765b9-3337-46ca-a54c-979179cd62fa",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1170: Article 5 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"4b36ec07-6a0a-4e55-87c7-3d446ceb219c",
        "text":"(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes that person or another person physical or psychological harm;",
        "title":"Amendment 1171: Article 5 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"ff29f1e0-71a1-49d3-9725-d18b3bc9f81c",
        "text":"(a a) The placing on the market, putting into service or use of an AI system that deploys purposefully manipulative or deceptive techniques in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm, infringe on that person’s or another person’s fundamental rights, or contravene the Union values enshrined in Article 2 TEU;",
        "title":"Amendment 1172: Article 5 – paragraph 1 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8e04b100-e316-4312-a254-b33f17ca4445",
        "text":"(a a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques.",
        "title":"Amendment 1173: Article 5 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9b2d74e6-eea8-42cd-8dd1-ec99041b2095",
        "text":"(b) the development, placing on the market, putting into service, deployment or use of an AI system that exploits or may be reasonably foreseen to exploit any of the characteristics of one or more individuals, or a specific group of persons, including those characteristic of known, inferred or predicted personality traits, orientations, or social or economic situation, with the effect or likely effect of materially distorting the behaviour of one or more persons that are part of that group in a manner that causes or is likely to cause any person material or non-material harm, including physical, economic or psychological harm or affecting democracy or society at large;",
        "title":"Amendment 1174: Article 5 – paragraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"fcfea3ae-7e05-4fd9-8fd9-6d183b82e041",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the characteristics of a specific group of persons due to their age, gender, ethnic origin, sexual orientation, disability, or any other biological, physical, physiological, behavioural or social characteristics that results in a detrimental, unfavourable, or discriminatory treatment vis-à-vis persons without those characteristics, or that is used in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical, psychological or material harm;",
        "title":"Amendment 1175: Article 5 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d91d7652-c8e4-4bb1-9fd3-43efd0274e1f",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits or may be reasonably foreseen to exploit vulnerabilities of children or characteristics of a person or a specific group of persons due to their age, physical or mental ability, gender, sexual orientation, ethnicity, race, origin, and religion or social or economic situation, with the effect or likely effect of materially distorting the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person material or non-material harm, including physical, psychological or economic harm;",
        "title":"Amendment 1176: Article 5 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"b9dfc0c6-a787-4672-aaf3-b2e99e408f71",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits or may be reasonably foreseen to exploit the vulnerabilities of a specific group of persons due to their age, physical or mental ability, sex, gender, sexual orientation, ethnic or social origin, race, religion or belief, or social or economic situation, with the effect or the likely effect of materially distorting the behaviour of a person in a manner that causes or is likely to cause that person or other persons material or non-material harm, including physical, psychological or economic harm;",
        "title":"Amendment 1177: Article 5 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2b0c5fa6-0463-45d4-b7fe-b64c73a676c3",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a person or a group of persons based on any characteristic or a combination thereof, including but not limited to: their age, race, sex, colour, health status, social and economic status, disability, political or other opinion, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1178: Article 5 – paragraph 1 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"3d56e359-9d5a-4628-b336-6fc48c00200c",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a person or a specific group of persons, such as age or physical or mental disability;",
        "title":"Amendment 1179: Article 5 – paragraph 1 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"62d5ed4b-ddd9-4856-a0e2-b788dc9b3eca",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits, intentionally or not, any of the vulnerabilities of a person or group of persons based on any sensitive or protected characteristic, including but not limited to age, gender and gender identity, racial or ethnic origin, health status, sexual orientation, sex characteristics, social or economic status, worker status, migration status, or disability in accordance with Article 21 of the Charter of Fundamental Rights;",
        "title":"Amendment 1180: Article 5 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"66a3c12f-e645-48c7-b6c3-99c6164cc2c7",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of an individual, including characteristics of such individual’s known or predicted personality or social or economic situation, a specific group of persons due to their age or disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1181: Article 5 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"65f83e72-35f7-4be1-a5f4-16c438d21fc4",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of an individual or a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm, material or economic damage;",
        "title":"Amendment 1182: Article 5 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão-"
    },
    {
        "uuid":"aa586217-f1f6-4f32-b654-1ffa1f6182ec",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm that could be predicted with due diligence;",
        "title":"Amendment 1183: Article 5 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"9841fa4a-18a2-4f7c-abc2-488ef6e968d8",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, with the objective to or the effect of materially distorting the behaviour of a person pertaining to that group in a manner that causes or is likely to directly cause that person or another person significant harm;",
        "title":"Amendment 1184: Article 5 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f3ca7d28-8ed2-4b33-9567-125225361ca0",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1185: Article 5 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"eb018375-22e2-482d-af96-c8b1bb180519",
        "text":"(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes that person or another person physical or psychological harm;",
        "title":"Amendment 1186: Article 5 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"7e71b9df-447c-4d77-95fa-b9ee0f8b11b1",
        "text":"(c) The placing on the market, putting into service or use of AI systems by or on behalf of public authorities or by private actors for the purpose of social scoring.",
        "title":"Amendment 1187: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0b7d9eed-45a8-4dc0-8a7b-e7b423025bd5",
        "text":"(c) the placing on the market, putting into service or use of AI systems for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics;",
        "title":"Amendment 1188: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b1bd8de7-9353-4f31-9377-2cfea0fd3fb0",
        "text":"(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf as well as private companies, including social media and cloud service providers, for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics, with the social score leading to either or both of the following:",
        "title":"Amendment 1189: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo"
    },
    {
        "uuid":"6866b0de-0086-469b-bda4-dd65afebe13c",
        "text":"(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics.",
        "title":"Amendment 1190: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"2067dbd7-a754-4adf-aab3-81f83781dda4",
        "text":"(c) the placing on the market, putting into service or use of AI systems for the scoring, evaluation or classification of natural persons or groups related to their education, employment, housing, socioeconomic situation, health, reliability, social behaviour, location or movements;",
        "title":"Amendment 1191: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6be2c299-f8d5-4685-9c25-ac3c399e6411",
        "text":"(c) the placing on the market, putting into service or use of AI systems by private actors or public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons based on their social behaviour or known or predicted personal or personality characteristics;",
        "title":"Amendment 1192: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"aa5d41e5-f79e-41f8-ba56-2ea91f8832cd",
        "text":"(c) the placing on the market, putting into service or use of AI systems for the evaluation or classification of the trustworthiness of natural persons or groups thereof relating to their education, employment, housing, socio-economic situation, health, reliability, social behaviour, location or movements.",
        "title":"Amendment 1193: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"acdeb0ed-5e84-4073-aaab-03f2199c68bc",
        "text":"(c) the placing on the market, putting into service or use of AI systems for calculation or establishment of a 'social score' resulting from the evaluation or classification of natural persons based on their physical attributes, social behaviour or known or predicted personal or personality characteristics.",
        "title":"Amendment 1194: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"dc847d18-ef61-4b73-972d-34bea860a83a",
        "text":"(c) the development, placing on the market, putting into service, deployment or use of AI systems for the evaluation or classification of the trustworthiness or social standing of natural persons over a certain period of time based on their social behaviour or known, inferred or predicted personal or personality characteristics, potentially leading to detrimental or unfavourable treatment of persons or whole groups;",
        "title":"Amendment 1195: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3c29b39e-fca6-41eb-8984-eb3cdfc76584",
        "text":"(c) the placing on the market, putting into service or use of AI systems for the scoring, evaluation or classification of natural persons or groups thereof relating to their social behaviour or known or predicted personal or personality characteristics, where the score or assessment leads to any of the following:",
        "title":"Amendment 1196: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"fb621d1b-09b0-4ee2-baae-050a6127afca",
        "text":"(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of natural persons over an extended period of time based on their social behaviour or known or predicted personal or personality characteristics (social scoring),with the social score leading to either of the following:",
        "title":"Amendment 1197: Article 5 – paragraph 1 – point c – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e7af9dbf-f7c0-4f09-9296-3de96c5c4aaa",
        "text":"deleted",
        "title":"Amendment 1198: Article 5 – paragraph 1 – point c – point i  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"8ff8f83a-7053-4659-b152-b79d04919123",
        "text":"deleted",
        "title":"Amendment 1199: Article 5 – paragraph 1 – point c – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"e6e5b662-e688-46f2-a99a-3dadc120c2d6",
        "text":"deleted",
        "title":"Amendment 1200: Article 5 – paragraph 1 – point c – point i  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"3a9a2200-2f01-4648-94a2-cc3e7d3cbf76",
        "text":"deleted",
        "title":"Amendment 1201: Article 5 – paragraph 1 – point c – point i  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f6eda4f2-07f7-4011-a367-dcd95b5bfe10",
        "text":"deleted",
        "title":"Amendment 1202: Article 5 – paragraph 1 – point c – point i  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"1f11aeee-1b78-42e9-873c-0294c3aac8dd",
        "text":"deleted",
        "title":"Amendment 1203: Article 5 – paragraph 1 – point c – point i  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"746af9c6-4d97-4588-9d0f-d5d77cc84be0",
        "text":"deleted",
        "title":"Amendment 1204: Article 5 – paragraph 1 – point c – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"6f31f2e3-fc63-4082-99b9-149e72c0995e",
        "text":"deleted",
        "title":"Amendment 1205: Article 5 – paragraph 1 – point c – point i  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"04fb6820-e32c-4a63-beac-b5e562c2fc6e",
        "text":"(i) detrimental or unfavourable treatment affecting the fundamental rights of certain natural persons or whole groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;",
        "title":"Amendment 1206: Article 5 – paragraph 1 – point c – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"c63afe33-ad5e-418d-af49-95fd19d10e64",
        "text":"(i) preferential, detrimental or unfavourable treatment of certain natural persons or whole groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;",
        "title":"Amendment 1207: Article 5 – paragraph 1 – point c – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"92feb62f-a86e-403a-a01f-c90c521d8ed2",
        "text":"(i) detrimental or unfavourable treatment of certain natural persons or whole groups thereof in social contexts that are unrelated to the contexts in which the data was originally generated or collected;",
        "title":"Amendment 1208: Article 5 – paragraph 1 – point c – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"76e8d0bb-e967-4fab-9851-2876ee092226",
        "text":"(i) detrimental or unfavourable treatment of certain natural persons or groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;",
        "title":"Amendment 1209: Article 5 – paragraph 1 – point c – point i  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7a19760a-0919-460e-9e9e-d796a28cc034",
        "text":"deleted",
        "title":"Amendment 1210: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"0356b200-14b7-44e4-bee7-2693c4f8fbd4",
        "text":"deleted",
        "title":"Amendment 1211: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"2cf43c59-447f-404d-ad7e-0312334cea78",
        "text":"deleted",
        "title":"Amendment 1212: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"5b2dd357-ce6f-47af-9033-4b8b8b06b2ca",
        "text":"deleted",
        "title":"Amendment 1213: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"6fc04770-142d-43d9-bd8d-2a4d4c74589a",
        "text":"deleted",
        "title":"Amendment 1214: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"1b397f96-2c0d-467e-9395-d1d177e3a2da",
        "text":"deleted",
        "title":"Amendment 1215: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"24e6fbc4-cf93-4bd9-899e-76abfa03d182",
        "text":"deleted",
        "title":"Amendment 1216: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9fa4f4b3-7d8d-4b73-b51a-1947c6926228",
        "text":"deleted",
        "title":"Amendment 1217: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"7ad29c96-4740-41fe-b318-f319105028a4",
        "text":"(ii) preferential, detrimental or unfavourable treatment of certain natural persons or whole groups thereof that is unjustified or disproportionate to their social behaviour or its gravity;",
        "title":"Amendment 1218: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"bd432bd5-b4f3-4c07-a754-c0c41c4efe40",
        "text":"(ii) detrimental or unfavourable treatment of certain natural persons or groups thereof that is unjustified or disproportionate to their social behaviour or its gravity;",
        "title":"Amendment 1219: Article 5 – paragraph 1 – point c – point ii  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5b3e0298-2183-420a-8461-fae2f54fffec",
        "text":"(ii a) privileged treatment of certain natural persons or whole groups thereof in social contexts that are unrelated to the contexts in which the data was originally generated or collected;",
        "title":"Amendment 1220: Article 5 – paragraph 1 – point c – point ii a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"81ababd3-1d0f-4ab3-96c2-a75fec3a28d4",
        "text":"(ii a) treatment of certain natural persons or whole groups thereof otherwise amounting to an unnecessary or disproportionate restriction on fundamental rights.",
        "title":"Amendment 1221: Article 5 – paragraph 1 – point c – point ii a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"5450fba8-4116-494c-abe4-7742bcdb92d6",
        "text":"(c a) the placing on the market, putting into service or use of an AI system for making individual or place-based risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of a natural person or on assessing personality traits and characteristics or past criminal behaviour of natural persons or groups of natural persons;",
        "title":"Amendment 1222: Article 5 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"bec406e4-aeb8-4d91-b518-9739f1fb2475",
        "text":"(c a) the placing on the market, putting into service or use of an AI system for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of a natural person or on assessing personality traits and characteristics or past criminal behaviour of natural persons or groups of natural persons;",
        "title":"Amendment 1223: Article 5 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Samira"
    },
    {
        "uuid":"da7037c7-9de1-4c25-9040-54dc72217035",
        "text":"(c a) the placing on the market, putting into service or use of an AI system that takes decisions to dispatch or set priorities for dispatching emergency response services on which the lives of those rescued depend;",
        "title":"Amendment 1224: Article 5 – paragraph 1 – point c a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"fc710f55-53a1-49f0-961b-f90cd37510fd",
        "text":"(c a) the placing on the market, putting into service, or use of AI systems intended to be used as polygraphs and similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person;",
        "title":"Amendment 1225: Article 5 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"8b9344b9-352e-4bd1-b051-d23ce8093e77",
        "text":"(c b) the placing on the market, putting into service or use of an AI system that performs individual risk assessments, serves as polygraphs or similar tools, or analyses the emotional state of natural persons, or predicts the occurrence or repetition of an actual or potential criminal offence on the basis of profiling of natural persons or groups, or which assesses the personality traits of natural persons or groups for profiling purposes in the context of detection, investigation or prosecution of criminal offences;",
        "title":"Amendment 1226: Article 5 – paragraph 1 – point c b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"71cf4e4f-dcfb-4ced-98ee-6980fe04337f",
        "text":"(c c) the placing on the market, putting into service or use of an AI system for the administration of justice and for democratic processes, which helps judicial authorities to investigate and interpret facts and the law, and to apply the law to a specific set of facts, with the exception of purely ancillary administrative activities which have no impact on the actual administration of justice in individual cases;",
        "title":"Amendment 1227: Article 5 – paragraph 1 – point c c (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"e65eab36-4f41-4f84-b808-279d42751c15",
        "text":"(c d) the placing on the market, putting into service or use of an AI system that performs genomic, physiological, psychological or behavioural analyses of a natural person for the purpose of profiling that natural person;",
        "title":"Amendment 1228: Article 5 – paragraph 1 – point c d (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b77354a0-416d-4a51-b640-1822505ebe16",
        "text":"(c e) the placing on the market, putting into service or use of an AI system that may affect the cognitive integrity or personality of a natural person, with or without the support of physical implants;",
        "title":"Amendment 1229: Article 5 – paragraph 1 – point c e (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"f83158ca-6c46-48d4-82e7-145024ae2f7d",
        "text":"deleted",
        "title":"Amendment 1230: Article 5 – paragraph 1 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"7c93770a-b39b-4fcb-ad15-dfd38246402b",
        "text":"(d) the use of biometric identification systems, except those strictly used for individual authentication of access to protected spaces or systems, those used for the execution of administrative procedures by tax and customs authorities, and by law enforcement authorities if and in as far as such use is strictly necessary for one of the following objectives:",
        "title":"Amendment 1231: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"1a4815e8-b3cf-440e-860c-eb1220d98a24",
        "text":"(d) putting into service, by public and private entities or on their behalf, of remote biometric identification systems that are or may be used in publicly-accessible, including online, spaces; and the use of remote biometric identification systems in publicly accessible, including online, spaces, but without affecting employees who work in publicy accessibe spaces.",
        "title":"Amendment 1232: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"6fe17307-9375-4963-8c97-695903740246",
        "text":"(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces",
        "title":"Amendment 1233: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b402fa73-4fb3-4d84-a02c-7da2b54a2933",
        "text":"(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces.",
        "title":"Amendment 1234: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"8bace03b-4b7e-4b47-9eb0-fab906d1af08",
        "text":"(d) The placing on the market, putting into service or use of of AI for an automated recognition of human features in publicly accessible spaces - such as of faces but also of gait, fingerprints, DNA, voice, keystrokes and other biometric or behavioral signals - for any purpose, including law enforcement.",
        "title":"Amendment 1235: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"e7d67913-e14b-4d9a-b371-ae959d54f557",
        "text":"(d) the placing on the market and use of remote biometric identification systems in publicly accessible spaces;",
        "title":"Amendment 1236: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"84cb9adc-325b-4af7-b3a0-825b10feff5d",
        "text":"(d) the use of remote biometric identification systems in publicly or privately accessible spaces, both online and offline.",
        "title":"Amendment 1237: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"a3c266da-53a1-43da-bd32-14f77baab46a",
        "text":"(d) the placing or making available on the market or putting into service of remote biometric identification systems that are or may be used in publicly-accessible spaces, as well as online spaces, and the use of remote biometric identification systems in publicly accessible spaces;",
        "title":"Amendment 1238: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3f2e6772-2510-499f-9a02-2cf3e89d43a4",
        "text":"(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement;",
        "title":"Amendment 1239: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"6cb832b7-c549-4d2f-bf02-e4759487a850",
        "text":"(d) the use of ‘real-time’ remote biometric identification function of an AI system in publicly accessible spaces by law enforcement or on their behalf, unless and in as far as such use is strictly necessary used for one of the following objectives:",
        "title":"Amendment 1240: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"57e51317-a28b-4a2a-a58e-d30a66a7b254",
        "text":"(d) the use and installation of 'real-time' or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement, except in relation to border control and in the context of the fight against terrorism:",
        "title":"Amendment 1241: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"ec34363e-9e40-4224-988c-665c4d6c6957",
        "text":"(d) the development, placing on the market, putting into service, deployment or use of remote biometric identification systems or biometrics-based in publicly accessible spaces, including online accessible spaces;",
        "title":"Amendment 1242: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"1b43d1b4-24e9-44e1-a3da-ca424442a9c5",
        "text":"(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces, unless and in as far as such use by law enforcement is strictly necessary for one of the following objectives:",
        "title":"Amendment 1243: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"922d799a-6ab2-4036-8dba-5afd2c7007dc",
        "text":"(d) the placing or making available on the market, the putting into service or use of remote biometric identification systems that are or maybe used in publicly or privately accessible spaces, as well as online spaces;",
        "title":"Amendment 1244: Article 5 – paragraph 1 – point d – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4b25c0bb-ba8d-4259-b47b-0804ef003c1f",
        "text":"deleted",
        "title":"Amendment 1245: Article 5 – paragraph 1 – point d – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"88b4dce0-43f3-4e44-9a38-a9f363eed879",
        "text":"deleted",
        "title":"Amendment 1246: Article 5 – paragraph 1 – point d – point i  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"50e86c9b-2362-4e22-83e0-d987d3dc1904",
        "text":"deleted",
        "title":"Amendment 1247: Article 5 – paragraph 1 – point d – point i  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"45a5f3c6-3806-47f3-a297-164e8979b9f5",
        "text":"deleted",
        "title":"Amendment 1248: Article 5 – paragraph 1 – point d – point i  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c505c5c4-b790-4afe-937b-e67fe78a7adb",
        "text":"deleted",
        "title":"Amendment 1249: Article 5 – paragraph 1 – point d – point i  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"6772a71c-d9f9-45f1-9c62-12aa73d20178",
        "text":"deleted",
        "title":"Amendment 1250: Article 5 – paragraph 1 – point d – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"93862c12-4283-4c50-a7b5-97d703d95612",
        "text":"deleted",
        "title":"Amendment 1251: Article 5 – paragraph 1 – point d – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"c62a17e0-7453-449b-b0bf-509beae24f51",
        "text":"deleted",
        "title":"Amendment 1252: Article 5 – paragraph 1 – point d – point i  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"c070a929-cfc8-4ceb-8247-4ce53cc1e58e",
        "text":"deleted",
        "title":"Amendment 1253: Article 5 – paragraph 1 – point d – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"5258278b-ba73-4329-aa9b-039d99b808df",
        "text":"deleted",
        "title":"Amendment 1254: Article 5 – paragraph 1 – point d – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,"
    },
    {
        "uuid":"5978870b-538b-49ac-b354-9c29934867c7",
        "text":"(i) the targeted search for specific potential victims of crime;",
        "title":"Amendment 1255: Article 5 – paragraph 1 – point d – point i  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"48fec6d9-c9f1-4322-9724-54bfb8b7983e",
        "text":"deleted",
        "title":"Amendment 1256: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"4103b78f-1acb-4bc1-8dd7-68ae1397f19c",
        "text":"deleted",
        "title":"Amendment 1257: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"930fc188-61f5-417f-a25e-0e1ed3a82d99",
        "text":"deleted",
        "title":"Amendment 1258: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"e32c6617-fa1a-4e55-986a-276246773823",
        "text":"deleted",
        "title":"Amendment 1259: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"ccc02d54-95d0-43c0-ba23-ac6046d33aed",
        "text":"deleted",
        "title":"Amendment 1260: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,"
    },
    {
        "uuid":"3c51d27f-9338-4029-aeb7-e0f17d668ec7",
        "text":"deleted",
        "title":"Amendment 1261: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"f2c7c1c8-a45c-4a9b-a38f-cf4f05dca201",
        "text":"deleted",
        "title":"Amendment 1262: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"e8baed21-fcce-418d-8c63-3ce4d8c59083",
        "text":"deleted",
        "title":"Amendment 1263: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"85a1682e-f125-43e0-9af7-fbc18ede1d30",
        "text":"deleted",
        "title":"Amendment 1264: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"ac3afa6a-e9c4-4bbe-9155-d377158412fe",
        "text":"deleted",
        "title":"Amendment 1265: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"20199cf7-466a-4b6c-b3d3-0e145733eb8d",
        "text":"(ii) the prevention of a specific and substantial threat to the critical infrastructure, life, health or physical safety of natural persons or of a terrorist attack;",
        "title":"Amendment 1266: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d0e2a4e8-f271-41bd-8b4d-48328e8fc9f6",
        "text":"(ii) the prevention of a threat to the life or physical safety of natural persons or of a terrorist attack;",
        "title":"Amendment 1267: Article 5 – paragraph 1 – point d – point ii  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"63063401-1318-4507-ba4b-8e52a980a8d6",
        "text":"deleted",
        "title":"Amendment 1268: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"65b469b9-7c1b-4f1d-8002-f3ff16d98504",
        "text":"deleted",
        "title":"Amendment 1269: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"035d90e3-6a3d-433e-97ee-b18b9da87c5a",
        "text":"deleted",
        "title":"Amendment 1270: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"36e467f9-f627-4e7e-8088-69e14007d93d",
        "text":"deleted",
        "title":"Amendment 1271: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"29ba501e-ec9f-4368-8402-ee7aee881152",
        "text":"deleted",
        "title":"Amendment 1272: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"85d78955-7fa2-446b-8251-40a1c985b91b",
        "text":"deleted",
        "title":"Amendment 1273: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"361aff2c-90cc-477a-bf61-224a6e482df4",
        "text":"deleted",
        "title":"Amendment 1274: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,"
    },
    {
        "uuid":"65c416e1-17a6-464b-8053-ff578e7cc90a",
        "text":"deleted",
        "title":"Amendment 1275: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"ab905485-245b-4c97-9b77-692c5a21ae16",
        "text":"deleted",
        "title":"Amendment 1276: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9a5803a1-e7f3-4379-854e-48ee48759f27",
        "text":"deleted",
        "title":"Amendment 1277: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"96f96188-4671-4959-941a-e6507159e129",
        "text":"deleted",
        "title":"Amendment 1278: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a6733a3c-9d0e-4f9b-b936-d3505eca64d9",
        "text":"deleted",
        "title":"Amendment 1279: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"62fb6c69-6ad0-452b-b725-f8761f362fa3",
        "text":"(iii) the localisation or identification of a natural person for the purpose of conducting a criminal investigation, prosecution or exeuting a criminal penalty for offences referred to in Article 2(2) of Council Framework Decision 2002\/584\/JHA62 and punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least three years, or other specific offences punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least five years as determined by the law of that Member State.' '62 Council Framework Decision 2002\/584\/JHA of 13 June 2002 on the European arrest warrant and the surrender procedures between Member States (OJ L 190, 18.7.2002, p. 1).",
        "title":"Amendment 1280: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"287742a2-e420-4960-abbb-5101e88ab5df",
        "text":"(iii) the detection, localisation, identification or prosecution of a perpetrator or suspect of a criminal offence punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least ten years, as determined by the law of that Member State.",
        "title":"Amendment 1281: Article 5 – paragraph 1 – point d – point iii  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"7c0ac6f3-6252-4b2c-a035-05ba9dcf170b",
        "text":"(iii a) searching for missing persons, especially those who are minors or have medical conditions that affect memory, communication, or independent decision-making skills;",
        "title":"Amendment 1282: Article 5 – paragraph 1 – point d – point iii a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"df8bd5b2-89b0-4e1f-a8d4-2fe6a359bcda",
        "text":"(d a) the placing on the market, putting into service or use of:', '(i) AI systems intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;', '(ii) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions.', '(iii) AI systems intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(iv) AI systems intended to be used for making decisions on promotion and termination of work-related contractual relationships, for task allocation and for monitoring and evaluating performance and behavior of persons in such relationships.', '(v) AI systems intended to be used by public authorities, private entities or on their behalf to evaluate the eligibility of natural persons for public assistance benefits and services, essential private services, as well as to grant, reduce, revoke, or reclaim such benefits and services;', '(vi) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;', '(vii) AI systems intended to be used by competent authorities for migration, asylum and border control management to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;', '(viii) AI systems intended to be used by public authorities, including competent authorities for migration, asylum and border control management, as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 1283: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"32967884-ca93-41a9-b06d-6e7a6004fd74",
        "text":"(d a) the placing on the market, putting into service, or use of an AI system for the specific technical processing of brain or brain-generated data in order to access, infer, influence, or manipulate a person's thoughts, emotions, memories, intentions, beliefs, or other mental states against that person's will or in a manner that causes or is likely to cause that person or another person physical or psychological harm.",
        "title":"Amendment 1284: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Maria-Manuel Leitão-Marques, Eva Kaili"
    },
    {
        "uuid":"f57c576a-f3a1-4802-b3ff-cb682f5ccc5a",
        "text":"(d a) AI systems intended to be used by law enforcement authorities for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or the risk for potential victims of criminal offences;",
        "title":"Amendment 1285: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"40e460aa-d97e-4e13-aa64-f1015552e2de",
        "text":"(d a) the use of an AI system for the general monitoring, detection and interpretation of private content in interpersonal communication services, including all measures that would undermine end-to-end encryption..",
        "title":"Amendment 1286: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Moritz Körner, Jan-Christoph Oetjen, Karen Melchior,"
    },
    {
        "uuid":"69c78099-4bb7-415e-9d87-760d39216a9a",
        "text":"(d a) The creation or expansion of facial recognition or other biometric databases through the untargeted scraping of biometric data from social media profiles or CCTV footage or equivalent methods;",
        "title":"Amendment 1287: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"5e3c5c29-f6ed-49e8-8e9c-f5aae1997f28",
        "text":"(d a) the creation or expansion of biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;",
        "title":"Amendment 1288: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f676b3db-b314-4b91-8bf3-e38c2e20293d",
        "text":"(d a) the development, placing on the market, putting into service, deployment or use of of biometric categorisation systems;",
        "title":"Amendment 1289: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"1d34a782-918f-46c9-a378-89e23a9e2245",
        "text":"(d a) The use of predictive, profiling and risk assessment AI systems in law enforcement and criminal justice;",
        "title":"Amendment 1290: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"6d08b9a4-f87c-487a-a97c-3a3078d1e36a",
        "text":"(d a) The use of private biometric databases for the purpose of law enforcement;",
        "title":"Amendment 1291: Article 5 – paragraph 1 – point d a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"b93445b8-18b7-4a49-820e-466d6c55dcab",
        "text":"(d b) The use of predictive, profiling and risk assessment AI system by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1292: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"7514639f-84b8-4c8f-b79b-f7fa24b77ec9",
        "text":"(d b) the placing on the market, putting into service or use of AI systems to infer emotions of a natural person, except for health or research purposes or other exceptional purposes, and subject to full regulatory review and with full and informed consent at all times.",
        "title":"Amendment 1293: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"50a51089-86d3-400d-8eed-a2864f663ff3",
        "text":"(d b) AI systems intended to be used by law enforcement authorities or other competent public authorities as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 1294: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bcd96b3d-ce12-4e08-b4d1-c6ce16968e92",
        "text":"(d b) the placing on the market, putting into service, deployment or use of of emotion recognition systems other than for the personal use of natural persons as an assistive technology;",
        "title":"Amendment 1295: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"5670a623-e114-4767-a940-cea5506aa324",
        "text":"(d b) The use of private facial recognition or other private biometric databases for the purpose of law enforcement",
        "title":"Amendment 1296: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"a070a149-25dd-44a7-8bf3-7b6fba8ade75",
        "text":"(d b) The placing on the market, putting into service or use of ‘emotion recognition systems’;",
        "title":"Amendment 1297: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"1fe8730c-2969-433f-ae58-82a73e728800",
        "text":"(d b) the use of remote biometric categorisation systems in publicly accessible spaces;",
        "title":"Amendment 1298: Article 5 – paragraph 1 – point d b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1298971b-7416-4847-8fc6-098554da91fd",
        "text":"(d c) The placing on the market, putting into service or use of 'emotion recognition systems', unless for health purposes, which would be considered high risk.Emotion recognition systems for health purposes shall be limited to their intended purpose, subject to all applicable data protection conditions and limits, and:\", '(i) undergo strict testing to ensure scientific and clinical validity;', '(ii) contain clear advice to anyone that may procure or use them about the limitations of such technologies and their potential risks, including of flawed or potentially harmful outcomes;', '(iii) be developed with the active participation and input of the groups they are intended to benefit, as well as those with expertise in the range of fundamental rights that could be deliberately or inadvertently impacted;', '(iv) be developed and deployed in a manner that respects the rights of all persons likely to be affected by them;', '(v) be subject to an opinion of the Health Security Committee and the Fundamental Rights Agency.",
        "title":"Amendment 1299: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"ef876ea3-0c5d-40a0-93f6-3012761496bf",
        "text":"(d c) the placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics.Sensitive attributes or characteristics include, but are not limited to:', '(i) Gender & gender identity', '(ii) Race', '(iii) Ethnic origin', '(iv) Migration or citizenship status', '(v) Political orientation', '(vi) Sexual orientation', '(vii) Religion', '(viii) Disability', '(ix) Or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the Regulation (EU) 2016\/679;",
        "title":"Amendment 1300: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"093eceb7-9736-4b0f-aa46-fd12cc99bf86",
        "text":"(d c) the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1301: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"cfea81de-924e-48ee-8b96-27e347172e80",
        "text":"(d c) AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016\/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons, groups, or locations;",
        "title":"Amendment 1302: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1572cf47-c981-4f12-b061-2d250ae0d0e5",
        "text":"(d c) the placing on the market, putting into service, or use of AI systems by law enforcement authorities or by competent authorities in migration, asylum and border control management, such as polygraphs and similar tools to detect deception, trustworthiness or related characteristics;",
        "title":"Amendment 1303: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"8246ec40-3e8a-4216-90be-febec6e109b7",
        "text":"(d c) the development, placing on the market, putting into service, deployment or use of AI systems for automated monitoring and analysis of human behaviour in publicly accessible spaces, including online;",
        "title":"Amendment 1304: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"697cb745-d9d1-46fd-a25e-c50fa9773403",
        "text":"(d c) The use of biometric categorisation systems;",
        "title":"Amendment 1305: Article 5 – paragraph 1 – point d c (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"21b5cb69-ac2d-4461-b36c-47599fe3792d",
        "text":"(d d) the development, placing on the market, putting into service, deployment or use of an AI system that can reasonably foreseeably be used for constant monitoring of an individual’s behaviour to identify, predict or deter rule-breaking or fraud in a relationship of power, such as at work or in education, in particular where this constant monitoring has potential punitive or detrimental consequences for individuals;",
        "title":"Amendment 1306: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"651b7a79-b0eb-4862-85ba-c384b246d53f",
        "text":"(d d) the placing on the market, putting into service or use of an AI system for making predictions, profiles or risk assessments based on data analysis or profiling of natural persons, groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour;",
        "title":"Amendment 1307: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"df45b30c-7bc8-4266-8c31-8aa4c4f91ae8",
        "text":"(d d) the use of AI systems by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;",
        "title":"Amendment 1308: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"1b069dfc-87b3-4b00-ab5a-b5d8dbd63de4",
        "text":"(d d) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or closed circuit television (CCTV) footage, or equivalent methods;",
        "title":"Amendment 1309: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2408fd40-b06a-4f15-bfe4-a4d3bbf79707",
        "text":"(d d) AI systems intended to be used by law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016\/680 in the course of detection, investigation or prosecution of criminal offences;",
        "title":"Amendment 1310: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"75d1ead2-61fa-4987-a932-9d63acc2337d",
        "text":"(d d) AI systems intended to be used by law enforcement authorities as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 1311: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"efa3eba0-79f3-423d-92f8-03fa268b1f6d",
        "text":"(d d) The use of private facial recognition or other private biometric databases for the purpose of law enforcement;",
        "title":"Amendment 1312: Article 5 – paragraph 1 – point d d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"683475f2-dc0e-492a-a387-c6f347149430",
        "text":"(d e) The placing on the market, putting into service or use of AI systems including, but not limited to polygraphs and similar tools to detect deception, trustworthiness or related characteristics, by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member state, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1313: Article 5 – paragraph 1 – point d e (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"a0246da1-1a12-4687-a75d-817f96d86f81",
        "text":"(d e) AI systems intended to be used for crime analytics regarding natural persons, allowing law enforcement authorities to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.",
        "title":"Amendment 1314: Article 5 – paragraph 1 – point d e (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0e54c58f-95fc-4976-87be-8592b480c127",
        "text":"(d e) the placing on the market, putting into service, deployment or use of recommender systems aimed at generating interaction that systematically suggest disinformation or illegal content;",
        "title":"Amendment 1315: Article 5 – paragraph 1 – point d e (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"6045cf9e-273d-4ce0-9169-bd0ecd3cc923",
        "text":"(d e) the use of private facial recognition or other private biometric databases for the purpose of law enforcement;",
        "title":"Amendment 1316: Article 5 – paragraph 1 – point d e (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d3e5b17d-b504-4893-83f2-58e1f0c5b15e",
        "text":"(d f) the placing on the market, putting into service or use of AI systems that use psysiological, behavioural or biometric data to infer attributes or characteristics of persons or groups which are not solely determined by such data or are not externally observable or whose complexity is not possible to fully capture in data, including but not limited to gender, race, colour, ethnic or social origin, as well as political or sexual orientation, or other grounds for discrimination prohibited under Article 21 of the Charter.",
        "title":"Amendment 1317: Article 5 – paragraph 1 – point d f (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"fc458289-fed2-4851-9161-29ebb615ec89",
        "text":"(d f) the use of AI systems by law enforcement authorities, criminal justice authorities, migration, asylum and border-control authorities, or other public authorities to make predictions, profiles or risk assessments based on data analysis or profiling of natural persons as referred to in Article 3(4) of Directive EU 2016\/680, groups or locations, for the purpose of predicting the occurrence or recurrence of an actual or potential criminal offence(s) or other offences, or rule-breaking;",
        "title":"Amendment 1318: Article 5 – paragraph 1 – point d f (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"56483d94-6972-45c8-9647-b2e32769bf73",
        "text":"(d f) the placing on the market, putting into service, or use of AI systems that are aimed at automating judicial or similarly intrusive binding decisions by state actors;",
        "title":"Amendment 1319: Article 5 – paragraph 1 – point d f (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"af262299-f35d-4461-a5a6-24a7d4d8b484",
        "text":"(d f) The use of remote biometric identification in migration management, border surveillance and humanitarian aid.",
        "title":"Amendment 1320: Article 5 – paragraph 1 – point d f (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a19d38df-278b-4518-bd2f-9feedcb6a516",
        "text":"(d f) the placing on the market, putting into service or use of ‘emotion recognition systems’",
        "title":"Amendment 1321: Article 5 – paragraph 1 – point d f (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"db55fabe-9448-4a88-969e-ba9403fecaf4",
        "text":"(d g) the placing on the market, putting into service or the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1322: Article 5 – paragraph 1 – point d g (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f5d3c906-36d6-4b55-a94d-9ff899ce9230",
        "text":"(d g) the use of AI systems by or on behalf of competent authorities, or third parties acting on their behalf, in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1323: Article 5 – paragraph 1 – point d g (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"36df6cbb-0e7f-4ba4-b318-9889c2f67955",
        "text":"(d g) the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;",
        "title":"Amendment 1324: Article 5 – paragraph 1 – point d g (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"00870d15-81bf-4a2d-9766-8015461c1548",
        "text":"(d g) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;",
        "title":"Amendment 1325: Article 5 – paragraph 1 – point d g (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"308e5e10-48cb-4dfb-8ba1-1aa8c1458328",
        "text":"(d g) the use of biometric categorisation systems in publicly-accessible spaces, workplaces (including in hiring processes), and educational settings;",
        "title":"Amendment 1326: Article 5 – paragraph 1 – point d g (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0bb6e1bd-dc2a-4467-8a7d-0b644340e4f5",
        "text":"(d h) the placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics, including:', '◦ Sex', '◦ Gender & gender identity', '◦ Race', '◦ Ethnic origin', '◦ Membership of a national minority', '◦ Migration or citizenship status', '◦ Political orientation', '◦ Social origin or class', '◦ Language or dialect', '◦ Trade union membership', '◦ Sexual orientation', '◦ Religion or philosophical orientation', '◦ Disability', '◦ Or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the General Data Protection Regulation",
        "title":"Amendment 1327: Article 5 – paragraph 1 – point d h (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2e315e4f-2035-43f8-bb4c-08577225ae48",
        "text":"(d h) the placing on the market, putting into service or the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the prohibiting, curtailing or preventing migration or border crossings;",
        "title":"Amendment 1328: Article 5 – paragraph 1 – point d h (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ef65b65b-91c2-41e7-974b-094e29bfd505",
        "text":"(d h) the placing on the market, putting into service, or use of AI systems by law enforcement authorities, or by competent authorities in migration, asylum and border control management, as polygraphs and similar tools to detect deception, trustworthiness or related characteristics",
        "title":"Amendment 1329: Article 5 – paragraph 1 – point d h (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7095e905-3fd9-47b5-a438-7ce8d0f6eafd",
        "text":"(d h) The use of private facial recognition or other private biometric databases for the purpose of law enforcement;",
        "title":"Amendment 1330: Article 5 – paragraph 1 – point d h (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"84c92a05-e30b-4e44-8293-5012d1be7bc6",
        "text":"(d i) the use of AI systems by law enforcement authorities, criminal justice authorities, or other public authorities in conjunction with law enforcement and criminal justice authorities, to make predictions, profiles or risk assessments based on data analysis or profiling of natural persons [as referred to in Article 3(4) of Directive EU)2016\/680], groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour.”",
        "title":"Amendment 1331: Article 5 – paragraph 1 – point d i (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1e871ca8-f715-4be4-b6f1-a4d9bbc825b8",
        "text":"(d i) the placing on the market, putting into service or the use of AI systems intended to assist competent authorities for the examination of application for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status;",
        "title":"Amendment 1332: Article 5 – paragraph 1 – point d i (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"67401a52-e008-4ce8-8d46-d45cfadaa464",
        "text":"(d i) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;",
        "title":"Amendment 1333: Article 5 – paragraph 1 – point d i (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bca4f8bb-0820-4b76-b0a3-d2f7449d347a",
        "text":"(d i) The development of private facial recognition or other private biometric databases and the use of such databases for the purpose of law enforcement;",
        "title":"Amendment 1334: Article 5 – paragraph 1 – point d i (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"d89679bc-12ec-4848-89b8-4bdc17ccf240",
        "text":"(d j) the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;",
        "title":"Amendment 1335: Article 5 – paragraph 1 – point d j (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"714cc173-06f2-406a-b894-7d6c7c191346",
        "text":"(d j) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;",
        "title":"Amendment 1336: Article 5 – paragraph 1 – point d j (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"031db1f1-f1ff-4ff1-bf90-a137c57079a4",
        "text":"(d j) the placing on the market, putting into service or use of ‘emotion recognition systems’;",
        "title":"Amendment 1337: Article 5 – paragraph 1 – point d j (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0164cf63-244a-498f-9c25-0ede05bbb065",
        "text":"(d k) The use of AI systems by law enforcement and criminal justice authorities to make predictions, profiles or risk assessments for the purpose of predicting crime.",
        "title":"Amendment 1338: Article 5 – paragraph 1 – point d k (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0c6f1608-fe65-4921-acf7-473671b77bf1",
        "text":"(d k) the use of biometric categorisation systems in publicly-accessible spaces, workplaces (including in hiring processes), and educational settings;",
        "title":"Amendment 1339: Article 5 – paragraph 1 – point d k (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4a818570-77e9-40e9-9711-884c560954da",
        "text":"(d k) The use of remote biometric identification for the purpose of migration management, border surveillance and humanitarian aid;",
        "title":"Amendment 1340: Article 5 – paragraph 1 – point d k (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"8a728ef8-a682-4f72-89b8-6917c848fd36",
        "text":"(d l) the placing on the market, putting into service or use of:', '(i) AI systems intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;', '(ii) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions.', '(iii) AI systems intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(iv) AI systems intended to be used for making decisions on promotion and termination of work-related contractual relationships, for task allocation and for monitoring and evaluating performance and behaviour of persons in such relationships;', '(v) AI systems intended to be used by public authorities, private entities or on their behalf to evaluate the eligibility of natural persons for public assistance benefits and services, essential private services, as well as to grant, reduce, revoke, or reclaim such benefits and services;', '(vi) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score;",
        "title":"Amendment 1341: Article 5 – paragraph 1 – point d l (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"cab04fec-31e9-4139-8eda-6c3dfe80cf99",
        "text":"(d l) the use of AI systems for indiscriminate surveillance applied in a generalised manner to a large number of natural persons without differentiation;",
        "title":"Amendment 1342: Article 5 – paragraph 1 – point d l (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"03bcdde0-5c95-46e5-94cb-c080554d8c00",
        "text":"(d m) The collection or generation of data for practices and AI systems listed in paragraphs -1 and 1 shall also be prohibited throughout their lifecycle, including training, validation and testing;",
        "title":"Amendment 1343: Article 5 – paragraph 1 – point d m (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3a8f2c8b-44f3-47f2-b6e0-e7ed7d272dfe",
        "text":"(d n) The placing on the market, putting into use or deployment of AI systems built on, designed, trained, validated or tested with data that was collected, processed or generated illegally;",
        "title":"Amendment 1344: Article 5 – paragraph 1 – point d n (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"0ac32c80-2ccd-40bc-9c87-f468546a3a6e",
        "text":"(d o) The Union shall not fund research into and development of AI systems which are likely to be used for indiscriminate surveillance of publicly accessible spaces applied in a generalised manner to a large number of natural persons without differentiation.",
        "title":"Amendment 1345: Article 5 – paragraph 1 – point d o (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"8741a6fc-11cd-4916-8751-8491ccaa62dd",
        "text":"1 a. In Accordance with Article 73, the Commission is empowered to amend paragraph 1 of this Article by means of a delegated act by adding systems that adversely affect, or are likely to adversely affect, the essence of fundamental rights. In doing so the Commission shall consult civil society and human rights experts annually to reflect state-of-the-art knowledge regarding the potential impacts of technology on fundamental rights.",
        "title":"Amendment 1346: Article 5 – paragraph 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"e480f20f-1a6e-4092-977f-68cc05b3ae8c",
        "text":"1 a. the placing on the market, putting into service or use of an AI system that analyses and understands human non-verbal signs such as facial expressions, body language, gestures and voice tones to assess their emotional state or perform biometric categorisation.",
        "title":"Amendment 1347: Article 5 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão-"
    },
    {
        "uuid":"f8739e6b-be3b-4f62-9f52-764d6114c031",
        "text":"deleted",
        "title":"Amendment 1348: Article 5 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ba642cc5-d29a-45dc-b5dd-be2c42c7d219",
        "text":"deleted",
        "title":"Amendment 1349: Article 5 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"352e0be6-ef00-42b2-b633-fd12e44a97bc",
        "text":"deleted",
        "title":"Amendment 1350: Article 5 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"a3b9753a-1964-4d38-80e8-65dad214f282",
        "text":"deleted",
        "title":"Amendment 1351: Article 5 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"4f6febe2-a648-4258-b2e2-397ca34cd2fa",
        "text":"deleted",
        "title":"Amendment 1352: Article 5 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"cf556b14-ba70-4296-9bed-ca40577941fd",
        "text":"deleted",
        "title":"Amendment 1353: Article 5 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"eee58421-5464-4805-b9e6-abf74f2ec6ef",
        "text":"deleted",
        "title":"Amendment 1354: Article 5 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"4ed27516-2122-44a3-be4e-e3da2f96bd3e",
        "text":"deleted",
        "title":"Amendment 1355: Article 5 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e930a96f-7464-4eba-83e5-6aed6a1ce2aa",
        "text":"deleted",
        "title":"Amendment 1356: Article 5 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"2d68ba9c-1f39-4cb2-ba93-d775c6ac5e5c",
        "text":"deleted",
        "title":"Amendment 1357: Article 5 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b52e4c37-0879-497d-ba20-c1c57b47722d",
        "text":"deleted",
        "title":"Amendment 1358: Article 5 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"77303aaf-5e14-41ad-b99c-0a33b8559ea5",
        "text":"deleted",
        "title":"Amendment 1359: Article 5 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"67b77467-ace3-47d9-9ebb-e7619ff5fc2c",
        "text":"(b a) the full respect of fundamental rights and freedoms in conformity with Union values, the Universal Declaration of Human Rights, the European Convention of Human Rights and the Charter of Fundamental Rights of the EU.",
        "title":"Amendment 1360: Article 5 – paragraph 2 – point b a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"358c651f-591f-4d48-b5da-33ff4348acfe",
        "text":"deleted",
        "title":"Amendment 1361: Article 5 – paragraph 2 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"39fa2d58-98d2-445b-949a-da761a3f4bea",
        "text":"deleted",
        "title":"Amendment 1362: Article 5 – paragraph 2 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"52198918-4a8a-43a9-8d2b-430f2bb9b5be",
        "text":"In addition, the use of ‘real-time’ or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement for any of the objectives referred to in paragraph 1 point d) shall comply with necessary and proportionate safeguards and conditions in relation to the use.",
        "title":"Amendment 1363: Article 5 – paragraph 2 – subparagraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"16b94215-a5b7-4924-9cee-760513cde812",
        "text":"deleted",
        "title":"Amendment 1364: Article 5 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e621ff94-b210-4577-8f3e-ae1817aa0a6f",
        "text":"deleted",
        "title":"Amendment 1365: Article 5 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"ca1a35cc-44e1-4bcc-b8d3-a55147439b1b",
        "text":"deleted",
        "title":"Amendment 1366: Article 5 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"92b76eaa-5e65-4915-8c6d-c5cddbb24fc1",
        "text":"deleted",
        "title":"Amendment 1367: Article 5 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"dd05c66a-882f-45d8-b7a7-975af9abba1a",
        "text":"deleted",
        "title":"Amendment 1368: Article 5 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"c2d2290d-bea2-4c82-b10a-c21a9615f2b4",
        "text":"deleted",
        "title":"Amendment 1369: Article 5 – paragraph 3  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"5ebdbe7d-add8-4eac-b604-cc2e47dfaf48",
        "text":"deleted",
        "title":"Amendment 1370: Article 5 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"48c50b1d-ad4e-4265-901d-70eddfcec923",
        "text":"deleted",
        "title":"Amendment 1371: Article 5 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"0942876a-3153-4475-a101-8ee018007dd3",
        "text":"3. As regards paragraphs 1, point (d) and 2, each individual use for the purpose of law enforcement of a ‘real-time’ or 'post' remote biometric identification system in publicly accessible spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation and the authorisation may be requested only during or after the use. If the prior justification does not comply with the principles of necessity and proportionality, the results obtained by the use of this technology may not be used for law enforcement purposes.",
        "title":"Amendment 1372: Article 5 – paragraph 3 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"5d326b08-bfca-425e-b346-ee1a4996d046",
        "text":"3. As regards paragraphs 1, point (d) and 2, each use for the purpose of law enforcement of a ‘real-time’ remote biometric identification system in publicly accessible spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation if such authorisation is requested without undue delay, and, if such authorisation is rejected, the system’s use is stopped with immediate effect.",
        "title":"Amendment 1373: Article 5 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"58a9300e-e51a-487d-ae98-ae3ef28e7e12",
        "text":"3. As regards paragraphs 1, point (d) and 2, each individual use for the purpose of law enforcement of a ‘real-time’ remote biometric identification system in publicly accessible or online spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation and the authorisation may be requested only during or after the use.",
        "title":"Amendment 1374: Article 5 – paragraph 3 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"36411325-f462-4130-8f8d-ed1172339bc4",
        "text":"deleted",
        "title":"Amendment 1375: Article 5 – paragraph 3 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und"
    },
    {
        "uuid":"6a73a906-1397-426e-aaf2-a308d677710f",
        "text":"deleted",
        "title":"Amendment 1376: Article 5 – paragraph 3 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"1d0ea163-ba3f-4217-a990-5df123e184a0",
        "text":"deleted",
        "title":"Amendment 1377: Article 5 – paragraph 3 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"fa81a9a6-9b01-422d-bc42-531a603929a3",
        "text":"The competent judicial or administrative authority shall only grant the authorisation where it is satisfied, based on objective evidence or clear indications presented to it, that the use of the ‘real-time’ remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request. In deciding on the request, the competent judicial or administrative authority shall take into account the elements referred to in paragraph 2. It shall grant the authorisation for a limited period and scope. Any renewal or amendment of the authorisation shall be subject to the submission of a new request to the competent judicial or administrative authority.",
        "title":"Amendment 1378: Article 5 – paragraph 3 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"97d3c1a1-72cd-4af7-8987-5d51fdf343d2",
        "text":"The competent judicial or administrative authority shall only grant the authorisation where it is satisfied, based on objective evidence or clear indications presented to it, that the use of the ‘real-time’ or 'post' remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request. In deciding on the request, the competent judicial or administrative authority shall take into account the elements referred to in paragraph 2.",
        "title":"Amendment 1379: Article 5 – paragraph 3 – subparagraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"edbacf7b-7728-4ed4-ab46-083ce2837d2d",
        "text":"(1) The placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons or groups of persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics. Sensitive attributes or characteristics include, but are not limited to: gender and gender identity, race, ethnic origin, migration or citizenship status, political orientation, sexual orientation, religion, disability or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the Regulation (EU) 2016\/679.",
        "title":"Amendment 1380: Article 5 – paragraph 3 – subparagraph 1 – point 1 (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"e5413d76-548b-49e5-b1ad-de6bb93bbe1b",
        "text":"deleted",
        "title":"Amendment 1381: Article 5 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"93b90a88-c8d3-49e9-aaba-725bded44653",
        "text":"deleted",
        "title":"Amendment 1382: Article 5 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"eafb3413-dde9-4593-a843-2bf84539664b",
        "text":"deleted",
        "title":"Amendment 1383: Article 5 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"2ff784c3-8ec8-42b8-838e-f64f57f22971",
        "text":"deleted",
        "title":"Amendment 1384: Article 5 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"47fdcb34-b39c-4c30-82e1-e3525f4ab6cf",
        "text":"deleted",
        "title":"Amendment 1385: Article 5 – paragraph 4  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"fd250ef6-5683-4add-9cf8-f83cf721fecf",
        "text":"deleted",
        "title":"Amendment 1386: Article 5 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ac6c66bf-a791-40a6-a6dc-afe0b87afa8c",
        "text":"deleted",
        "title":"Amendment 1387: Article 5 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Róża Thun und Hohenstein, Vlad-Marius"
    },
    {
        "uuid":"251391c0-42b5-489b-a6fe-588997e74c03",
        "text":"deleted",
        "title":"Amendment 1388: Article 5 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9800ccf9-22f8-4234-9f0b-9eeb490259b5",
        "text":"4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall fully comply with EU values, the Universal Declaration of Human Rights, the European Convention of Human Rights and the Charter of Fundamental Rights of the EU and shall specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.",
        "title":"Amendment 1389: Article 5 – paragraph 4  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"4f33e0cc-711a-4c2c-9b03-d6016567f2ac",
        "text":"4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d) the competent authorities may be authorised to use those systems for the purpose of law enforcement.",
        "title":"Amendment 1390: Article 5 – paragraph 4  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"818aae96-e3c5-47d1-b1f1-c60a4a52509f",
        "text":"4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision and reporting relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.",
        "title":"Amendment 1391: Article 5 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"5b52b91f-bac9-4f64-9bec-e3103a9058e4",
        "text":"4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.",
        "title":"Amendment 1392: Article 5 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7d4e45f7-20db-4023-aef1-33b2dfdc958b",
        "text":"4 a. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on worker’s rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall seek and take into account the opinion of social partners.",
        "title":"Amendment 1393: Article 5 – paragraph 4 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"eda5712f-2657-4d35-997a-85ad69d9f2a1",
        "text":"4 a. This Article shall not affect the restrictions, prohibitions or enforcement that apply where an artificial intelligence practice infringes another EU law, including EU acquis on data protection, privacy, or the confidentiality of communications, on non discrimination, consumer protection or on competition.",
        "title":"Amendment 1394: Article 5 – paragraph 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"63b127fa-2160-46ef-8f5d-68780c40aead",
        "text":"4 a. The placing on the market, putting into service or use of AI systems intended to be used as polygraphs, emotion recognition systems or similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person.",
        "title":"Amendment 1395: Article 5 – paragraph 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"02fb3a98-8574-489d-aa84-819c4982f6b2",
        "text":"4 a. In order to increase public transparency and oversight every decision about the deployment or marketing of any AI system that is categorised as posing an unacceptable risk shall be made public.",
        "title":"Amendment 1396: Article 5 – paragraph 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"d5164221-bec0-492e-801e-43217a9101e9",
        "text":"4 b. Member States may, by law or collective agreement, decide to prohibit or to limit the use of AI systems or provide more specific provisions for this purpose to ensure the protection of the rights of workers in the employment context, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, protection of employer’s or customer’s property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.",
        "title":"Amendment 1397: Article 5 – paragraph 4 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"d8cf81d6-9b1b-4ba7-bea3-ad76978c7289",
        "text":"4 b. Member States may, by law or collective agreements, decide to prohibit or to limit the use of AI systems to ensure the protection of the rights of workers in the employment context, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge obligations laid down by law or by collective agreements, management, planning and organization of work, equality and diversity at the workplace, health and safety at work, protection of employers or customers' property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.",
        "title":"Amendment 1398: Article 5 – paragraph 4 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a6ea9a85-bd8f-491f-b21e-952b1db659cf",
        "text":"4 c. the placing on the market, putting into service or the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;",
        "title":"Amendment 1399: Article 5 – paragraph 4 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"86d1b730-4504-40ce-a342-e3dce9402a57",
        "text":"4 d. the placing on the market, putting into service or use of AI systems by competent authorities or on their behalf in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the prohibiting, curtailing or preventing migration or border crossings;",
        "title":"Amendment 1400: Article 5 – paragraph 4 d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"c1ccfc32-5ae7-42ea-94bd-458c7a04d91a",
        "text":"4 e. the placing on the market, putting into service or the use of AI systems intended to assist competent authorities for the examination of application for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status;",
        "title":"Amendment 1401: Article 5 – paragraph 4 f (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"32b347c1-d0e8-4a0f-ba5a-93aecfa621f3",
        "text":"4 f. the placing on the market, putting into service, or use of an AI system for the specific technical processing of brain or brain-generated data in order to access, infer, influence, or manipulate a person's thoughts, emotions, memories, intentions, beliefs, or other mental states against that person's will or in a manner that causes or is likely to cause that person or another person physical or psychological harm;",
        "title":"Amendment 1402: Article 5 – paragraph 4 f (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a96ff5f4-44b4-47e2-be3c-bfd7829668f0",
        "text":"Article 5 a', 'Accessibility Requirements for providers and users of AI systems', '1. Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882 prior to those systems being placed on the market or put into service.', '2. Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882.', '3. Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019\/882. Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public in an accessible manner for persons with disabilities and be kept for as long as the AI system is in use.', '4. Without prejudice to right of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, obligations to ensure consistent and meaningful public transparency under this Regulation, providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019\/882.', '5. Users of AI systems shall ensure that procedures are in place so that the use of AI systems remains in conformity with the applicable accessibility requirements. Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user.', '6. In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements. When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements.', '7. Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken. They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements.', '8. AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019\/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements.', '9. AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive (EU) 2019\/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.",
        "title":"Amendment 1403: Article 5 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"04c8108d-5de4-4d97-9d6d-0e2c77fe77ff",
        "text":"Article 5 a', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of prohibited artificial intelligence practices referred to in Article 5 by adding AI systems that pose an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights.', '2. When assessing for the purposes of paragraph 1 whether an AI system poses an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights, the Commission shall take into account the following non-cumulative criteria:', 'a) the extent to which the intended purpose of the AI system, or the reasonably foreseeable consequences of its use, conflict with the essence of the rights and freedoms established by the Charter, such that these rights and freedoms would lose their value either for the rights holder or for society as a whole;', 'b) the extent to which the risks posed by an AI system cannot be sufficiently mitigated, including by the obligations imposed upon high-risk AI systems under this Regulation;', 'c) the extent to which an AI system violates human dignity;', 'd) the extent to which the use of an AI system has already caused harm to the health and safety of persons or disproportionate impact on their fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'e) the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect a particular group of persons disproportionately;', 'f) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;', 'g) the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers or age;', 'h) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;', 'i) the extent to which existing Union legislation lacks:', '1) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;', '2) effective measures to prevent those risks.",
        "title":"Amendment 1404: Article 5 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6f047187-d772-4a0c-85a8-4d24da034d7b",
        "text":"Article 5 a', 'Amendments to Article 5', 'The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of AI systems and practices prohibited under Article 5 of the present regulation, according to the latest development in technology and to the assessment of increased or newly emerged risks to fundamental rights.",
        "title":"Amendment 1405: Article 5 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"23a3dd71-aa88-4fda-b897-9bb7a6ee096f",
        "text":"Article 5 b', 'Delegated acts to update the list of prohibited AI practices', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of prohibited artificial intelligence practices referred to in Article 5 by adding AI systems that pose an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights.2. When assessing for the purposes of paragraph 1 whether an AI system poses an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights, the Commission shall take into account the following non-cumulative criteria:', 'a) the extent to which the intended purpose of the AI system, or the reasonably foreseeable consequences of its use, conflict with the essence of the rights and freedoms established by the Charter, such that these rights and freedoms would lose their value either for the rights holder or for society as a whole;', 'b) the extent to which the risks posed by an AI system cannot be sufficiently mitigated, including by the obligations imposed upon high-risk AI systems under this Regulation;', 'c) the extent to which an AI system violates human dignity;', 'd) the extent to which the use of an AI system has already caused harm to the health and safety of persons or disproportionate impact on their fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'e) the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect a particular group of persons disproportionately;', 'f) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;', 'g) the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers or age;', 'h) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;', 'i) the extent to which existing Union legislation lacks: i) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages; ii) effective measures to prevent those risks.",
        "title":"Amendment 1406: Article 5 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b5fd9528-1063-45fe-b932-34983a2abe25",
        "text":"Horizonal Requirements for all AI systems Title for a new Article -Accessibility Requirements for providers and users of AI systems 1.Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882 prior to those systems being placed on the market or put into service. 2.Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019\/882. 3.Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019\/882.Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public inan accessible manner for persons with disabilities and be kept for as long as the AI system is in use. 4.Without prejudice to right of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, 4obligations to ensure consistent and meaningful public transparency under this Regulation , providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019\/882. 5.Users of AI systems shall ensure that procedures are in place 6 so that the use of AI systems remains in conformity with the applicable accessibility requirements.Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user. 6.In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements.When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements. 7.Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken.They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements. 8.AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019\/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements. 9.AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive(EU) 2019\/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.",
        "title":"Amendment 1407: Title II a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2b98ed43-7677-473d-84e6-c509f107ad22",
        "text":"HIGH-RISK USES OF AI SYSTEMS",
        "title":"Amendment 1408: Title III  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"7cd49898-446f-4389-bbf0-e406bc505eda",
        "text":"1 CLASSIFICATION OF AI SYSTEMS AS WITH HIGH-RISK USES",
        "title":"Amendment 1409: Title III – Chapter 1 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"c65e9597-9d67-4ea9-883d-9dcf9cc8d2cd",
        "text":"",
        "title":"Amendment 1410: Article 6 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"b211dece-f7cf-4f7d-a173-a8066210f128",
        "text":"Classification rules for high-risk uses of AI systems",
        "title":"Amendment 1411: Article 6 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"7da8abbe-c978-44b5-a698-e8f3f4e65a3a",
        "text":"-1. The AI system shall be considered high-risk where it meets the following two cumulative criteria: ', '(a) the AI system is used or applied in a sector where, given the characteristics of the activities typically undertaken, significant risks of harm to the health and safety or a risk of adverse impact on fundamental rights of users, as outlined in Article 7(2) can be expected to occur.', '(b) the AI system application in the sector in question is used in such a manner that significant risks of harm to the health and safety or a risk of adverse impact on fundamental rights of users, as outlined in Article 7(2) are likely to arise.",
        "title":"Amendment 1412: Article 6 – paragraph -1 (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski, Radosław Sikorski"
    },
    {
        "uuid":"64cc6b3e-89d8-41ab-9327-c27f3def8c3c",
        "text":"-1. AI systems referred to in Annex III shall be considered high-risk for the purposes of this Regulation.",
        "title":"Amendment 1413: Article 6 – paragraph -1 (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2512205c-f530-49c0-ac6f-e49988718498",
        "text":"1. An AI system that is itself a product shall be considered as high risk AI system if, under the applicable Union harmonisation legislation listed in Annex II, it is classified as high-risk AI system or an equivalent thereof and has to undergo a third-party conformity assessment for meeting essential safety requirements prior to placing it on the market or putting it into service.', 'An AI system intended to be used as a core and essential safety component of a product under the applicable Union harmonisation legislation listed in Annex II, shall be considered as high risk if such Union harmonisation legislation classifies it as high-risk or an equivalent thereof and requires it to undergo a third-party conformity assessment for meeting essential safety requirements with a view to placing it on the market or putting it into service.', 'The high-risk classification set in paragraph 1 shall not impact or determine the outcome of other risk classification procedures established in Union harmonisation legislation listed in Annex II",
        "title":"Amendment 1414: Article 6 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a0c2f0ea-ea46-4308-9588-e449f69dce60",
        "text":"1. Irrespective of whether an AI system is placed on the market or put into service independently from the products referred to in point (a), that AI system shall be considered high-risk where:",
        "title":"Amendment 1415: Article 6 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"292fbb57-6c21-4781-861e-756cdc005ba8",
        "text":"1. Irrespective of whether an AI system is placed on the market or put into service independently from the products referred to in points (a) and (b), that AI system shall be considered high-risk where one of the following conditions are fulfilled:",
        "title":"Amendment 1416: Article 6 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a5d06482-01f4-43b2-bbbe-4d1bc5b8093e",
        "text":"deleted",
        "title":"Amendment 1417: Article 6 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"11bb871c-9296-4c99-8a04-2ff7fd1f4443",
        "text":"(a) the AI system is intended to be used as a safety component of a product, or is itself a product or it is required to undergo a third-party conformity assessment with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 1418: Article 6 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c88e5ff1-030f-4852-a534-c2412a19957c",
        "text":"(a) the AI system has a self-evolving behaviour, the failure of which results in an immediate hazardous condition in a specific domain, and is intended to be used as a safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 1419: Article 6 – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"c800a311-070e-4633-8e5c-421df00b4eb5",
        "text":"(a) the AI system is intended to be used or reasonably foreseeable used as a safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 1420: Article 6 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"5b33861d-ab20-4d92-b739-276e0cd9412b",
        "text":"(a) the AI system is intended to be used as a component of a product, or is itself a product, the failure or malfunctioning of which endangers the health, safety or fundamental rights of persons;",
        "title":"Amendment 1421: Article 6 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"af53aad5-8d79-405d-9526-83ae2a76135e",
        "text":"(a) the AI system is intended to be used as a safety component of a product, or is itself a product involving significant risks, covered by the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 1422: Article 6 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"017eb88c-e66e-40fe-870e-09139b240336",
        "text":"(a) the AI system is intended to be used as a main safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;",
        "title":"Amendment 1423: Article 6 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"6e3f6c85-c657-4e3c-835c-1ef887737a68",
        "text":"(a a) its uses are undetermined or indeterminate;",
        "title":"Amendment 1424: Article 6 – paragraph 1 – point a a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c0915fa1-5c43-4574-a45d-4eb47f00ee5f",
        "text":"(a b) in the course of the self-assessment pursuant to Article 6 a of this Regulation, the AI system or its operation is found to result in a high risk to the rights and freedoms of natural persons; or",
        "title":"Amendment 1425: Article 6 – paragraph 1 – point a b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"75948450-23a4-46e2-87a3-7dbae91a8f3c",
        "text":"(a c) it is listed in Annex III.",
        "title":"Amendment 1426: Article 6 – paragraph 1 – point a c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"1ce3d90e-75e2-485d-9dfb-d07d8becc6c3",
        "text":"deleted",
        "title":"Amendment 1427: Article 6 – paragraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"aa72b15c-59a3-4338-a504-cf7c6a45e56f",
        "text":"deleted",
        "title":"Amendment 1428: Article 6 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"df97a7f9-10ec-49a4-bd98-1d6beac8c2de",
        "text":"(b) the product whose main safety component is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment in order to ensure compliance with essential safety requirements with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II.",
        "title":"Amendment 1429: Article 6 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"f6a12231-a368-440a-927a-fbf88b63e5bf",
        "text":"(b) the product whose safety component as meant under (a) is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment with a view to the placing on the market or putting into service or use of that product pursuant to the Union harmonisation legislation listed in Annex II.",
        "title":"Amendment 1430: Article 6 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bf5d406d-54c8-4b77-a558-9d98cf591008",
        "text":"(b) the product whose safety component is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment related to safety with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II.",
        "title":"Amendment 1431: Article 6 – paragraph 1 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"47f8f463-fdd4-46d7-98cf-568f5a6e1360",
        "text":"(b a) the AI system is used by a public authority.",
        "title":"Amendment 1432: Article 6 – paragraph 1 – point b a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e9d5f91d-dce2-41b3-9451-8e5d75cdc2f4",
        "text":"deleted",
        "title":"Amendment 1433: Article 6 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"aa143068-7202-4a5d-9f9a-f3033490e106",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems identified as posing a risk to fundamental human rights as defined in the EU Charter of Fundamental Rights, in relation to a specific intended use shall also be considered high-risk. Such risk is to be determined by completion of a Human Rights Impact Assessment by the user of the AI in relation to the specific use intended for the AI system, with records of such assessment retained for regulatory inspection.', \"The provider shall apply a precautionary principle and, in case of uncertainty over the AI system's classification, shall consider the AI system high-risk.",
        "title":"Amendment 1434: Article 6 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ce2e9fdf-d3dd-4a25-a351-de75b6266106",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, with the exception of those AI systems that are not safety components of a product and that fulfil both of the following conditions:', '(a) they are not developed with and do not use biometric data, biometrics-based data, or personal data as inputs;', '(b) they are not intended to influence decisions of natural persons or to make decisions or to assist in the making of decisions affecting natural persons.",
        "title":"Amendment 1435: Article 6 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a90d5099-9855-481a-aa4d-37d6ea3c017a",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, each AI system with an intended purpose - as specified in its instruction to use in accordance with Art 3(12) and Art 13(2) - that means that it will be deployed in a way that falls under one of the critical use cases referred to in Annex III shall also be considered high-risk if that AI system will make a final decision that puts significantly at risk the health, safety or fundamental rights of natural persons.",
        "title":"Amendment 1436: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bd1bedf0-f4b8-4706-9c55-5276d9fb76a0",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems shall also be considered high-risk in the meaning of this regulation, if they will be deployed in a critical area referred to in Annex III and an individual assessment of the specific application carried out in accordance with Art. 6a showed that a significant harm is likely to arise.",
        "title":"Amendment 1437: Article 6 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Samira Rafaela,"
    },
    {
        "uuid":"342b8142-2af1-4e89-87fe-135c7863023e",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk if they pose a risk of harm to the health and safety or a risk of adverse impact on fundamental rights.",
        "title":"Amendment 1438: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"b6cffa6f-f201-4a0d-b4fa-8f44d861394c",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, if they pose a risk of harm to either physical health and safety or fundamental human rights, or both.",
        "title":"Amendment 1439: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"3fe6950d-3503-4dd6-89e4-45d037023aef",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk if they pose a threat to the health, safety or fundamental rights of persons.",
        "title":"Amendment 1440: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"a137f5bf-2ebb-4134-87c7-9db9d96591fd",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, if they pose a risk of harm to either physical health and safety or human rights, or both.",
        "title":"Amendment 1441: Article 6 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"959e7ee6-e731-475a-b9ee-82ca33ed2eb4",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk when no internal risk-mitigation mechanisms embedded in the AI system apply.",
        "title":"Amendment 1442: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"20346247-3298-4be4-abba-67705b124b43",
        "text":"2. In addition to the high-risk AI systems referred to in paragraph 1 and in accordance with Article 6– paragraph -1a, AI systems referred to in Annex III shall also be considered high-risk.",
        "title":"Amendment 1443: Article 6 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"677869b5-621d-4934-9e4e-7ef449234de1",
        "text":"2 a. The classification as high-risk as a consequence of Article 6(1) and 6(2) shall be disregarded for AI systems whose intended purpose demonstrates that the generated output is a recommendation requiring a human intervention to convert this recommendation into a decision and for AI systems which do not lead to autonomous decisions or actions of the overall system.",
        "title":"Amendment 1444: Article 6 – paragraph 2 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"201a2f88-5774-4b6c-bca1-b4038347c61f",
        "text":"2 a. The assessment by the provider of whether an AI system puts at risk the health, safety or fundamental rights of natural persons shall also take into account the factors enumerated in Article 7(2).",
        "title":"Amendment 1445: Article 6 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a488f7bb-7bb2-42f3-8404-af706a494b4b",
        "text":"2 a. The assessment referred to in paragraph 2 shall be conducted by the Commission annually and under the consultation conditions laid down in this regulation, notably in Article 73;",
        "title":"Amendment 1446: Article 6 – paragraph 2 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"d56311d1-3ad5-49bc-baa6-31a5d09cc6c8",
        "text":"2 a. An artificial intelligence system with indeterminate uses shall also be considered high risk if so identified per Article 9, paragraph 2, point (a).",
        "title":"Amendment 1447: Article 6 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"07a1e1c0-47fb-4174-b67f-48bc01cc6408",
        "text":"2 a. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk.",
        "title":"Amendment 1448: Article 6 – paragraph 2 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"fe5ff741-19c6-4eb1-beba-f61b748c09b0",
        "text":"2 b. Where the Commission finds in the course of the assessment pursuant to paragraphs 1 and 2 that an AI system or an area of AI systems must be considered \"high risk\" or can not or no longer be considered “high risk”, including due to improvements in technology or to social or legal safeguards put in place, it is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding or removing AI systems and areas of AI systems.",
        "title":"Amendment 1449: Article 6 – paragraph 2 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"597c73ce-bda4-4dfd-b6ca-b0a91ad793b5",
        "text":"2 b. In addition to the high-risk AI systems referred to in paragraphs 1, AI systems that have over 20 million EU citizens across the EU or 50% of any given Member States’ population as active monthly users, or whose users have cumulatively over 20 million customers or beneficiaries in the EU affected by it shall be considered high-risk, unless these are placed onto the market.",
        "title":"Amendment 1450: Article 6 – paragraph 2 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2ca23736-50ff-4f9b-b6f7-cee4c24b26b8",
        "text":"2 b. When assessing an AI system for the purposes of paragraph 1 of Article 6, a safety component shall be assessed against the essential health and safety requirements of the relevant EU harmonisation legislation listed in Annex II.",
        "title":"Amendment 1451: Article 6 – paragraph 2 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"e1460c7b-6cde-419c-86a8-337a5cba8566",
        "text":"2 b. In addition to the high-risk AI systems referred to in paragraph 1 and paragraph 2, AI systems that create foreseeable high-risks when combined shall also be considered high-risk.",
        "title":"Amendment 1452: Article 6 – paragraph 2 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ac43db55-f8eb-464e-b350-f7553900c520",
        "text":"2 c. In addition to the high-risk AI systems referred to in paragraph 1, AI systems affecting employees in the employment relationship or in matters of training or further education shall be considered high risk.",
        "title":"Amendment 1453: Article 6 – paragraph 2 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1237f0e6-31b4-400b-a417-ecf5b40f76f3",
        "text":"2 d. In addition to the high-risk AI systems referred to in paragraph 1, AI systems likely to interact with children shall be considered high-risk.",
        "title":"Amendment 1454: Article 6 – paragraph 2 d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8eab9569-d588-4e67-acd8-e39bd86f006d",
        "text":"2 e. In addition to the high-risk AI systems referred to in paragraph 1, an artificial intelligence system with indeterminate uses shall also be considered high risk.",
        "title":"Amendment 1455: Article 6 – paragraph 2 e (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8621f0de-5514-479d-99b9-b5ffac2880d9",
        "text":"Article 6 a', 'Risk assessment', '1. In order to determine the level of risk of AI systems, the provider of an AI system with an intended purpose in the areas referred to in Annex III has to conduct a risk assessment.', '2.The risk assessment has to contain the following elements:', 'a) name all possible harms to life, health and safety or fundamental rights of potentially impacted persons or entities or society at large;', 'b) asses the likelihood and severity these harms might materialise;', 'c) name the potential benefits of such system for the potentially impacted persons and society at large;', 'd) name possible and taken measures to address, prevent, minimise or mitigate the identified harms with a high probability to materialise;', 'e) asses the possibilities to reverse these negative outcome;', 'f) the extent to which decision-making of the system is autonomous and outside of human influence.', '3. If the risk assessment showed a significant harm is likely to materialise the provider has to comply with Chapter 2 in a way that is appropriate and proportionate to the identified risks.",
        "title":"Amendment 1456: Article 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Catharina"
    },
    {
        "uuid":"2443b5b9-22bc-4df0-9ec7-b9479fc9cbf5",
        "text":"Article 6 a', 'Preliminary self-assessment', '1. Before the conformity assessment procedure foreseen in Articles 43 for high-risk AI systems and 51a for other than high-risk AI system, the provider of the AI system shall carry out a preliminary self-assessment to determine whether:', '(a) the intended purpose, potential use, or reasonably foreseeable misuse of the AI system constitute a prohibited practice pursuant to Article 5; or', '(b) the AI system is classified as ‘high-risk’ pursuant to Article 6.', '2. The provider of the AI system shall keep a detailed record, including all relevant documentation, of that self-assessment at the disposal of the national competent authorities during the lifespan of the AI system concerned.', '3. Where the preliminary self-assessment indicates non-compliance of the AI system with this Regulation, in particular due to it falling within the scope of Article 5, the provider shall, without delay, take measures to ensure compliance of the concerned AI system with this Regulation, or immediately desist from placing it on the market.",
        "title":"Amendment 1457: Article 6 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"bac534da-6452-4d31-924b-88a2115d5e5b",
        "text":"Article 6 a', 'Risk assessment', 'The European Artificial Intelligence Board shall develop guidance for the risk assessment.",
        "title":"Amendment 1458: Article 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"7cea52a6-77a7-4786-a63e-746830839c82",
        "text":"deleted",
        "title":"Amendment 1459: Article 7  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"ecbcecd8-be61-4c2c-9e7d-85e615209cbb",
        "text":"deleted",
        "title":"Amendment 1460: Article 7 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"7000927f-e153-493f-bec0-6784a9663683",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where the following condition is fulfilled: the AI systems pose a risk of harm to health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity or probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact associated with the high-risk AI systems already referred to in Annex III. Where an AI system is not intended to be used in any of the areas listed in points 1 to 8 of Annex III, the Commission is empowered to update the list of areas in Annex III by including new areas or extending the scope of existing areas.",
        "title":"Amendment 1461: Article 7 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"98709b47-4f5b-483d-9a15-dde753b2d914",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update Annex III, including by adding new areas of high-risk AI systems, where a type of AI system poses a risk of harm to the health and safety, a risk of adverse impact on fundamental rights, on climate change mitigation and adaptation, the environment, or a risk of contravention of the Union values enshrined in Article 2 TEU, and that risk is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems in use in the areas listed in Annex III.",
        "title":"Amendment 1462: Article 7 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"80b756be-5686-44cd-9d98-5ae64b45c259",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update or amend the list in Annex III by adding areas of high-risk AI systems where the AI systems pose a risk of harm to the health and safety, or a risk of adverse impact on fundamental rights, a risk of breach of the Union values enshrined in Article 2 TEU or a risk of adverse impact on the society and the environment.",
        "title":"Amendment 1463: Article 7 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ee15a1d3-a93b-4eb5-aee1-11fb92d3fc08",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where both of the following conditions are fulfilled and areas of high-risk systems that pose a risk of harm to health and safety, or a risk of adverse impact on fundamental rights, environment, society, rule of law or democracy, a risk of economic harm or to consumer protection that is, in respect of its severity or probability of occurrence;",
        "title":"Amendment 1464: Article 7 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"65ad7aab-adbe-4867-be47-e8e3289e658e",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list set out in Annex III by adding fields of high-risk AI systems where they present a risk of harm to health and safety or a risk of a negative impact on fundamental rights which, taking into account its severity and likelihood of occurrence, is equivalent to or higher than the risk of harm or negative impact of high-risk AI systems already listed in Annex III.",
        "title":"Amendment 1465: Article 7 – paragraph 1 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"db65714c-39ae-4e4c-b9c6-122053f5aaaf",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73, after an adequate and transparent consultation process involving the relevant stakeholders, to update the list in Annex III by withdrawing areas from that list or by adding critical areas. For additions both of the following conditions need to be fulfilled:",
        "title":"Amendment 1466: Article 7 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"6e130ee0-9567-4e7d-bee5-9809ad543c20",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73, after ensuring adequate consultation with relevant stakeholders, to update the list in Annex III by adding high-risk AI systems where both of the following conditions are fulfilled:",
        "title":"Amendment 1467: Article 7 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5d9a718b-2b7e-43ec-9895-37db8f636cc0",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding new area headings and high-risk AI systems where both of the following conditions are fulfilled:",
        "title":"Amendment 1468: Article 7 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"af7c070e-196c-4103-8bf7-46b3a1620d96",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems.",
        "title":"Amendment 1469: Article 7 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"91e9466d-9489-4fae-84d1-2c8229a9a950",
        "text":"1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where either of the following conditions is fulfilled:",
        "title":"Amendment 1470: Article 7 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"43caa37f-6bd9-43c7-b106-36550c227970",
        "text":"deleted",
        "title":"Amendment 1471: Article 7 – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"4c4ed3e2-4077-4f42-9874-3568e9848cb9",
        "text":"deleted",
        "title":"Amendment 1472: Article 7 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"58abe6b5-8d82-4129-8d5b-8a5a5f0af037",
        "text":"deleted",
        "title":"Amendment 1473: Article 7 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"622214b3-744f-4bc5-89a7-58fdfbd2127b",
        "text":"deleted",
        "title":"Amendment 1474: Article 7 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"6e6a3fed-8dab-4bc2-b6ea-afd646d2b98e",
        "text":"deleted",
        "title":"Amendment 1475: Article 7 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"dfe2b409-d579-452b-a7ec-dba76b0ca469",
        "text":"(a) the AI systems are intended to be used in any of the areas listed in points 1 to 8 of Annex III or in the newly identified area headings;",
        "title":"Amendment 1476: Article 7 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"d7dc6bc8-5b03-4086-b401-0a9ca27fec39",
        "text":"deleted",
        "title":"Amendment 1477: Article 7 – paragraph 1 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"4421d952-66b4-4290-a680-59e3c2f90b6b",
        "text":"deleted",
        "title":"Amendment 1478: Article 7 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"acdf6e9f-de34-4574-b1e9-99eaca56ccd4",
        "text":"deleted",
        "title":"Amendment 1479: Article 7 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"a50e4c17-a24b-43cf-ac49-dc377af5cc72",
        "text":"deleted",
        "title":"Amendment 1480: Article 7 – paragraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"104c9f25-79ad-4ad8-83b5-ee3febf765b9",
        "text":"deleted",
        "title":"Amendment 1481: Article 7 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"11de39ad-d5aa-4791-a649-e984b5f5078a",
        "text":"(b) the AI systems pose a risk of economic harm, negative societal impacts or harm to the environment, health and safety, or a risk of adverse impact on fundamental rights, democracy and the rule of law, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems already referred to in Annex III.",
        "title":"Amendment 1482: Article 7 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3f42999f-eb5d-40ba-92d3-dbdd0048dcc7",
        "text":"(b) the AI systems pose a risk of harm to the health, natural environment and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems already referred to in Annex III.",
        "title":"Amendment 1483: Article 7 – paragraph 1 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"978f4f1b-68f0-4fa6-81fb-7666cbbc6bdf",
        "text":"(b) the AI systems pose a serious risk of harm to the health and safety, or a serious risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact.",
        "title":"Amendment 1484: Article 7 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cbddafc2-0966-4397-8122-2eecdc6980c8",
        "text":"(b a) the AI systems pose a risk of harm to occupational health and safety, including psychosocial risks.",
        "title":"Amendment 1485: Article 7 – paragraph 1 – point b a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8eb78181-3e40-44c5-b194-a550a882ad06",
        "text":"deleted",
        "title":"Amendment 1486: Article 7 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"8a42568b-6643-4a38-b776-f47b716a1e3a",
        "text":"2. When assessing an AI system for the purposes of paragraph 1, the Commission shall take into account the following criteria:",
        "title":"Amendment 1487: Article 7 – paragraph 2 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"42b8753d-935e-45ca-9f32-79d14c609307",
        "text":"2. When assessing for the purposes of paragraph 1, the Commission shall take into account the following criteria:",
        "title":"Amendment 1488: Article 7 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"25579451-f6d7-4f46-af8e-b9b765c0e238",
        "text":"2. When assessing for the purposes of paragraph 1 the Commission shall take into account the following non-cumulative criteria:",
        "title":"Amendment 1489: Article 7 – paragraph 2 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"5f259be7-a1e5-4fca-91d7-56fc13188fe0",
        "text":"2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights or on the environment, democracy and rule of law that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall consult social partners and civil society and take into account, including but not limited to, the following non-cumulative criteria:",
        "title":"Amendment 1490: Article 7 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1a44bcdf-8d33-4d78-9051-3d68bf113632",
        "text":"2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall take into account, including but not limited to, the following criteria:",
        "title":"Amendment 1491: Article 7 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"99c9761d-1b36-44f2-b1eb-3e00d1e0dc96",
        "text":"2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health, natural environment and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall take into account the following criteria:",
        "title":"Amendment 1492: Article 7 – paragraph 2 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"b92dbee8-e234-4bf8-8026-f414ccadde87",
        "text":"(a) a description of the AI system, including the intended purpose, the concrete use and context, complexity and autonomy of the AI system, the potential persons impacted, the extent to which the AI system has been used or is likely to be used, the extent to which any outcomes produced are subject to human review or intervention;",
        "title":"Amendment 1493: Article 7 – paragraph 2 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"7f2f766a-d0ba-4d8a-b2e5-e3c35c31bcff",
        "text":"(a) the intended purpose of the AI system, or the reasonably foreseeable consequences of its use;",
        "title":"Amendment 1494: Article 7 – paragraph 2 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"49bbb403-da4c-4fd7-a7bf-d6e17e76a6b0",
        "text":"(a) the intended purpose of the AI system, potential use, or reasonably foreseeable misuse;",
        "title":"Amendment 1495: Article 7 – paragraph 2 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"bfe0ed9a-49e1-41cb-8caf-36b55f92795a",
        "text":"(a) the intended purpose or the reasonably foreseeable use of the AI system;",
        "title":"Amendment 1496: Article 7 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"0d40eb68-0d21-4964-8ac0-079c2888c3f5",
        "text":"(a a) the general capabilities and functionalities of the AI system independent of its intended purpose;",
        "title":"Amendment 1497: Article 7 – paragraph 2 – point a a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1419c512-6a49-49f7-98f3-11da64ff557f",
        "text":"(b) an assessment of the potential benefits provided by the use of the AI system, as well as reticence risk and\/or opportunity costs of not using the AI for individuals, groups of individuals, or society at large. This includes weighing the benefits of deploying the AI system against keeping the status quo;",
        "title":"Amendment 1498: Article 7 – paragraph 2 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"ca147016-cd3d-4609-b312-5513d48cd144",
        "text":"(b) the extent to which an AI system has been used or is likely to be used, including its reasonably foreseeable misuse;",
        "title":"Amendment 1499: Article 7 – paragraph 2 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3047b9e1-9810-4e3c-b677-cd13fe336894",
        "text":"(b) the extent to which an AI system has been used or is likely to be used and misused;",
        "title":"Amendment 1500: Article 7 – paragraph 2 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"def5fa6e-c25c-45de-aea3-a69c3f8947cc",
        "text":"(b a) the extent to which the AI system acts with a certain level of autonomy;",
        "title":"Amendment 1501: Article 7 – paragraph 2 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"03f207ed-7e50-4d58-974b-c937c30cfa3b",
        "text":"(b a) the type and nature of the data processed and used by the AI system;",
        "title":"Amendment 1502: Article 7 – paragraph 2 – point b a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"88a21625-c790-45f0-b6cd-2579ebf6b57a",
        "text":"(b a) the extent to which the AI system acts autonomously;",
        "title":"Amendment 1503: Article 7 – paragraph 2 – point b a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"03afa97b-5b8b-4be1-9db1-ffc958451288",
        "text":"(b b) the extent to which the AI system respects the principles of Article 4a;",
        "title":"Amendment 1504: Article 7 – paragraph 2 – point b b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"15f68cec-ce08-453c-8a45-4ee3ec3626b1",
        "text":"(c) an assessment of the probability of worst-case scenario, likelihood and severity of harm, to the health and safety or fundamental rights of potentially impacted persons and its irreversibility, including:', '(i) the extent to which the AI system has already been evaluated and proven to have caused material harm as demonstrated by studies or reports published by the national competent authorities;', '(ii) the extent to which potentially impacted persons are dependent on the outcome produced from the AI system, in particular because of practical or legal reasons it is not reasonably possible to opt-out from that outcome;', '(iii) the extent to which the outcome produced by the AI system is easily reversible;', '(iv) the extent to which potentially impacted persons are in a vulnerable position in relation to the user of the AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, or age.",
        "title":"Amendment 1505: Article 7 – paragraph 2 – point c  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"38dc87ba-5da7-400b-9f31-681d30d83700",
        "text":"(c) the extent to which the use of an AI system has already caused harm to natural persons, has breached the Union values enshrined in Article 2 TEU, has caused harm to the health and safety or has had an adverse impact on the fundamental rights, on the environment or the society or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to the national supervisory authority, to the national competent authorities, to the Commission, to the Board, to the EDPS or to the European Union Agency for Fundamental Rights (FRA);",
        "title":"Amendment 1506: Article 7 – paragraph 2 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d9246c31-bc86-4250-ac33-f18f64fa328e",
        "text":"(c) the extent to which the use of an AI system has already caused harm to natural persons, has contravened the Union values enshrined in Article 2 TEU, has caused harm to the health and safety or has had an adverse impact on the fundamental rights, on the environment or society, or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities, to the Commission, to the Board, to the EDPS or to the European Union Agency for Fundamental Rights (FRA);",
        "title":"Amendment 1507: Article 7 – paragraph 2 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"afd6ef90-616f-4719-949e-4c1f9b4b6648",
        "text":"(c) the extent to which the use of an AI system has already caused harm to the health and safety or adversely impacted fundamental rights, environment, society, rule of law or democracy, consumer protection or caused economic harm or has given rise to reasonable concerns in relation to the likelihood of such harm or adverse impact;",
        "title":"Amendment 1508: Article 7 – paragraph 2 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"46e8421c-d080-484d-9c53-a2ab12f52891",
        "text":"(c) the extent to which the use of an AI system has already caused harm to the health, natural environment and safety or adverse impact on the fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities;",
        "title":"Amendment 1509: Article 7 – paragraph 2 – point c  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"1798779a-7a17-488a-b730-240365ad4ac2",
        "text":"(c) the extent to which the use of an AI system has already caused harm to the health and safety or adverse impact on the fundamental rights, democracy, rule of law and the environment has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by available reports or documented allegations;",
        "title":"Amendment 1510: Article 7 – paragraph 2 – point c  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9444f60f-de01-4910-8aa7-e1f0f39f2f46",
        "text":"(c a) the AI systems pose a risk of harm to occupational health and safety, including psychosocial risks and mental health;",
        "title":"Amendment 1511: Article 7 – paragraph 2 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"e247888e-dc81-445f-8e82-ccfe377f4a29",
        "text":"(d) measures taken to address or mitigate the identified risks, including to the extent existing Union legislation provides for:', '(i) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;', '(ii) effective measures to prevent or substantially minimise those risks.",
        "title":"Amendment 1512: Article 7 – paragraph 2 – point d  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"8dfe7467-b4db-4997-946f-21519edfc0cb",
        "text":"(d) the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect a plurality of persons or on the environment or to affect a particular group of persons disproportionately;",
        "title":"Amendment 1513: Article 7 – paragraph 2 – point d  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"cf0be69e-9c6a-4d63-93ad-28f05cea4b51",
        "text":"(d) the potential extent of such harm or such adverse impact;",
        "title":"Amendment 1514: Article 7 – paragraph 2 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4fc17b4f-cb32-46e2-8052-2872196857f0",
        "text":"deleted",
        "title":"Amendment 1515: Article 7 – paragraph 2 – point e  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"0d966b91-8ad1-47ad-a73e-0253da8dd69a",
        "text":"(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system with a distinction to be made between an AI system used in an advisory capacity or one used directly to make a decision, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;",
        "title":"Amendment 1516: Article 7 – paragraph 2 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6012e7bf-5430-4b4d-8d54-7e841830e5d0",
        "text":"(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced by a process involving an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out of that outcome;",
        "title":"Amendment 1517: Article 7 – paragraph 2 – point e  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"e64082ac-a4d0-4830-b6ae-c84d20fab11a",
        "text":"(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced involving an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;",
        "title":"Amendment 1518: Article 7 – paragraph 2 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c81639b4-c8b0-49fe-97f1-52febd4ddaae",
        "text":"(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;",
        "title":"Amendment 1519: Article 7 – paragraph 2 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"132d8ec3-959e-4401-b44e-81617d68a9a7",
        "text":"(e a) the potential misuse and malicious use of the AI system and of the technology underpinning it;",
        "title":"Amendment 1520: Article 7 – paragraph 2 – point e a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"e562747b-2aef-40e4-94c9-00b2c4fbe018",
        "text":"(e a) the potential misuse and malicious use of the AI system and of the technology underpinning it;",
        "title":"Amendment 1521: Article 7 – paragraph 2 – point e a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d5a44c60-8b64-4668-b653-c9e60d2d1675",
        "text":"deleted",
        "title":"Amendment 1522: Article 7 – paragraph 2 – point f  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"4bb7f0b9-5785-4034-811f-8c675c449852",
        "text":"(f) the extent to which there is an imblanace of power, or the potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to status, authority, knowledge, economic or social circumstances, or age;",
        "title":"Amendment 1523: Article 7 – paragraph 2 – point f  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c1d02db0-facd-441d-a82c-7e58f7855131",
        "text":"deleted",
        "title":"Amendment 1524: Article 7 – paragraph 2 – point g  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"2a41252a-45f8-45ea-8f0f-3e19f678c789",
        "text":"(g) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the fundamental rights of persons, the environment or the society, the health or safety of persons, or on the Union values enshrined in Article 2 TEU, shall not be considered as easily reversible;",
        "title":"Amendment 1525: Article 7 – paragraph 2 – point g  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b8641872-136b-4961-b2a2-aee0a97dce62",
        "text":"(g) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons, the fundamental rights of persons, the environment or society, or on the Union values enshrined in Article 2 TEU shall not be considered as easily reversible;",
        "title":"Amendment 1526: Article 7 – paragraph 2 – point g  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"37f69cce-47a2-4448-9308-ad589ef0b616",
        "text":"(g) the extent to which the outcome produced involving an AI system is easily reversible and can effectively be appealed by AI subjects. Outcomes having an impact on the fundamental rights or health or safety of persons shall not be considered as easily reversible;",
        "title":"Amendment 1527: Article 7 – paragraph 2 – point g  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"67e13d87-0811-4f92-9ce0-3b515b945415",
        "text":"(g) the extent to which the outcome produced with an AI system is not easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;",
        "title":"Amendment 1528: Article 7 – paragraph 2 – point g  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"832d5576-332a-4819-b5a8-515f4f54d03b",
        "text":"(g) the extent to which the outcome produced with an AI system is not easily reversible or remedied, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;",
        "title":"Amendment 1529: Article 7 – paragraph 2 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"061ce37d-214b-437a-9e37-bd48d659c410",
        "text":"(g a) the extent of the availability and use of demonstrated technical solutions and mechanisms for the control, reliability and corrigibility of the AI system;",
        "title":"Amendment 1530: Article 7 – paragraph 2 – point g a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d445f0b7-8519-4089-a192-803c3a15e3ea",
        "text":"(g a) magnitude and likelihood of benefit of the deployment of the AI system for individuals, groups, or society at large;",
        "title":"Amendment 1531: Article 7 – paragraph 2 – point g a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"9f3c3759-6bb1-494c-a1b6-5590b72e5e6e",
        "text":"(g b) the extent of human oversight and the possibility for a human to intercede in order to override a decision or recommendations that may lead to potential harm;",
        "title":"Amendment 1532: Article 7 – paragraph 2 – point g b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"76e93199-0118-42a7-87bc-00f5a62a97a6",
        "text":"(g c) the magnitude and likelihood of benefit of the deployment of the AI system for industry, individuals, or society at large;",
        "title":"Amendment 1533: Article 7 – paragraph 2 – point g c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b917da2e-0972-4291-a76c-bf54aafaf951",
        "text":"(g d) the reticence risk and\/or opportunity costs of not using the AI system for industry, individuals, or society at large;",
        "title":"Amendment 1534: Article 7 – paragraph 2 – point g d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6d5093dd-3a3e-4bbd-8b1e-d9f38027c645",
        "text":"(g e) the amount and nature of data processed;",
        "title":"Amendment 1535: Article 7 – paragraph 2 – point g e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"adbf367f-612e-4e5b-8d89-84acc0075375",
        "text":"(g f) the benefits provided by the use of the AI system, including making products safer;",
        "title":"Amendment 1536: Article 7 – paragraph 2 – point g f (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9200f291-474c-45fc-9641-64965e23defc",
        "text":"deleted",
        "title":"Amendment 1537: Article 7 – paragraph 2 – point h  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"2892e0fb-e86d-4f17-816d-2d273159dcb0",
        "text":"(h) the extent to which existing Union legislation, in particular the GDPR, provides for:",
        "title":"Amendment 1538: Article 7 – paragraph 2 – point h – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"feba4ee6-a3ca-44e1-ab27-ec3c7d81959a",
        "text":"(h) the extent to which existing Union legislation, in particular GDPR, provides for:",
        "title":"Amendment 1539: Article 7 – paragraph 2 – point h – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"f06a629f-a60e-423b-b24f-1daa8492ff57",
        "text":"(h) the extent to which existing Union legislation lacks:",
        "title":"Amendment 1540: Article 7 – paragraph 2 – point h – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ea250c89-8dd7-4c09-a220-cc1ed64c8bae",
        "text":"(i) effective measures of redress, the availability of redress-by-design mechanisms and procedures in relation to the risks posed by an AI system, including claims for material and non-material damages;",
        "title":"Amendment 1541: Article 7 – paragraph 2 – point h – point i  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"19ef1372-e372-403d-a39b-d54b0b2c32e1",
        "text":"(i) effective measures of redress in relation to the damage caused by an AI system, with the exclusion of claims for direct or indirect damages;",
        "title":"Amendment 1542: Article 7 – paragraph 2 – point h a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"996f28c1-e873-4647-8184-99411bc2da42",
        "text":"(h a) The general capabilities and functionalities of the AI system independent of its foreseeable use;",
        "title":"Amendment 1543: Article 7 – paragraph 2 – point h a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e14f2e13-f331-40d2-b1f4-e04b5ec94ed6",
        "text":"(h b) The extent of the availability and use of demonstrated technical solutions and mechanisms for the control, reliability and corrigibility of the AI system;",
        "title":"Amendment 1544: Article 7 – paragraph 2 – point h b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"90ec24eb-f931-4901-af21-9d9b0b23b9d6",
        "text":"(h c) The potential misuse and malicious use of the AI system and of the technology underpinning it.",
        "title":"Amendment 1545: Article 7 – paragraph 2 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f03a1312-8ee2-4345-87ff-60588816c665",
        "text":"2a. When assessing an AI system for the purposes of paragraph 1, the Commission shall consult, where appropriate, national and European authorities and bodies, representatives of the groups concerned by that system, industry professionals, independent experts and civil society organisations. The Commission shall organise public consultations in this regard.",
        "title":"Amendment 1546: Article 7 – paragraph 2 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9eba0189-cb0e-4be8-a8e9-8040d1694d95",
        "text":"2 a. When carrying out the assessment referred to in paragraph 1 the Commission shall consult, where relevant, representatives of groups on which an AI system has an impact, stakeholders, independent experts and civil society organisations. The Commission shall organise public consultations in this regard.",
        "title":"Amendment 1547: Article 7 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1523d925-cede-43e8-8189-c3ea93ea8ece",
        "text":"2 a. The Commission may remove AI systems from the list in Annex III if the conditions referred to in paragraph 1 are no longer met.",
        "title":"Amendment 1548: Article 7 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1d780748-df6e-48ae-a94a-7847107e2509",
        "text":"2 a. The Commission shall provide a transitional period of at least 24 months following each update of Annex III.",
        "title":"Amendment 1549: Article 7 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"6df1acda-996e-4da5-9194-b87b982aa192",
        "text":"2 b. The Board, notified bodies and other actors may request the Commission to reassess an AI system. The AI system shall then be reviewed for reassessment and may be re-categorized. The Commission shall give reasons for its decision and publish the reasons. The details of the application procedure shall be laid down by the Commission by means of delegated acts in accordance with Article 73.",
        "title":"Amendment 1550: Article 7 – paragraph 2 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"091ce477-8bb8-41ea-8174-90ad4e4f095b",
        "text":"2b. The Commission shall publish a detailed report on the assessment referred to in paragraph 2.",
        "title":"Amendment 1551: Article 7 – paragraph 2 b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"6f6d0427-ef1a-4b22-9940-b12e27ac846f",
        "text":"2c. The Commission shall consult the Board before adopting delegated acts pursuant to paragraph 1.",
        "title":"Amendment 1552: Article 7 – paragraph 2 c (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"5dea65fb-eeb3-4701-b1ab-8ed5af2b4175",
        "text":"1. High-risk AI systems shall comply with the requirements established in this Chapter throughout the entire lifecycle of the AI system. This includes their placing on the market as well as their deployment and use. Providers and deployers of AI systems shall ensure compliance by establishing technical and operational measures in line with this Chapter.",
        "title":"Amendment 1553: Article 8 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8ca04e16-8f83-4643-b602-f982e52ddcd6",
        "text":"1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art and industry standards, including as reflected in relevant harmonised standards or common specifications.",
        "title":"Amendment 1554: Article 8 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"2cedf08b-18a5-41d8-b7bd-5d6bd7e1f499",
        "text":"1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art, including as reflected in relevant harmonised standards or common specifications.",
        "title":"Amendment 1555: Article 8 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"e4dbda45-92df-4fc8-bf05-31dd3903428f",
        "text":"1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art and industry standards, including as reflected in relevant harmonised standards or common specifications.",
        "title":"Amendment 1556: Article 8 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"8af9a8e4-c4c6-4e1b-b65d-c8e0b5eabdf8",
        "text":"1. High-risk AI systems shall comply with the essential requirements established in this Chapter, taking into account the generally acknowledged state of the art, including as reflected in relevant industry and harmonised standards.",
        "title":"Amendment 1557: Article 8 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"27d05482-696c-49ac-8630-74bcee48dd22",
        "text":"1. 1. Operators of high-risk AI systems shall comply with the requirements established in this Chapter.",
        "title":"Amendment 1558: Article 8 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"868974d0-ae00-40ed-a6ed-4a6787ee891e",
        "text":"1 a. In complying with the requirements established in this Chapter, operators of high-risk AI systems shall take into account the generally-acknowledged state of the art, including as reflected in the relevant harmonised standards and common specifications referenced in Articles 40 and 41.",
        "title":"Amendment 1559: Article 8 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"457f387f-60ac-4626-b8cb-fda7d409779f",
        "text":"1 a. Where a deployer discovers non-compliance of a high-risk AI system with this regulation during reasonably foreseeable use, the deployer shall have the right to obtain the necessary modifications from the provider to the high-risk AI system.",
        "title":"Amendment 1560: Article 8 – paragraph 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"493d757b-8cc0-4ba7-965d-c8a83a63c23d",
        "text":"1 b. Prospective deployers of high-risk AI systems shall have certified third parties assess and confirm the conformity of the AI system and its use with this Regulation and relevant applicable Union legislation before putting it into use. The conformity certificate shall be uploaded to the database pursuant to Article 60.",
        "title":"Amendment 1561: Article 8 – paragraph 1 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"404d5de5-3e4e-4148-9bb9-164a77ea4b64",
        "text":"1 c. Where personal data is processed or is expected to be processed in the use of a high-risk AI system, this shall be understood as constituting a high risk in the meaning of Article 35 of Regulation (EU) 2016\/679.",
        "title":"Amendment 1562: Article 8 – paragraph 1 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"21431860-4d0a-4910-937c-0177214a5438",
        "text":"2. The intended purpose of the high-risk AI system, the foreseeable uses and foreseeable misuses of AI systems with indeterminate uses and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",
        "title":"Amendment 1563: Article 8 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6115c9f9-5d45-42e4-b082-9c8a013c906e",
        "text":"2. The foreseeable uses and foreseeable misuses of AI systems with indeterminate uses of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",
        "title":"Amendment 1564: Article 8 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b09be87b-015f-4be6-8ade-79f544c4c2f2",
        "text":"2. The intended purpose, the potential or reasonably foreseeable use or misuse of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",
        "title":"Amendment 1565: Article 8 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b3bcca84-a407-4512-9e8f-9315c1f9fb6e",
        "text":"2. The intended purpose, reasonably foreseeable uses and foreseeable misuses of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",
        "title":"Amendment 1566: Article 8 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"0c4bb84c-6bad-4836-b744-f1bda8a2c2a7",
        "text":"2. The intended purpose of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with the relevant requirements depending on the type of risks posed.",
        "title":"Amendment 1567: Article 8 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"15b768c3-61b6-4e2b-a45e-d0b507f6bb5e",
        "text":"2. The intended purpose or reasonably foreseeable use of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",
        "title":"Amendment 1568: Article 8 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b065a109-72d5-46ba-a514-30b9cb4d9a18",
        "text":"2 a. AI systems referred to in Article 6 may be wholly or partially exempted from fulfilling the requirements referred to in Articles 8-15 if risks posed by the AI systems are sufficiently eliminated or mitigated through appropriate operational countermeasures or built-in fail-safe systems.",
        "title":"Amendment 1569: Article 8 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bd1a0f58-ee6b-47eb-8d4f-8d46cb0eb40c",
        "text":"2 a. This article shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme.",
        "title":"Amendment 1570: Article 8 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"d17c25dd-6508-418f-90dc-4811b2399f0e",
        "text":"2 a. This article shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional and analogous work or programme.",
        "title":"Amendment 1571: Article 8 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"ca032022-8651-4e68-8ec2-c0acee77484a",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems. The risk management system can be integrated into, or a part of, already existing risk management procedures insofar as it fulfils the requirements of this article.",
        "title":"Amendment 1572: Article 9 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b6ac202e-e093-4fbc-9dff-faa56fd75a97",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems, unless the AI system is covered by New Legislative Framework (NLF) legislation.",
        "title":"Amendment 1573: Article 9 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"c6e0ffff-6531-482b-bb39-2d810dc4b0d7",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems if this system poses a risk of harm to health and safety or a risk of adverse impacts on fundamental rights.",
        "title":"Amendment 1574: Article 9 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"01fd0814-b4c4-44f3-9626-c2a07b960607",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in appropriate relation to high-risk AI systems and its risks identified in the risk assessment referred to in Art. 6a.",
        "title":"Amendment 1575: Article 9 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"fb1bf651-224c-4695-8ab5-40d37f1bf971",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems or be included in existing risk management procedures.",
        "title":"Amendment 1576: Article 9 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"50bba538-83e0-4f3b-8bed-63a9f6398749",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems, throughout the entire lifecycle of the AI system.",
        "title":"Amendment 1577: Article 9 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b69538bf-e405-41b9-92fd-92331301ea12",
        "text":"1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems throughout the entire lifecycle of the AI system.",
        "title":"Amendment 1578: Article 9 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0e0779c1-b383-4dc7-9aad-611fa3fe36d6",
        "text":"2. The risk management system shall consist of a continuous iterative process run throughout the entire lifetime of a high-risk AI system, requiring regular review of the suitability of the risk management process to ensure its continuing effectiveness, and documentation of any decisions and actions taken. It shall comprise the following steps and all of these steps shall be integrated into already existing risk management procedures relating to the relevant Union sectoral legislation to avoid unnecessary bureaucracy:",
        "title":"Amendment 1579: Article 9 – paragraph 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a7e3002e-2da9-45d7-b76a-c465eced3599",
        "text":"2. The risk management system shall consist of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic review and updating, including when the high-risk AI system is subject to significant changes in its design or purpose. It shall comprise the following steps:",
        "title":"Amendment 1580: Article 9 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"af438d71-c206-4b6c-95ad-0723e2f8ef5e",
        "text":"2. The risk management system shall consist of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic review and updating. It shall comprise the following steps:",
        "title":"Amendment 1581: Article 9 – paragraph 2 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8c8871f3-7596-495e-9110-3f80e4f82fb2",
        "text":"(a) identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system, and AI systems with indeterminate uses can pose to:', '(i) the health or safety of natural persons;', '(ii) the legal rights or legal status of natural persons;', '(iii) the fundamental rights of natural persons;', '(iv) the equal access to services and opportunities of natural persons;', '(v) the Union values enshrined in Article 2 TEU;', '(vi) society at large and the environment.",
        "title":"Amendment 1582: Article 9 – paragraph 2 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2bec9d03-63d6-4cf8-920a-e50b18c5b2a6",
        "text":"(a) identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system, and AI systems with indeterminate uses, can pose to:', '(i) the health or safety of natural persons;', '(ii) the legal rights or legal status of natural persons;', '(iii) the fundamental rights;', '(iv) the equal access to services and opportunities of natural persons;', '(v) the Union values enshrined in Article 2 TEU.",
        "title":"Amendment 1583: Article 9 – paragraph 2 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"a1351f0f-09a9-4abb-821b-0db34ceaacf2",
        "text":"(a) identification and analysis of the known and reasonably foreseeable risks associated with each high-risk AI system with respect to health, safety, fundamental rights, and the values of the Union as enshrined in Article 2 TEU;",
        "title":"Amendment 1584: Article 9 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"21577b30-207d-46bb-82e0-4be33ecaa323",
        "text":"(a) identification and analysis of the known and reasonable foreseeable risks of harms most likely to occur to the health, safety or fundamental rights in view of the intended purpose of the high-risk AI system;",
        "title":"Amendment 1585: Article 9 – paragraph 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"57e65ca8-87bf-44f8-bc18-fa0f1b8c4c16",
        "text":"(a) identification and analysis of the known and foreseeable risks associated with each high-risk AI system, including by means of a fundamental rights impact assessment as provided for in Article 9a;",
        "title":"Amendment 1586: Article 9 – paragraph 2 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f19e9ef0-bac8-40ed-9ff1-c430d53b1fda",
        "text":"(a) identification and analysis of the known and foreseeable risks most likely to occur to health, safety and fundamental rights in view of the intended purpose of the high-risk AI system;",
        "title":"Amendment 1587: Article 9 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"79567d37-ba59-4bbe-affe-c626b6243b41",
        "text":"(a) identification and analysis of the known and foreseeable risks to the health and safety or fundamental rights of a person associated with each high-risk AI system;",
        "title":"Amendment 1588: Article 9 – paragraph 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"36e0671b-77d1-4912-ad90-d6d3f87c34f3",
        "text":"(aa) identification of the risks, damage and harm actually caused by the high-risk AI system in the past, whether these are the result of use of the high-risk AI system for its intended purpose or of another use;",
        "title":"Amendment 1589: Article 9 – paragraph 2 – point a a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2505c1d8-6ce6-4966-884b-141a17e314e3",
        "text":"(a a) evaluation of how the principles of Article 4a are adhered to;",
        "title":"Amendment 1590: Article 9 – paragraph 2 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"45fac791-7295-491e-9d64-8060d0aeb2fe",
        "text":"deleted",
        "title":"Amendment 1591: Article 9 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"3729e9ef-b0e3-4e97-bcde-5ca6ca07f344",
        "text":"deleted",
        "title":"Amendment 1592: Article 9 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e4ddcb24-4fa6-441c-bbdb-055f4823d424",
        "text":"(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use and under conditions of reasonably foreseeable misuse;",
        "title":"Amendment 1593: Article 9 – paragraph 2 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f75a4dad-97ed-4a15-a686-e1f4c55d2f84",
        "text":"(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use and under conditions of reasonably foreseeable misuse;",
        "title":"Amendment 1594: Article 9 – paragraph 2 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"cb4d6a5a-d291-4459-b26c-556778947cb7",
        "text":"(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose;",
        "title":"Amendment 1595: Article 9 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"a106490b-71ae-44d3-bea4-d0cb68b2f670",
        "text":"(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose and under conditions of reasonably foreseeable use or misuse;",
        "title":"Amendment 1596: Article 9 – paragraph 2 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"691d8b77-3fcd-471a-b1ee-e5c600a9bc65",
        "text":"(c) evaluation of new risks consistent with those described in paragraph (2a) of this Article and identified based on the analysis of data gathered from the post-market monitoring system referred to in Article 61;",
        "title":"Amendment 1597: Article 9 – paragraph 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8dc9a6ca-41b5-4437-9640-c78bd310cef7",
        "text":"(c) evaluation of new arising significant risks based on the analysis of data gathered from the post-market monitoring system referred to in Article 61;",
        "title":"Amendment 1598: Article 9 – paragraph 2 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"67d2c39e-199a-415d-b942-1218c11f29b5",
        "text":"(ca) sandbox experimentation on the functioning of the AI systems;",
        "title":"Amendment 1599: Article 9 – paragraph 2 – point c a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"394b4be8-ee7f-4e62-ba4a-75463accfe49",
        "text":"(d) adoption of appropriate and targeted risk management measures designed to address identified known and foreseeable risks to health and safety or fundamental rights, in accordance with the provisions of the following paragraphs.",
        "title":"Amendment 1600: Article 9 – paragraph 2 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5cadf9f3-2ee4-45f0-a7d4-9e35296bf9b5",
        "text":"(d) adoption of appropriate and targeted risk management measures to address identified significant risks in accordance with the provisions of the following paragraphs.",
        "title":"Amendment 1601: Article 9 – paragraph 2 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"9382fef2-a982-4d2f-9285-4abc81c72fda",
        "text":"2 a. The risks referred to in paragraph 2 shall concern only those which may be reasonably mitigated or eliminated through the development or design of the high-risk AI system, or the provision of adequate technical information.",
        "title":"Amendment 1602: Article 9 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"190e02e3-bd77-4fa7-bea3-413df94ae191",
        "text":"3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2, with a view to treating risks effectively while ensuring an appropriate and proportionate implementation of the requirements. They shall take into account the generally acknowledged state of the art, including as reflected in relevant harmonised standards.",
        "title":"Amendment 1603: Article 9 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4ba9a971-58aa-4610-8f79-33181397476a",
        "text":"3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2. They shall take into account the generally acknowledged state of the art, including as reflected in the common technical specifications adopted by the Commission or in relevant harmonised standards.",
        "title":"Amendment 1604: Article 9 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2cf8a37e-7082-4ad1-96f8-654fc9bd4f5a",
        "text":"3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2, with a view to minimising risks more effectively while achieving an appropriate balance in implementing the measures to fulfil those requirements.",
        "title":"Amendment 1605: Article 9 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"5180bdc8-239a-4288-8d48-3738b57268fa",
        "text":"3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2. They shall take into account the state of the art, including as reflected in relevant harmonised standards or common specifications.",
        "title":"Amendment 1606: Article 9 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4d428fab-ff0e-4324-8710-92a137178f49",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that the overall residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regard to the benefits that the high-risk AI system is reasonably expected to deliver and, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, subject to terms, conditions as made available by the provider, and contractual and license restrictions. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1607: Article 9 – paragraph 4 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo"
    },
    {
        "uuid":"54d31582-72a1-4077-8899-fda1938e92ec",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard, as well as the overall residual risk of the high-risk AI systems, is:",
        "title":"Amendment 1608: Article 9 – paragraph 4 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"6391c57f-d574-4284-94c0-0768fc94782a",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual significant risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regard to the benefits that the high-risk AI system is reasonably expected to deliver and provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual significant risks shall be communicated to the user.",
        "title":"Amendment 1609: Article 9 – paragraph 4 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"a341a08a-0eb2-4403-8fa6-5a027590000f",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual risks and the reasoned judgements made shall be communicated to the deployer and made available to AI subjects.",
        "title":"Amendment 1610: Article 9 – paragraph 4 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ce2cb090-38f6-4caa-aafe-cffd9fde48e5",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any significant residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regards to the benefits that the high-risk AI system is reasonably expected to deliver and provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Significant residual risks shall be communicated to the user.",
        "title":"Amendment 1611: Article 9 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1959cdc3-1693-4923-99e4-3c64abfacc2a",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use or under conditions of reasonably foreseeable misuse. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1612: Article 9 – paragraph 4 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bd446737-d927-47a5-8bdd-c95d182b0607",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1613: Article 9 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"3bcdf26b-ea3c-435d-a1bb-2b1daa500a06",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any relevant residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1614: Article 9 – paragraph 4 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"1e4cb96f-4a45-4838-968e-62a4fe098724",
        "text":"4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1615: Article 9 – paragraph 4 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"fa6f1ef4-81d6-4583-94f7-161d9707a019",
        "text":"In identifying the most appropriate risk management measures, the following shall be taken into account:",
        "title":"Amendment 1616: Article 9 – paragraph 4 – subparagraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0f874520-a68a-42c7-980e-f89da362d1b6",
        "text":"In identifying appropriate risk management measures, the following outcomes shall be pursued:",
        "title":"Amendment 1617: Article 9 – paragraph 4 – subparagraph 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"ef491502-df79-4945-819c-7b74ed7b7b52",
        "text":"(a) reduction of identified and evaluated risks as far as proportionate and technologically possible in light of the generally acknowledged state of the art and industry standards, through adequate design and development of the high risk AI system in question;",
        "title":"Amendment 1618: Article 9 – paragraph 4 – subparagraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8796a6f7-2199-404e-b701-b5a0aa11e998",
        "text":"(a) elimination or reduction of risks as far as possible through adequate design and development involving relevant domain and other experts and internal and external stakeholders, including but not limited to representative bodies and the social partners;",
        "title":"Amendment 1619: Article 9 – paragraph 4 – subparagraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a9796b37-b712-4f7a-b11a-fa7741839332",
        "text":"(a) elimination or reduction of risks as far as commercially reasonable and technologically feasible in light of the generally acknowledged state of the art, through appropriate design and development measures;",
        "title":"Amendment 1620: Article 9 – paragraph 4 – subparagraph 1 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"d5439857-cabc-487a-ab7e-00f39d899671",
        "text":"(a) elimination or reduction of identified and evaluated risks as far as economically and technologically feasible through adequate design and development of the high-risk AI system;",
        "title":"Amendment 1621: Article 9 – paragraph 4 – subparagraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"a40cc07b-838c-459f-8dc0-5b1dafc258c0",
        "text":"(a) reduction of identified and evaluated risks as far as commercially reasonable and technologically feasable through adequate design and development;",
        "title":"Amendment 1622: Article 9 – paragraph 4 – subparagraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"03a6644c-2821-4ddb-925c-18f596974615",
        "text":"deleted",
        "title":"Amendment 1623: Article 9 – paragraph 4 – subparagraph 1 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"a1b099a7-53a7-4b32-9228-7d7d7de22d3d",
        "text":"(b) where appropriate, implementation of adequate mitigation and control measures in relation to significant risks that cannot be eliminated;",
        "title":"Amendment 1624: Article 9 – paragraph 4 – subparagraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"3eea3817-f4d1-44a7-9479-eaa7ac50cbb2",
        "text":"(b) where appropriate, implementation of adequate mitigation and control measures addressing risks that cannot be eliminated;",
        "title":"Amendment 1625: Article 9 – paragraph 4 – subparagraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"853d4d33-8483-4a4a-852f-b1ebca8b4ffc",
        "text":"(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (b) of this Article, and, where appropriate, and relevant information on necessary competence training and authority for natural persons exercising such oversight.",
        "title":"Amendment 1626: Article 9 – paragraph 4 – subparagraph 1 – point c  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"2df514b7-84c9-436d-99b2-898bed160566",
        "text":"(c) provision of adequate information pursuant to Article 13 and, where appropriate, training to users.",
        "title":"Amendment 1627: Article 9 – paragraph 4 – subparagraph 1 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"57312c8b-807a-4434-94c9-37ee65d29081",
        "text":"(c) provision of the required adequate information pursuant to Article 13 of this Article, and, where appropriate, training to users.",
        "title":"Amendment 1628: Article 9 – paragraph 4 – subparagraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"089ce407-203e-4c87-a60b-88b824b6940e",
        "text":"(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (a) and (b) of this Article, and, where appropriate, training to users.",
        "title":"Amendment 1629: Article 9 – paragraph 4 – subparagraph 1 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ad9ddc8f-2b6f-480e-9dd2-afdb0f20fd4c",
        "text":"(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (b) of this Article, and, where appropriate, training to deployers.', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)",
        "title":"Amendment 1630: Article 9 – paragraph 4 – subparagraph 1 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d9c0954f-0dd7-4ad1-bee9-33eff199925c",
        "text":"(c a) the governance structures to mitigate risks.",
        "title":"Amendment 1631: Article 9 – paragraph 4 – subparagraph 1 – point c a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a37dbbce-7fca-45e0-aa14-532d711ffb65",
        "text":"In eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the deployer, to the socio-technical context in which the system is intended to be used, and to reasonably foreseeable use or misuse.",
        "title":"Amendment 1632: Article 9 – paragraph 4 – subparagraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia"
    },
    {
        "uuid":"87d6f34e-9eda-47ce-977a-c7a5197552e2",
        "text":"In eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the user and the environment in which the system is intended or reasonably foreseeable to be used.",
        "title":"Amendment 1633: Article 9 – paragraph 4 – subparagraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4b3c1cd7-792d-49ef-9aad-c1bed71ab31a",
        "text":"In seeking to reduce risks related to the use of the high-risk AI system, providers shall take into due consideration the technical knowledge, experience, education, training the user may need, including in relation to the environment in which the system is intended to be used.",
        "title":"Amendment 1634: Article 9 – paragraph 4 – subparagraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d0ea7bc0-9045-4adc-adf8-34fd8cb17373",
        "text":"In seeking to eliminate or reduce risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the user and the environment in which the system is intended to be used.",
        "title":"Amendment 1635: Article 9 – paragraph 4 – subparagraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"a6094308-cad3-4e88-bcf4-dcf1f6ff6f55",
        "text":"(a) technically and structurally minimised by the high-risk AI system;",
        "title":"Amendment 1636: Article 9 – paragraph 4 – point a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"525e8229-590d-485a-ae61-f52646ca4033",
        "text":"(b) deemed acceptable, provided that the high-risk AI system is used for its intended purpose or under conditions of reasonably foreseeable misuse.",
        "title":"Amendment 1637: Article 9 – paragraph 4 – point b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"76b068c6-f4df-4d0a-b557-c557861b4dd4",
        "text":"4a. Those residual risks shall be communicated to the user.",
        "title":"Amendment 1638: Article 9 – paragraph 4 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"cc6f3684-631d-4bd0-af99-9ea139ae7777",
        "text":"5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system. Evaluations shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the relevant requirements set out in this Chapter.",
        "title":"Amendment 1639: Article 9 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"acf33121-199b-430f-bb5d-5e5fc42a6ee4",
        "text":"5. High-risk AI systems shall be tested for the purposes of identifying appropriate risk management measures for the specific scenario in which the system will be operating and to ensure that a system is performing appropriately for a given use case. Testing shall ensure that high-risk AI systems perform in a manner that is consistent with their intended purpose and they are in compliance with the requirements set out in this Chapter.",
        "title":"Amendment 1640: Article 9 – paragraph 5  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"b61908de-d34b-4d2c-974d-1dc0887691d7",
        "text":"5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system. Evaluations shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the relevant requirements set out in this Chapter.",
        "title":"Amendment 1641: Article 9 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f0e5f027-414f-4c35-8f49-f61e9941a5e3",
        "text":"5. High-risk AI systems shall be tested for the purposes of identifying the most appropriate risk management measures. Testing shall ensure that high-risk AI systems perform consistently, safely during reasonably foreseeable conditions of use or misuse, and they are in compliance with the requirements set out in this Chapter.",
        "title":"Amendment 1642: Article 9 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bbcfb0cf-755a-44c8-b819-08e3650b57e9",
        "text":"5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system.",
        "title":"Amendment 1643: Article 9 – paragraph 5  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia Sardone, Annalisa Tardino"
    },
    {
        "uuid":"c0cde293-9cba-47f3-a20c-59c09e0697de",
        "text":"5. High-risk AI systems shall be tested for the purposes of identifying the most appropriate risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose or reasonably foreseeable use and they are in compliance with the requirements set out in this Chapter.",
        "title":"Amendment 1644: Article 9 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7f763ead-acb9-4f36-8396-70a200d4c8e8",
        "text":"deleted",
        "title":"Amendment 1645: Article 9 – paragraph 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c8028149-00ac-41da-9cd3-3fa5daf8ddea",
        "text":"6. Testing procedures shall be suitable to achieve the intended purpose of the AI system.",
        "title":"Amendment 1646: Article 9 – paragraph 6  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c0b7bb12-bf60-42f2-8da5-31951bd2b349",
        "text":"6. Testing procedures shall be suitable to achieve the intended purpose or reasonably foreseeable use of the AI system and do not need to go beyond what is necessary to achieve that purpose.",
        "title":"Amendment 1647: Article 9 – paragraph 6  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"6f7c5b07-3247-4d99-92c2-e1e0b0ba1f36",
        "text":"6. Evaluation or testing procedures shall be suitable to achieve the intended purpose of the AI system.",
        "title":"Amendment 1648: Article 9 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"351985cc-0826-4780-a9aa-453237aed174",
        "text":"They shall test:",
        "title":"Amendment 1649: Article 9 – paragraph 6 – subparagraph 1 (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"288c3009-e901-4961-898c-a2649b6f788f",
        "text":"(a) the ability of the high-risk AI system to generate an accurate and robust result;",
        "title":"Amendment 1650: Article 9 – paragraph 6 – point a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"34b69973-8a1d-4766-a9b1-8dbc743bbe51",
        "text":"(b) the trustworthiness of the high-risk AI system and its ability to actually generate a result such as that expected in accordance with its intended purpose;",
        "title":"Amendment 1651: Article 9 – paragraph 6 – point b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"355a4b46-b5df-4e6d-8059-8e4999946d8d",
        "text":"(c) the structural and technical capacity of the high-risk AI system to ensure it cannot be used for purposes other than its intended purpose.",
        "title":"Amendment 1652: Article 9 – paragraph 6 – point c (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"7a596d68-ed79-4dfc-af9e-6e4179308efa",
        "text":"7. The testing of the high-risk AI systems shall be performed prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.",
        "title":"Amendment 1653: Article 9 – paragraph 7  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"0ab2dbef-c453-48cb-b933-c04a53500f8d",
        "text":"7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against metrics and probabilistic thresholds that are preliminarily defined according to common standards or technical specifications and appropriate to the intended purpose of the high-risk AI system.",
        "title":"Amendment 1654: Article 9 – paragraph 7  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"a4348df4-1162-4baf-87d5-6a79710b6f7d",
        "text":"7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended purpose or reasonably foreseeable use of the high-risk AI system.",
        "title":"Amendment 1655: Article 9 – paragraph 7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"68ba5ae6-361b-43b9-a4c0-cc9b45eb6318",
        "text":"7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended use or reasonably foreseeable misuse of the high-risk AI system.",
        "title":"Amendment 1656: Article 9 – paragraph 7  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"206e4a98-aa57-42cd-981c-1e822cf38a13",
        "text":"7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against prior defined metrics, such as probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.",
        "title":"Amendment 1657: Article 9 – paragraph 7  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cb3f488d-a356-408f-a0c6-811576bb0258",
        "text":"7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and rubrics that are appropriate to the intended purpose of the high-risk AI system.",
        "title":"Amendment 1658: Article 9 – paragraph 7  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"27d11c41-9a9f-449e-89d5-9c3144b430da",
        "text":"8. When implementing the risk management system described in paragraphs 1 to 7, specific consideration shall be given to whether the high-risk AI system is likely to be accessed by or have an impact on children or natural persons suffering from disabilities that render them legally unable to give their consent.",
        "title":"Amendment 1659: Article 9 – paragraph 8  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"369fe36b-c0dc-4c2d-965e-ad3e2a6d5724",
        "text":"8. When implementing the risk management system described in paragraphs 1 to 7, specific consideration shall be given to whether the high-risk AI system is likely to:",
        "title":"Amendment 1660: Article 9 – paragraph 8  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"36d6a689-9e84-4f90-beac-b306513c56eb",
        "text":"8. When implementing the risk management system described in paragraphs 1 to 7, shall give specific consideration to whether the high-risk AI system is likely to be accessed by or have an impact on children.",
        "title":"Amendment 1661: Article 9 – paragraph 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4f974cce-fd65-4eed-a94b-669eb3ab62d7",
        "text":"(a) adversely affect specific groups of people, in particular on the basis of gender, sexual orientation, age, ethnicity, disability, religion, socio-economic standing, religion or origin, including asylum seekers including migrants, refugees and asylum seekers;",
        "title":"Amendment 1662: Article 9 – paragraph 8 – point b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia"
    },
    {
        "uuid":"85d59d02-4ee9-4244-acd9-8cff65429236",
        "text":"(b) have an adverse impact on the environment, or;",
        "title":"Amendment 1663: Article 9 – paragraph 8 – point b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2e030c9f-4119-4ef1-9897-9d7482233d39",
        "text":"(c) be implemented on children;",
        "title":"Amendment 1664: Article 9 – paragraph 8 – point c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b85e5cfb-e010-4c22-a77a-c6f27c4a9dc7",
        "text":"(d) have an adverse effect on mental health, individual’s behaviour;",
        "title":"Amendment 1665: Article 9 – paragraph 8 – point e (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f296418b-7756-4a78-b33e-44df30948fa4",
        "text":"(e) amplify the spread of disinformation and amplify polarisation;",
        "title":"Amendment 1666: Article 9 – paragraph 8 – point e (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b7d990ea-21b9-4450-9f3d-ac1a7e303326",
        "text":"(f) amplify the spread of disinformation and amplify polarisation;",
        "title":"Amendment 1667: Article 9 – paragraph 8 – point f (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b13fe3cd-8a3c-43b4-91f8-c43bc4c4d326",
        "text":"9. For AI systems already covered by Union law that requires a specific risk assessment, the aspects described in paragraphs 1 to 8 may be incorporated into that risk assessment, without the need to conduct a separate, additional risk assessment in order to comply with this Article.",
        "title":"Amendment 1668: Article 9 – paragraph 9  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"535726b7-dfa3-4a85-a60f-43126ac88e75",
        "text":"9. For providers and AI systems already covered by Union law that require them to establish a specific risk management, the aspects described in paragraphs 1 to 8 shall be part of the risk management procedures established by that Union law or deemed to be covered as part of it.",
        "title":"Amendment 1669: Article 9 – paragraph 9  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"21e9f321-7a7f-496a-b9de-b20e5fff5f9a",
        "text":"9. For AI systems already covered by Union law that require them to carry out specific risk assessments, the aspects described in paragraphs 1 to 8 shall be combined with the risk assessment procedures established by that Union law or deemed to be covered as part of it.",
        "title":"Amendment 1670: Article 9 – paragraph 9  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"49228f91-c72e-46e1-bbc9-1c71992f4c74",
        "text":"Article 9 a', 'Fundamental rights impact assessments for high-risk AI systems', '1. Providers, and deployers at each proposed deployment, must designate the categories of individuals and groups likely to be impacted by the system, assess the system’s impact on fundamental rights, its accessibility for persons with disabilities, and its impact on the environment and broader public interest. Deployers of high-risk AI systems as defined in Article 6(2) shall, prior to putting the system into use, publish a fundamental rights impact assessment of the systems’ impact in the context of use throughout the entire lifecycle. This assessment shall include at least:', 'a) the intended purpose for which the system will be used;', 'b) the intended geographic and temporal scope of the system;', 'c) the potential risks of the use to the rights and freedoms of natural persons, including any indirect impacts or consequences of the systems;', 'd) the categories of natural persons and groups likely or foreseen to be affected;', 'e) the proportionality and necessity of the system’s use;', 'f) verification of the legality of the use of the system in accordance with Union and national law;', 'g) any specific risk of harm likely to impact marginalised, vulnerable persons or groups at risk of discrimination, and risk of increasing existing societal inequalities;', 'h) the foreseeable impact of the use of the system on the environment over its entire life cycle, including but not limited to energy consumption;', 'i) any other negative impact on the public interest and clear plans relating to how the harms identified will be mitigated, and how effective this mitigation is expected to be; and', 'j) the governance system the deployer will put in place, including human oversight, complaint-handling and redress.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to Articles 65 and 67, may take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new deployment of the high-risk AI system.', '4. Deployers shall consult with relevant stakeholders, in particular groups of natural persons exposed to heightened risks from the AI system, civil society and social partners when preparing the impact assessment. The impact assessment shall be repeated on a regular basis throughout the entire lifecycle.', '5. Publication of the results of the impact assessment shall be part of the registration of use pursuant to Article 51(2).', '6. Where the deployer is already required to carry out a data protection impact assessment under Article 35 of Regulation(EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680, the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment and be published as an addendum.', '7. Deployers of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation under paragraph 1.",
        "title":"Amendment 1671: Article 9 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia"
    },
    {
        "uuid":"b4674bcd-5c36-45e3-b6b5-77638488f318",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.', 'Techniques such as unsupervised learning and reinforcement learning that do not use validation and testing data sets shall be developed on the basis of training data sets the quality criteria referred to in paragraphs 2 to 5.",
        "title":"Amendment 1672: Article 10 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"5453b7f6-5881-4712-9f69-6500f61aa97e",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be, as far as this can be reasonably expected and is feasible from a technical and economical point of view, developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.",
        "title":"Amendment 1673: Article 10 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"d55c000a-1eb9-4437-8ef0-b392328c464c",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be, as far this can be reasonably expected and is feasible from a technical point of view, developed with the best efforts to ensure training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.",
        "title":"Amendment 1674: Article 10 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"36faacab-b73e-4b93-a7a3-5e53a9ecf852",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be, with reasonable expectations and in accordance with the state-of-art, developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5;",
        "title":"Amendment 1675: Article 10 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"99d84d84-802d-4e30-81fd-1b847e4ef073",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5, when applicable.",
        "title":"Amendment 1676: Article 10 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"d2046bfc-df79-4ee1-aeda-2eb02768f4cc",
        "text":"1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality and fairness criteria referred to in paragraphs 2 to 5.",
        "title":"Amendment 1677: Article 10 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"9fe07ba9-9040-4ef9-be1e-0974f4d1e39a",
        "text":"1 a. Validation datatsets shall be separate datasets from both the testing and the training datasets, in order for the evaluation to be unbiased. If only one dataset is available, it shall be divided in three parts: a training set, a validation set, and a testing set. Each set shall comply with paragraph 3 of this Article.",
        "title":"Amendment 1678: Article 10 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"02c65f3f-0d0c-4717-bd58-3342371c2029",
        "text":"1 a. Techniques such as unsupervised learning and reinforcement learning, that do not use validation and testing data sets, shall be developed on the basis of training data sets that meet the quality criteria referred to in paragraphs 2 to 5.",
        "title":"Amendment 1679: Article 10 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"a77b8912-63ca-4fe9-93be-74429e155e63",
        "text":"1 b. Techniques such as unsupervised learning and reinforcement learning, that do not use validation and testing datasets, shall be developed on the basis of training datasets that meet the quality criteria referred to in paragraphs 2 to 4.",
        "title":"Amendment 1680: Article 10 – paragraph 1 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"db7830bc-eb58-4997-834e-bea6c3068feb",
        "text":"2. Training, validation and testing data sets as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall be subject to appropriate data governance and management practices. Those practices shall concern in particular,",
        "title":"Amendment 1681: Article 10 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"76976d38-74c4-4339-97d7-fe3f32b9d50e",
        "text":"2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices for the entire lifecycle of data processing. Where relevant to appropriate risk management measures, those practices shall concern in particular,",
        "title":"Amendment 1682: Article 10 – paragraph 2 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"3247c12f-60d2-4c2a-bb32-c525b9556757",
        "text":"2. Training, validation and testing data sets shall be subject to data governance and management practices appropriate for the context of the use as well as the intended purpose of the AI system. Those practices shall concern in particular,",
        "title":"Amendment 1683: Article 10 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"93953a27-ee29-458b-8140-5f5b7cc1ec19",
        "text":"2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices. throughout the entire lifecycle of the AI system. Those practices shall concern in particular,",
        "title":"Amendment 1684: Article 10 – paragraph 2 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6b9c88e2-7c4e-472f-9fa5-86dc08c916e2",
        "text":"2. Training, machine-learning validation and testing data sets shall be subject to appropriate data governance and management practices during the expected lifetime. Those practices shall concern, where relevant:",
        "title":"Amendment 1685: Article 10 – paragraph 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a9106824-7d82-493d-b454-3ca078f71a83",
        "text":"2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices for the entire lifecycle of data processing. Those practices shall concern in particular,",
        "title":"Amendment 1686: Article 10 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"17b1a37f-3971-41d9-b382-5e823ec38f62",
        "text":"(a) the relevant design choices, including the extent to which the functioning of the algorithms can be audited and reproduced;",
        "title":"Amendment 1687: Article 10 – paragraph 2 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2f933cc2-0ca7-4210-9806-5f1232351786",
        "text":"(a) the design choices for training and machine learning validation;",
        "title":"Amendment 1688: Article 10 – paragraph 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"10a75d8e-ab89-4977-8bf9-454fa395e45f",
        "text":"(a) the design choices;",
        "title":"Amendment 1689: Article 10 – paragraph 2 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"303cc406-692a-4b1b-acdf-486f5790dd99",
        "text":"(b) data collection processes;",
        "title":"Amendment 1690: Article 10 – paragraph 2 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e3bf878b-4a4d-49db-aed2-386de4416b32",
        "text":"(b) data collection processes;",
        "title":"Amendment 1691: Article 10 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"12975038-a5ba-43dc-b6f2-24ac7a15f4be",
        "text":"(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;",
        "title":"Amendment 1692: Article 10 – paragraph 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"175c992c-4824-4fa8-a54e-0a5165f98761",
        "text":"(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;",
        "title":"Amendment 1693: Article 10 – paragraph 2 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"fd9f2313-327a-4e19-b46d-e059c3ac35d9",
        "text":"(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;",
        "title":"Amendment 1694: Article 10 – paragraph 2 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"c1e224ff-877e-4b55-ab4e-aaf470fcd4a2",
        "text":"(d) the formulation of relevant, justified and reasonable assumptions, notably with respect to the information that the data are supposed to measure and represent;",
        "title":"Amendment 1695: Article 10 – paragraph 2 – point d  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"58886eaf-630e-47a2-ae4b-b2deddf753d1",
        "text":"deleted",
        "title":"Amendment 1696: Article 10 – paragraph 2 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bee74ba8-e937-4988-b7ff-3612146e10c7",
        "text":"(e) an assessment of the availability, quantity and suitability of the data sets that are needed;",
        "title":"Amendment 1697: Article 10 – paragraph 2 – point e  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"4aae2cd1-b5ad-4357-af58-bb976af33f37",
        "text":"(f) examination in view of possible biases defined as a statistical error or a top-down introduction of assumptions harmful to an individual, that are likely to affect health and safety of persons or lead to discrimination prohibited by Union law;",
        "title":"Amendment 1698: Article 10 – paragraph 2 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Radosław Sikorski,"
    },
    {
        "uuid":"a2c51f6e-3612-4c41-bddd-0ae5cb9a9e46",
        "text":"(f) examination in view of possible unfair biases that are likely to affect the health and safety of persons or lead to discrimination prohibited under Union law;",
        "title":"Amendment 1699: Article 10 – paragraph 2 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8f830d79-94d1-4fac-8efb-e08fd69d201d",
        "text":"(f) examination in view of possible biases, that are likely to affect health and safety of persons or lead to discrimination prohibited by Union law;",
        "title":"Amendment 1700: Article 10 – paragraph 2 – point f  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"66536e47-3cb3-426e-a632-767ba3e94c72",
        "text":"(f) examination of possible biases, especially where data outputs are used as an input for future operations(‘feedback loops’);",
        "title":"Amendment 1701: Article 10 – paragraph 2 – point f  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"13e431ed-9781-46f5-9314-22b39ffbc276",
        "text":"(f) examination in view of possible biases that are likely to affect the output of the AI system;",
        "title":"Amendment 1702: Article 10 – paragraph 2 – point f  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"eb10ab1f-1c8a-49be-98b8-28a9b0338b36",
        "text":"(f) examination in view of biases;",
        "title":"Amendment 1703: Article 10 – paragraph 2 – point f  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"9aa9fdd7-b575-472c-90d8-fbff55464b41",
        "text":"(g) the identification of any other data gaps or shortcomings that materially increase the risks of harm to the health, natural environment and safety or the fundamental rights of persons, and how those gaps and shortcomings can be addressed.",
        "title":"Amendment 1704: Article 10 – paragraph 2 – point g  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"4b1dc348-ecec-45c0-9976-0123fcee0078",
        "text":"(g) the identification of significant and consequential data gaps or shortcomings, and how those gaps and shortcomings can be addressed;",
        "title":"Amendment 1705: Article 10 – paragraph 2 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bcef1ec2-67c3-461f-a630-72116c6eacd4",
        "text":"(g) the identification of relevant possible data gaps or shortcomings, and how those gaps and shortcomings can be addressed.",
        "title":"Amendment 1706: Article 10 – paragraph 2 – point g  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Malik Azmani, Alin Mituța"
    },
    {
        "uuid":"6ac53350-0705-4bd0-b610-ec34bea6a355",
        "text":"(g) the identification of significant data gaps or shortcomings, and how those gaps and shortcomings can be addressed.",
        "title":"Amendment 1707: Article 10 – paragraph 2 – point g  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"67bf6c7a-4604-41c5-b1d8-1e117c329148",
        "text":"(g) the identification of possible data gaps or shortcomings, and how those gaps and shortcomings can be addressed.",
        "title":"Amendment 1708: Article 10 – paragraph 2 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"d948c896-dd35-4c5f-adcf-3d2e5b0fa071",
        "text":"(g a) the presumable context of the use as well as the intended purpose of the AI System.",
        "title":"Amendment 1709: Article 10 – paragraph 2 – point g a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"50a76de7-fa91-4e7e-8d38-b67caa9f4ed1",
        "text":"(g a) verification of the legality of the sources of the data.",
        "title":"Amendment 1710: Article 10 – paragraph 2 – point g a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"565588fa-733f-4299-ac00-1e31f6f83bf6",
        "text":"2 a. the evaluation of the impacts of a high-risk AI system, designed to ensure it is functioning as intended, that there are no errors or risks left unaddressed and that the system continues to meet the state-of-the-art standards required by this Regulation (ex post requirement).",
        "title":"Amendment 1711: Article 10 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"8f0dab94-57aa-46ce-b032-494a4fdf8743",
        "text":"3. Training data sets, validation and testing data sets, including the labels, as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall be relevant, representative, free of errors and complete. They shall have the appropriate properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. The required characteristics should be met at the level of each individual dataset, whether in combination or not.', 'Training validation and testing data sets shall be relevant, representative, free of errors and complete. They shall have the appropriate properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used.",
        "title":"Amendment 1712: Article 10 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"39d4f494-d333-493a-99e2-15ebf857bdfb",
        "text":"3. Training, validation and testing data sets shall be relevant, representative and as complete and close to zero error as possible, having regard to the intended purpose of the AI system. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof. In case of observational data, a common approach on data requirements shall be defined together with regulators.",
        "title":"Amendment 1713: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"be9375bc-759c-4201-979e-39903851c7f9",
        "text":"3. Training, validation and testing data sets shall be relevant, representative, reliable, limited in terms of bias, and complete. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1714: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"2fc6cac0-1e3e-43cb-8042-ee3d82800903",
        "text":"3. High-risk AI systems shall be designed and developed with the best efforts to ensure that training, validation and testing data sets shall be relevant, representative, and to the best extent possible, free of errors and complete in accordance with industry standards. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1715: Article 10 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"455da904-0d52-48f8-93c8-48aec743542d",
        "text":"3. Training, validation and testing datasets sets shall be relevant, representative, up-to-date, and to the extent that it could be reasonably expected, taking into account the state of the art, free of errors and as complete as could be reasonably expected . They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1716: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"3208b9d1-f042-465d-867f-b0caec370870",
        "text":"3. High risk AI systems should be designed and developed with the best efforts to ensure that, where appropriate, training, validation and testing data sets are sufficiently relevant, representative and appropriately vetted for errors. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1717: Article 10 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"048e525f-2635-44b3-943b-0be198ef119d",
        "text":"3. Training datasets, and where applicable, validation and testing datasets, including the labels, shall be relevant, representative, up-to-date, and to the best extent possible, free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets shall be met at the level of each individual data set.",
        "title":"Amendment 1718: Article 10 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"7667b611-1e07-4725-ab9c-971990073b32",
        "text":"3. Training, validation and testing datasets shall be relevant, representative, up-to-date, and to the best extent possible, taking into account the state of the art, free of errors and be as complete as possible. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets shall be met at the level of each individual dataset.",
        "title":"Amendment 1719: Article 10 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"cce98e91-482d-4896-a806-7fd68f1176ae",
        "text":"3. Training, validation and testing data sets shall be relevant, sufficiently diverse to mitigate bias, and, to the best extent possible, representative, free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1720: Article 10 – paragraph 3  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2426f0d1-4e7b-438f-aa71-9fad5b1ba30d",
        "text":"3. Training, validation and testing data sets shall be relevant, representative, and to the best extent possible free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk uses of AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1721: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"2087e9f0-cc5e-41c2-b9fb-08b76eb56a06",
        "text":"3. Training, validation and testing data sets shall be relevant, representative, free of errors and statistically complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1722: Article 10 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"754a2c01-2141-49c0-89ee-e06b3eaee2a0",
        "text":"3. Training, validation and testing data sets shall be relevant and representative. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1723: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"c4bf5b53-285a-4683-8ba9-a5d58a52ffec",
        "text":"3. Training, validation and testing data sets shall be relevant and representative. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1724: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"1de8f02a-4691-42d5-9c14-c4c93f5cb4a8",
        "text":"3. High Risk AI systems should be designed and developed with the best efforts to ensure that, where appropriate, training datasets, machine-learning validation and testing data sets are sufficiently accurate, relevant and representative in view of the intended purpose of the AI system. These characteristics may be met at the level of individual data sets or a combination thereof.",
        "title":"Amendment 1725: Article 10 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1cfde108-4574-4127-a06e-9b495f23119f",
        "text":"3 a. In assessing the quality of a data set, account shall be taken to the extent to which the data set is constructed with a view to fulfilling in particular the following aspects:', 'a) provides a similar output for relevant demographic Groups impacted by the system;', 'b) minimizes disparities in outcomes for relevant demographic groups impacted by the system, in case where the system allocates resources or opportunities to natural persons;', 'c) minimizes the potential for stereotyping, demeaning, or erasing relevant demographic groups impacted by the system where the system describes, depicts, or otherwise represents people, cultures, or society.",
        "title":"Amendment 1726: Article 10 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fbb1a906-1b3c-4422-a5a3-0eafad9cfb74",
        "text":"deleted",
        "title":"Amendment 1727: Article 10 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7262df85-4dc6-44d2-a219-a9eee4ea397d",
        "text":"4. Training, validation and testing data sets as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall take into account, to the extent required by the intended purpose or reasonably foreseeable use , the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used.",
        "title":"Amendment 1728: Article 10 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"bbbd749e-91fb-4fd2-a176-fa882211ef7a",
        "text":"4. Data sets shall take into account, to the extent required by the intended purpose, the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses, the characteristics or elements that are particular to the specific geographical, ,behavioural or functional setting within which the high-risk AI system is intended to be used.",
        "title":"Amendment 1729: Article 10 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"3adf99f3-9ec8-4a6c-a9dc-6f70d1a9c89d",
        "text":"4. Training, validation and testing data sets shall take into account the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is used.",
        "title":"Amendment 1730: Article 10 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"4aa1f5d9-299e-45e8-90e0-abbd925f2929",
        "text":"4. Training, validation and testing data sets shall be sufficiently diverse to accurately capture, to the extent required by the intended purpose, the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used.",
        "title":"Amendment 1731: Article 10 – paragraph 4  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"bc0d3997-59f1-40b6-aa21-f885a9b089b4",
        "text":"4. Data sets shall take into account, to the extent required by the intended purpose, the reasonably foreseeable uses and misuses of AI systems, the characteristics or elements that are particular to the specific geographical, cultural, behavioural or functional setting within which the high-risk AI system is intended to be used.",
        "title":"Amendment 1732: Article 10 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"7e094a57-4eb1-4fb4-9ae7-42e8a618f4f6",
        "text":"4 a. The processing of personal data to train, validate and test data sets of an AI system in order to meet the requirements of this Regulation shall be lawful for the purpose of the legitimate interest of the provider as referred to in Article 6(1f) GDPR or in accordance with Article 6(4) GDPR subject to appropriate safeguards in line with Article 89 GDPR for ensuring to the extent necessary and proportionate one or more of the following objectives:', 'a) national and common security;', 'b) functioning of the internal market;', 'c) prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;', 'd) exercise of public authorities’ official mission, such as tax and customs authorities, financial investigation units, independent administrative authorities, or financial market authorities responsible for the regulation and supervision of securities markets should not be regarded as recipients if they process personal data to train, validate and test an AI system which are necessary to carry out a particular inquiry in the general interest, in accordance with Union or Member State law;', 'e) network and information security to the extent necessary and proportionate for this purpose;', 'f) protection of an interest which is essential for the life of the data subject or that of another natural person, in particular where it is necessary for reasons of public interest in the areas of public health.",
        "title":"Amendment 1733: Article 10 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"ce68b7c6-6636-449d-be1f-96a7af8ac6f1",
        "text":"deleted",
        "title":"Amendment 1734: Article 10 – paragraph 5  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"94dd8dd5-7067-4db9-ba51-3e23d5ee51de",
        "text":"deleted",
        "title":"Amendment 1735: Article 10 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"604fcaf6-83a6-42f3-b5fd-1d782ac96aec",
        "text":"deleted",
        "title":"Amendment 1736: Article 10 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"b78a6bdb-a6dd-4991-9c10-62452c63d6a7",
        "text":"deleted",
        "title":"Amendment 1737: Article 10 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0832399c-1d67-4301-861b-5e8eb2ff06d6",
        "text":"5. To the extent that it is necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems will have a legal basis and necessary exception to process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016\/679, Article 10 of Directive (EU) 2016\/680 and Article 10(1) of Regulation (EU) 2018\/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including:', '(i) state-of-the-art security and privacy-preserving measures, such as data-minimization, pseudonymisation, encryption, and where anonymisation may significantly affect the purpose pursued;', '(ii) measures ensuring availability and resilience of processing systems and services, and the ability to restore the availability and access to special category personal data in a timely manner in the event of a physical or technical incident;', '(iii) processes for regularly testing, assessing and evaluating the effectiveness of technical and organisational measures in order to ensure the security of the processing;', '(iv) measures for user identification, authorisation, protection of data during transmission, protection of data during storage, ensuring physical security of locations at which personal data are processed, internal IT and IT security governance and management, certification\/assurance of processes and products;', '(v) measures for ensuring data minimisation, data quality, limited data retention, and data portability and ensuring erasure.",
        "title":"Amendment 1738: Article 10 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"e37f9be2-1bdb-4f07-a4cd-13f80c613bfc",
        "text":"5. To the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems may process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016\/679, Article 10 of Directive (EU) 2016\/680 and Article 10(1) of Regulation (EU) 2018\/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including technical limitations on the re-use and use of state-of-the-art security and privacy-preserving measures, such as pseudonymisation, or encryption where anonymisation may significantly affect the purpose pursued. This should also guarantee explainability of AI driven recommendations or decisions.",
        "title":"Amendment 1739: Article 10 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d9e5eeea-546b-4160-b2d0-b33ace14a30b",
        "text":"5. To the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems may process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016\/679, Article 10 of Directive (EU) 2016\/680 and Article 10(1) of Regulation (EU) 2018\/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including technical limitations on the re-use and use of state-of-the-art security and privacy-preserving measures, such as pseudonymisation, or encryption or biometric template protection technologies where anonymisation may significantly affect the purpose pursued.",
        "title":"Amendment 1740: Article 10 – paragraph 5  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"3e211555-233e-4def-8390-5b27549a266d",
        "text":"5a. The dissemination of data by an AI system to other AI systems, whether or not they are of the same origin and whether or not they are installed on the same medium, shall be checked by the provider and may be retracted if necessary.",
        "title":"Amendment 1741: Article 10 – paragraph 5 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"08d8b87c-1563-4178-a7b2-7470af80f1e5",
        "text":"6. For the development of high-risk AI systems not using techniques involving the training of models, paragraphs 2 to 5 shall apply only to the testing data sets.",
        "title":"Amendment 1742: Article 10 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"e143e212-3531-4e72-befc-4a703f648773",
        "text":"6 a. Providers and user may comply with the obligations set out in this Article through the use of third-parties that offer certified compliance services including verification of data governance, data set integrity, and data training, validation and testing practices.",
        "title":"Amendment 1743: Article 10 – paragraph 6 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"08234475-c6fa-4b9b-b22c-0c8521e79756",
        "text":"6 a. The training, testing and validation processes of data sets should have a duration based on the training periodicity of the systems, the timing of notification of incidents and the normal supervisory activity of the national competent authority",
        "title":"Amendment 1744: Article 10 – paragraph 6 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"fb10b629-a572-4533-ba49-26f5611dd163",
        "text":"6 b. Where the provider cannot comply with the obligations laid down in this Article because it does not have access to the data and\/or the data is held exclusively by the user, the user may, on the basis of a contract, be made responsible for any infringement of this Article.",
        "title":"Amendment 1745: Article 10 – paragraph 6 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"735ff3e1-4cbe-4042-9904-6d65953bbfc9",
        "text":"Article 10 a', 'Environmental Impact of high-risk AI systems', '1. High-risk AI systems shall be designed and developed making use of state-of-the-art methods to reduce energy use, resource use and waste, as well as to increase energy efficiency, and the overall efficiency of the system. They shall be designed and developed and set up with capabilities enabling the measurement and logging of the consumption of energy and resources, and other environmental impact the deployment and use of the systems may have over their entire lifecycle.', '2. Member States shall ensure that relevant national authorities issue guidelines and provide support to providers and deployers in their efforts to reduce the environmental impact and resource use of high-risk AI systems.', '3. The Commission shall be empowered to adopt delegated acts in accordance with Article 73 to detail the measurement and logging procedures, taking into account state-of-the-art methods, in particular to enable the comparability of the environmental impact of systems, and taking into account the economies of scale.",
        "title":"Amendment 1746: Article 10 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b04a44c4-127f-4686-8860-1c0c06cacbc2",
        "text":"Article 10 a', 'Risk management system for AI systems likely to interact with children', 'AI systems likely to interact with or impact on children shall implement a riskmanagement system addressing content, contact, conduct and contract risks to children;",
        "title":"Amendment 1747: Article 10 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Milan Brglez, Hilde Vautmans, Catharina Rinzema"
    },
    {
        "uuid":"abc0525b-6d76-48d6-814f-cefbcbb2f0fe",
        "text":"1. The technical documentation of a high-risk AI system shall be drawn up, where possible, relevant, and without compromising intellectual property rights or trade secrets, before that system is placed on the market or put into service and shall be kept up-to date.",
        "title":"Amendment 1748: Article 11 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c4f4084b-d88a-4289-93b3-cb7106e00921",
        "text":"1. The technical documentation of a high-risk AI system shall be drawn up before that system is placed on the market or put into service and shall be kept up-to date throughout its entire lifecycle, and where appropriate, beyond.",
        "title":"Amendment 1749: Article 11 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f4aacf50-63b6-4dfb-9124-dee43bf9ea12",
        "text":"The technical documentation shall be drawn up, where possible, relevant, and without compromising intellectual property rights or trade secrets, in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or in the case of SME’s and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent national authority.",
        "title":"Amendment 1750: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5039d8d1-3c66-499a-8a6e-511e276fa8bb",
        "text":"The technical documentation shall vary according to each use of the AI system and drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or in the case of SMEs and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent national authority.",
        "title":"Amendment 1751: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"31ece37a-6943-421b-9e71-238380f82ea3",
        "text":"The technical documentation shall be appropriate to the context of application or use of the AI system and drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or any equivalent documentation meeting the same objectives, subject to approval of the competent authority.",
        "title":"Amendment 1752: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"8c668f81-18ed-4187-bc5f-5460d0a83e1d",
        "text":"The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or, in the case of SMEs and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent authority.",
        "title":"Amendment 1753: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"d02d519d-79e1-4f09-8818-3f27a8725637",
        "text":"The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or equivalent documentation meeting the same objectives, subject to the approval of the competent authority.",
        "title":"Amendment 1754: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e4890e4d-a63d-49a9-9542-2e009d701dbb",
        "text":"The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide the national supervisory authority, the national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV.",
        "title":"Amendment 1755: Article 11 – paragraph 1 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"b95ef212-2462-43ec-ae4c-00717b8a922b",
        "text":"The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV.",
        "title":"Amendment 1756: Article 11 – paragraph 1 – point 1 (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"fc7480d0-d6a8-49a5-b7af-b674a4667dc2",
        "text":"(1) Technical documentation is not mandatory, but it is recommended for the testing of a high-risk AI system before it is placed on the market or made available.",
        "title":"Amendment 1757: Article 11 – paragraph 1 – point 1 (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"ccbdc7ae-776e-4dc6-b581-5016d98038f3",
        "text":"2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service only one single and appropriate technical documentation shall be drawn up for each product, containing all the information set out in Annex IV as well as the information required under those legal acts.",
        "title":"Amendment 1758: Article 11 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2a5c15fb-e1ab-439c-83f8-166e4800a49e",
        "text":"2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service one single technical documentation shall be drawn up containing all the information set out in paragraph 1 as well as the information required under those legal acts.",
        "title":"Amendment 1759: Article 11 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a94f79b5-d4e0-4105-b744-ab0a7d39388e",
        "text":"2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service appropriate technical documentation shall be drawn up containing all the information set out in Annex IV as well as the information required under those legal acts.",
        "title":"Amendment 1760: Article 11 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"fe278b73-a8d9-48b4-a216-e4fc125716fd",
        "text":"2 a. To ensure that a single technical documentation is possible, terms and definitions related to this required documentation and any required documentation in the appropriate Union sectoral legislation shall be aligned as much as possible;",
        "title":"Amendment 1761: Article 11 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"22ca8e7d-8f1c-46a8-8a18-bf5ced060097",
        "text":"deleted",
        "title":"Amendment 1762: Article 11 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"d24dbc01-0b31-4340-a77e-246d3f569a80",
        "text":"3. The Commission is empowered to adopt delegated acts in accordance with Article 73 to add to Annex IV where necessary to ensure that, in the light of technical progress, the technical documentation provides all the necessary information to assess the compliance of the system with the requirements set out in this Chapter.",
        "title":"Amendment 1763: Article 11 – paragraph 3 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e6c71fac-8f63-4d50-a86b-b8f60ded2330",
        "text":"3 a. Providers that are credit institutions regulated by Directive 2013\/36\/EU shall maintain the technical documentation as part of the documentation concerning internal governance, arrangements, processes and mechanisms pursuant to Article 74 of that Directive.",
        "title":"Amendment 1764: Article 11 – paragraph 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"7a3f3e73-a7f7-464b-a070-217d7b554070",
        "text":"1. High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems are operating. Those logging capabilities shall conform to recognised standards or common specifications. Where possible, these capabilities shall be local ones and the logs shall be stored on the medium employed by the user of the AI system.",
        "title":"Amendment 1765: Article 12 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"6ce5662b-9b35-43e6-83ce-2ba23d8fff12",
        "text":"1. Where reasonably practicable high-risk AI systems, which are capable of changing behaviour during operation, shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications.",
        "title":"Amendment 1766: Article 12 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"e8cc6536-5757-46aa-a90b-cc6bbdfd59bd",
        "text":"1. High-risk AI systems shall technically allow the automatic recording of events (‘logs’) over the durations of the lifetime of the system.",
        "title":"Amendment 1767: Article 12 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0c0e7759-23f9-4f9b-8505-00109b469f56",
        "text":"1. High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems is operating. Those logging capabilities shall conform to the state of the art and recognised standards or common specifications.",
        "title":"Amendment 1768: Article 12 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"22b24afe-5a17-4d3a-9e93-689284a656ab",
        "text":"1. High-risk AI systems shall be designed and developed with appropriate technical and organizational measures to enable effective monitoring and human oversight by those using the system as well as effective supervision by regulators.",
        "title":"Amendment 1769: Article 12 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki"
    },
    {
        "uuid":"73c50fe7-9a1a-45a3-b8b2-6469b4b1c7ba",
        "text":"1. All AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications.",
        "title":"Amendment 1770: Article 12 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"25d468e5-3b61-43e8-be13-0930f609e200",
        "text":"2. In order to ensure a level of traceability of the AI system’s functioning which is appropriate to the intended purpose of the system, the logging capabilities shall enable the recording of events relevant for the identification of situations that may:', '(i) result in the AI system presenting a risk within the meaning of Article 65 (1);or', '(ii) lead to a substantial modification that facilitates the post market monitoring referred to in Article 61.",
        "title":"Amendment 1771: Article 12 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"11cfe717-08ea-49a4-9363-111041885976",
        "text":"2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning that is appropriate to the intended purpose of the system. The storage period should be determined on the business needs and informational value, without exceeding a maximum of 10 fiscal years",
        "title":"Amendment 1772: Article 12 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"f4c8a6b7-7b54-439c-81e4-8b1d10c8bb2a",
        "text":"2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to the intended purpose or reasonably foreseeable use of the system.",
        "title":"Amendment 1773: Article 12 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6646c096-db34-492f-a346-1ced21ffd34c",
        "text":"2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to the intended purpose or reasonably foreseeable use of the system.",
        "title":"Amendment 1774: Article 12 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"b4aa54bf-5b16-4faf-808d-1875d0c47b8c",
        "text":"2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning while the AI system is used within its lifecycle that is appropriate to the intended purpose of the system.",
        "title":"Amendment 1775: Article 12 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2dde06c4-6175-4a1d-9c3b-f041cf694f0e",
        "text":"deleted",
        "title":"Amendment 1776: Article 12 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2d7f39b6-2a0d-4073-ab8c-c16669d53848",
        "text":"3 a. For records constituting trade secrets as defined in Article 2 of Directive (EU) 2016\/943, provider may elect to confidentially provide such trade secrets only to relevant public authorities to the extent necessary for such authorities to perform their obligations hereunder.",
        "title":"Amendment 1777: Article 12 – paragraph 3 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"acc2c9dc-f203-469b-a2a2-c33bee0a5075",
        "text":"deleted",
        "title":"Amendment 1778: Article 12 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"24308310-3318-49df-8248-0a3a52dc9fc3",
        "text":"deleted",
        "title":"Amendment 1779: Article 12 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cb417b96-adfa-41da-9b13-d9a81af753e3",
        "text":"deleted",
        "title":"Amendment 1780: Article 12 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"17a2420f-e096-4272-82f1-141937bfb51d",
        "text":"4. For high-risk AI systems referred to in Annex III, the logging capabilities shall provide, at a minimum:",
        "title":"Amendment 1781: Article 12 – paragraph 4 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3dec6b6e-eed0-4886-9b39-8fa1590a7414",
        "text":"(a) recording of the period of each use of the system;",
        "title":"Amendment 1782: Article 12 – paragraph 4 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"5a6679aa-6138-48a2-a5f9-1cbcaf465c80",
        "text":"deleted",
        "title":"Amendment 1783: Article 12 – paragraph 4 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"c3ef50bf-93d1-4b38-9f02-66d3f1377309",
        "text":"4 a. For high-risk self-learning AI systems the logging of self-learning shall be maintained.The logging shall provide, at a minimum:', '(a) the input data used for self-learning;', '(b) the used algorithms of the input data interpretation;', '(c) the results of self-learning.",
        "title":"Amendment 1784: Article 12 – paragraph 4 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a805efe8-d83f-4acf-a4b0-d3012115aac4",
        "text":"4 b. Where a decision and\/or proposal of decision is the outcome of an AI system, the logging shall cover information comprehensively sufficient for further human manual review of the decision\/proposal with no need to refer to the AI system itself.The logging shall provide, at a minimum:', '(a) the input data;', '(b)the reference database, if such present;', '(c) the algorithms that could had been used;', '(d) the algorithms that actually had been used;', '(e) output data (decision and\/or proposal);', '(f) comprehensive mechanism of how the input data resulted into the output data.",
        "title":"Amendment 1785: Article 12 – paragraph 4 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5d955f28-02dd-4432-9b81-2f1460d3518e",
        "text":"4 c. For all high-risk AI systems, including those mentioned in paragraphs 4–6 above, the logging shall provide, at a minimum:', '(a) log-in information (user, date, time, authentication type);', '(b) the input data;', '(c) the output data.",
        "title":"Amendment 1786: Article 12 – paragraph 4 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e1d1b697-fdf2-48f9-8adb-fc6bc9f785b5",
        "text":"4 d. The Commission is empowered to adopt delegated acts in accordance with Article 73 to define more minimum logging requirements for AI systems or their certain types.",
        "title":"Amendment 1787: Article 12 – paragraph 4 d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f7764fac-d09a-4be9-829c-f7a8ff2b7c49",
        "text":"Transparency and provision of information to deployers and AI subjects",
        "title":"Amendment 1788: Article 13 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6e268846-82e1-404d-bf07-55ee2e5345cd",
        "text":"1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to reasonably understand the system’s functioning. An appropriate type and degree of transparency shall be ensured, depending on the intended purpose of the system, with a view to achieving compliance with the relevant obligations of the user and of the provider set out in Article 16 and Article 29 of this Title. The explanation shall be provided at least in the language of the country where the AI system is deployed.', 'Transparency shall thereby mean that, to the extent that can be reasonably expected and is feasible in technical terms at the time when the AI system is placed on the market, the AI system is interpretable to the provider, in that the provider can understand the rationale of decisions taken by the high risk AI system, while enabling the user to understand and use the AI system appropriately, by generally knowing how the AI system works and what data it processes.",
        "title":"Amendment 1789: Article 13 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1a193b41-2849-453a-8979-13675de017ea",
        "text":"1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system’s output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obligations of the user and of the provider set out in Chapter 3 of this Title. Transparency shall thereby mean that, to the extent that can be reasonably expected and is feasible in technical terms, the AI systems output is interpretable by the user and the user is able to understand the general functionality of the AI system and its use of data.",
        "title":"Amendment 1790: Article 13 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"7686de14-3408-41ce-8814-3cbcd0e86268",
        "text":"1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable deployers to interpret the system’s output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obligations of the deployer and of the provider set out in Chapter 3 of this Title. Where individuals are passively subject to AI systems (AI subjects), information to ensure an appropriate type and degree of transparency shall be made publicly available, with full respect to the privacy, personality, and related rights of subjects.",
        "title":"Amendment 1791: Article 13 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"543324c3-c299-42a8-ad2d-6ae3fd2a244e",
        "text":"2. High-risk AI systems shall be accompanied by comprehensible instructions for use in an appropriate digital format or made otherwise available that include concise, correct and clear information that helps supporting informed decision-making by users and is reasonably relevant, accessible and comprehensible to users.",
        "title":"Amendment 1792: Article 13 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cc821d87-56ed-4b49-b0d9-03a0f0c07e33",
        "text":"2. High-risk AI systems shall be accompanied by instructions for use in an appropriate digital format or otherwise that include concise, complete, correct and clear information that helps supporting informed decision-making by users and is relevant, accessible and comprehensible to users.",
        "title":"Amendment 1793: Article 13 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"1f3bfb82-6506-490a-a0e8-cddd36bafc46",
        "text":"2. High-risk AI systems shall be accompanied by instructions for use in an appropriate digital format or otherwise that include concise, statistically complete, correct and clear information that is relevant, accessible and comprehensible to deployers.",
        "title":"Amendment 1794: Article 13 – paragraph 3 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"60db0bc6-163c-4963-a64c-e80a1afd740a",
        "text":"3. To the extent neccessary to achieve the outcomes referred to in paragraph 1, the information referred to in paragraph 2 shall specify:",
        "title":"Amendment 1795: Article 13 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"67d8084a-4fed-4337-8393-0da36d968de9",
        "text":"(a) the identity and the contact details of the provider, where applicable, of their authorised representative;",
        "title":"Amendment 1796: Article 13 – paragraph 3 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"acebb0a0-a0c4-478b-9ad7-36a2e02d8552",
        "text":"(b) the capabilities and limitations of performance of the high-risk AI system that are relevant to the material risks associated with the intended purpose, including where appropriate:",
        "title":"Amendment 1797: Article 13 – paragraph 3 – point b – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2d423768-93e9-4d66-9091-fff227e9fdc8",
        "text":"(ii) the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity, including an overview of the capabilities and performance metrics of the AI system, and of representative use cases based on the intended purpose;",
        "title":"Amendment 1798: Article 13 – paragraph 3 – point b – point ii  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"524b5ae8-e78d-4f83-bb33-a656c62ff9f5",
        "text":"(ii) the performance metrics and its appropriateness, including the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of performance, robustness and cybersecurity;",
        "title":"Amendment 1799: Article 13 – paragraph 3 – point b – point ii  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"39666b10-e463-4556-aaea-2835a99b6eaf",
        "text":"(ii) the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated before being placed on the market and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity;",
        "title":"Amendment 1800: Article 13 – paragraph 3 – point b – point ii  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c7e8ba59-0cf6-4fb3-9f60-920f9afb40f5",
        "text":"deleted",
        "title":"Amendment 1801: Article 13 – paragraph 3 – point b – point iii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"d8d44973-eb0f-4ab8-bebb-174742e72cd7",
        "text":"(iii) the known or foreseeable circumstances, related to the use of the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, which may lead to risks to the health and safety or fundamental rights, including, where appropriate, illustrative examples of such limitations and of scenarios for which the system should not be used;",
        "title":"Amendment 1802: Article 13 – paragraph 3 – point b – point iii  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"14400cc9-5ff4-4606-8b41-32b61506cf6f",
        "text":"(iii) any known or foreseeable circumstance, related to the use of the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse, which may lead to risks to the health, safety, fundamental rights, the environment, or democracy;",
        "title":"Amendment 1803: Article 13 – paragraph 3 – point b – point iii  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2578ee38-c184-49e6-ab9b-f0736ba33040",
        "text":"(v) relevant information about user actions that may influence system performance, including type or quality of input data, or any other relevant information in terms of the training, validation and testing data sets used, taking into account the intended purpose of the AI system.",
        "title":"Amendment 1804: Article 13 – paragraph 3 – point b – point v  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d7169297-4a1f-4069-9f1d-0ad45eb80235",
        "text":"(v) when appropriate, specifications for the input data, or any other relevant information in terms of the data sets used, including their limitation and assumptions, taking into account the intended purpose, the foreseeable and reasonably foreseeable misuses of the AI system.",
        "title":"Amendment 1805: Article 13 – paragraph 3 – point b – point v  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"68bcf9d1-eb9d-4371-a31d-7e636ca8231c",
        "text":"(d) the human oversight measures referred to in Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the deployers;",
        "title":"Amendment 1806: Article 13 – paragraph 3 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"541247f1-1c36-4a03-8aaf-49fd98be5aad",
        "text":"(e a) a description of the mechanisms included within the AI system that allow users to properly collect, store and interpret the logs in accordance with Art 12(1), where relevant.",
        "title":"Amendment 1807: Article 13 – paragraph 3 – point e a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a177387c-2a9e-481b-ba71-5ed188413517",
        "text":"(e a) a description of the mechanisms included within the AI system that allow users to properly collect, store and interpret the logs in accordance with Article 12(1).",
        "title":"Amendment 1808: Article 13 – paragraph 3 – point e a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"1d00200b-fbcf-4fc4-8b3d-b32065af80e2",
        "text":"(e a) the level of extraction and consumption of natural resources.",
        "title":"Amendment 1809: Article 13 – paragraph 3 – point e a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"eb42b893-4dc3-4c94-932b-48c89d98ab12",
        "text":"Article 13 a', 'Transparency for affectees of AI systems', '1) High-risk AI systems shall be designed, developed and used in such a way that an affectee can obtain an explanation from the developer and user for any decision taken or supported by a high-risk AI system that significantly affects the affectee;', \"2) Providers and users of high-risk AI systems shall provide access to the person of persons designated with the exercise of 'human oversight' as described in Art. 14 to discuss and to clarify the facts, circumstances and reasons having led to the decision by the AI system;\", '3) Providers and users of high-risk AI systems shall provide the affectee with a written statement of the reasons for any decision taken or supported by a high-risk AI system;', '4) Where the affectee is not satisfied with the explanation or the written statement of reasons obtained or consider that the decision referred to in paragraph (1) jeopardizes their health, safety or fundamental rights, the provider or user, as the case may be, shall review that decision, upon reasonable request by the affectee. The provider or user, as the case maybe, shall respond to such request by providing the affectee with a substantiated reply without undue delay and in any event within one week of receipt of the request.",
        "title":"Amendment 1810: Article 13 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"72292641-8d8d-4b27-b049-b9267f59db2d",
        "text":"1. Where proportionate to the risks associated with the high-risk system and where technical safeguards are not sufficient, high-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they allow informed oversight by natural persons during the expected lifetime of the device. Oversight capabilities should be tailored to the AI system’s intended purpose and the context of use and take into account cases where human oversight may compromise the correct and safe functioning of the AI system.",
        "title":"Amendment 1811: Article 14 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7779d932-7476-4d6d-ad67-7076ccd0950b",
        "text":"1. Where proportionate to the risks associated with the high-risk system and where technical safeguards are not sufficient, high-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use.",
        "title":"Amendment 1812: Article 14 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"d754826a-d697-401b-8766-88960790073d",
        "text":"1. High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use, where required by the risk analysis as foreseen in the product legislations listed in Annex II.",
        "title":"Amendment 1813: Article 14 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"41235862-094c-4f55-bddb-bf70e472d688",
        "text":"1. High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use, and to allow for thorough investigation after an incident.",
        "title":"Amendment 1814: Article 14 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9d9bea27-e895-4405-b3a2-75d98f143169",
        "text":"2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, provided that those risks, if they persist notwithstanding the application of other requirements set out in this Chapter, do not result in a requirement for the high-risk AI system to be recalled or withdrawn.",
        "title":"Amendment 1815: Article 14 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"404d5cd3-7334-4c45-bc44-14e4b173769a",
        "text":"2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when AI systems that pose risks to health and safety or fundamental rights or AI systems subjected to the transparency obligations ex Article 52 are used in accordance with their foreseeable uses or under conditions of reasonably foreseeable misuse, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.",
        "title":"Amendment 1816: Article 14 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst, Kateřina Konečná"
    },
    {
        "uuid":"d6edffee-8613-4a54-88ca-8902dc43fb55",
        "text":"2. Human oversight shall aim at preventing or minimising the risks to health, safety, fundamental rights, democracy, or the environment that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.",
        "title":"Amendment 1817: Article 14 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a6bb68f3-f643-4faf-8b0e-2fde88c7c61a",
        "text":"2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.",
        "title":"Amendment 1818: Article 14 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"77d35975-f82e-4a68-92e1-62bb0646b215",
        "text":"3. The degree of human oversight shall be adapted to the specific risks, the level of automation, and context of the AI system and shall be ensured through either one or all of the following types of measures:",
        "title":"Amendment 1819: Article 14 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a32d30ac-4edd-4fc3-ad06-67f322342ec6",
        "text":"3. The degree of human oversight shall be adapted to the specific risks, the level of automation, and context of the AI system and shall be ensured through either one or all of the following measures:",
        "title":"Amendment 1820: Article 14 – paragraph 3 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"4137f5fe-ab9b-4c8e-b678-8bc7b40bb7c3",
        "text":"3. Human oversight shall be ensured through either one or both of the following:",
        "title":"Amendment 1821: Article 14 – paragraph 3 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"20e4ef9e-b5b7-4f7a-bbab-ef416affb4bc",
        "text":"(a) measures identified by the provider building human oversight, when technically feasible, into the high-risk AI system before it is placed on the market or put into service;",
        "title":"Amendment 1822: Article 14 – paragraph 3 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"81ee6c91-72c3-46aa-aab3-9c015f511f38",
        "text":"(a) identified and built, when technically feasible and appropriate, into the high-risk AI system by the provider before it is placed on the market or put into service;",
        "title":"Amendment 1823: Article 14 – paragraph 3 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e97d292f-e75f-4411-93ff-6d96f77ed3bb",
        "text":"(b) other measures identified by the provider before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the deployer, such as user guides.",
        "title":"Amendment 1824: Article 14 – paragraph 3 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b7abb88c-4ad6-44a1-afa1-3e7fbd11d79d",
        "text":"(b) identified by the provider operationalized before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the user;",
        "title":"Amendment 1825: Article 14 – paragraph 3 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ae752b7c-9f8f-465d-ab3b-83b89d775f30",
        "text":"(b a) required of the user, if appropriate, for their implementation;",
        "title":"Amendment 1826: Article 14 – paragraph 3 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9b199872-4b11-429e-8e29-4354cf357d72",
        "text":"(b b) included during the development, testing, or monitoring processes.",
        "title":"Amendment 1827: Article 14 – paragraph 3 – point b b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"39e88a3b-6193-4ac0-9f24-345cbcc642ea",
        "text":"3 a. The commission, in accordance with the relevant stakeholders, shall provide comprehensive guidelines, in order to clarify the required form of human supervision for high-risk AI systems.",
        "title":"Amendment 1828: Article 14 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"d42fd2c5-a8bb-46ca-a518-e5b1b723abbd",
        "text":"4. For the purpose of implementing paragraphs 1 to 3, the high-risk AI system shall be provided to the user in such a way that natural persons to whom human oversight is assigned can do the following, as appropriate and proportionate to the circumstances and instructions for use and in accordance with industry standards:",
        "title":"Amendment 1829: Article 14 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4e441929-b843-4834-a505-3c7f3a56c02f",
        "text":"4. For the purpose of implementing paragraphs 1 to 3, the high-risk AI system shall be provided to the user in such a way that the individuals to whom human oversight is assigned are enabled as appropriate and proportionate, to the circumstances and in accordance with industry standards:",
        "title":"Amendment 1830: Article 14 – paragraph 4 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"65796455-af77-473f-bf4a-cd400a0c8b67",
        "text":"(a) to be aware and sufficiently understand the relevant capacities and limitations of the high-risk AI system and be able to duly monitor its operation, so that signs of anomalies, dysfunctions and unexpected performance can be detected and addressed as soon as possible;",
        "title":"Amendment 1831: Article 14 – paragraph 4 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4f716a23-2ff1-4317-9e58-450d40582eff",
        "text":"(a) to be aware of and sufficiently understand the capacities and limitations of the high-risk AI system and be able to duly monitor its operation, so that signs of anomalies, dysfunctions and unexpected performance can be detected and addressed as soon as possible;",
        "title":"Amendment 1832: Article 14 – paragraph 4 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"bb82684e-2f90-4174-81c2-8a2c09ddf3de",
        "text":"(b) remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’);",
        "title":"Amendment 1833: Article 14 – paragraph 4 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"fc257d26-12f3-4916-bb37-8deb9c596200",
        "text":"(b) remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’);",
        "title":"Amendment 1834: Article 14 – paragraph 4 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1adf021c-5800-4cef-a43a-f3d95827d94d",
        "text":"(b) mitigate the risk of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’), in particular for high-risk AI systems used to provide information or recommendations for decisions to be taken by natural persons;",
        "title":"Amendment 1835: Article 14 – paragraph 4 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ca523fbd-3e1e-4bd4-861c-b17a85080faa",
        "text":"(c) to correctly interpret the high-risk AI system’s output, taking into account for example the interpretation tools and methods available;",
        "title":"Amendment 1836: Article 14 – paragraph 4 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"5fafb591-a5d6-4c83-94a8-6d3fc9b215fa",
        "text":"(c) be able to correctly interpret the high-risk AI system’s output, taking into account, for example, the interpretation tools and methods available;",
        "title":"Amendment 1837: Article 14 – paragraph 4 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5773b93c-d69e-4822-8e8d-c8f6186c2176",
        "text":"(d) to be able to decide, in any particular situation, not to use the high-risk AI system or otherwise disregard, override or reverse the output of the high-risk AI system;",
        "title":"Amendment 1838: Article 14 – paragraph 4 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"15ed2e68-088e-4a13-a94a-2fdc6ad5b440",
        "text":"(d) be free to decide, in any particular situation, not to use the high-risk AI system or otherwise disregard, override or reverse the output of the high-risk AI system;",
        "title":"Amendment 1839: Article 14 – paragraph 4 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e70bf324-a232-4ed0-aeb6-3ed5c6f8b7d2",
        "text":"(e) be able to intervene on the operation of the high-risk AI system or interrupt, where reasonable and technically feasible, the system through a “stop” button or a similar procedure, except if the human interference increases the risk or would negatively impact the performance in consideration of generally acknowledge state-of-the-art.",
        "title":"Amendment 1840: Article 14 – paragraph 4 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c4c34076-0b1c-44ab-be46-e61c37e27e11",
        "text":"(e) to be able to intervene on the operation of the high-risk AI system, halt or interrupt the system where reasonable and technically feasible and except if the human interference increases the risks or would negatively impact the performance in consideration of generally acknowledged state-of-the-art.",
        "title":"Amendment 1841: Article 14 – paragraph 4 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"2b441986-d11a-4a90-bea2-58a2e88aa639",
        "text":"(e) be able to intervene in the operation of the high-risk AI system or interrupt the system through a “stop” button or a similar procedure that allows the system to come to a halt in a safe state.",
        "title":"Amendment 1842: Article 14 – paragraph 4 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"256201aa-c232-44d0-9faf-a15c878c7854",
        "text":"5. For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the user on the basis of the identification resulting from the system unless this has been separately verified and confirmed by at least two natural persons on-site or remotely, except for temporary actions or decisions which cannot be delayed due to safety or security reasons for the purpose of law enforcement.",
        "title":"Amendment 1843: Article 14 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1bf546c5-8e13-4a73-a010-62dfdc260be6",
        "text":"5. For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the user on the basis of the identification resulting from the system unless this has been verified and confirmed by at least two natural persons separately.",
        "title":"Amendment 1844: Article 14 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"b847edf0-cfc6-47d3-86b9-0dfc8da7853d",
        "text":"5. For high-risk AI systems referred to in point 1(a) and 1(b) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the deployer on the basis of the output from the system unless this has been verified and confirmed by at least two natural persons.",
        "title":"Amendment 1845: Article 14 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5c271c70-932c-4aeb-9bc1-ecb162b6b649",
        "text":"5 a. For the purpose of implementing paragraph 2, in the case where the result of an identification is inconclusive, the human oversight requirements from paragraphs 3 to 5 shall be performed directly internally by the closest entity to the user in the supply chain of the high-risk AI system.",
        "title":"Amendment 1846: Article 14 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"88b0c513-6b10-4c08-9292-a719f31b731a",
        "text":"5 b. With the exception of high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall not be interpreted as requiring a human to review every action or decision taken by the AI system. Full automation of such systems shall be possible provided that technical measures are put in place to comply with provisions in paragraphs 1 to 4.",
        "title":"Amendment 1847: Article 14 – paragraph 5 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f0690fca-00b2-4709-bf8e-fd3ee3383d7b",
        "text":"1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose and to the extent that can be reasonably expected and is in accordance with relevant industry standards, an appropriate level of accuracy, reliability, robustness and cybersecurity, and the basic pillars of information security and protection, such as confidentiality, integrity and availability as well as to perform consistently in those respects throughout their lifetime while taking their evolving nature into account.",
        "title":"Amendment 1848: Article 15 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a1d341af-5d26-49ad-8dac-b413b6253158",
        "text":"1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose, the foreseeable uses and reasonably foreseeable misuses, an appropriate level of perfomance (such as accuracy, reliability and true positive rate), robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.",
        "title":"Amendment 1849: Article 15 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"0e7304ba-0929-47e6-99be-9c223c84d25c",
        "text":"1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose and to the extent that can be reasonably expected and is in accordance with relevant industry standards, an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.",
        "title":"Amendment 1850: Article 15 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"68ee7661-b549-4426-a054-aadceab4db2c",
        "text":"1. High-risk AI systems shall be designed and developed in such a way that they achieve security by design and by default, in the light of their intended purpose, an appropriate level of accuracy, reliability, robustness, resilience, safety and cybersecurity throughout their lifecycle.",
        "title":"Amendment 1851: Article 15 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5c662d40-7f0a-46bb-a40a-9395f8e56aea",
        "text":"1 a. To address the technical aspects of how to measure the appropriate levels of accuracy and robustness in paragraph 1, the European Artificial Intelligence Board shall bring together national metrology and benchmarking authorities and provide non-binding guidance on the matter as per Article 56(2a) of this Regulation.",
        "title":"Amendment 1852: Article 15 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3a7e5e3e-cc41-41fc-a8c2-5fe2ec2034e2",
        "text":"2. The levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be assessed by an independent entity and declared in the accompanying instructions of use. The language used shall be clear, free of misunderstandings or misleading statements.",
        "title":"Amendment 1853: Article 15 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7f5bcdb1-1a6d-45f6-ba10-b2aa2557e7df",
        "text":"2. The perfomance metrics and its appropriateness, including the levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be declared in the accompanying instructions of use.",
        "title":"Amendment 1854: Article 15 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"cd0f8955-8750-44ba-951c-7f000ae35541",
        "text":"2. The range of expected performance and the operational factors that affect that performance, shall be declared, where possible, in the accompanying instructions of use.",
        "title":"Amendment 1855: Article 15 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e0a3df4d-1e44-4d0a-b936-2025fc66073f",
        "text":"2. The range of expected performance and the operational factors that affect that performance shall be declared in the accompanying instructions of use.",
        "title":"Amendment 1856: Article 15 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"c87859fa-ad1e-4bfc-9f66-f08269287bf6",
        "text":"3. High-risk AI systems shall be designed and developed with safety and security by design mechanism by default so that they achieve, in the light of their intended purpose, an appropriate level of cyber resilience as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.",
        "title":"Amendment 1857: Article 15 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"342e1a08-9a58-4f66-8d4d-5c856ce6c4dd",
        "text":"3. High-risk AI systems shall be designed and developed with safety and security-by-design mechanism so that they achieve, in the light of their intended purpose, an appropriate level of cyber resilience as regards to errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.",
        "title":"Amendment 1858: Article 15 – paragraph 3 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"38ab9e73-2f8e-42d9-b65f-1ddece816669",
        "text":"3. High-risk AI systems shall be robust as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.",
        "title":"Amendment 1859: Article 15 – paragraph 3 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7d206c17-fc44-48bc-9219-15c18d337630",
        "text":"The robustness of high-risk AI systems may be achieved through diverse technical redundancy solutions, which may include reasonably designed backup or fail-safe plans by the appropriate provider or user or as mutually agreed by the provider and the user.",
        "title":"Amendment 1860: Article 15 – paragraph 3 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"59e4dd3a-932d-4dc7-a92d-55130234f8d5",
        "text":"High-risk AI systems that continue to learn after being put into service shall ensure that 'feedback loops' caused by biased outputs are adequately addressed with appropriate mitigation measures.",
        "title":"Amendment 1861: Article 15 – paragraph 3 – subparagraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9febfb6a-ca6e-4163-bf15-0307933e8802",
        "text":"High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs influencing an input for future operations (‘feedback loops’) are duly addressed with appropriate mitigation measures.",
        "title":"Amendment 1862: Article 15 – paragraph 3 – subparagraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5fd1cdb6-9e73-47c8-ab49-f3d189278d23",
        "text":"High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs influencing input for future operations (‘feedback loops’) are duly addressed with appropriate mitigation measures.",
        "title":"Amendment 1863: Article 15 – paragraph 3 – subparagraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"e48cc4b5-25c6-474f-bd42-cc51992f5234",
        "text":"It shall be possible for the user, the provider, the national competent authority or authorities and the Commission, as appropriate, to audit and reproduce the functioning of the high-risk AI systems.",
        "title":"Amendment 1864: Article 15 – paragraph 3 – subparagraph 2 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"61497ffa-0542-491e-9c14-007437a2e369",
        "text":"3 a. In accordance with Article 42 (2), the compliance with Article 15 for high-risk AI systems that have already been certified or for which a statement of conformity has been issued under a cybersecurity scheme pursuant to Regulation (EU) 2019\/881 shall be assumed.",
        "title":"Amendment 1865: Article 15 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"721819a7-d122-4fdc-b517-aeb785f3a9a2",
        "text":"4. High-risk AI systems shall be adequately protected against attempts by unauthorised third parties to alter their use or performance.",
        "title":"Amendment 1866: Article 15 – paragraph 4 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"34349fd8-3d9a-432a-bcfe-f825afc1dbd5",
        "text":"The technical solutions aimed at ensuring and organisational measures designed to uphold the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.",
        "title":"Amendment 1867: Article 15 – paragraph 4 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"1bd916e5-1621-4402-b55e-c25679cd95d4",
        "text":"The technical solutions and organisational measures designed to uphold the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.",
        "title":"Amendment 1868: Article 15 – paragraph 4 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"923c107c-6d62-458c-90df-1a979be6659b",
        "text":"The technical and orgaisational measures aimed at ensuring the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.",
        "title":"Amendment 1869: Article 15 – paragraph 4 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1ab911ee-3ffb-413f-9dd8-8295431067c6",
        "text":"The technical solutions may include, where appropriate, measures to prevent and control for attacks trying to manipulate the training dataset (‘data poisoning’), inputs designed to cause the model to make a mistake (‘adversarial examples’), or model flaws, or exploratory attacks that may aim to extract knowledge, algorithms, trade secrets or training information from the AI.",
        "title":"Amendment 1870: Article 15 – paragraph 4 – subparagraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c456dfa8-0fbc-4b41-9aa3-9e265ab2174d",
        "text":"The technical and orgaisational measures to address AI specific vulnerabilities shall include at least, where appropriate, measures to prevent and control attacks trying to manipulate the training dataset (‘data poisoning’), inputs designed to cause the model to make a mistake (‘adversarial examples’), or model flaws.",
        "title":"Amendment 1871: Article 15 – paragraph 4 – subparagraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f9e01a84-fa34-47ef-b082-984ea738969a",
        "text":"4 a. High risk AI shall be accompanied by security solutions and patches for the lifetime of the product it is embedded in, or in case of the absence of dependence on a specific product, for a time that needs to be stated by the manufacturer and cannot be less then 10 years.",
        "title":"Amendment 1872: Article 15 – paragraph 4 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"549cdd38-2a7f-41e1-a9af-8452f0cfecd3",
        "text":"Article 15 a', 'Sustainable AI systems reporting', '1. Providers of high-risk AI systems shall make publicly available information on the energy consumption of the AI system, in particular its carbon footprint with regard to the development of hardware, computational resources, as well as algorithm design and training, testing and validating processes of the high-risk AI systems. The provider shall include this information in the technical documentation referred to in Article 11.', '2. The Commission shall develop, by means of an implementing act, a standardised document to facilitate the disclosure of information on the energy used in the training and execution of AI systems and their carbon intensity.",
        "title":"Amendment 1873: Article 15 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"1aa51483-bf80-4464-8073-29dd0165d89d",
        "text":"3 OBLIGATIONS OF PROVIDERS AND DEPLOYERS OF HIGH-RISK AI SYSTEMS and other parties",
        "title":"Amendment 1874: Title III – Chapter 3 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e27efb66-1251-4361-a3d8-e14b03d74008",
        "text":"Obligations of providers and deployers of high-risk AI systems",
        "title":"Amendment 1875: Article 16 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"62f9a4da-cca9-4939-856a-3732df21a99a",
        "text":"As long as providers of high-risk AI systems exercise full control over the systems, they shall:",
        "title":"Amendment 1876: Article 16 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"678b533a-798c-415f-a6a2-842ad1e96ce3",
        "text":"Providers and, where applicable, deployers of high-risk AI systems shall:",
        "title":"Amendment 1877: Article 16 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2aaaa3de-3157-45be-acc4-8e9552f4fc12",
        "text":"(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title before placing them on the market or putting them into service, and shall be responsible for compliance of these systems after that point only to the extent that they exercise actual control over relevant aspects of the system;",
        "title":"Amendment 1878: Article 16 – paragraph 1 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"39038ca3-9eb4-4eb5-b236-f536f39ac439",
        "text":"(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title before placing them on the market or putting them into service;",
        "title":"Amendment 1879: Article 16 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ffdff4a2-40e6-4592-982f-9f2cd04f5bb8",
        "text":"(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title as long as the provider exercise control over the AI systems;",
        "title":"Amendment 1880: Article 16 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"1b8b3025-65c6-4000-a4d3-84ea306ed8f1",
        "text":"(a a) indicate their name, registered trade name or registered trade mark, the address at which they can be contacted on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as applicable;",
        "title":"Amendment 1881: Article 16 – paragraph 1 – point a a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6598ee02-f550-4d26-bee8-3b12226415b5",
        "text":"(a a) indicate their name, registered trade name or registered trade mark, and their address on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as appropriate;",
        "title":"Amendment 1882: Article 16 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2e8a0cfa-1088-4b5a-b4ff-00daab8c14ea",
        "text":"(a a) ensure that the performance of their high-risk AI system is measured appropriately, including its level of accuracy, robustness and cybersecurity;",
        "title":"Amendment 1883: Article 16 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0a60f04b-43d9-490a-9087-d1d0b2f6e510",
        "text":"(a a) ensure that, in the case of a general purpose AI system, the reasonably foreseeable uses of this system are assessed.",
        "title":"Amendment 1884: Article 16 – paragraph 1 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"7f7953b1-2fd7-4d5d-8cae-6e2a738bafa1",
        "text":"(a a) include name and contact information;",
        "title":"Amendment 1885: Article 16 – paragraph 1 – point a a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4ea06374-aa5c-42da-9b3c-12e6284b83d7",
        "text":"(a b) provide specifications for the input data, or any other relevant information in terms of the data sets used, including their limitation and assumptions, taking into account of the intended purpose and the foreseeable and reasonably foreseeable misuses of the AI system;",
        "title":"Amendment 1886: Article 16 – paragraph 1 – point a b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"606e01b9-dc3f-4d71-aa7c-1b6226b1d95d",
        "text":"(c) draw-up the technical documentation of the high-risk AI system referred to in Article 18;",
        "title":"Amendment 1887: Article 16 – paragraph 1 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"f41f563d-7d09-41b0-aa4f-8f97972ea844",
        "text":"(c) keep the documentation referred to in Article 18;",
        "title":"Amendment 1888: Article 16 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e3663716-fbb8-4c6d-aac4-892ec6f3831f",
        "text":"(d) when under their control, keep the logs automatically generated by their high-risk AI systems for a period of at least two years, or as long as is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law;",
        "title":"Amendment 1889: Article 16 – paragraph 1 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ee00363f-34da-4c9a-9680-198a8c2ee757",
        "text":"(d) when under their control, keep the logs automatically generated by their high-risk AI systems, in accordance with Article 20;",
        "title":"Amendment 1890: Article 16 – paragraph 1 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a87cc7fc-1a25-46ff-9420-201f9bac2c70",
        "text":"(d) keep the logs automatically generated by their high-risk AI systems as referred to in Article 20;",
        "title":"Amendment 1891: Article 16 – paragraph 1 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"e3f2c7e4-3bc5-461e-a31a-6e93e1f97d80",
        "text":"(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure prior to its placing on the market or putting into service, and ensure it is periodically reviewed;",
        "title":"Amendment 1892: Article 16 – paragraph 1 – point e  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"cd649cfa-f8af-41c9-bc8e-1130f2b4a6f5",
        "text":"(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure as referred to in Article 43, prior to its placing on the market or putting into service;",
        "title":"Amendment 1893: Article 16 – paragraph 1 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"6309a613-3e79-470d-ab0c-c18e581019a5",
        "text":"(e) ensure that the high-risk AI system undergoes the relevant independent third party assessment procedure, prior to its placing on the market or putting into service;",
        "title":"Amendment 1894: Article 16 – paragraph 1 – point e  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a71aef52-8b7b-4cf4-b3a2-72b8d27a122d",
        "text":"(e) ensure that the high-risk AI system undergoes the relevant third party conformity assessment procedure, prior to its placing on the market or putting into service;",
        "title":"Amendment 1895: Article 16 – paragraph 1 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7d2b93e5-58ef-4f13-a15a-06526eab20d7",
        "text":"(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure, prior to its placing on the market or putting into service or use;",
        "title":"Amendment 1896: Article 16 – paragraph 1 – point e  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f8cdaf03-c547-4457-9258-a12d57c13c26",
        "text":"(e) carry out the relevant conformity assessment procedure, as provided for in Article 19, prior to its placing on the market or putting into service;",
        "title":"Amendment 1897: Article 16 – paragraph 1 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f01f9da7-4c3f-48f6-a006-1b4d2832fad2",
        "text":"(g) take the necessary corrective action, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, before the high-risk AI system concerned is placed on the market, made available on the market or put into service, or before a high-risk AI system that has been withdrawn or recalled is placed on the market, made available on the market or put into service once again;",
        "title":"Amendment 1898: Article 16 – paragraph 1 – point g  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"74c40fa5-a714-42a5-8b88-e65b3aee2567",
        "text":"(g) take the necessary corrective actions as referred to in Article 21, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title;",
        "title":"Amendment 1899: Article 16 – paragraph 1 – point g  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"48aed0a6-121f-47c0-8988-c089bdeac384",
        "text":"(g) take the necessary corrective actions as referred to in Art 21, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title;",
        "title":"Amendment 1900: Article 16 – paragraph 1 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0538070a-0951-41e8-8259-12b152214a9e",
        "text":"(i) affix the CE marking to their high-risk AI systems to indicate the conformity with this Regulation in accordance with Article 49;",
        "title":"Amendment 1901: Article 16 – paragraph 1 – point i  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7e5d842d-247e-4079-a632-1504bf8ac51f",
        "text":"(j) upon reasoned request of a national competent authority, provide the relevant information and documentation to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title.",
        "title":"Amendment 1902: Article 16 – paragraph 1 – point j  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"680c3695-2380-49b8-89da-568a83e91973",
        "text":"(j) upon request of a national supervisory authority or a national competent authority, demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title.",
        "title":"Amendment 1903: Article 16 – paragraph 1 – point j  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"30dabe57-35cb-4498-85a1-4589f694dd61",
        "text":"(j) upon reasoned request of a national competent authority, provide the relevant information and documentation to demonstrate the conformity of the high-risk AI system.",
        "title":"Amendment 1904: Article 16 – paragraph 1 – point j  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e0baacda-857b-4410-896d-7a27f3e798cd",
        "text":"(j a) refrain from placing on the market or putting into service a High-Risk AI system that:', '(i) is not in conformity with the requirements set out in Chapter 2 of this Title;or', '(ii) poses a risk of harm to health, safety or fundamental rights despite its conformity with the requirements set out in Chapter 2 of this Title.",
        "title":"Amendment 1905: Article 16 – paragraph 1 – point j a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7589f92a-bfab-4aaf-a48b-28cf142e6c78",
        "text":"(j a) conduct and publish a fundamental rights impact assessment.",
        "title":"Amendment 1906: Article 16 – paragraph 1 – point j a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"61a9df22-6cbd-439e-bad6-2fb976696940",
        "text":"(j b) ensure that the individual to whom human oversight is assigned shall either be fully independent from the provider or user or, be adequately protected against negative consequences for their position within the organisation, resulting from or related to their exercise of human oversight.",
        "title":"Amendment 1907: Article 16 – paragraph 1 – point j b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"25068a02-6ed5-496b-961f-a3d159175ee3",
        "text":"The obligations contained in paragraph 1 shall be without prejudice to obligations applicable to providers of high-risk AI systems arising from Regulation (EU) 2016\/679 of the European Parliament and of the Council and Regulation (EU) 2018\/1725 of the European Parliament and of the Council",
        "title":"Amendment 1908: Article 16 – paragraph 1 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"635f3c8e-4f58-4a74-80f1-1789116024fe",
        "text":"Article 16 a', 'Obligations of users of high-risk AI systems', 'Users of high-risk AI systems shall conduct and publish a fundamental rights impact assessment, detailing specific information relating to the context of use of the high-risk AI system in question, including:', '(a) the affected persons,', '(b) intended purpose,', '(c) geographic and temporal scope,', '(d) assessment of the legality and fundamental rights impacts of the system,', '(e) compatibility with accessibility legislation,', '(f) potential direct and indirect impact on fundamental rights,', '(g) any specific risk of harm likely to impact marginalised persons or those at risk of discrimination,', '(h) the foreseeable impact of the use of the system on the environment,', '(i) any other negative impact on the public interest,', '(j) clear steps as to how the harms identified will be mitigated and how effective this mitigation is likely to be.",
        "title":"Amendment 1909: Article 17 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"edad0468-01c4-4369-9536-bcda6b2337f0",
        "text":"1. Unless existing risk management systems are already in place to warrant the quality of the high-risk AI systems, providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:",
        "title":"Amendment 1910: Article 17 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"2db41e22-8443-4d55-9695-fb35fb0d69d5",
        "text":"1. In case there are no risk management systems already in place, providers and users of high-risk AI systems shall implement a quality management system to ensure compliance with this Regulation and corresponding obligations. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:",
        "title":"Amendment 1911: Article 17 – paragraph 1 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"07770654-7bc8-4275-8f3f-41302f2dcfee",
        "text":"1. Providers and, where applicable, deployers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:",
        "title":"Amendment 1912: Article 17 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9c45e3f5-e1f9-42b8-85b5-9dbc91109c4a",
        "text":"1. Providers of high-risk AI systems shall put a quality management system in place, certified by an independent third party that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:",
        "title":"Amendment 1913: Article 17 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"794250c0-4273-49d9-a170-779e43ee95e7",
        "text":"1. Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures or instructions, and shall include at least the following aspects:",
        "title":"Amendment 1914: Article 17 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"25c1cff5-a926-4caa-bb11-7657321cab63",
        "text":"1. Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation and that shall be incorporated as part of an existing quality management system under sectoral legislation or as provided by the International Organisation for Standardization.",
        "title":"Amendment 1915: Article 17 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d05b6ba2-47ad-468c-af43-22e2491629f8",
        "text":"deleted",
        "title":"Amendment 1916: Article 17 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"7dabda57-ba31-42da-a532-79390a083d3d",
        "text":"deleted",
        "title":"Amendment 1917: Article 17 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6c8494d0-6381-47fb-95c9-9bd194d6d3e5",
        "text":"deleted",
        "title":"Amendment 1918: Article 17 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1996079e-6370-4def-a644-4a8ba67e3047",
        "text":"deleted",
        "title":"Amendment 1919: Article 17 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c38ca843-3827-4ab4-9893-427d6ad95459",
        "text":"deleted",
        "title":"Amendment 1920: Article 17 – paragraph 1 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1ee41be0-f0ae-4341-89ab-62fc0083e817",
        "text":"deleted",
        "title":"Amendment 1921: Article 17 – paragraph 1 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"2e796f30-03a9-4116-b923-ca3a2aa022c2",
        "text":"deleted",
        "title":"Amendment 1922: Article 17 – paragraph 1 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9671795b-0310-413e-a072-57fcb3143b25",
        "text":"(e) technical specifications, including standards, to be applied and, where the relevant harmonised standards are not applied in full, or do not cover all of the relevant requirements, the means to be used to ensure that the high-risk AI system complies with the requirements set out in Chapter 2 of this Title;",
        "title":"Amendment 1923: Article 17 – paragraph 1 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7f974e80-1b0a-4a5e-8d4c-dfd5e4c3777c",
        "text":"deleted",
        "title":"Amendment 1924: Article 17 – paragraph 1 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f3052ce2-fcc6-41a9-bb37-a376a43345d9",
        "text":"(f) systems and procedures for data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for the purposes of the placing on the market, putting into service, and deployment of high-risk AI systems;",
        "title":"Amendment 1925: Article 17 – paragraph 1 – point f  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"67af6a76-fa5a-4546-8de8-262d1413bc32",
        "text":"(f) systems and procedures for data management, including data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before for the purposes of the placing on the market or putting into service of high-risk AI systems, and after deployment of the high-risk AI;",
        "title":"Amendment 1926: Article 17 – paragraph 1 – point f  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"398058c8-454c-466a-aa99-f3a50940dc82",
        "text":"(f) systems and procedures for data management, including data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for the purposes of the placing on the market or putting into service or use of high-risk AI systems;",
        "title":"Amendment 1927: Article 17 – paragraph 1 – point f  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2d147a34-fa42-4848-b94b-d0d961e6d225",
        "text":"deleted",
        "title":"Amendment 1928: Article 17 – paragraph 1 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"df5333a7-322d-4d67-9252-303bcfb3f51e",
        "text":"deleted",
        "title":"Amendment 1929: Article 17 – paragraph 1 – point h  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"01cd2c94-6e9c-4bd1-9128-b85260f54ecf",
        "text":"deleted",
        "title":"Amendment 1930: Article 17 – paragraph 1 – point i  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f020b2bb-52c1-4684-af50-2bb9d1e07254",
        "text":"(i) procedures related to the reporting of serious incidents and of malfunctioning, including near misses, in accordance with Article 62;",
        "title":"Amendment 1931: Article 17 – paragraph 1 – point i  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2ef7e9fa-67d9-486e-85bf-eb1a10563c86",
        "text":"(i) procedures related to the reporting of serious incidents and of malfunctioning, including near misses, in accordance with Article 62;",
        "title":"Amendment 1932: Article 17 – paragraph 1 – point j  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"b7e3302a-d2d3-489b-a45d-ea796b336b20",
        "text":"deleted",
        "title":"Amendment 1933: Article 17 – paragraph 1 – point j  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4e339f59-e263-4fb7-b469-928d18a13bb1",
        "text":"(j) the handling of communication with national competent authorities, competent authorities, including sectoral ones;",
        "title":"Amendment 1934: Article 17 – paragraph 1 – point j  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"ecaef7e6-58b7-42f5-bf36-8c303ca028f2",
        "text":"deleted",
        "title":"Amendment 1935: Article 17 – paragraph 1 – point k  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"6436e39c-fe94-4790-9ccb-01a4456b5b31",
        "text":"deleted",
        "title":"Amendment 1936: Article 17 – paragraph 1 – point k  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9e890ec3-660b-49ec-98a7-8ea2cf5efdcf",
        "text":"deleted",
        "title":"Amendment 1937: Article 17 – paragraph 1 – point l  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5016ab19-0bdc-4b08-b2e1-340361175304",
        "text":"deleted",
        "title":"Amendment 1938: Article 17 – paragraph 1 – point m  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"29c919a1-0f8e-4a46-b7b6-a3fafa13d22c",
        "text":"deleted",
        "title":"Amendment 1939: Article 17 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"621e393f-2b46-4380-8cf4-7a1883a281d0",
        "text":"2. The implementation of aspects referred to in paragraph 1 shall be proportionate to the size of the provider’s organisation and can be fulfilled by further elaborating existing quality management systems.",
        "title":"Amendment 1940: Article 17 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"63f28bf7-848c-4b2d-845f-c52a8fca8206",
        "text":"2. The implementation of aspects referred to in paragraph 1 shall be proportionate to the size of the provider’s and user's organisation.",
        "title":"Amendment 1941: Article 17 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"3961d276-438f-4ad8-beaf-093c2b7f98eb",
        "text":"3. This Article applies without prejudice to the obligations for providers that are credit institutions regulated by Directive 2013\/36\/ EU.",
        "title":"Amendment 1942: Article 17 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f669fc36-e108-45b0-9e9f-612a48636c36",
        "text":"3 a. High-risk AI systems shall make use of high quality models, that use relevant, justified and reasonable parameters and features and optimise for justified goals;",
        "title":"Amendment 1943: Article 17 – paragraph 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f5f63b39-6f3b-49a0-9c4f-85869c11f41d",
        "text":"3 b. High-risk AI systems shall only be used in a different domain or environment where they are generalisable to such domain or environment",
        "title":"Amendment 1944: Article 17 – paragraph 3 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"01ddad5f-439c-4dcd-bf62-aa2beb087b3c",
        "text":"deleted",
        "title":"Amendment 1945: Article 18  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2293a3e5-a160-4400-bbb5-a8c5e2f01eae",
        "text":"1. The provider shall, for a period of 3 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:', '(a) the technical documentation referred to in Article 11 and Annex IV;', '(b) the documentation concerning the quality management system referred to in Article 17;', '(c) the documentation concerning the changes approved by notified bodies where applicable;', '(d) the decisions and other documents issued by the notified bodies where applicable;', '(e) the EU declaration of conformity referred to in Article 48.",
        "title":"Amendment 1946: Article 18 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"46e8670a-f88b-4f10-98e9-62d1a5685b8f",
        "text":"1. Providers of high-risk AI systems shall draw up the technical documentation referred to in Article 11 in accordance with Annex IV. When applicable, the technical documentation shall be treated as containing trade secrets as regulated by Directive (EU) 2016\/943.",
        "title":"Amendment 1947: Article 18 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"c9988367-ec13-4880-9cbe-8655f11ea596",
        "text":"1. Providers of high-risk AI systems shall draw up the technical documen\\xadtation referred to in Article 11 in accordance with Annex IV and make it available at the request of a national competent authority.",
        "title":"Amendment 1948: Article 18 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d2b39928-287b-4006-bee6-dd6c8af4b5fc",
        "text":"Independent Third party Conformity assessment",
        "title":"Amendment 1949: Article 19 – title  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ec17317e-260b-46b7-8e45-1305648347ef",
        "text":"1. Providers of high-risk AI systems shall ensure that their systems undergo an independent third party conformity assessment procedure in accordance with Article 43 and Annex VII, prior to their placing on the market or putting into service. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49. The conformity assessment shall be publicly available.",
        "title":"Amendment 1950: Article 19 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2dcb335e-3c59-4b7c-87ac-42c223263e52",
        "text":"1. Providers of high-risk AI systems shall ensure that their systems undergo the relevant conformity assessment procedure in accordance with Article 43, before they are placed on the market, made available on the market or put into service. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49.",
        "title":"Amendment 1951: Article 19 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c97c6f51-60f1-43f7-b4e0-829bb1b8d70f",
        "text":"1. Providers of high-risk AI systems shall ensure that their systems undergo the relevant conformity assessment procedure in accordance with Article 43, prior to their placing on the market or putting into service or use. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49.",
        "title":"Amendment 1952: Article 19 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ac6275c8-613d-4712-897a-82f4476eb213",
        "text":"1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law. When applicable, the automatically generated logs shall be treated as containing trade secrets as regulated by Directive (EU) 2016\/943.",
        "title":"Amendment 1953: Article 20 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e56956d3-82df-4b40-a88d-7d474f599e2d",
        "text":"1. Providers of high-risk AI systems shall guarantee the storage of the logs automatically generated by their high-risk AI systems, where possible on the media employed by users, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of the high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 1954: Article 20 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"108a0a17-7515-43e8-8924-0e2b058255fb",
        "text":"1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose or reasonably foreseeable use of high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 1955: Article 20 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e768136d-646e-41b6-a453-7e35ac4d8213",
        "text":"1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of industry standards, the intended purpose of high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 1956: Article 20 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"587cc69b-1943-44be-85d8-0574006be673",
        "text":"1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the deployer or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 1957: Article 20 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"150c2d86-e173-4d0f-bfcf-840b7cd2593f",
        "text":"1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by law as well as under their factual control and to the extent that it is technically feasible. They shall keep them for a period of at least six months, unless provided otherwise in applicable Union or national law.",
        "title":"Amendment 1958: Article 20 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a007d043-bc3c-4d0c-a8c5-46a7c01c2b6d",
        "text":"Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately, where applicable, investigate the causes in collaboration with the user and, take the necessary corrective actions to bring that system into conformity, to withdraw it or to recall it, as appropriate. They shall inform the distributors of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.",
        "title":"Amendment 1959: Article 21 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"22dbef38-038a-49dc-a94d-2596578ae555",
        "text":"Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately inform the competent authorities and take the necessary corrective actions to bring that system into conformity, to withdraw it, to disable it, or to recall it, as appropriate. They shall inform the distributors and deployers of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.",
        "title":"Amendment 1960: Article 21 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"24cbb53f-4f98-401e-b56e-282669ecb1eb",
        "text":"Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately take the necessary corrective action to withdraw or recall the system, as appropriate, so as to bring it into conformity. They shall inform the distributors of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.",
        "title":"Amendment 1961: Article 21 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e3908b77-6dfd-4f5f-b3bf-d517c157d02c",
        "text":"In the cases referred to in paragraph 1, providers shall immediately inform the distributors of the high-risk AI system and, where applicable, the legal representative, importers and users accordingly. They shall also immediately inform the national supervisory authority and the national competent authorities of the Member States where they made the AI system available or put it into service, and where applicable, the notified body of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 1962: Article 21 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"823c7b25-499d-4f38-9ce0-c86ed75bca96",
        "text":"Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known by the provider of the system, the provider shall immediately inform the national supervisory authority and the national competent authorities of the Member States in which it made the system available and, where applicable, the user, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken. Where applicable, the provider shall also inform the users of the high-risk AI system.",
        "title":"Amendment 1963: Article 22 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"9d02327c-95c5-4d6f-84cd-8a1e918943d2",
        "text":"Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known to the provider of the system, that provider shall immediately inform the market surveillance authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular the nature of the non-compliance and of any relevant corrective actions taken by the provider.",
        "title":"Amendment 1964: Article 22 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8c47a02d-bf44-46b8-af0d-55870a9f395f",
        "text":"Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known to the provider of the system, that provider shall immediately inform the market surveillance authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 1965: Article 22 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"c5ad43df-fce8-4df3-a488-cf1062257f87",
        "text":"Where the high-risk AI system presents a risk within the meaning of Article 65(1) and the provider of the system becomes aware of that risk, that provider shall immediately inform the competent authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 1966: Article 22 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a321dc26-742a-40ec-b5cd-f9e2f14818db",
        "text":"Cooperation with competent authorities, the AI Office and the Commission",
        "title":"Amendment 1967: Article 23 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"db6915b6-5212-4383-af4c-81a8e0ee5661",
        "text":"Providers of high-risk AI systems shall, upon a reasoned request by a national competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in a language that can be easily understood by that national competent authority. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. Any information submitted in accordance with the provision of this article shall be considered by the national competent authority a trade secret of the company that is submitting such information and kept strictly confidential.",
        "title":"Amendment 1968: Article 23 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"77f0d4ed-90fb-4798-9ece-5eea8b9eb79f",
        "text":"Providers of high-risk AI systems shall, upon request by a national competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. Any information submitted in accordance with the provision of this article shall be considered by the national competent authority a trade secret of the company that is submitting such information and kept strictly confidential.",
        "title":"Amendment 1969: Article 23 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"e67713f5-b164-485b-a129-087576a9b81c",
        "text":"Providers of high-risk AI systems and where applicable, users shall, upon request by a national competent authority or where applicable, by the AI Office or the Commission, provide them with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned.",
        "title":"Amendment 1970: Article 23 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"bc0c49c0-d137-4c15-87da-7aaa308113a9",
        "text":"Providers and, where applicable, users of high-risk AI systems shall, upon request by a national supervisory authority or a national competent authority or, where applicable, by the Board or the Commission, provide them with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned.",
        "title":"Amendment 1971: Article 23 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"1cfa11a8-c578-439c-9c7f-a849614ee361",
        "text":"Providers of high-risk AI systems shall, upon request by a competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a request from a competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control.",
        "title":"Amendment 1972: Article 23 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0ff5bd24-e277-446f-a466-6cba5b9c7197",
        "text":"Providers of high-risk AI systems shall, upon reasoned request by a national competent authority, provide that authority with all the information and documentation they deem necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law.",
        "title":"Amendment 1973: Article 23 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"1df5c88f-20e8-4234-9dfb-57e2f99263e5",
        "text":"Upon a reasoned request by a national competent authority or, where applicable, by the Commission, providers and, where applicable, users shall also give the requesting national competent authority or the Commission, as applicable, access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The national competent authorities or, where applicable, the Commission, shall keep confidential all trade secrets contained in the information received, in accordance with Article 70(2).",
        "title":"Amendment 1974: Article 23 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e00ec749-514c-45eb-a513-cff38048d850",
        "text":"Upon a reasoned request by a national supervisory authority or a national competent authority or, where applicable, by the Board or the Commission, providers and, where applicable, users shall also give them access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law.",
        "title":"Amendment 1975: Article 23 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"346b5497-fd61-4854-ac5b-9b5a68adfe46",
        "text":"Article 23 a', 'Clarification of responsibilities along the AI value chain', '1. Concerning high risk AI systems, any natural or legal person shall be considered a new provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:', '(a) they put their name or trademark on a high-risk AI system already placed on the market or put into service, without prejudice to contractual arrangements stipulating that the obligations are allocated otherwise;', '(b) they make a substantial modification or modify the intended purpose of a high-risk AI system already placed on the market or put into service;', '(c) they modify the intended purpose of a non high-risk AI system already placed on the market or put into service, in a way which makes the modified system a high-risk AI System;', '(d) they adapt a general purpose AI system system, already placed on the market or put into service, to a specific intended purpose.', '2 . Where the circumstances referred to in paragraphs 1(a), (b) and (c) occur, the former provider shall no longer be considered a provider for the purposes of this Regulation. The former provider shall upon request and without compromising its own intellectual property rights or trade secrets, provide the new provider with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '3. The original provider of a general purpose AI system shall, without compromising its own intellectual property rights or trade secrets and to the extent appropiate and feasible:', '(a) ensure that the general purpose AI system which may be used as high-risk AI system complies with the requirements established in Article 9, 10, 11, 13(2)\/(3) and 15 of this Regulation;', '(b) comply with the obligations set out in Art 16aa, 16e, 16f, 16g, 16i, 16j, 48 and 61 of this Regulation;', '(c) assess the reasonable foreseeable misuses of the general purpose AI system that may arise during the expected lifetime and install mitigation measures against those cases based on the generally acknowledged state of the art;', '(d) provide the new provider referred to in paragraph 1(d) with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '4. For high-risk AI systems that are safety components of products to which the legal acts listed in Annex II, section A apply, the manufacturer of those products shall be considered the provider of the high-risk AI system and shall be subject to the obligations referred to in Article 16 under either of the following scenarios:', '(i) the high-risk AI system is placed on the market together with the product under the name or trademark of the product manufacturer; or', '(ii) the high-risk AI system is put into service under the name or trademark of the product manufacturer after the product has been placed on the market.', '5. Third parties involved in the sale and the supply of software including general purpose application programming interfaces (API), software tools and components, providers who develop and train AI systems on behalf of a deploying company in accordance with their instruction, or providers of network services shall not be considered providers for the purposes of this Regulation.",
        "title":"Amendment 1976: Article 23 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fa1148cf-c12c-419b-8d4c-1558ed35d90f",
        "text":"Article 23 a', 'Conditions for other persons to be subject to the obligations of a provider', '1. Concerning high risk AI systems any natural or legal person shall be considered a provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:', '(a) they put their name or trademark on a high-risk AI system already placed on the market or put into service, without prejudice to contractual arrangements stipulating that the obligationsare allocated otherwise;', '(b) they make a substantial modification to or modify the intended purpose of a high-risk AI system already placed on the market or put into service;', '(c) they modify the intended purpose of a non-high-risk AI system already placed on the market or put it to service, in a way which makes the modified system a high-risk AI system;', '(d) they fulfil the conditions referred in Article 3a(2).', '2. Where the circumstances referred to in paragraph 1 occur, the provider that initially placed the high-risk AI system on the market or put it into service shall no longer be considered a provider for the purposes of this Regulation. The initial provider subject to the previous sentence, shall upon request and without compromising its own intellectual property rights or trade secrets, provide the new provider referred to in paragraph (1a), (1b) or (1c) with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '3. For high-risk AI systems that are safety components of products to which the legal acts listed in Annex II, section A apply, the manufacturer of those products shall be considered the provider of the high-risk AI system and shall be subject to the obligations referred to in Article 16 under either of the following scenarios:', '(i) the high-risk AI system is placed on the market together with the product under the name or trademark of the product manufacturer; or', '(ii) the high-risk AI system is put into service under the name or trademark of the product manufacturer after the product has been placed on the market.', '4. Third parties involved in the sale and the supply of software including general purpose application programming interfaces (API), software tools and components, providers who develop and train AI systems on behalf of a deploying company in accordance with their instruction, or providers of network services shall not be considered providers for the purposes of this Regulation.",
        "title":"Amendment 1977: Article 23 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"ffd45440-c15f-41d7-8009-97cd07b7ce37",
        "text":"deleted",
        "title":"Amendment 1978: Article 24  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"f7e6b58e-0419-44e3-a515-4acf78eae4a2",
        "text":"deleted",
        "title":"Amendment 1979: Article 24  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b35abc59-3579-48c4-8534-e29fe5e87e27",
        "text":"deleted",
        "title":"Amendment 1980: Article 25  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"44ce5a59-fc60-45ae-891e-3cbd8269c791",
        "text":"1. Prior to making their systems available on the Union market providers established outside the Union shall, by written mandate, appoint an authorised representative which is established in the Union.",
        "title":"Amendment 1981: Article 25 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"3f7c8dbc-b42c-4648-90d7-6a0b72b785fc",
        "text":"1. Prior to making their systems available on the Union market, providers established outside the Union shall, by written mandate, appoint an authorised representative which is established in the Union.",
        "title":"Amendment 1982: Article 25 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"46040bc4-2f0a-4a43-8e23-6a2430b79b76",
        "text":"1a. As of the time they are appointed, authorised representatives must be able to correspond, exchange technical information and carry out the duties required of them under this Regulation with the national authorities and in the official languages of all the Member States.",
        "title":"Amendment 1983: Article 25 – paragraph 1 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2bc4b6be-c9ae-4ddd-a24c-a4a865d30442",
        "text":"2. The authorised representative shall perform the tasks specified in the mandate received from the provider. For the purpose of this Regulation, the mandate shall empower the authorised representative to carry out only the following tasks:",
        "title":"Amendment 1984: Article 25 – paragraph 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c8ee5c4c-ea2f-4579-a9b4-5ae0102f6eb3",
        "text":"(a) carry out or commission the conformity assessment referred to in Article 43;",
        "title":"Amendment 1985: Article 25 – paragraph 2 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c154c597-b8b8-4c07-881c-8a0f8ba3d1cd",
        "text":"(a) ensure that the EU declaration of conformity and the technical documentation have been drawn up and that an appropriate conformity assessment procedure has been carried out by the provider;",
        "title":"Amendment 1986: Article 25 – paragraph 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"af56492e-47cc-4e23-bdd1-18a192ab93bd",
        "text":"(b) keep a copy of the EU declaration of conformity and the technical documentation at the disposal of the national competent authorities and national authorities referred to in Article 63(7);",
        "title":"Amendment 1987: Article 25 – paragraph 2 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"1deee49e-224e-4f6c-9eb0-5bf113e6e6be",
        "text":"(b) provide a national competent authority with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider;",
        "title":"Amendment 1988: Article 25 – paragraph 2 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2942d676-aed2-4c4e-9f82-7989106f864b",
        "text":"(b a) keep at the disposal of the national competent authorities and national authorities referred to in Article 63(7), for a period ending 3 years after the high-risk AI system has been placed on the market or put into service, a copy of the EU declaration of conformity, the technical documentation and, if applicable, the certificate issued by the notified body;",
        "title":"Amendment 1989: Article 25 – paragraph 2 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"dda4b02a-278c-4a8b-9dd2-1a8e2e0e000e",
        "text":"(c) provide a national competent authority, upon a reasoned request, with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law;",
        "title":"Amendment 1990: Article 25 – paragraph 2 – point c  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"58908c4a-8241-42fe-a683-4f4a78fd9058",
        "text":"(c) cooperate with competent national authorities, upon a reasoned request, on any action the latter takes to reduce and mitigate the risks posed by a high-risk AI system covered by the authorised representative's mandate.",
        "title":"Amendment 1991: Article 25 – paragraph 2 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-"
    },
    {
        "uuid":"fb1ee9cf-dcca-48fe-a459-b777b0eabe5d",
        "text":"(c) cooperate with national supervisory authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system;",
        "title":"Amendment 1992: Article 25 – paragraph 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"be1c695d-b08e-4a51-8b42-98f16f0ed410",
        "text":"(c a) comply with the registration obligations referred to in Article 51 or, if the registration is carried out by the provider itself, ensure that the information referred to in point 3 of Annex VIII is correct.",
        "title":"Amendment 1993: Article 25 – paragraph 2 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bad50fe3-5093-46b8-9c07-596744fa82b9",
        "text":"(ca) cooperate with competent national authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system.",
        "title":"Amendment 1994: Article 25 – paragraph 2 – point c a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"cf9ae1c8-abf0-4fc4-afbd-7e415c2dd2d4",
        "text":"The authorised representative shall terminate the mandate if it considers or has reason to consider that the provider acts contrary to its obligations under this Regulation. In such a case, it shall also immediately inform the market surveillance authority of the Member State in which it is established, as well as, where applicable, the relevant notified body, about the termination of the mandate and the reasons thereof.",
        "title":"Amendment 1995: Article 25 – paragraph 2 – subparagraph 1 (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d9ed6a47-43bf-495a-b881-85d273283111",
        "text":"1. Before placing a high-risk AI system on the market, importers of such system shall ensure that such a system is in conformity with this Regulation by ensuring that:",
        "title":"Amendment 1996: Article 26 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1778c377-4520-4a1b-a5fb-f4c70c025ac1",
        "text":"(a) the appropriate conformity assessment procedure has been carried out by the provider of that AI system following its import and prior to its deployment;",
        "title":"Amendment 1997: Article 26 – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"dea63d42-2b85-4693-8ec5-a71a0be61d6c",
        "text":"(a) the relevant conformity assessment procedure referred to in Article 43 has been carried out by the provider of that AI system;",
        "title":"Amendment 1998: Article 26 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"818186c0-4c12-4231-b13e-44429aab43e6",
        "text":"(c) the system bears the required conformity marking and is accompanied by the required documentation and instructions of use;",
        "title":"Amendment 1999: Article 26 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f93f3f4e-8f24-4741-8cb7-24c81d030b86",
        "text":"(c a) the authorised representative referred to in Article 25 has been established by the Provider.",
        "title":"Amendment 2000: Article 26 – paragraph 1 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"40e057f0-c1f0-42d4-ae8f-7e49e990f9db",
        "text":"2. Where an importer considers or has reason to consider that a high-risk AI system is not in conformity with this Regulation, or is falsified, or accompanied by falsified documentation it shall not place that system on the market until that AI system has been brought into conformity. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the importer shall inform the provider of the AI system and the market surveillance authorities to that effect.",
        "title":"Amendment 2001: Article 26 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8377b87b-d985-44c5-a826-88876a82177b",
        "text":"3. Importers shall indicate their name, registered trade name or registered trade mark, and the address at which they can be contacted on the high-risk AI system and, on its packaging or its accompanying documentation, where applicable.",
        "title":"Amendment 2002: Article 26 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8437666a-f4bb-402b-bef5-d93a8ea74c4e",
        "text":"4. Importers shall keep, for a period ending 3 years after the AI system has been placed on the market or put into service, a copy of the certificate issued by the notified body, where applicable, of the instructions for use and of the EU declaration of conformity.",
        "title":"Amendment 2003: Article 26 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c5309f0d-2bb6-4cd2-b5d8-8ca803e8d4a7",
        "text":"5. Importers shall provide the national supervisory authority and the national competent authorities, upon a reasoned request, with all the necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by them, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law. They shall also cooperate with those authorities on any action the national supervisory authority and the national competent authority take in relation to that system.",
        "title":"Amendment 2004: Article 26 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"6904c29b-579f-459d-af4a-a7859b30ccc6",
        "text":"5. Importers shall provide national competent authorities, upon request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by that national competent authority, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider. They shall also cooperate with those authorities on any action national competent authority takes in relation to that system.",
        "title":"Amendment 2005: Article 26 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"09cee3c2-3499-42e9-9bdc-89f1f4743c93",
        "text":"5. Where no authorised representative has been established, importers shall provide national competent authorities, upon a reasoned request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by that national competent authority. To this purpose they shall also ensure that the technical documentation can be made available to those authorities.",
        "title":"Amendment 2006: Article 26 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9e832c6a-1bd5-4ad2-96c5-a210c9e403b5",
        "text":"5. Importers shall provide national competent authorities, upon a reasoned request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in an official language of that national competent authority, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law. They shall also cooperate with those authorities on any action national competent authority takes in relation to that system.",
        "title":"Amendment 2007: Article 26 – paragraph 5  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2ca1bfc2-749c-4292-9c71-b517a5b4924c",
        "text":"5 a. Importers shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.",
        "title":"Amendment 2008: Article 26 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b8f6a150-b076-4d36-80aa-674fa269d3fd",
        "text":"1. Before making a high-risk AI system available on the market, distributors shall verify that the high-risk AI system bears the required CE conformity marking, that it is accompanied by the required documentation and instruction of use, and that the provider and the importer of the system, as applicable, have complied with their obligations set out in this Regulation in Article 16 and Article 26(3), respectively.",
        "title":"Amendment 2009: Article 27 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e1d4aeac-cdae-4abe-98af-539f63d99cc8",
        "text":"2. Where a distributor considers or has reason to consider, on the basis of the information in its possession, that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the provider or the importer of the system, as applicable, to that effect, and the market surveillance authorities.",
        "title":"Amendment 2010: Article 27 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"18f6a9c1-525a-4b7a-85e5-83dd0b477628",
        "text":"2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the provider or the importer of the system as well as the market surveillance authorities, as applicable, to that effect.",
        "title":"Amendment 2011: Article 27 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"f1ab9395-3144-4dc5-9803-0a1b4dcdfc61",
        "text":"2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the market surveillance authority and the provider or the importer of the system, as applicable, to that effect.",
        "title":"Amendment 2012: Article 27 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"7e6951f5-34ca-4bf7-a3cb-c2dbe0cb2bc0",
        "text":"2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the competent authorities and the provider or the importer of the system, as applicable, to that effect.",
        "title":"Amendment 2013: Article 27 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7f7447df-44b7-4750-99a4-0b13d0391ec5",
        "text":"4. A distributor that considers, on the basis of the information in its possession, or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the provider or importer of the system and the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 2014: Article 27 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"42c0a68d-aaec-4ec5-a5b0-5fa989e1ae5b",
        "text":"4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the provider or the importer of the system as well as the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 2015: Article 27 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"0a17aa6b-d5e9-4e93-8959-8170842afb89",
        "text":"4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to to withdraw or recall that system in order to bring it into conformity with those requirements, or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 2016: Article 27 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"79f1f4f5-c0a7-4c8a-9189-a85101141df1",
        "text":"4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.",
        "title":"Amendment 2017: Article 27 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9e13985c-105a-4b61-bd31-20fd615762c8",
        "text":"5. Upon a reasoned request from a national competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation regarding its activities pursuant to paragraphs 1 to 4.",
        "title":"Amendment 2018: Article 27 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"61cf1936-129c-45d3-a976-6c5f562865ac",
        "text":"5. Upon a reasoned request from a national competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation in its possession or available to it, in accordance with the obligations of distributors as outlined by this Regulation, that are necessary to demonstrate the conformity of a high-risk system with the requirements set out in Chapter 2 of this Title. Distributors shall also cooperate with that national competent authority on any action taken by that authority.",
        "title":"Amendment 2019: Article 27 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"eefa0f50-d1a8-4ceb-a713-52c8a79d9302",
        "text":"5. Upon a reasoned request from a national competent authority and where no authorised representative has been appointed, distributors of high-risk AI systems shall provide that authority with all the information and documentation regarding its activities as described in paragraphs 1 to 4.",
        "title":"Amendment 2020: Article 27 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"93f259c4-9105-4cb5-8039-d0dcf4a0a617",
        "text":"5. Upon request from a competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation necessary to demonstrate the conformity of a high-risk system with the requirements set out in Chapter 2 of this Title. Distributors shall also cooperate with that competent authority on any action taken by that authority.",
        "title":"Amendment 2021: Article 27 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"10fbfc33-9595-42fb-98f4-4a394c2d1043",
        "text":"5 a. Importers shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.",
        "title":"Amendment 2022: Article 27 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ab098f06-5f65-470f-9d90-0d7270954c46",
        "text":"deleted",
        "title":"Amendment 2023: Article 28  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1777013b-8295-4d90-bead-d31f75c47136",
        "text":"deleted",
        "title":"Amendment 2024: Article 28  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"f9d0d780-c8a9-4a02-8e9c-171569074367",
        "text":"Obligations of distributors, importers, deployers or any other third-party",
        "title":"Amendment 2025: Article 28 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4556e8f4-2cbb-42bd-b05e-821358ba614e",
        "text":"1. Any distributor, importer, user or other third-party shall be considered a provider of a high-risk AI system for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:",
        "title":"Amendment 2026: Article 28 – paragraph 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"c4a4a0d8-51ea-492b-b83a-37f5f45e67d8",
        "text":"1. Any distributor, importer, deployer or other third-party shall be considered a provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:",
        "title":"Amendment 2027: Article 28 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8f41d459-702e-4eab-9c7a-7c7dede29113",
        "text":"(b) they modify the intended purpose or reasonably foreseeable use of a high-risk AI system already placed on the market or put into service;",
        "title":"Amendment 2028: Article 28 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"ee7eb65d-abb1-406c-aa9e-e118eab05957",
        "text":"(ba) they have placed on the market or put into service a high-risk AI system which they have substantially modified by their own means;",
        "title":"Amendment 2029: Article 28 – paragraph 1 – point b a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"4b049a9b-316b-45fe-aab8-3b008b931550",
        "text":"(b a) they deploy a high-risk system for a purpose other than the intended purpose;",
        "title":"Amendment 2030: Article 28 – paragraph 1 – point b a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bdf0bd1c-2b69-4c8d-831c-60ab5ca2ec01",
        "text":"(c a) they modify the intended purpose of an AI system which is not high-risk and is already placed on the market or put into service, in a way which makes the modified system a high-risk AI system.",
        "title":"Amendment 2031: Article 28 – paragraph 1 – point c a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2d5da33d-c563-46ca-bb4b-896ebdd7dd0b",
        "text":"(c a) they modify the intended purpose of an AI system which is not high-risk and is already placed on the market or put into service, in a way which makes the modified system a high-risk AI system.",
        "title":"Amendment 2032: Article 28 – paragraph 1 – point c a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e9d5d4b6-7234-4eb0-9eab-dcb667501ed0",
        "text":"2 a. Providers that initially placed the high-risk AI system on the market or put it into service shall cooperate closely with distributors, importers, users, or other third-parties to supply them with the necessary information or documentation in their possession that is required for the fulfilment of the obligations set out in this Regulation, in particular at the moment when such distributors, importers, users or other third-parties become the new providers as determined in paragraph 1 and the initial providers are no longer considered a provider for the purposes of this Regulation as determined in paragraph 2.",
        "title":"Amendment 2033: Article 28 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8a9c6a4f-d784-4fc9-bb3e-b48e8c68cfa9",
        "text":"Article 28 a', 'Obligations of employers', '1. Employers shall have the following additional obligations when deploying AI surveillance or monitoring systems in the workplace:', '(a) consult trade unions on the use of high risk and intrusive forms of AI in the workplace;', '(b) ensure that workers are aware of the AI systems at the workplace, including their impact on data, digital footprint and work organisation;', '(c) ensure a human review of decisions made by AI systems that could affect the worker;', '(d) deliver an annual conformity assessment for workplace-based AI to guard against discrimination by algorithm.",
        "title":"Amendment 2034: Article 28 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst, Kateřina Konečná"
    },
    {
        "uuid":"b6815622-9a20-456b-be48-0359e16c49a1",
        "text":"29 Obligations of deployers of high-risk AI systems', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)",
        "title":"Amendment 2035: Article 29 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fdca18ba-bce3-4f32-9619-c4af00522e1e",
        "text":"-1. Users of high-risk AI systems shall ensure that natural persons assigned to ensure or entrusted with human oversight for high-risk AI systems are competent, properly qualified and trained, free from external influence and neither seek nor take instructions from anybody. They shall have the necessary resources in order to ensure the effective supervision of the system in accordance with Article 14.",
        "title":"Amendment 2036: Article 29 – paragraph -1 (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7183c7a6-bab1-41ca-807f-31b2660c288e",
        "text":"1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this Article. Users shall bear sole responsibility in case of any use of the AI system that is not in accordance with the instructions of use accompanying the systems.",
        "title":"Amendment 2037: Article 29 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a941ec39-2d0c-4336-b815-6bd495866bc2",
        "text":"1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures and ensure that the use of such systems is in accordance with the instructions of use accompanying the systems and enables human oversight and decision-making, pursuant to paragraphs 2 and 5.",
        "title":"Amendment 2038: Article 29 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9ccbc9b1-b3dc-4d17-b0d1-5b415e209d3f",
        "text":"1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this article.",
        "title":"Amendment 2039: Article 29 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"5b86db35-c311-42ae-bbb7-5d1621c8907d",
        "text":"1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5.",
        "title":"Amendment 2040: Article 29 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"7ff8b666-f128-4a62-ad4e-f9627ec3176a",
        "text":"1. Users shall bear sole responsibility in case of any use of the AI system that is not in accordance with the instructions of use accompanying the systems.",
        "title":"Amendment 2041: Article 29 – paragraph 1 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"da4f6b9f-8b92-45fb-8ba0-8de4ceba577a",
        "text":"1 a. To the extent the user exercises control over the high-risk AI system, that user shall only assign human oversight to natural persons who have the necessary competence, training and authority as well as ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.",
        "title":"Amendment 2042: Article 29 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7e22f98f-4959-4c88-9682-59859d5f1024",
        "text":"1 a. Deployers shall identify the categories of natural persons and groups likely to be affected by the system before putting it into use.",
        "title":"Amendment 2043: Article 29 – paragraph 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"70631342-c0da-4985-b98d-5ff5d265bc33",
        "text":"1 a. Users shall assign human oversight to natural persons who have the necessary competence, training and authority.",
        "title":"Amendment 2044: Article 29 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"187d95c2-d580-41f0-b36d-659828685602",
        "text":"1 b. Human oversight following paragraph 1 shall be carried out by natural persons having the necessary competences, training, authority and independence.",
        "title":"Amendment 2045: Article 29 – paragraph 1 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a0b7234e-4899-4181-bd83-a54606d27cb6",
        "text":"2. The obligations in paragraph 1 are without prejudice to other user obligations under Union or national law and to the user’s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.', 'This regulation does not conflict with the scope of Art. 153 TFEU, which sets minimum requirements for Member States that may be exceeded.",
        "title":"Amendment 2046: Article 29 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f750db99-2b0e-4d7f-afc7-b4a6a7720fca",
        "text":"2. The obligations in paragraph 1 are without prejudice to other deployer obligations under Union or national law and shall take due account of the deployer's discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.",
        "title":"Amendment 2047: Article 29 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"abfa6fa5-f077-41ff-bda9-948ebe49f11d",
        "text":"2. The obligations in paragraph 1 and 1a are without prejudice to other user obligations under Union or national law and to the user’s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.",
        "title":"Amendment 2048: Article 29 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7cd6d6f8-313c-4f72-b3ee-7a4226f5a2a1",
        "text":"3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose of the high-risk AI system. To the extent the user exercises control over the high-risk AI system, that user shall also ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.",
        "title":"Amendment 2049: Article 29 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"7ef2c555-3bfa-4f9e-a5d3-9980fdb23457",
        "text":"3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose of the high-risk AI system. To the extent the user exercises control over the high-risk AI system, that user shall also ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.",
        "title":"Amendment 2050: Article 29 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"de95f6b2-9a7a-4b68-9675-08f7bb62cf23",
        "text":"3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.",
        "title":"Amendment 2051: Article 29 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9ea65ecb-2575-4cb3-b10d-5372f6388db1",
        "text":"3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose or reasonably foreseeable use of the high-risk AI system.",
        "title":"Amendment 2052: Article 29 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"9426830c-f926-4b9b-b37b-173d9e87f7de",
        "text":"4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use and, when relevant, inform providers in accordance with Article 61. To the extent the user exercises control over the high-risk AI system, users shall also perform risk assessments in line with Article 9 but limited to the potential adverse effects of using the high-risk AI system and the respective mitigation measures. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the provider or distributor and relevant regulatory authority and suspend the use of the system. They shall also inform the provider or distributor and relevant regulatory authority when they have identified any serious incident and interrupt the use of the AI system. In case the user is not able to reach the provider, importer or distributer Article 62 shall apply mutatis mutandis.",
        "title":"Amendment 2053: Article 29 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"83b28e24-d502-4d87-b557-499cffc4fa2b",
        "text":"4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use and, when relevant, inform providers in accordance with Article 61. To the extent the user exercises control over the high-risk AI system, the user shall also establish a risk management system in line with Article 9 but limited to the potential adverse effects of using the high-risk AI system, the respective mitigation measures. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the provider or distributor and suspend the use of the system. They shall also inform the provider or distributor when they have identified any serious incident or any malfunctioning within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.",
        "title":"Amendment 2054: Article 29 – paragraph 4 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-"
    },
    {
        "uuid":"8a62819b-a3f3-45e9-9c4c-c35dbf231683",
        "text":"4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the national competent authorities and the provider or distributor and suspend the use of the system. They shall also inform the national competent authorities and the provider or distributor when they have identified any serious incident or any malfunctioning, including near misses, within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.",
        "title":"Amendment 2055: Article 29 – paragraph 4 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"de2603d2-e6cb-4689-af8d-0e58a1fb239b",
        "text":"4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall immediately inform the provider or distributor and suspend the use of the system. They shall also immediately inform the provider or distributor when they have identified any serious incident or any malfunctioning, including near misses, within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.",
        "title":"Amendment 2056: Article 29 – paragraph 4 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"30e682c3-844b-4064-a435-2c11a12e1e5c",
        "text":"5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of the intended purpose or reasonably foreseeable use of the high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 2057: Article 29 – paragraph 5 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"06316641-c1fc-47a9-ad0f-e02b13b03346",
        "text":"5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. They shall keep them for a period of at least six months, unless provided otherwise in applicable Union or national law.",
        "title":"Amendment 2058: Article 29 – paragraph 5 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5a64a6a1-655d-4240-bb91-1c000f14684e",
        "text":"5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of industry standards, the intended purpose of the high-risk AI system and applicable legal obligations under Union or national law.",
        "title":"Amendment 2059: Article 29 – paragraph 5 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"8d835f6b-504e-41b8-a36b-ab1e12284040",
        "text":"Prior to putting into service or use an AI system at the workplace, users shall consult workers representatives, inform the affected employees that they will be subject to the system and obtain their consent.",
        "title":"Amendment 2060: Article 29 – paragraph 5 – subparagraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"53c2ce2f-a18c-4f54-9b68-915588c42bdd",
        "text":"5 a. Users of high-risk AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an high-risk AI system.', 'This information shall include a clear and concise indication of the user and the purpose of the high-risk AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the high-risk AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', 'This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016\/679 [GDPR], Directive 2016\/680 [LED], Regulation 2022\/XXX [DSA].",
        "title":"Amendment 2061: Article 29 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"7eb58112-367f-441a-8f93-d9b04908dfa5",
        "text":"5 a. Users of high-risk AI systems that are public authorities or Union institutions, bodies, offices and agencies shall conduct a fundamental rights impact assessment prior to commencing the use of a high-risk AI system;",
        "title":"Amendment 2062: Article 29 – paragraph 5 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"53cc9ec8-3298-402d-a797-860e65a530d5",
        "text":"5 a. Users of high-risk AI systems shall comply with the registration obligations referred to in Article 51.",
        "title":"Amendment 2063: Article 29 – paragraph 5 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b5a4377c-01ce-438e-b4e5-2081cca2e125",
        "text":"6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680, and may revert in part to those data protection impact assessments for fulfilling the obligations set out in this article.",
        "title":"Amendment 2064: Article 29 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"dbd27822-0dff-49c4-b82f-62bd9451baac",
        "text":"6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680 and may revert in part to those data protection impact assessments for fulfilling the obligations set out in this Article.",
        "title":"Amendment 2065: Article 29 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4d5e0101-6c47-46c7-aa11-a0f67048ac40",
        "text":"6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680, where applicable.', 'The data protection impact assessment shall be published.",
        "title":"Amendment 2066: Article 29 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"6ed2db6b-e13a-40cd-a2ce-27b7f3043104",
        "text":"6 a. Users of high-risk AI systems shall carry out a human rights impact assessment for the different uses of the system, containing specific information on the context of use of that system, including, the intended purpose or reasonable foreseeably use, geographic and temporal scope, assessment of the legality and fundamental rights impacts of the system, any specific risk of harm likely to impact marginalised persons or those at risk of discrimination, any other negative impact on the public interest;and clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.', 'The human rights impact assessment shall be published, and be registered by the user in the database referred to under Article 60.",
        "title":"Amendment 2067: Article 29 – paragraph 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"6214950e-1ba6-436a-bf67-3dcdae8875de",
        "text":"6 a. Where a user of a high risk AI system is obliged pursuant to Regulation (EU) 2016\/679 to provide information regarding the use of automated decision making procedures, the user shall not be obliged to provide information on how the AI system reached a specific result. When fulfilling the information obligations under Regulation (EU) 2016\/679, the user shall not be obliged to provide information beyond the information he or she received from the provider under Article 13 of this Regulation.",
        "title":"Amendment 2068: Article 29 – paragraph 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-"
    },
    {
        "uuid":"0da36df0-8987-410a-8b91-ed67acf30018",
        "text":"6 a. Users of high risk systems involving an emotion recognition system or a biometric categorisation system in accordance with Article 52 shall implement suitable measures to safeguard the natural person's rights and freedoms and legitimate interests in such a system, including providing the natural person with the ability to express his or her point of view on the resulting categorisation and to contest the decision.",
        "title":"Amendment 2069: Article 29 – paragraph 6 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Vincenzo Sofo, Kosma Złotowski"
    },
    {
        "uuid":"3e594eb8-c5ab-4460-ba06-81f0153c3f2b",
        "text":"6 a. Users shall monitor the performance of high-risk AI systems deployed by end-users and shall ensure that all possible malfunctioning and performance issues are recorded, and when not able to justify or ensure proper performance, communicated to the AI provider. In such cases, the provider and the user shall coordinate to establish the cause of a possible malfunctioning or performance issue.",
        "title":"Amendment 2070: Article 29 – paragraph 6 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"5336c588-d239-4709-bba3-74d1704ae57d",
        "text":"6 a. Users of high-risk AI systems shall refrain from placing on the market or putting into service a high-risk AI system that:', '(i) is not in conformity with the requirements set out in Chapter 2 of this Title;or', '(ii) poses a risk of harm to health, safety or fundamental rights despite its conformity with the requirements set out in Chapter 2 of this Title.",
        "title":"Amendment 2071: Article 29 – paragraph 6 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bd6b369e-ff2d-47c6-84a6-09720744974b",
        "text":"6 a. Users of high-risk AI systems referred to in Annex III that make decisions or assist in making decisions related to an affected person, shall inform them that they are subject to the use of the high-risk AI system. This information shall include the type of the AI system used, its intended purpose and the type of decisions it makes.",
        "title":"Amendment 2072: Article 29 – paragraph 6 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c921d310-57d3-4469-8fa4-feaf1c7f5c2d",
        "text":"6 a. Users of high risk AI systems, who modify or extend the purpose for which the conformity of the AI system was originally assessed, shall establish and document a post-market monitoring system (Art. 61)and must undergo a new conformity assessment (Art. 43) involved by a notified body.",
        "title":"Amendment 2073: Article 29 – paragraph 6 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f2d11e6e-af12-44c3-ad7f-00015960ab14",
        "text":"6 a. The provider shall be obliged to cooperate closely with the user and in particular provide the user with the necessary information to allow the fulfilment of the obligations set out in this Article.",
        "title":"Amendment 2074: Article 29 – paragraph 6 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f81cb045-1ea7-47a2-afed-65131a442d14",
        "text":"6 a. Users of high-risk AI systems shall conduct and publish a fundamental rights impact assessment.",
        "title":"Amendment 2075: Article 29 – paragraph 6 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"ab1fe018-f9b3-4bfd-8ba5-9cfbce7c93c8",
        "text":"6 b. The obligations established by this Article shall not apply to users who use the AI system in the course of a personal non-professional activity.",
        "title":"Amendment 2076: Article 29 – paragraph 6 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej"
    },
    {
        "uuid":"cefff099-a86e-454a-a4cf-cbbcdc2141e9",
        "text":"6 b. Users shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.",
        "title":"Amendment 2077: Article 29 – paragraph 6 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6a3d319b-123b-44ac-9d55-def2d6b98242",
        "text":"Article 29 a', 'Fundamental rights impact assessment for a high-risk AI system', '1. Prior to putting a high-risk AI system into use, as defined in Article 6(2), the user shall conduct an assessment of the system’s impact in the context of use. This assessment shall consist of, but not limited to, the following elements:', '(a) a clear outline of the intended purpose for which the system will be used;', '(b) a clear outline of the intended geographic and temporal scope of the system’s use;', '(c) verification that the use of the system is compliant with Union and national law;', '(d) categories of natural persons and groups likely to be affected by the use of the system;', '(e) the foreseeable direct and indirect impact on fundamental rights of putting the high-risk AI system into use;', '(f) any specific risk of harm likely to impact marginalised persons or vulnerable groups;', '(g) the foreseeable impact of the use of the system on the environment, including, but not limited to, energy consumption;', '(h) any other negative impact on the protection of the values enshrined in Article 2 TEU;', '(i) in the case of public authorities, any other impact on democracy, rule of law and allocation of public funds; and', '(j) detailed plan on how the risk of harm or the negative direct and indirect impact on fundamental rights identified will be mitigated.', '2. If a detailed plan to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the user shall refrain from putting the high-risk AI system into use and inform the provider, the national supervisory authority and market surveillance authority without undue delay. Market surveillance authorities or, where relevant, national supervisory authorities, pursuant to their capacity under Articles 65, 67 and 67a, shall take this information into account when investigating systems which present a risk at national level.', '3. The obligations as per paragraph 1 apply for each new deployment of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify the national supervisory authority, the market surveillance authority and the relevant stakeholders. and involve representatives of the foreseeable persons or groups of persons affected by the high-risk AI system, as identified in paragraph 1, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment. The user must allow a period of six weeks for bodies to respond.', '5. The user shall publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).', '6. Where the user is already required to carry out a data protection impact assessment pursuant to Article 29(6), the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment.",
        "title":"Amendment 2078: Article 29 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6877e3dd-0dc9-4287-bfde-28821d31e9d4",
        "text":"Article 29 a', 'Fundamental rights impact assessment for high-risk AI systems', '1. Prior to putting a high-risk AI system as defined in Article 6(2) into use, users shall conduct an assessment of the systems’ impact in the specific context of use. This assessment shall include, at a minimum, the following elements:', '(a) a clear outline of the intended purpose for which the system will be used;', '(b) a clear outline of the intended geographic and temporal scope of the system’s use;', '(ba) categories of natural persons and groups likely to be affected by the use of the system;', '(c) verification that the use of the system is compliant with relevant Union and national law, and with fundamental rights law;', '(d) the foreseeable direct or indirect impact on fundamental rights of putting the high-risk AI system into use;', '(e) any specific risk of harm likely to impact marginalised persons or vulnerable groups;', '(f) the foreseeable impact of the use of the system on the environment including, but not limited to, energy consumption;', '(g) any other negative impact on the protection of the values enshrined in Article 2 TEU;', '(h) in the case of public authorities, any other impact on democracy, rule of law and allocation of public funds; and', '(i) a detailed plan as to how the harms and the negative direct or indirect impact on fundamental rights identified will be mitigated.', '2. If a detailed plan to mitigate the risks outlined in the course of the assessment outlined in paragraph 1 cannot be identified, the user shall refrain from putting the high-risk AI system into use and inform the provider and the relevant national competent authorities without undue delay. Market surveillance authorities, pursuant to Articles 65 and 67, shall take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new use of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify relevant national competent authorities and relevant stakeholders and involve representatives of the persons or groups of persons that are reasonably foreseeable to be affected by the high-risk AI system, as identified in paragraph 1, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment. The user must allow a period of six weeks for bodies to respond.', '5. The user that is a public authority shall publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).",
        "title":"Amendment 2079: Article 29 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"113e4cc1-c2a2-4419-b140-207c9925863f",
        "text":"Article 29 a', 'Fundamental rights impact assessments for high-risk AI systems', '1. The user of a high-risk AI system as defined in Article 6 paragraph 2 shall conduct an assessment of the system’s impact on fundamental rights and public interest in the context of use before putting the system into use and at least every two years afterwards. The information on clear steps as to how the potential harms identified will be mitigated and how effective this mitigation is likely to be should be included.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to their capacity under Articles 65 and 67, shall take this information into account when investigating systems which present a risk at national level.', '3. In the course of the impact assessment, the user shall notify relevant national authorities and all relevant stakeholders.', '4. Where, following the impact assessment process, the user decides to put the high-risk AI system into use, the user shall be required to publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51 paragraph 2.', '5. Users of high-risk AI systems shall use the information provided to them by providers of high-risk AI systems under Article 13 to comply with their obligation under paragraph 1.', '6. The obligations on users in paragraph 1 is without prejudice to the obligations on users of all high-risk AI systems as outlined in Article 29.",
        "title":"Amendment 2080: Article 29 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"369b2c64-b98e-4a45-bd99-835be0ee1125",
        "text":"Article 29 a', 'Human rights impact assessment for high-risk AI systems', '1. The user of a high-risk AI system as defined in Article 6 paragraph 2 may conduct an assessment of the system’s impact on fundamental rights and public interest in the context of use before putting the system into use and at least every three years afterwards. This assessment shall include, at minimum, the following:', 'a) a clear outline of the intended purpose for which the system will be used;', 'b) a clear outline of the intended geographic and temporal scope of the system’s use;', 'c) categories of natural persons and groups likely to be affected by the use of the system;', 'd) the likely impact on human rights of affected persons identified pursuant to point (c), including any indirect impacts or consequences of the system’s use;', 'e) in the case of public authorities, any other impact on the public interest, including democracy and allocation of public funds;', '2. Where the user of a high-risk AI system is already required to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680, the impact assessment outlined in paragraph 1 may be conducted in conjunction to the data protection impact assessment. The user may publish the results of both assessments, following the obligation under Article 51 paragraph 2.",
        "title":"Amendment 2081: Article 29 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Vincenzo Sofo"
    },
    {
        "uuid":"34eb9956-aafb-4e0b-8788-626fd465c454",
        "text":"Article 29 a', 'Fundamental rights impact assessment for users of high-risk AI', 'Users of high-risk AI systems as defined in Article 6(2) shall conduct an assessment of the systems’ impact in the context of use before putting the system into use. This assessment shall include, but is not limited to, the following:', 'a. a clear outline of the intended purpose for which the system will be used;', 'b. a clear outline of the intended geographic and temporal scope of the system’s use;', 'c. verification of the legality of the system in accordance with Union and national law, fundamental rights law, Union accessibility legislation, and the extent to which the system is in compliance with this Regulation;', 'd. the likely impact on fundamental rights of the high-risk AI system, including any indirect impacts or consequences of the system’s use;', 'e. any specific risk of harm likely to impact persons or groups of persons at risk of discrimination, or increase existing societal inequalities;', 'f. risk to the health of individuals and public health;', 'g. any other negative impact on the public interest; and', 'h. clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.",
        "title":"Amendment 2082: Article 29 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"64be265e-2010-42f8-b27e-f81487d044bb",
        "text":"Article 29 a', 'Obligation on users to define affected persons', '1. Before putting into use a high-risk AI system as defined in Article 6(2), the user shall define categories of natural persons and groups likely to be affected by the use of the system.",
        "title":"Amendment 2083: Article 29 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"559f4cef-f8d0-4241-9548-189183a5755a",
        "text":"Article 29 a', 'A fiduciary duty for providers and users of high-risk AI systems', 'Providers and users of high-risk AI systems have a fiduciary duty to act in the interest of the affectees.",
        "title":"Amendment 2084: Article 29 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2ffb884b-1b95-4ca4-ac3e-5148d9460cb7",
        "text":"Article 29 b', 'Fundamental rights impact assessments for high-risk AI systems', '1. Users of high-risk AI systems as defined in Article 6(2) shall conduct an assessment of the systems’ impact in the context of use before putting the system into use. This assessment shall include, but is not limited to, the following:', 'a. a clear outline of the intended purpose for which the system will be used;', 'b. a clear outline of the intended geographic and temporal scope of the system’s use;', 'c. verification of the legality of the system in accordance with Union and national law, fundamental rights law, Union accessibility legislation, and the extent to which the system is in compliance with this Regulation;', 'd. the likely impact on fundamental rights of the high-risk AI system, including any indirect impacts or consequences of the system’s use;', 'e. any specific risk of harm likely to impact marginalised persons or those groups at risk of discrimination, or increase existing societal inequalities;', 'f. the foreseeable impact of the use of the system on the environment, including but not limited to energy consumption;', 'g. any other negative impact on the public interest; and', 'h. clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to their capacity under Articles 65 and 67, may take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new deployment of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify relevant national authorities and allrelevant stakeholders, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment.The user must allow a period of six weeks for bodies to respond.', '5. Where, following the impact assessment process, the user decides to put the high-risk AI system into use, the user shall be required to publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).', '6. Where the user is already required to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680, the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment and be published as an addendum.', '7. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation under paragraph 1.', '8. Where the user, pursuant to their obligation to define affected categories of persons under Article 29a,finds that use of a high-risk system poses a particular risk to a specific group of natural persons, the user has the obligation to notify established representatives or interest groups acting on behalf of those persons before putting the system into use, with a view to receiving input into the impact assessment.', '9 The obligations on users in paragraph 1 is without prejudice to the obligations on users of all high risk AI systems as outlined in Article 29.",
        "title":"Amendment 2085: Article 29 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"dd6d2292-5b13-4887-9336-f10b6cc93cc3",
        "text":"1. Each Member State shall designate or establish a notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring. These procedures shall be developed in cooperation between the notifying authorities of all Member States and shall result in standard procedures implemented equally in all Member States, with a view to removing administrative border barriers and ensuring that the potential of the internal market is realised.",
        "title":"Amendment 2086: Article 30 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"cd110bc8-76b9-48f0-83e2-15e2b13a281d",
        "text":"1. Each Member State shall designate or establish a notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring. To this end, Member States shall ensure a sufficient number of conformity assessment bodies, in order to make the certification feasible in a timely manner.",
        "title":"Amendment 2087: Article 30 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"d0c981c8-83ca-4f86-936d-5f09d02e0f8c",
        "text":"1. Each Member State shall designate the national Data Protection Authority (DPA) as the notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring",
        "title":"Amendment 2088: Article 30 – paragraph 7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"52abf597-3230-4a18-9c49-aeeed7a8f972",
        "text":"7. Notifying authorities shall have a sufficient number of competent personnel at their disposal for the proper performance of their tasks. Where applicable, competent personnel shall have necessary expertise in supervision of fundamental rights.",
        "title":"Amendment 2089: Article 30 – paragraph 7  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5c1fa2dc-3d4a-4b1f-8500-85c9606e3637",
        "text":"8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of the AI system in question. Particular attention shall be paid to minimising administrative burdens and compliance costs for micro, small and medium-sized enterprises as defined in Commission Recommendation 2003\/361\/EC.",
        "title":"Amendment 2090: Article 30 – paragraph 8  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"2e9e4ac5-654d-46cd-a906-32f601177e27",
        "text":"8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of and risk posed by the AI system in question.",
        "title":"Amendment 2091: Article 30 – paragraph 8  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"1e44636d-8aba-4d91-aed7-946e888e029b",
        "text":"8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate and timely manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of the AI system in question.",
        "title":"Amendment 2092: Article 30 – paragraph 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8b149b39-13fb-4e01-8bf7-77434d42f3d3",
        "text":"2. The application for notification shall be accompanied by a description of the conformity assessment activities, the conformity assessment module or modules for which the conformity assessment body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation shall be added.",
        "title":"Amendment 2093: Article 31 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"08090f90-dd59-44b4-8cd5-d9da0782bee5",
        "text":"3. Where the conformity assessment body concerned cannot provide an accreditation certificate, it shall provide the notifying authority with all the documentary evidence necessary for the verification, recognition and regular monitoring of its compliance with the requirements laid down in Article 33. For notified bodies which are designated under any other Union harmonisation legislation, all documents and certificates linked to those designations may be used to support their designation procedure under this Regulation, as appropriate.",
        "title":"Amendment 2094: Article 32 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a63109a3-f38c-4b9c-be78-ec4c38bf9a67",
        "text":"1. Notifying authorities shall notify only conformity assessment bodies which have satisfied the requirements laid down in Article 33.",
        "title":"Amendment 2095: Article 32 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"80760d6e-4807-4d39-b4e9-130f1b95e893",
        "text":"3. The notification referred to in paragraph 2 shall include full details of the conformity assessment activities, the conformity assessment module or modules and the artificial intelligence technologies concerned, as well as the relevant attestation of competence.",
        "title":"Amendment 2096: Article 32 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"247727bf-f59f-45e9-bc0a-1eee18ffb802",
        "text":"3. The notification shall include full details of the conformity assessment activities, the conformity assessment module or modules concerned.",
        "title":"Amendment 2097: Article 32 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"813ecdf6-7c79-4fdb-90bd-fc6746e56dd3",
        "text":"4. The conformity assessment body concerned may perform the activities of a notified body only where no objections are raised by the Commission or the other Member States. within two weeks of the validation of the notification where it includes an accreditation certificate referred to in Article 31(2), or within two months of the notification where it includes documentary evidence referred to in Article 31(3).",
        "title":"Amendment 2098: Article 32 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2c1bcfee-7f63-4ab2-95cb-3ec25ba1b598",
        "text":"4. The conformity assessment body concerned may begin to perform the activities of a notified body only where no objections are raised by the Commission or the other Member States within one month of a notification.",
        "title":"Amendment 2099: Article 32 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c73db4ca-05d6-4775-b64b-cd8848ef0dad",
        "text":"4 a. Where objections are raised, the Commission shall without delay enter into consultation with the relevant Member States and the conformity assessment body. In view thereof, the Commission shall decide whether the authorisation is justified or not. The Commission shall address its decision to the Member State concerned and the relevant conformity assessment body.",
        "title":"Amendment 2100: Article 32 – paragraph 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"cb65ebc9-5c34-473c-9b9f-fb207691346d",
        "text":"2. Notified bodies shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive (…) on measures for a high common level of cybersecurity across the Union, repealing Directive (EU) 2016\/1148;",
        "title":"Amendment 2101: Article 33 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"22fea366-79dd-43ba-b813-75364c7f99e7",
        "text":"2 a. Notified bodies shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive XXXX\/XX on measures for a high common level of cybersecurity across the Union (NIS 2), repealing Directive (EU) 2016\/1148.",
        "title":"Amendment 2102: Article 33 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7e2711c2-0e94-4ca2-b94e-b89693cd51bb",
        "text":"4. Notified bodies shall be independent of the provider of a high-risk AI system in relation to which it performs conformity assessment activities. Notified bodies shall also be independent of any other operator having an economic interest in the high-risk AI system that is assessed, as well as of any competitors of the provider. Notified bodies and their employees should not have provided any service to the provider of a high-risk system for 12 months before the assessment. They should also commit not to work for the provider of a high-risk system assessed or a professional organisation or business association of which the provider of a high-risk system is a member for 12 months after their position in the auditing organisation has ended.",
        "title":"Amendment 2103: Article 33 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f3cb401c-006f-4214-8df0-727ae85a044e",
        "text":"4. Notified bodies shall be independent of the provider of a high-risk AI system in relation to which it performs conformity assessment activities. Notified bodies shall also be independent of any other operator having an economic interest in the high-risk AI system that is assessed, as well as of any competitors of the provider. This shall not preclude the use of assessed AI systems that are necessary for the operations of the conformity assessment body or the use of such systems for personal purposes.",
        "title":"Amendment 2104: Article 33 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"1327d6bc-6dd2-4d5f-a731-1e8ab6fb9dc9",
        "text":"6. Notified bodies shall have documented procedures in place ensuring that their personnel, committees, subsidiaries, subcontractors and any associated body or personnel of external bodies respect the confidentiality of the information which comes into their possession during the performance of conformity assessment activities, except when disclosure is required by law. The staff of notified bodies shall be bound to observe professional secrecy with regard to all information obtained in carrying out their tasks under this Regulation, except in relation to the notifying authorities of the Member State in which their activities are carried out. Any information and documentation obtained by notified bodies pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2105: Article 33 – paragraph 6  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"179eb73b-339d-4155-af3b-6c59f748e5d2",
        "text":"7. Notified bodies shall have procedures for the performance of activities which take due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of and risk posed by the AI system in question.",
        "title":"Amendment 2106: Article 33 – paragraph 7  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"653d6200-931c-4770-be46-a8fddbb6552d",
        "text":"10. Notified bodies shall have sufficient internal competences to be able to effectively evaluate the tasks conducted by external parties on their behalf. To that end, at all times and for each conformity assessment procedure and each type of high-risk AI system in relation to which they have been designated, the notified body shall have permanent availability of sufficient administrative, technical and scientific personnel who possess experience and knowledge relating to AI, data and data computing and to the requirements set out in Chapter 2 of this Title.",
        "title":"Amendment 2107: Article 33 – paragraph 10  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0ce0be75-de6e-491b-a6f7-d5878f30aeeb",
        "text":"3. Activities may be subcontracted or carried out by a subsidiary only with the agreement of the provider and the notifying authority.",
        "title":"Amendment 2108: Article 34 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e78f7f16-e6dc-439c-8334-6343f1371ff0",
        "text":"4. Notified bodies shall keep at the disposal of the notifying authority the relevant documents concerning the verification of the qualifications of the subcontractor or the subsidiary and the work carried out by them under this Regulation.",
        "title":"Amendment 2109: Article 34 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4798fa59-a588-4a7a-a738-97792b7917cc",
        "text":"1. Where a notifying authority has suspicions or has been informed that a notified body no longer meets the requirements laid down in Article 33, or that it is failing to fulfil its obligations, that authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw the notification as appropriate, depending on the seriousness of the failure. It shall also immediately inform the Commission and the other Member States accordingly.",
        "title":"Amendment 2110: Article 36 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9167a568-d9f7-4ea7-8d2a-6b9a1fe66618",
        "text":"1. The Commission shall investigate all cases where there are reasons to doubt whether a notified body complies with the requirements laid down in Article 33.",
        "title":"Amendment 2111: Article 37 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"48c374b6-89c0-434d-a6d8-e9c20fdfb55d",
        "text":"3. The Commission shall ensure that all sensitive information obtained in the course of its investigations pursuant to this Article is treated confidentially.",
        "title":"Amendment 2112: Article 37 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"71f80894-ae75-43f1-ba3c-631eb1c71c50",
        "text":"4. Where the Commission ascertains that a notified body does not meet or no longer meets the requirements laid down in Article 33, it shall adopt a reasoned decision requesting the notifying Member State to take the necessary corrective measures, including withdrawal of notification if applicable. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2113: Article 37 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"98c9c179-9a28-4a2c-be4c-2ba6e0b8dd09",
        "text":"4. Where the Commission ascertains that a notified body does not meet or no longer meets the requirements laid down in Article 33, it shall adopt a reasoned decision requesting the notifying Member State to take the necessary corrective measures, including withdrawal of notification if necessary. That request shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2114: Article 37 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"651b67b7-9fb4-4e09-b656-ea841db09048",
        "text":"1. The Commission shall ensure that, with regard to the areas covered by this Regulation, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures of AI systems pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. The coordination role will be held by the European Data Protection Supervisor.",
        "title":"Amendment 2115: Article 38 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"59406ce5-b157-450b-ba90-81db007587d0",
        "text":"2 a. The Commission shall provide for the exchange of knowledge and best practices between the Member States' national authorities responsible for notification policy.",
        "title":"Amendment 2116: Article 38 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"98d4f8ff-fb94-4a7c-8b53-a25fb8a8145e",
        "text":"deleted",
        "title":"Amendment 2117: Article 39  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"127feab8-dac5-478e-a382-d59a708f109e",
        "text":"1. In line with EU commitments under the World Trade Organization (WTO) Agreement on Technical Barriers to Trade (TBT), the Commission shall endeavour to maximise the acceptance of test results produced by competent conformity assessment bodies, independent of the territory in which they may be established, where necessary to demonstrate conformity with the applicable requirements of the Regulation.",
        "title":"Amendment 2118: Article 39 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"42f6c885-abb8-402e-8c2c-22bbc534e705",
        "text":"Conformity assessment bodies established under the law of a third country with which the Union has concluded an agreement in this respect may be authorised to carry out the activities of notified Bodies under this Regulation.",
        "title":"Amendment 2119: Article 39 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4795956d-503f-4e5d-bb3f-4efe4f3b6418",
        "text":"2. Conformity assessment bodies established under the law of a third country may carry out the activities of notified bodies under this regulation where they have been accredited as competent by an accreditation body, whether established in the territory of the EU or a third country, that is a signatory of an international accreditation or conformity assessment scheme based on rigorous peer-review processes, such as the International Laboratory Accreditation Collaboration (ILAC) Mutual Recognition Arrangement (MRA) and International Accreditation Forum (IAF) Multilateral Recognition Arrangement (MLA).",
        "title":"Amendment 2120: Article 39 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"93465697-8444-4a04-8212-7b4e32e666e5",
        "text":"3. In addition, where conformity assessment bodies established under the law of a third country have not been accredited by signatory bodies of such international accreditation or conformity assessment schemes, third-country conformity assessment bodies may carry out the activities of notified bodies where international mutual recognition arrangements, conformity assessment protocols, or other agreements exist between the EU and the country in which the conformity assessment body is established.",
        "title":"Amendment 2121: Article 39 – paragraph 1 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"953e1c78-259d-42f6-a9fb-8226fd055b16",
        "text":"1. High-risk AI systems which are in conformity with harmonised standards developed in accordance with Regulation 1025\/2021 or parts thereof the references of which have been published in the Official Journal of the European Union shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those standards cover those requirements.",
        "title":"Amendment 2122: Article 40 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5f2130bd-8a15-4914-9a15-f023d98652da",
        "text":"High-risk AI systems shall be in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union, to the extent those standards cover those requirements.",
        "title":"Amendment 2123: Article 40 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"db578cb3-5bf3-436f-bd5e-ad0f89cfbb45",
        "text":"2.When issuing a standardisation request to European standardisation organisations in accordance with Article 10 of Regulation (EU) 1025\/2012, the Commission shall specify that standards are coherent, including with sectorial legislation listed in Annex 2, easy to implement and drafted in such a way that they aim to fulfil in particular the following objectives:', \"(a) ensure that AI systems placed on the market or put into service in the Union are safe and respect Union values and strengthen the Union's digital sovereignty;\", '(b) take into account the concept of trustworthy AI set out in Article 4(a);', '(c) promote investment and innovation in AI, as well as competitiveness and growth of the Union market;', '(d) enhance multistakeholder governance, representative of allrelevant European stakeholders (e.g. industry, SMEs, civil society, researchers);', '(e) contribute to strengthening global cooperation on standardisation in the field of AI that is consistent with Union values and interests.', 'The Commission shall request the European standardisation organisations to provide evidence of their best efforts to fulfil the above objectives.",
        "title":"Amendment 2124: Article 40 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bbb06be3-16cb-4ef5-a22c-83b6475d4052",
        "text":"The Commission shall issue standardisation requests covering all essential requirements of this Regulation in accordance with Article 10 of Regulation 1025\/2012 no later than 6 months after the date of entry into force of this Regulation.",
        "title":"Amendment 2125: Article 40 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e0341b3c-de69-4853-8253-a6adb7aebfad",
        "text":"Harmonised standards shall be limited to technical specifications and procedures. Work organisation and ethical considerations are not applicable.",
        "title":"Amendment 2126: Article 40 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"6d66c157-ba46-44e1-9e31-0bead99c5927",
        "text":"When AI systems are intended to be deployed at the workplace, harmonised standards shall be limited to technical specifications and procedures.",
        "title":"Amendment 2127: Article 40 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4eb2ce0f-11e5-4382-a7a1-65c05cbd6b98",
        "text":"The Commission shall issue standardisation requests covering all essential requirements of the Regulation in accordance with Article 10 of Regulation (EU) No 1025\/2012 no later than 6 months after the date of entry into force of the Regulation.",
        "title":"Amendment 2128: Article 40 – paragraph 1 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cbb45d1c-213e-4c4e-a1d0-56bb4f5771ce",
        "text":"deleted",
        "title":"Amendment 2129: Article 41  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"64584914-be3b-4ea3-93ce-94848cb88156",
        "text":"1. The Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title for the essential requirements where health and safety, the protection of consumers or of the environment, other aspects of public interest, or clarity and practicability so require after consulting the Board, the Committee referred to in Art 22 of Regulation 1025\/20212 as well as the relevant stakeholders and where the following conditions have been fulfilled:', '(a) the Commissions has concluded, that contrary to Article 10(6) of Regulation (EU) No 1025\/2012 a harmonised standard does not satisfy the requirements which it aims to cover and which are set out in the corresponding Union harmonisation and has therefore not published a reference of such harmonised standard in the Official Journal of the European Union in accordance with Regulation (EU) No 1025\/2012;', '(b) the Commission has requested one or more European standardization organisations to draft a harmonised standard for the essential health and safety requirements and there are undue delays in the standardisation procedure;', '(c) the request has, without reason, not been accepted by the European standardization organisations concerned.', 'Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2130: Article 41 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"def42377-acd9-4fb5-9e78-52faca52d67e",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission shall issue a standardisation request to one or several of the European standardization organizations in accordance with Article 10 of Regulation 1025\/2012 and may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title, which shall only be valid until the requested harmonised standards have been elaborated and published in the Official Journal of the European Union. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2131: Article 41 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"164ce3be-75c4-4287-b9b1-01ff45d52d69",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).', 'The Commission shall adopt common specifications setting out how risk management systems should give specific consideration to interaction with or impact on children.",
        "title":"Amendment 2132: Article 41 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a8802938-c39f-45e7-af12-d81896c5d8e9",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist and are not expected to be published within a reasonable period or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2133: Article 41 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"28993126-3c33-4b6b-a586-e2868825a649",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist or relevant international standards do not apply or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2134: Article 41 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"cbfb9263-41e8-4c55-830a-33879937ed08",
        "text":"1. Where harmonised standards referred to in Article 40 and international standards do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2135: Article 41 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"1a0a2026-da6d-45a4-ab49-5aaaa770c815",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety, accessibility, or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2136: Article 41 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"339cda54-87c7-4ffe-a1a5-5a6d7ef9613e",
        "text":"1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient, because there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2137: Article 41 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"c3584e1b-905a-453c-b6c0-658eb395c225",
        "text":"1 a. When deciding to draft and adopt common specifications, the Commission shall consult the Board, the European standardisation organisations as well as the relevant stakeholders, and duly justify why it decided not to use harmonised standards. The abovementioned organisations shall be regularly consulted while the Commission is in the process of drafting the common specifications.",
        "title":"Amendment 2138: Article 41 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"ad5b2d8a-954a-49ff-be8b-7473a6c87d98",
        "text":"2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant stakeholders, including industry, start-ups, and SMEs, and of relevant bodies or expert groups established under relevant sectorial Union law.",
        "title":"Amendment 2139: Article 41 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c37deb97-49f4-415e-a3ae-3ccd8788712d",
        "text":"2. When preparing the common specifications referred to in paragraph 1, the Commission shall fulfil the objectives referred of Article 40(2) and gather the views of relevant bodies or expert groups established under relevant sectorial Union law.",
        "title":"Amendment 2140: Article 41 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a21ffe44-1057-4fba-9886-09911e9400eb",
        "text":"2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of stakeholders, including SMEs and start-ups, relevant bodies or expert groups established under relevant sectorial Union law.",
        "title":"Amendment 2141: Article 41 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5f8cba62-3de4-4d8b-bf3e-56d3460385fc",
        "text":"2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant bodies, stakeholders or expert groups established under relevant sectorial Union law.",
        "title":"Amendment 2142: Article 41 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"1c49e6d3-cebe-49b0-b0c0-9eb2f4239bfe",
        "text":"2. The Commission shall, before preparing the common specifications referred to in paragraph 1, consult relevant bodies, expert groups and other relevant stakeholders established under relevant sectorial Union law.",
        "title":"Amendment 2143: Article 41 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"d4f9af0b-1752-4334-9aa3-0cf432684a44",
        "text":"2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant bodies, stakeholders or expert groups established under relevant sectorial Union law.",
        "title":"Amendment 2144: Article 41 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"3c1d6bb8-5eb1-4501-92b2-611e8b7d16c5",
        "text":"deleted",
        "title":"Amendment 2145: Article 41 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"67484f25-b6d3-4f4d-a6ed-abd9131cd008",
        "text":"3. High-risk AI systems which are in conformity with the common specifications referred to in paragraph 1 shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those common specifications cover those requirements, and as long as those requirements are not covered by harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union in accordance with Regulation (EU) No 1025\/2012.",
        "title":"Amendment 2146: Article 41 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"780bb892-47b0-4d39-b730-32d206092ed0",
        "text":"deleted",
        "title":"Amendment 2147: Article 41 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"94fcf61f-5b9f-49ff-83fd-ef4348704ff4",
        "text":"4. Where providers do not comply with the common specifications referred to in paragraph 1, they shall duly justify that they have adopted technical solutions that meet the requirements referred to in Chapter 2 to a level at least equivalent thereto.",
        "title":"Amendment 2148: Article 41 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2599a032-bf84-4bb7-9b90-8a11640d1e4d",
        "text":"4. Where providers of high-risk AI systems do not comply with the common specifications referred to in paragraph 1, they shall duly justify that they have adopted technical solutions that are at least equivalent thereto.",
        "title":"Amendment 2149: Article 41 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"326b9d27-da90-46bd-a6d5-df34a388f990",
        "text":"4 a. If harmonised standards referred to in Article 40 are developed and the references to them are published in the Official Journal of the European Union in accordance with Regulation (EU) No 1025\/2012 in the future, the relevant common specifications shall no longer apply.",
        "title":"Amendment 2150: Article 41 – paragraph 4 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"b1fe9ec0-2ec2-4982-832b-e7a40f50c568",
        "text":"deleted",
        "title":"Amendment 2151: Article 42  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"fdfd8eaa-dbc5-4133-8e46-e76f5510795f",
        "text":"1. Taking into account their intended purpose, high-risk AI systems that have been trained and tested on data concerning the specific geographical, behavioural and functional setting within which they are intended to be used or are reasonably foreseeable to be used shall be presumed to be in compliance with the requirement set out in Article 10(4).",
        "title":"Amendment 2152: Article 42 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"501dc9bb-4a50-4405-8adc-22e96939caf1",
        "text":"1. Taking into account their foreseeable uses, high-risk AI systems that have been trained and tested on data concerning the specific geographical, behavioural and functional setting within which they are intended to be used shall be presumed to be in compliance with the requirement set out in Article 10(4).",
        "title":"Amendment 2153: Article 42 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4d12c9b5-f4d2-4f32-ae20-0b8b04eb8409",
        "text":"1. High-risk AI systems that have been trained and tested on data reflecting the specific geographical, behavioural and functional setting within which they are intended to be used shall be presumed to be in compliance with the respective requirements set out in Article 10(4).",
        "title":"Amendment 2154: Article 42 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"082946e6-0ace-48ac-9bbd-a09fef2d9bb1",
        "text":"2. High-risk AI systems that have been certified or for which a statement of conformity has been issued under a cybersecurity scheme to Regulation (EU) 2019\/881 of the European Parliament and of the Council63 or pursuant to other harmonization legislation in the field of security of network and information systems and electronic communications networks and services and the references of which have been published in the Official Journal of the European Union shall be presumed to be in compliance with the cybersecurity requirements set out in Article 15 of this Regulation in so far as the cybersecurity certificate or statement of conformity or parts thereof cover those requirements.' '63 Regulation (EU) 2019\/881 of the European Parliament and of the Council of 17 April 2019 on ENISA (the European Union Agency for Cybersecurity) and on information and communications technology cybersecurity certification and repealing Regulation (EU) No 526\/2013 (Cybersecurity Act) (OJ L 151, 7.6.2019, p. 1).",
        "title":"Amendment 2155: Article 42 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"989f733f-4da2-44fb-9b50-fbbbe8d67bfc",
        "text":"Third party conformity assessment",
        "title":"Amendment 2156: Article 43 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a3dbb0db-5246-4be3-8540-fcf91ea44430",
        "text":"1. For high-risk AI systems listed in point 1, 3 and 4 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.",
        "title":"Amendment 2157: Article 43 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ad0e795b-ec48-4201-b20a-5a194f2d4fa0",
        "text":"1. For high-risk AI systems listed in point 1 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.",
        "title":"Amendment 2158: Article 43 – paragraph 1 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9334b09c-e289-4b7a-9bc3-548a0d4d96c9",
        "text":"1. For high-risk AI systems listed in Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has not applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.",
        "title":"Amendment 2159: Article 43 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"cc4c0f11-700d-4de6-8364-8c2bf718ae6e",
        "text":"1. For high-risk AI systems listed in Annex III the provider shall have a conformity assessment carried out by an independent third-party, following the conformity assessment procedure set out in Annex VII.",
        "title":"Amendment 2160: Article 43 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"71980ca9-5403-4a0e-b755-48631b7df52d",
        "text":"1. For high-risk AI systems listed in point 1 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall opt for one of the following procedures:",
        "title":"Amendment 2161: Article 43 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"adf2518c-701e-4e18-9e74-8f8bb35cb41a",
        "text":"deleted",
        "title":"Amendment 2162: Article 43 – paragraph 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b6df8574-997e-4fcc-8d6e-1b5dcb88b09e",
        "text":"deleted",
        "title":"Amendment 2163: Article 43 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8b677a5c-0617-4e25-aeb3-ce5d72dbfdd3",
        "text":"deleted",
        "title":"Amendment 2164: Article 43 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"96e6f525-4691-442b-9a56-21519ed8c0ac",
        "text":"deleted",
        "title":"Amendment 2165: Article 43 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bc57e646-717b-439d-a79d-fae080b14950",
        "text":"(a) the conformity assessment procedure based on internal control referred to in Annex VI; or",
        "title":"Amendment 2166: Article 43 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3adeb669-032d-4285-93ef-75bf17e6feb3",
        "text":"deleted",
        "title":"Amendment 2167: Article 43 – paragraph 1 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"d0ab6969-3536-4a79-a989-865153196eb9",
        "text":"deleted",
        "title":"Amendment 2168: Article 43 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"54b014f7-da48-4391-8e56-967b91d6da89",
        "text":"deleted",
        "title":"Amendment 2169: Article 43 – paragraph 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d9f9b4d2-a708-45be-893c-66e6f06ff0e8",
        "text":"(b) the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, documentation of analysis and achievement of the tests of strict necessity, proportionality and legality of the system, as well as any associated database or data repository on which it relies; with the involvement of a notified body, referred to in Annex VII, and with the involvement of the relevant national data protection authority.",
        "title":"Amendment 2170: Article 43 – paragraph 1 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"de887ed1-eb9d-4bc4-9230-56316b9f8cd9",
        "text":"(b) the conformity assessment procedure based on assessment of the quality management system and technical documentation, with the involvement of a notified body, referred to in Annex VII.",
        "title":"Amendment 2171: Article 43 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"83a09905-2dd6-486b-83c1-b4fc40c856b3",
        "text":"deleted",
        "title":"Amendment 2172: Article 43 – paragraph 1 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b185dde7-a43d-4908-9dee-4bcb23886797",
        "text":"deleted",
        "title":"Amendment 2173: Article 43 – paragraph 1 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"fd81b7c0-ab18-42a1-bdf4-595e91124fd3",
        "text":"Where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has not applied or has applied only in part harmonised standards referred to in Article 40, or where such harmonised standards do not exist and common specifications referred to in Article 41 are not available, the provider shall follow the conformity assessment procedure set out in Annex VII. Should the provider already have established internal organisation and structures for existing conformity assessments or requirements under other existing rules, the provider may utilise those, or parts of those, existing compliance structures, so long as they also have the capacity and competence needed to fulfil the requirements for the product set out in this Regulation.",
        "title":"Amendment 2174: Article 43 – paragraph 1 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia"
    },
    {
        "uuid":"804504dc-137d-4921-9a35-377777430071",
        "text":"deleted",
        "title":"Amendment 2175: Article 43 – paragraph 1 – subparagraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"04e740bd-b5c0-4376-b7fb-c296ecbb74f0",
        "text":"deleted",
        "title":"Amendment 2176: Article 43 – paragraph 1 – subparagraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"c4da9ab5-7aa4-4d72-a364-c1e2b1ff2a3f",
        "text":"For the purpose of carrying out the conformity assessment procedure referred to in Annex VII, the provider may choose any of the notified bodies. However, when the system is intended to be put into service by law enforcement, immigration or asylum authorities as well as EU institutions, bodies or agencies, the market surveillance authority referred to in Article 63(5) or (6), as applicable, shall act as a notified body.",
        "title":"Amendment 2177: Article 43 – paragraph 1 – subparagraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"070ede4d-96cc-4ec9-ba06-8471c444ad44",
        "text":"1 a. Without prejudice to paragraph 1, if the provider has applied harmonised standard referred to in Article 40, or where applicable, common specifications referred to in Article 41, it shall follow the conformity assessment procedure based on internal control referred to in Annex VI.",
        "title":"Amendment 2178: Article 43 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"daa6bd2b-1f9d-4080-82fd-17623945e56d",
        "text":"1 b. In the following cases, the compliance of the high-risk AI system with requirements laid down in Chapter 2 of this Title shall be assessed following the conformity assessment procedure based on the assessment of the quality management system and the assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII:', '(a) where harmonised standards, the reference number of which has been published in the Official Journal of the European Union, covering all relevant safety requirements for the AI system, do not exist;', '(b) where the harmonised standards referred to in point (a) exist but the manufacturer has not applied them or has applied them only in part;', '(c) where one or more of the harmonised standards referred to in point (a) has been published with a restriction;', '(d) when the provider considers that the nature, design, construction or purpose of the AI system necessitate third party verification.",
        "title":"Amendment 2179: Article 43 – paragraph 1 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"b40f3e8b-b184-4d2e-92c1-11afd7078dbb",
        "text":"2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013\/36\/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.",
        "title":"Amendment 2180: Article 43 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"75e62346-245f-41b9-8e8a-3cc7a8571cd0",
        "text":"2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013\/36\/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.",
        "title":"Amendment 2181: Article 43 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7d25ac2e-0fc3-4634-9960-053722841e53",
        "text":"2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013\/36\/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.",
        "title":"Amendment 2182: Article 43 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"333053de-2fa0-4b74-a80c-87947026d581",
        "text":"2. For high-risk AI systems referred to in points 2 to 8 of Annex III, providers shall follow the conformity assessment procedure based on internal control as referred to in Annex VI, which does not provide for the involvement of a notified body. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013\/36\/EU, the conformity assessment based on internal control shall be verified by means of an ex-post assessment and carried out as part of the procedure referred to in Articles 97 to101 of that Directive but only to the extent that prudential risks and related requirements are concerned.",
        "title":"Amendment 2183: Article 43 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"44fc539e-c03b-4c12-ba98-7f165c9acd5d",
        "text":"2. For high-risk AI systems referred to in points 2 to 8 of Annex III, providers shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013\/36\/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.",
        "title":"Amendment 2184: Article 43 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"42ece877-d194-42c3-befa-801aef3adfa8",
        "text":"3. For high-risk AI systems, to which legal acts listed in Annex II, section A, apply, and which are subject to points 1 and 2 of Article 6 the provider shall follow the relevant conformity assessment as required under those legal acts. The requirements set out in Chapter 2 of this Title shall apply to those high-risk AI systems and shall be part of that assessment. Points 4.3., 4.4., 4.5. and the fifth paragraph of point 4.6 of Annex VII shall also apply.",
        "title":"Amendment 2185: Article 43 – paragraph 3 – subparagraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a5b95abe-73b8-4c27-8d90-38a3554d1521",
        "text":"deleted",
        "title":"Amendment 2186: Article 43 – paragraph 3 – subparagraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"08b0f265-6d1f-412f-aaa3-3c199fb25881",
        "text":"3a. High-risk AI systems shall periodically be subject to a conformity assessment review procedure.",
        "title":"Amendment 2187: Article 43 – paragraph 3 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud"
    },
    {
        "uuid":"07dae37f-4c79-4986-a57a-10a109c84251",
        "text":"4. High-risk AI systems, that have already been subject to a conformity assessment procedure, shall undergo a new conformity assessment procedure in line with the provisions foreseen by the legal acts listed in Annex II, section A, whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user.",
        "title":"Amendment 2188: Article 43 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2be90c0c-b715-4416-8872-c878fb843c32",
        "text":"4. High-risk AI systems shall undergo a new conformity assessment procedure whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user, or whenever a change occurs which may affect the compliance with this Regulation.",
        "title":"Amendment 2189: Article 43 – paragraph 4 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"db7209d1-d895-44e8-8d94-721233e785c3",
        "text":"4. High-risk AI systems shall undergo a new conformity assessment procedure whenever they are substantially modified and the changes could impact performance related to essential requirements, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user.",
        "title":"Amendment 2190: Article 43 – paragraph 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"498c48ea-3218-421f-a14b-511de7fba30d",
        "text":"4. High-risk AI systems that have already been subject to a conformity assessment procedure shall undergo a new conformity assessment procedure whenever they are substantially modified, if the modified system is intended to be further distributed or continues to be used by the current user.",
        "title":"Amendment 2191: Article 43 – paragraph 4 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"8573d97c-cc85-4c94-bcb6-a5abb8ffde9b",
        "text":"4. High-risk AI systems shall undergo a new third party conformity assessment procedure whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current deployer.",
        "title":"Amendment 2192: Article 43 – paragraph 4 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6cd99bd9-9cc5-498f-afc8-8b9d91a61b05",
        "text":"For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification. The same should apply to updates of the AI system for security reasons in general and to protect against evolving threats of manipulation of the system as long as the update does not include significant changes to the functionality of the system.",
        "title":"Amendment 2193: Article 43 – paragraph 4 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"93a1f8eb-930a-4c25-aaf2-8289b4a4c734",
        "text":"For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification. A new conformity assessment is always required whenever safety-related limits of continuing learning high-risk AI systems may be exceeded or have an impact on the health or safety.",
        "title":"Amendment 2194: Article 43 – paragraph 4 – subparagraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"463b122b-dd13-49dc-bb31-a70a34afa3fa",
        "text":"For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance shall constitute a substantial modification, including if they have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV.",
        "title":"Amendment 2195: Article 43 – paragraph 4 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"85ba2cca-0ce6-46f0-a326-d15cfffa650b",
        "text":"The same should apply to updates of the AI system for security reasons in general and to protect against evolving threats of manipulation of the system. This paragraph only applies if the Member State has established a legal framework, which allows the provider of a high risk AI system, which autonomously make substantial modifications to itself, to regularly perform an automated real-time conformity assessment procedure.",
        "title":"Amendment 2196: Article 43 – paragraph 4 – subparagraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8840843a-3501-4843-9a57-d88a24f23206",
        "text":"4 a. The specific interests and needs of the small-scale providers shall be taken into account when setting the fees for third-party conformity assessment under this Article, reducing those fees proportionately to their size and market size.",
        "title":"Amendment 2197: Article 43 – paragraph 4 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2cfc3693-529e-4d5b-a6b3-7bef849e6b74",
        "text":"4 a. Any provider may voluntarily apply for a third-party conformity assessment regardless of the risk level of their AI system.",
        "title":"Amendment 2198: Article 43 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"82baf3b9-94b1-4029-89c3-25e27e023192",
        "text":"deleted",
        "title":"Amendment 2199: Article 43 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"9edfdd3c-8689-4ec4-b5d1-602ac3ab288e",
        "text":"5. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annexes VI and Annex VII in order to amend elements of the conformity assessment procedures that become necessary or unnecessary in light of technical progress.",
        "title":"Amendment 2200: Article 43 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6c5609a7-9970-4542-9692-8d6539851fe5",
        "text":"5. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annexes VI and Annex VII in order to introduce elements of the conformity assessment procedures that become necessary in light of technical progress.",
        "title":"Amendment 2201: Article 43 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"79b50341-8685-4537-991b-672d39cf7dfb",
        "text":"5. The Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annex VII in order to introduce elements of the conformity assessment procedures that become necessary in light of technical progress.",
        "title":"Amendment 2202: Article 43 – paragraph 5  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"3c456084-550a-46e0-9b26-1d6330b822e8",
        "text":"deleted",
        "title":"Amendment 2203: Article 43 – paragraph 6  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"bb4d860c-0085-4195-9189-bc2251199532",
        "text":"deleted",
        "title":"Amendment 2204: Article 43 – paragraph 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f95845d4-0ab3-401a-b1bc-07005b244000",
        "text":"deleted",
        "title":"Amendment 2205: Article 43 – paragraph 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"bee68f50-4fb5-47e9-a5f1-09567443453b",
        "text":"deleted",
        "title":"Amendment 2206: Article 43 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"4fd1eccd-b148-4157-8820-f12ed6eddfdf",
        "text":"6. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2 in order to subject high-risk AI systems referred to in points 2 to 8 of Annex III to the conformity assessment procedure referred to in Annex VII or parts thereof. The Commission shall adopt such delegated acts taking into account the effectiveness of the conformity assessment procedure based on internal control referred to in Annex VI in preventing or minimizing the risks to health and safety and protection of fundamental rights posed by such systems as well as the availability of adequate capacities and resources among notified bodies.",
        "title":"Amendment 2207: Article 43 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"98df9660-ddb6-4cf2-bd6d-1f940e0afec7",
        "text":"6. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2 in order to subject high-risk AI systems referred to in points 2 to 8 of Annex III to the conformity assessment procedure referred to in Annex VII or parts thereof. The Commission shall adopt such delegated acts taking into account the effectiveness of the conformity assessment procedure based on internal control referred to in Annex VI in preventing or minimizing the risks to health and safety and protection of fundamental rights posed by such systems as well as the availability of adequate capacities and resources among notified bodies.",
        "title":"Amendment 2208: Article 43 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"9eb5d158-891d-4e46-a161-9af192a4894a",
        "text":"1. Certificates issued by notified bodies in accordance with Annex VII shall be drawn-up in the official Union language of the Member State in which the notified body is established.",
        "title":"Amendment 2209: Article 44 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"8f6af09c-1e41-4eef-a4bf-4c5a0df79044",
        "text":"3. Where a notified body finds that an AI system no longer meets the requirements set out in Chapter 2 of this Title, it shall suspend or withdraw the certificate issued or impose any restrictions on it, unless compliance with those requirements is ensured by appropriate corrective action taken by the provider of the system within an appropriate deadline set by the notified body. The notified body shall give reasons for its decision.",
        "title":"Amendment 2210: Article 44 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d5aa9562-e64a-4db8-83f4-17f860b88e73",
        "text":"2. Each notified body shall inform the other notified bodies and the notifying authority of:",
        "title":"Amendment 2211: Article 46 – paragraph 2 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9e93324b-b145-40ff-a1e4-d9761e76d96b",
        "text":"3. Each notified body shall provide the other notified bodies carrying out similar conformity assessment activities with relevant information on issues relating to negative and, on request, positive conformity assessment results.",
        "title":"Amendment 2212: Article 46 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ee71fd09-9519-4d55-a5d0-21d560415109",
        "text":"3. Each notified body shall provide the other notified bodies carrying out similar conformity assessment activities covering the same artificial intelligence systems with relevant information on issues relating to negative and, on request, positive conformity assessment results.",
        "title":"Amendment 2213: Article 46 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1b307eaf-d1ca-487d-b0ba-91b85fb357c0",
        "text":"deleted",
        "title":"Amendment 2214: Article 47  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a29e6ed1-4fb7-402d-9b25-168a15e65023",
        "text":"deleted",
        "title":"Amendment 2215: Article 47  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0cb7ef01-04b8-4482-b40d-aa53ad5ffcc4",
        "text":"1. By way of derogation from Article 43, any market surveillance authority may request a judicial authority to authorise the placing on the market or putting into service of specific high-risk AI systems within the territory of the Member State concerned, for exceptional reasons of public security or the protection of life and health of persons, environmental protection and the protection of key industrial and infrastructural assets. That authorisation shall be for a limited period of time, while the necessary conformity assessment procedures are being carried out, and shall terminate once those procedures have been completed. The completion of those procedures shall be undertaken without undue delay.",
        "title":"Amendment 2216: Article 47 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"097fa21d-9d5f-4b9f-ad22-18dc27397cad",
        "text":"1 a. In a duly justified situation of urgency for exceptional reasons of public security or in case of specific, substantial and imminent threat to the life or physical safety of natural persons, law enforcement authorities may put a specific high-risk AI system into service without the authorisation referred to in paragraph 1 provided that such authorisation is requested during or after the use without undue delay, and if such authorisation is rejected, its use shall be stopped with immediate effect.",
        "title":"Amendment 2217: Article 47 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d8ec85d2-2571-448e-8afd-9a814e0ccde7",
        "text":"2. The authorisation referred to in paragraph 1 shall be issued only if the market surveillance authority and judicial authority conclude that the high-risk AI system complies with the requirements of Chapter 2 of this Title. The market surveillance authority shall inform the Commission and the other Member States of any request made and any subsequent authorisation issued pursuant to paragraph 1.",
        "title":"Amendment 2218: Article 47 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f54455a3-6d1d-480b-89ad-97b9d62f4dbd",
        "text":"3. Where, within 15 calendar days of receipt of the information referred to in paragraph 2, no objection has been raised by either a Member State or the Commission in respect to the request of the maret surveillance authority for an authorisation issued by a market surveillance authority of a Member State in accordance with paragraph 1, that request shall be deemed justified.",
        "title":"Amendment 2219: Article 47 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6a011147-5852-4ab3-8499-f49954367655",
        "text":"4. Where, within 15 calendar days of receipt of the notification referred to in paragraph 2, objections are raised by a Member State against an authorisation issued by a market surveillance authority of another Member State, or where the Commission considers the authorisation to be contrary to Union law or the conclusion of the Member States regarding the compliance of the system as referred to in paragraph 2 to be unfounded, the Commission shall without delay enter into consultation with the relevant Member State; the operator(s) concerned shall be consulted and have the possibility to present their views. In view thereof, the Commission shall decide whether the authorisation is justified or not. The Commission shall address its decision to the Member State concerned and the relevant operator(s).",
        "title":"Amendment 2220: Article 47 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"eee70386-d8d6-4414-bd5e-396e642bc1fd",
        "text":"4. Where, within 15 calendar days of receipt of the notification referred to in paragraph 2, objections are raised by a Member State against a request issued by a market surveillance authority of another Member State, or where the Commission considers the request to be contrary to Union law or the conclusion of the Member States regarding the compliance of the system as referred to in paragraph 2 to be unfounded, the Commission shall without delay enter into consultation with the relevant Member State; the operator(s) concerned shall be consulted and have the possibility to present their views. In view thereof, the Commission shall decide whether the request is justified or not. The Commission shall address its decision to the Member State concerned and the relevant operator or operators.",
        "title":"Amendment 2221: Article 47 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"122067cf-5af9-40db-b489-0400f10a3c49",
        "text":"5. If the request is considered unjustified, this shall be withdrawn by the market surveillance authority of the Member State concerned.",
        "title":"Amendment 2222: Article 47 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"53664a1f-e5cc-4db8-8a4d-d6bc14f55c20",
        "text":"1. The notifying authority after third party conformity assessment shall draw up a written physical and machine-readable electronic EU declaration of conformity for each AI system and keep it at the disposal of the national competent authorities for 15 years after the AI system has been placed on the market or put into service. The EU declaration of conformity shall identify the AI system for which it has been drawn up. A copy of the EU declaration of conformity shall be given to the relevant national competent authorities upon request.",
        "title":"Amendment 2223: Article 48 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1a8b641c-bc90-4d06-86ec-ee2f29604d60",
        "text":"1. The provider shall draw up a written EU declaration of conformity for each high-risk AI system and keep it at the disposal of the national supervisory authority and the national competent authorities after the high-risk AI system has been placed on the market or put into service for the entire lifecycle of the high-risk AI system. A copy of the EU declaration of conformity shall be given to the national supervisory authority and the relevant national competent authorities upon request.",
        "title":"Amendment 2224: Article 48 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0f209349-bbfa-47d6-bd16-dc2f86b1deb9",
        "text":"1. The provider shall draw up a written or electronically signed EU declaration of conformity for each AI system and keep it at the disposal of the national competent authorities for 10 years after the AI system has been placed on the market or put into service. The EU declaration of conformity shall identify the AI system for which it has been drawn up. A copy of the EU declaration of conformity shall be submitted to the relevant national competent authorities upon request.",
        "title":"Amendment 2225: Article 48 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3f4607bb-35bc-4d71-9ba1-a785fe976240",
        "text":"2. The EU declaration of conformity shall state that the high-risk AI system in question meets the requirements set out in Chapter 2 of this Title, including the requirements related to the respect of the Union data protection acquis. The EU declaration of conformity shall contain the information set out in Annex V and shall be translated into an official Union language or languages required by the Member State(s) in which the high-risk AI system is placed on the market or made available.",
        "title":"Amendment 2226: Article 48 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6cd777d7-6c54-488c-bc40-aa68d47bb970",
        "text":"4. After receiving the EU declaration of conformity, the provider shall assume responsibility for continuous compliance with the requirements set out in Chapter 2 of this Title throughout the entire lifecycle.",
        "title":"Amendment 2227: Article 48 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"51ea7c78-c5e2-4271-ab55-44353545138c",
        "text":"5. After consulting the Board, the Commission shall be empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating the content of the EU declaration of conformity set out in Annex V in order to introduce elements that become necessary in light of technical progress.",
        "title":"Amendment 2228: Article 48 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"50b1a165-6674-46a3-b853-26da63b13d5a",
        "text":"1. The CE marking shall be in digital format for high-risk AI systems.",
        "title":"Amendment 2229: Article 49 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"c773e9ea-bbda-4c0e-8a6b-d3606950ca9b",
        "text":"1. The CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems before the high-risk AI system is placed on the market. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate. It may be followed by a pictogram or any other marking indicating a special risk or use.",
        "title":"Amendment 2230: Article 49 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6170814f-28f4-4870-ac3e-8a32899fd65e",
        "text":"1. The CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems before they are placed on the market, made available on the market or put into service. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.",
        "title":"Amendment 2231: Article 49 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c824610f-9935-4848-9cfb-72fff44f2d68",
        "text":"1. The physical CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.",
        "title":"Amendment 2232: Article 49 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"e7921ea1-203e-45fd-a8e2-6c9aab5dc878",
        "text":"1. The physical CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.",
        "title":"Amendment 2233: Article 49 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"95b89611-8cea-47b7-a175-c36d903d4f63",
        "text":"1 a. A digital CE marking may be used instead of or additionally to the physical marking if it can be accessed via the display of the product or via a machine-readable code or other electronic means.",
        "title":"Amendment 2234: Article 49 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"bf29c001-aab5-4600-a187-5049d784b3bd",
        "text":"1 a. An electronic CE marking may replace the physical marking if it can be accessed via the display of the product or via a machine-readable code.",
        "title":"Amendment 2235: Article 49 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cfb80296-905a-4383-8510-f0ccc43c7b01",
        "text":"3 a. Where high-risk AI systems are subject to other Union legislation which also provides for the affixing of the CE marking, the CE marking shall indicate that the high-risk AI system also fulfil the requirements of that other legislation.",
        "title":"Amendment 2236: Article 49 – paragraph 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"f8ce1849-6ab4-47b3-b549-c934f9a1b937",
        "text":"deleted",
        "title":"Amendment 2237: Article 50  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1ce4bdb8-b1ab-469a-baee-52fab6db068e",
        "text":"The provider shall, for the entire lifecycle of the AI system or for a period ending 10 years after the AI system has been placed on the market or put into service, whichever is the longest, keep at the disposal of the national competent authorities:",
        "title":"Amendment 2238: Article 50 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"11fc58a7-238a-45dc-aa0b-ff28159693a0",
        "text":"The provider shall, for a period ending five years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:",
        "title":"Amendment 2239: Article 50 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"7a4d354f-9226-4c08-81e4-5f8546b7bab0",
        "text":"The provider shall, for a period ending 15 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:",
        "title":"Amendment 2240: Article 50 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fa70d2ed-1f69-412e-9be7-f129d0cbeb13",
        "text":"The provider shall, for a period ending 5 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:",
        "title":"Amendment 2241: Article 50 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"792142c5-519d-4275-9055-65d1801815b4",
        "text":"The provider shall, for the entire lifecycle of the AI system, keep at the disposal of the national supervisory authority and the national competent authorities:",
        "title":"Amendment 2242: Article 50 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d2c6a0e2-f291-40a9-a044-245e3c19c5e5",
        "text":"deleted",
        "title":"Amendment 2243: Article 51  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"a45c9db3-6002-4e88-808d-8efa45cb46cd",
        "text":"Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2) and Article 6a, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2244: Article 51 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"6e8dc21e-aefd-462f-8ed0-2f55b8cd65b3",
        "text":"1. Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2), the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2245: Article 51 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"5a0736ab-16f6-4f64-8095-a3d121244779",
        "text":"Before placing on the market or putting into service an AI system, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2246: Article 51 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"96ebb53b-bdf7-489f-831c-7104b8ad9d61",
        "text":"Before placing on the market or putting into service a high-risk AI system referred to in Article 6, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2247: Article 51 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e10b26b5-df14-4ec5-94e2-47fe7d3bcbc0",
        "text":"Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2), the provider shall register that system in the EU database referred to in Article 60, in accordance with Article 60(2).",
        "title":"Amendment 2248: Article 51 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"eb13e103-ed1e-46b9-828d-c08fbfc155ff",
        "text":"Before placing on the market or putting into service a high-risk AI system listed in Annex III, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2249: Article 51 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"dd5cebb9-69a8-4bba-8fb4-492df506bfad",
        "text":"2. A high-risk AI system designed, developed, trained, validate, tested or approved to be placed on the market or put into service, outside the EU, can be registered in the EU database referred to in Article 60 and placed on the market or put into service in the EU only if it is proven that at all stages of its design, development, training, validation, testing or approval, all the obligations required from such AI systems in EU have been met;",
        "title":"Amendment 2250: Article 51 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"981be0fb-4317-4c66-b20c-08ee3809211a",
        "text":"Before using a high-risk AI system referred to in Article 6(2), the user or, where applicable, the authorised representative, shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each new use of a high-risk AI system.",
        "title":"Amendment 2251: Article 51 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"782a1447-5fff-428b-9f1c-abee85deab1e",
        "text":"Before putting into service or using a high-risk AI system in one of the areas listed in Annex III, users who are public authorities or Union institutions, bodies, offices or agencies or users acting on their behalf shall register in the EU database referred to in Article 60.",
        "title":"Amendment 2252: Article 51 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"317057a5-e0f4-4470-9072-d30b22d4e897",
        "text":"Before each deployment of, or substantial modification to, a high-risk AI system referred to in Article 6, the deployer or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",
        "title":"Amendment 2253: Article 51 – paragraph 1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8e9c7c88-7760-4b00-a887-e9bd8d53730f",
        "text":"Before using an AI system, public authorities shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each use of an AI system.",
        "title":"Amendment 2254: Article 51 – paragraph 1 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"c7c955fc-3f73-4793-a1cd-f8f1bf1a6c35",
        "text":"Before putting into service or using a high-risk AI system in accordance with Article 6(2), the user shall register in the EU database referred to in Article 60.",
        "title":"Amendment 2255: Article 51 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4e58ede4-95fd-4e82-aab6-6fe71ee40a44",
        "text":"Before using an AI system, public authorities shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each new use of an AI system.",
        "title":"Amendment 2256: Article 51 – paragraph 1 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"04243dfa-8349-4995-81f7-538b0f2e4f13",
        "text":"In case the provider or deployer is a public authority they shall register both high-risk AI systems and all other AI systems.",
        "title":"Amendment 2257: Article 51 – paragraph 1 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8c3ad5d6-1d1f-4e7e-852a-598e3a12688c",
        "text":"Article 51 a', 'Legal representative', '1. Where an operator pursuant to Article 2 is established outside the Union, they shall designate, in writing, a legal representative in the Union.', '2. The legal representative shall reside or be established in one of the Member States where the activities pursuant to Article 2, paragraphs 1 and 1a, are taking place.', '3. The operator shall provide its legal representative with the necessary powers and resources to comply with its tasks under this Regulation and to cooperate with the competent authorities.', '4. The legal representative shall, where appropriate, also carry out the following compliance tasks:', '(a) keep a copy of the EU declaration of conformity and the technical documentation at the disposal of the national supervisory authority and the national competent authorities and national authorities referred to in Article 63(7);', '(b) provide a national supervisory authority or a national competent authority, upon a reasoned request, with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law;', '(c) cooperate with the national supervisory authority or the national competent authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system;', '(d) where applicable, comply with the registration obligations as referred into Article 51.', '5. The legal representative shall be mandated to be addressed, in addition to or instead of the operator, by, in particular, national supervisory authority or the national competent authorities and affected persons, on all issues related to ensuring compliance with this Regulation.', '6. The legal representative may be held liable for infringements of this Regulation, without prejudice to any liability of or legal actions against the operator, user or provider.",
        "title":"Amendment 2258: Article 51 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d45c3c8b-d86e-4de5-a3e1-0a5f1c03c2f4",
        "text":"TRANSPARENCY OBLIGATIONS",
        "title":"Amendment 2259: Title IV  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"866df3eb-7f14-4355-b120-8b9edc4dfd46",
        "text":"Transparency obligations",
        "title":"Amendment 2260: Article 52 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ae0b81e6-80de-4928-9e2a-32c77579fbde",
        "text":"1. Providers shall ensure that AI systems intended to directly interact with natural persons are designed and developed in such a way that the AI system, the provider itself or the user can inform the natural person exposed to an AI system that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Where relevant, this information shall also include which functions are AI enabled, if there is human oversight and who is responsible for the decision-making process. This obligation shall not apply to AI systems authorised by law to detect, prevent, investigate and prosecute criminal offences, unless those systems are available for the public to report a criminal offence.",
        "title":"Amendment 2261: Article 52 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a77dddad-7c64-468b-95d7-f7f514f8e208",
        "text":"1. Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system.",
        "title":"Amendment 2262: Article 52 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"59a11475-6c67-4cd3-8c23-c2c658d74a24",
        "text":"1. Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use.",
        "title":"Amendment 2263: Article 52 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"ece67930-e638-4628-ba9e-b5ed69e8c512",
        "text":"1. Providers shall ensure that AI systems are designed and developed in such a way that natural persons are informed without delay that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. This shall also include information on which components and functions are supported through AI, information which main parameters the AI system takes into account, and information on human oversight and which person is responsible for decisions made or influenced by the system as well as information on rectification, redress rights and options.",
        "title":"Amendment 2264: Article 52 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"16feb58f-2dfa-44b8-ac82-511a73cea6ba",
        "text":"deleted",
        "title":"Amendment 2265: Article 52 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"bf978a7a-0b2f-4cb6-bb58-f7ee891d2c46",
        "text":"2. Deployers of a remote biometric recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto. This shall also include information on which components and functions are supported through AI, information which main parameters the AI system takes into account, and information on human oversight and which person is responsible for decisions made or influenced by the system as well as information on rectification, redress rights and options.",
        "title":"Amendment 2266: Article 52 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"56ca2e36-63c0-453a-87b5-75be3c82d91f",
        "text":"2. Users of an emotion recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto.",
        "title":"Amendment 2267: Article 52 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"e8b3def0-f329-40b3-bcf9-ef15a2656fe4",
        "text":"2. Users of an emotion recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto.",
        "title":"Amendment 2268: Article 52 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,"
    },
    {
        "uuid":"06a26cf2-e054-4e7e-a81f-8c8962d42b15",
        "text":"3. Users of an AI system that generates or manipulates audio or visual content that would falsely appear to be authentic or truthful and which features depictions of people appearing to say or do things they did not say or do, without their consent (‘deep fake’), shall disclose that the content has been artificially generated or manipulated. Disclosure shall mean labelling the content in a way that informs that the content is inauthentic and that is clearly visible for the recipient of that content. To label the content, users shall take into account the generally acknowledged state of the art and relevant harmonised standards and specifications.",
        "title":"Amendment 2269: Article 52 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"53a5e92c-9da3-4bed-b045-9f62c5d3e03d",
        "text":"3. Users of an AI system that generates or manipulates image, audio, text, script or video content that appreciably resembles existing persons, objects, places, text, script or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose that the content has been artificially generated or manipulated.",
        "title":"Amendment 2270: Article 52 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"4e943ab1-49f0-4805-892c-0c10ca79a739",
        "text":"3. Users of an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose, in an appropriate, clear and visible manner, that the content has been artificially generated or manipulated.",
        "title":"Amendment 2271: Article 52 – paragraph 3 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"498256a2-c42c-4e4b-b2e4-d191d684a6f4",
        "text":"3. Deployers of an AI system other than those in paragraphs 1 or 2, that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose that the content has been artificially generated or manipulated.",
        "title":"Amendment 2272: Article 52 – paragraph 3 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bbc7bf19-8f8a-4ed3-b356-175978a1f2af",
        "text":"deleted",
        "title":"Amendment 2273: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"db89a336-58c4-4bbc-981a-54771eb99ba0",
        "text":"deleted",
        "title":"Amendment 2274: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"9c8d0352-5b82-4a7d-82b3-27561c1c2d62",
        "text":"However, the first subparagraph shall not apply where the use of an AI system that generates or manipulates audio or visual content is authorized by law to detect, prevent, investigate and prosecute criminal offences or where the content forms part of an evidently creative, satirical, artistic or fictional cinematographic, video game visuals or analogous work or it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.",
        "title":"Amendment 2275: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"41d51122-1da3-4a5e-936b-bfa64dbda2b8",
        "text":"However, the first subparagraph shall not apply where it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.",
        "title":"Amendment 2276: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"8670dd4b-70fc-45d6-b4b5-49fc473a7b5f",
        "text":"However, the first subparagraph shall not apply where the use is authorised by law to detect, prevent, investigate and prosecute criminal offences and shall be without prejudice to the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and to appropriate safeguards for the rights and freedoms of third parties.",
        "title":"Amendment 2277: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"1d8fc337-d20b-4a70-b6d9-ffa06f8074cb",
        "text":"However, the first subparagraph shall not apply where the content is part of an obviously artistic, creative or fictional cinematographic work or it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.",
        "title":"Amendment 2278: Article 52 – paragraph 3 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"62c9ae25-c832-4113-9238-5e2ebec85760",
        "text":"3 a. Providers shall ensure that recommendation systems used to disseminate and order cultural and creative content are designed in such a way that the personalised suggestion is explainable and non-discriminatory. A clear explanation regarding the parameters determining ranking shall be provided to users and shall be easily accessible. Natural persons shall have the right to opt out of recommended and personalised services. This opt-out possibility shall be easily accessible and not prevent from using the core service.",
        "title":"Amendment 2279: Article 52 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"4be5a7b7-1299-4b56-957d-5762109a7341",
        "text":"3 a. The obligations in paragraphs 1, 2 and 3 shall be without prejudice to Union law on delaying information of subjects in ongoing criminal investigations, and be without prejudice to the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.",
        "title":"Amendment 2280: Article 52 – paragraph 3 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"238a8945-cc5c-403f-b2ef-6b0c5217e455",
        "text":"3 a. The information referred to in paragraphs 1 to 3 shall be provided to natural persons in a clear and visible manner at the latest at the time of the first interaction or exposure.",
        "title":"Amendment 2281: Article 52 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"acddf44e-5606-43bb-b9c4-cf8a9f24b895",
        "text":"4. The information in paragraphs 1, 2 and 3 shall be provided in an accessible, easy to understand, yet comprehensive manner, at least in one of the languages of the Member State in which the system was made available, and shall not affect the requirements and obligations set out in Title III of this Regulation.",
        "title":"Amendment 2282: Article 52 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1372812b-6ff8-449b-bcd2-1e10e503f3a4",
        "text":"Article 52 a', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of AI systems subject to transparency obligations under Article 52 by adding AI systems that affect individuals or to which they are subject, where: the AI systems pose a risk of manipulation, harm to the health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity or probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the systems already referred to in Article52.', '2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk that is equivalent to or greater than the risk of harm posed by the AI systems already referred to in Article 52, the Commission shall take into account the following non-cumulative criteria:', 'a. the intended purpose of the AI system, or the reasonably foreseeable consequences of its use;', 'b. the extent to which an AI system poses a risk of manipulation, or of adversely impacting one or more fundamental rights in a manner which could be to some degree mitigated by additional transparency measures;', 'c. the extent to which the use of an AI system impairs natural persons’ agency, autonomy of choice or may lead to or already has led to developing addictive behaviour;', 'd. the extent to which the use of an AI system may lead to or has already led to price discrimination or other form of economic harm;', 'e. the extent to which the use of an AI system may lead to or has already led to negative societal effects such as increased polarisation of opinions, insufficient exposure to objective sources of information and amplification of illegal online content.', 'f. the extent to which an AI system has been used or is likely to be used;', 'g. the extent to which the use of an AI system has already been shown to pose a risk in the senses of points b) to e) above, has caused harm to health and safety or disproportionate impact on fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'h. the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect aparticular group of persons disproportionately;', 'i. the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome or from the functionality of the service which relies on the AI system;', 'j. the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers, or age;', 'k. the extent to which the outcome produced with an AI system is not easily reversible, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;', 'l. the extent to which existing Union legislation lacks: i. effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages; ii. effective measures to prevent or substantially minimise those risks.",
        "title":"Amendment 2283: Article 52 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"99a64120-0f24-41ca-849d-d8577327d10c",
        "text":"Article 52 a', 'General purpose AI systems', '1. The placing on the market, putting into service or use of general purpose AI systems shall not, by themselves only, make those systems subject to the provisions of this Regulation.', '2. Any person who places on the market or puts into service under its own name or trademark or uses a general purpose AI system made available on the market or put into service for an intended purpose that makes it subject to the provisions of this Regulation shall be considered the provider of the AI system subject to the provisions of this Regulation.', '3. Paragraph 2 shall apply, mutatis mutandis, to any person who integrates a general purpose AI system made available on the market, with or without modifying it, into an AI system whose intended purpose makes it subject to the provisions of this Regulation.', '4. The provisions of this Article shall apply irrespective of whether the general purpose AI system is open source software or not.",
        "title":"Amendment 2284: Article 52 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"56a00f73-db4e-454f-bb5f-c80b3aa85b89",
        "text":"Article 52 a', 'Limitations for deep fakes of persons', 'Notwithstanding Article 52 and subject to appropriate safeguards for the rights and freedoms of third parties, the use of AI systems that generate or manipulate image, audio or video content that appreciably resembles existing persons and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall be permitted only', '(a) when used for the exercise of the rights to freedom of expression and to artistic expression, or', '(b) with the explicit consent of the affected persons.",
        "title":"Amendment 2285: Article 52 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"71ab3de3-31ba-471c-9ec6-f15b03aedbcc",
        "text":"Title GENERAL PURPOSE AI SYSTEMS Article 52a (new):Establishment of the Navigator Programme for General purpose AI systems 1.A ‘Navigator Programme for General purpose AI systems’ (the ‘Navigator Programme’) is established and reports to the European AI Board referred to in Article 56. 2.The Navigator Programme shall provide advice and assistance to the Commission in order to: (a) Develop, maintain and enforce a Code of Practice for General purpose AI systems research and development. (b) Coordinate and contribute to the effective cooperation of the Commission and the developers of general purpose AI systems. (c) Assist the Commission in ensuring the enforcement of this Regulation to general purpose AI systems (d) Advise the Commission on the development or alteration of regulatory measures concerning general purpose AI systems to preserve fundamental rights, health and safety of citizens 3.The Navigator Programme shall be composed of staff selected for having the competences most appropriate to fulfill the Navigator Programme’s functions.External experts from government, civil society and academia may be invited on an ad hoc basis to advise on the issues related to the Navigator Programme’s tasks.The Navigator Programme may invite observers to attend its non-confidential meetings and may hold exchanges with interested third parties to an appropriate extent.To that end the Commission may facilitate exchanges between the Navigator Programme and other Union bodies, offices, agencies and advisory groups. 4.The modalities and rules of procedure of the Navigator Programme shall be set out in accordance with the internal rules of the Commission.The modalities shall also contain the operational aspects related to the execution of the Navigator Programme’s tasks as listed in paragraph 7 of this Article. 5.The Navigator Programme shall have a sufficient number of competent personnel for assistance in the proper performance of its tasks. 6.The Navigator Programme shall be organised and operated so as to safeguard the independence, objectivity and impartiality of its tasks.The Navigator Programme shall document and implement a structure and procedures to safeguard impartiality and to promote and apply the principles of impartiality throughout its tasks. 7.When providing advice and assistance to the Commission in the context of paragraph 2, the Navigator Programme shall in particular: (a) Navigate developers of general purpose AI systems in the legal implications of their work for the health and safety and fundamental rights of EU citizens. (b) Assign a staff member for each identified team of developers of General purpose AI systems to have direct bilateral monthly conversations on relevant advances and implications of the General purpose AI system in question.These conversations shall cover: (i) the latest progress and experimentation in the general purpose AI system team including findings related to unexpected behaviors and upcoming research projects, (ii) design measures taken to identify and mitigate risks prior to development, (iii) demonstrations (‘demos’) of new versions of the model and of its compliance-by-design features, (iv) steps to take to manage the model’s implications for fundamental rights, health and safety in line with this Regulation, (v) measures in place within the developers team for quality assurance and risk management and in the design of upcoming general purpose system for accuracy, robustness and control, (vi) the current usage of the general purpose AI system by other providers, including the estimated number of end-users affected by the general purpose AI system’s output monthly, the sectoral, functional, geographic and demographic distribution of applications based on the general purpose AI system, the novel applications, etc. (vii) the adequacy of the self-regulatory measures and of the help provided by the authorities for compliance with the Code of Practice, (viii) the adequacy of the Code of Practice in helping fulfill this Regulation objective of AI adoption and the protection of citizens’ fundamental rights, health and safety and societal interest of the Union, (ix) the state of the art of general purpose AI system research and development and the identification of new competing development teams worldwide that would benefit from joining the Navigator Programme. (c) Build and maintain mutual understanding and a common evidence base over the years on general purpose AI systems, their implications, and measures to govern them. (d) Build and maintain trust-based relationships with the developers. (e) Gain expertise on the topic of general purpose AI systems and transfer this expertise as appropriate to all decisions taken by the Commission related to AI systems. (f) Issue opinions, recommendations or written contributions on matters related to the application of the Union’s regulations to general purpose AI systems. (g) Develop, maintain and update a database of identified general purpose AI systems with assessment of their influence. (h) Develop, maintain and update a list of upcoming general purpose AI systems research and development projects by developer teams of existing general purpose AI systems, 8.The conversations and correspondence generated in the scope of the Navigator Programme shall be covered by a strict confidentiality agreement. 9.In particular, the staff members of the Navigator Programme may not share with each other confidential or commercially sensitive information about their assigned general purpose AI system. 10.The Navigator Programme shall have documented procedures in place ensuring that its personnel, observers, external experts, subcontractors and any associated body or personnel of external bodies respect the confidentiality of the information which comes into their possession during the performance of its tasks, except when disclosure is required by law.The staff of the Navigator Programme shall be bound to observe professional secrecy with regard to all information obtained in carrying out their tasks under this Regulation.The staff of the Navigator Programme shall undergo a cooldown period of 5 years after interruption of their contract during which they may not gain from the confidential information they have acquired, neither through entrepreneurial ventures nor contracts nor employments. 11.Any information and documentation obtained by the Navigator Programme and its staff during the performance of their duty shall be treated in compliance with the confidentiality obligations set out in Article 70. 12.The Code of Practice for general purpose AI systems research and development (the ‘Code of Practice’) shall be drawn following consultation with the developers of identified General purpose AI systems and shall aim to protect fundamental rights, health and safety of EU citizens by considering compliance with proportionate requirements at the design stage (‘compliance-by-design’).The Code of Practice shall be updated yearly in consultation with developers of general purpose AI systems, academics, civil society and national competent authorities in order to be adapted to the evolution of the technology, the progress of the technical safeguards and the maturity and effectiveness of existing institutional safeguards surrounding general purpose AI systems. 13.The developers of general purpose AI systems shall comply with the Code of Practice before allowing their general purpose AI systems to be adapted or used or integrated into AI systems or software put into service or made available on the market or to citizens.The Navigator Programme shall assist in their compliance.14.The Code of Practice and the list of systems whose compliance with it is monitored by the Navigator Programme shall be made public.",
        "title":"Amendment 2286: Title IV a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"0b071b40-da8f-4161-bc29-ccbab6ef3c05",
        "text":"Rights of affected persons Article 52 a 1.Natural persons have the right not to be subject to non-compliant AI systems.The placing on the market, putting into service or use of non-compliant AI system gives rise to the right of the affected natural persons subject to such non-compliant AI systems to seek and receive redress. 2.Natural persons have the right to be informed about the use and functioning of AI systems they have been or may be exposed to, particularly in the case of high-risk and other regulated AI systems, according to Article 52. 3.Natural persons and public interest organisations have the right to lodge a complaint before the relevant national supervisory authorities against a producer or user of non-compliant AI systems where they consider that their rights or the rights of the natural persons they represent under the present regulation have been violated, and have the right receive effective remedy.",
        "title":"Amendment 2287: Title IV a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"74a9a786-8ac9-4d6f-bfb4-9d5d1b587096",
        "text":"1. The competent authorities of the Member States shall establish several physical and digital AI regulatory sandboxes six months prior to the entry into application of this Regulation based on well-established criteria that provide a controlled environment that facilitates the development, testing and validation of innovative AI systems before their placement on the market or putting into service pursuant to a specific plan. SMEs, start-ups, enterprises, innovators or other relevant actors could be included as partners in the regulatory sandboxes. This shall take place under the direct supervision and guidance by the respective national competent authorities or by the European Data Protection Supervisor in relation to AI systems provided by the EU institutions, bodies and agencies with a view to identify risks to health and safety and fundamental rights, test mitigation measures for identified risks, demonstrate prevention of these risks and otherwise ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. The Commission shall play a complementary role, allowing those Member States with demonstrated experience with sandboxing to build on their expertise and, on the other hand, assisting and providing technical understanding and resources to those Member States that seek guidance on the set-up and running of these regulatory sandboxes.",
        "title":"Amendment 2288: Article 53 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"68fc4450-979a-4e45-acb5-f2acbd971564",
        "text":"1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. Following a fundamental rights impact assessment, as laid out in Article 9a, this shall take place under the direct supervision and guidance by the competent authorities with a view to identifying risks in particular to the environment, health and safety, and fundamental rights, ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. Access to the regulatory sandboxes shall require providers to apply for participation. Supervising authorities shall inform applicants of their decision within 3 months of the application, or, in justified cases, of an extension of this deadline by at most another 3 months. The supervising authority shall inform the European Artificial Intelligence Board of the provision of regulatory sandboxes.",
        "title":"Amendment 2289: Article 53 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"4e127bdc-d66c-4979-847c-f3af81317286",
        "text":"1. AI regulatory sandboxes established by the Commission in collaboration with one or more Member States competent authorities or the European Data Protection Supervisor, are considered high risk and shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. They shall operate in full compliance with the General Data Protection Regulation. This shall take place under the direct supervision and guidance by the Commission in collaboration with competent authorities with a view to identifying risks to health and safety and fundamental rights, testing mitigation measures for identified risks, demonstrating prevention of these risks and otherwise ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. AI regulatory sandboxes shall remain a technical solution, shall assess potentialadverse effects and not be used on the employment context.",
        "title":"Amendment 2290: Article 53 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2240b9e2-8405-4d62-a012-1ff4d66ec413",
        "text":"1. AI regulatory sandboxes established by SMEs, start-ups, enterprises and other innovators, one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. For Member States competent authorities or the European Data Protection Supervisor, this shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. For SMEs, start-ups, enterprises and other innovators, this shall take place independently from supervising authorities, while following rules and regulations (e.g. a Code of conduct) established in cooperation with Member State competent authorities.",
        "title":"Amendment 2291: Article 53 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Tomislav Sokol"
    },
    {
        "uuid":"bec8abb1-9d9e-49a9-9838-4a23f27f4e4b",
        "text":"1. AI regulatory sandboxes established by SMEs, start-ups, enterprises and other innovators, one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. For Member States competent authorities or the European Data Protection Supervisor, this shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. For SMEs, start-ups, enterprises and other innovators, this shall take place independently from supervising authorities, while following rules and regulations established in close cooperation with Member State competent authorities.",
        "title":"Amendment 2292: Article 53 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"1c0ba65a-e138-4d2e-95fc-309baa11988d",
        "text":"1. Member States shall establish AI regulatory sandboxes, which shall be operational by [24 months following the entering into force of this Regulation], and shall ensure that the competent authorities responsible for the regulatory sandboxes have sufficient resources available to fulfil their duties effectively and in a timely manner. Regulatory sandboxes can also be established at local, regional or European level.",
        "title":"Amendment 2293: Article 53 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0773cd1e-a694-44e7-b1e7-15a0d9fc34ae",
        "text":"1. AI regulatory sandboxes established by the European Commission, one or more Member States, or other competent entities shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place in collaboration with and guidance by the European Commission or the competent authorities in order to identify risks to health and safety and fundamental rights, test mitigation measures for identified risks, demonstrate prevention of these risks and otherwise ensure compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.",
        "title":"Amendment 2294: Article 53 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"5dcc5d08-df3e-4526-b44f-d5901932d647",
        "text":"1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised. Consultation with AI vendors on the technological feasibility of the guidance from the competent authorities should be possible as part of the proces.",
        "title":"Amendment 2295: Article 53 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"a83f3fce-ef7e-40ee-889c-ed03769fb991",
        "text":"1. National supervisory authorities or the European Data Protection Supervisor may establish AI regulatory sandboxes that shall provide a controlled environment facilitating the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation.",
        "title":"Amendment 2296: Article 53 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"ac405132-8411-49fd-a940-9f3f60ca3869",
        "text":"1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.",
        "title":"Amendment 2297: Article 53 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"d27fb005-33ca-42ab-a469-b860229496d6",
        "text":"1 a. AI regulatory sandboxes established by one or more Member States, by local, regional, or national competent authorities, by the Commission or by the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.",
        "title":"Amendment 2298: Article 53 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"52850976-e4f3-4ff8-9c45-d9193635d721",
        "text":"1 a. This article shall also apply to AI systems for which full compliance with the requirements of Title III Chapter 2 requires an initial phase of placing the systems on the market or putting them into service and using the experiences gained in such initial phase to further develop the AI system so as to fully fulfil the requirements of Title III Chapter 2, particularly for the case of general purpose AI Systems.",
        "title":"Amendment 2299: Article 53 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e9d6e9c0-fccd-4fc0-87dc-5a64adf4913e",
        "text":"1 a. The AI regulatory sandbox shall allow and facilitate cooperation with the private sector on technical test environments aimed at risk assessment, AI use cases and the involvement of notified bodies, standardisation bodies, and other relevant stakeholders when relevant.",
        "title":"Amendment 2300: Article 53 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"b01312c1-7b03-44dd-99a0-103a39f7d177",
        "text":"1 a. National supervisory authorities may establish AI regulatory sandboxes jointly with other national supervisory authorities.",
        "title":"Amendment 2301: Article 53 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"43a24948-c5f2-4552-bde4-3dec93abe8b2",
        "text":"1 b. The national competent authority or the European Data Protection Supervisor, as appropriate, may also supervise testing in real world conditions upon the request of participants in the sandbox.",
        "title":"Amendment 2302: Article 53 – paragraph 1 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8edf40ea-bf2d-4cb1-9738-8b4fe6c9b89c",
        "text":"1 c. 1c.The establishment of AI regulatory sandboxes as defined in paragraph 1 shall aim to contribute to the following objectives:', '(a) foster innovation and competiveness and facilitate the development of an AI ecosystem;', '(b) facilitate and accelerate access to the Union market for AI systems, including provided by small and medium enterprises (SMEs) and start-ups;', '(c) improve legal certainty through cooperation with the authorities involved in the AI regulatory sandbox with a view to ensuring compliance with this Regulation and, where appropriate, with other Union and Member States legislation;', '(d) enhance authorities’ understanding of the opportunities and risks of AI systems as well as of the suitability and effectiveness of the measures for preventing and mitigating those risks;', '(e) contribute to the uniform and effective implementation of this Regulation and, where appropriate, its swift adaptation, notably as regards the techniques in Annex I, the high-risk AI systems in Annex III, the technical documentation in Annex IV;', '(f) contribute to the development or update of harmonised standards and common specifications referred to in Articles 40 and 41 and their uptake by providers.",
        "title":"Amendment 2303: Article 53 – paragraph 1 c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c42596cb-bff5-4548-abb1-bdcd243aab43",
        "text":"2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox established by one or more Member States competent authorities or the European Data Protection Supervisor. Without prejudice to the Regulation (EU) 2016\/679, start-ups, SMEs, enterprises and other innovators may request access to personal data from relevant national authorities to be used in their AI sandbox under the guidelines defined through Member State rules and regulations (e.g. Code of conduct).",
        "title":"Amendment 2304: Article 53 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Tomislav Sokol"
    },
    {
        "uuid":"304dd45d-4d25-4c3c-ad3e-a23f96af76d0",
        "text":"2. Member States in collaboration with the Commission shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox. As appropriate, national competent authorities may allow for the involvement in the AI regulatory sandbox of other actors within the AI ecosystem such as national or European standardisation organisations, notified bodies, testing and experimentation facilities, research and experimentation labs and innovation hubs.",
        "title":"Amendment 2305: Article 53 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b7ca3519-1cd5-4536-8022-e08c49d804da",
        "text":"2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access personal data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox established by one or more Member States competent authorities or the European Data Protection Supervisor. Start-ups, SMEs, enterprises and other innovators may request access to personal data from relevant national authorities to be used in their AI sandbox under the guidelines defined through Member State rules and regulations.",
        "title":"Amendment 2306: Article 53 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"327feba9-4be3-4143-ae17-c04737724125",
        "text":"2. The national supervisory authority shall ensure that to the extent the innovative AI systems involve the processing of personal data, the national data protection authorities are associated to the operation of the AI regulatory sandbox.",
        "title":"Amendment 2307: Article 53 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2a8646c6-cccf-4cdf-94f1-77efdf145bc4",
        "text":"2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data, or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox and involved in the control of those aspects of the sandbox it supervises to the full extent of its respective powers.",
        "title":"Amendment 2308: Article 53 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b0bcfde6-1aac-4007-ba79-20453179c4f7",
        "text":"2. The European Commission in collaboration with Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.",
        "title":"Amendment 2309: Article 53 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-"
    },
    {
        "uuid":"02dd80aa-67e0-407e-b8da-808c76ad1138",
        "text":"2. The Commission in collaboration with Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.",
        "title":"Amendment 2310: Article 53 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"c1eba8fc-b200-4278-ac9b-5b5f2ab623fd",
        "text":"2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to personal data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.",
        "title":"Amendment 2311: Article 53 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"61187208-723e-4d57-8863-53347e516a35",
        "text":"2 a. Access to the AI regulatory sandboxes and supervision and guidance by the relevant authorities shall be free of charge, without prejudice to exceptional costs that national competent authorities may recover in a fair and proportionate manner. It shall be open to any provider or prospective provider of an AI system who fulfils national eligibility and selection criteria and who has been selected by the national competent authorities or by the European Data Protection Supervisor. Participation in the AI regulatory sandbox shall be limited to a period that is appropriate to the complexity and scale of the project in any case not longer than a maximum period of 2 years, starting upon the notification of the selection decision. The participation may be extended for up to 1 more year.",
        "title":"Amendment 2312: Article 53 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1c2b80b1-d5eb-4f44-8a25-1673b7d1229e",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to democracy, the environment, health and safety and fundamental rights identified during the development and testing of such systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place, or, where mitigating measures cannot be identified that stop and remedy such significant risk or harm, Member States shall ensure that the competent authorities have the power to permanently suspend the development and testing process. In the case of abuse, competent authorities shall have the power to ban providers from applying for and participating in the regulatory sandbox for a limited amount of time or indefinitely. Decisions to suspend or ban providers from participating in regulatory sandboxes shall be submitted without delay to the European Artificial Intelligence Board. Applicants shall have access to remedies.",
        "title":"Amendment 2313: Article 53 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"13698eb1-3cce-408e-b4f3-5cbda2689673",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Regulatory sandboxes involving activities that may impact health, safety and fundamental rights, democracy and rule of law or the environment shall be developed in accordance with redress-by-design principles. Any significant risks identified during the development and testing of such systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place.",
        "title":"Amendment 2314: Article 53 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e1f85b9c-8f3e-45f5-99ab-cffa1ceeadf0",
        "text":"3. The participation in the AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities supervising the sandbox. However, provided that the participant(s) respect the sandbox plan and the terms and conditions for their participation and follow in good faith the guidance given by the authorities, no administrative enforcement action shall be taken by the authorities for infringement of applicable Union or Member State legislation.",
        "title":"Amendment 2315: Article 53 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2e8ef9c1-4566-4a33-a0e2-3949c6a317d7",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to fundamental rights, health, safety or the environment identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.",
        "title":"Amendment 2316: Article 53 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"5f5bd14e-5b72-48a3-afde-ea24709cea10",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety, fundamental rights and the environment identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.",
        "title":"Amendment 2317: Article 53 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"12924814-885f-4174-a912-6978e4d8217b",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety and fundamental rights identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.",
        "title":"Amendment 2318: Article 53 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"4b0c40d2-281f-442e-8f6b-3e8c971cc643",
        "text":"3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety and fundamental rights identified during the development and testing of AI systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place.",
        "title":"Amendment 2319: Article 53 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Tomislav Sokol"
    },
    {
        "uuid":"fe72a109-a269-42ad-8bb7-9ffde02ee6c0",
        "text":"4. Participants in the AI regulatory sandbox shall remain liable under applicable Union and Member States liability legislation for any harm intentionally inflicted on third parties as a result from the experimentation taking place in the sandbox, which was known or reasonably foreseeable at the time of experimentation and the risk of which the sandbox participants was not made aware of.",
        "title":"Amendment 2320: Article 53 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"600d1ae0-28e0-4dc9-832e-9bb276661b50",
        "text":"4. Participants in the AI regulatory sandbox shall remain liable under applicable Union and Member States liability legislation for any harm inflicted on third parties as a result of the experimentation taking place in the sandbox.",
        "title":"Amendment 2321: Article 53 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"2ab1fbd3-0f28-4716-a45d-63a2a4771e78",
        "text":"4 a. The AI regulatory sandboxes shall be designed and implemented in such a way that, where relevant, they facilitate cross-border cooperation between national competent authorities and synergies with relevant sectoral regulatory sandboxes. Cooperation may also be envisaged with third countries outside the Union establishing mechanisms to support AI innovation.",
        "title":"Amendment 2322: Article 53 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4ecbe68a-05a2-4eea-8bf1-8ff3015c60cf",
        "text":"5. Member States’ competent authorities in collaboration with the Commission shall establish AI regulatory sandboxes, as much as possible through national and regional initiatives, in particular through European digital innovation hubs, and closely coordinate their activities as well as cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. The annual reports or abstracts shall be made available to the public, online, in order to further enable innovation within the Union. Outcomes and learnings of the sandbox should be leveraged when monitoring the effectiveness and enforcement of this Regulation and taken into account when proceeding to amending it. The annual reports shall also be submitted to the AI Board which shall publish on its website a summary of all good practices, lessons learnt and recommendations.",
        "title":"Amendment 2323: Article 53 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"84e0c347-0fef-49df-9401-138eb3e07cbe",
        "text":"5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union, in respect of protecting trade secrets and innovative business and technical ideas.",
        "title":"Amendment 2324: Article 53 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Morten Løkkegaard"
    },
    {
        "uuid":"fc18332c-f4f3-4ffb-baa3-3db7f04f4921",
        "text":"5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results of the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. SMEs, start-ups, enterprises and other innovators shall submit annual reports to Member States’ competent authorities and share their good practices, lessons learnt and recommendations on their AI sandboxes.",
        "title":"Amendment 2325: Article 53 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"6043cf73-506f-41f0-9296-b0228203a8ed",
        "text":"5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. SMEs, start-ups, enterprises and other innovators are invited to share their good practices, lessons learnt and recommendations on their AI sandboxes with Member State competent authorities.",
        "title":"Amendment 2326: Article 53 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Tomislav Sokol"
    },
    {
        "uuid":"0b086d1e-f950-4669-8634-ebc28bebb656",
        "text":"5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application and possible revision of this Regulation and other Union legislation supervised within the sandbox, in particular with regards to easing burdens and introducing further regulation where additional risks and potential harms are identified.",
        "title":"Amendment 2327: Article 53 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bfaa0283-5361-4b01-aad3-e4315e5ce513",
        "text":"5. The national supervisory authority that has established the AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results of the implementation of those schemes, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union.",
        "title":"Amendment 2328: Article 53 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"1958345f-ac03-4d3c-b0cd-1b270fad3bce",
        "text":"5. The European Commission, Member States’ competent authorities and other entities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Commission’s AI Regulatory Sandboxing programme. The European Commission shall submit annual reports to the European Artificial Intelligence Board on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.",
        "title":"Amendment 2329: Article 53 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej"
    },
    {
        "uuid":"7a334c64-335a-4a8b-ba03-afca3c1e55de",
        "text":"5. National competent authorities shall coordinate their activities and cooperate within the framework of the AI Office. They shall submit annual reports to the AI Office and the Commission on the results of the implementation of those scheme, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation another Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union.",
        "title":"Amendment 2330: Article 53 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"9c38ba94-4d48-4d70-99bc-83af858b23df",
        "text":"5. The Commission, Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.",
        "title":"Amendment 2331: Article 53 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"86454640-78ce-4d41-9f9a-e4f0759515a7",
        "text":"5. Member States’ competent authorities that have established AI regulatory sandboxes shall cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.",
        "title":"Amendment 2332: Article 53 – paragraph 5  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"7ddc957e-08e1-4c90-a70d-4a64832f35d5",
        "text":"5 a. Regulatory sandboxes shall allow and facilitate the testing of possible adaptations of the regulatory framework governing artificial intelligence in order to enhance innovation or reduce compliance costs, without prejudice to the provisions of this Regulation or to the health, safety, fundamental rights of natural persons or to the values of the Union as enshrined in Article 2 TEU. The results and lessons learned from such tests shall be submitted to the AI Office and the Commission.",
        "title":"Amendment 2333: Article 53 – paragraph 5 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"359858fe-2457-4e3b-9bc5-f896a94066ac",
        "text":"6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out in implementing acts. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2) no later than 12 months following the entry into force of this Regulation and shall ensure, inter alia:', '(a) that they allow start-ups to use their participation in the sandbox in order to fulfil, in a guided environment with significantly reduced costs, the conformity assessment obligations of this Regulation or the voluntary application of the codes of conduct referred to in Article 69;', '(b) that adequate resources are dedicated to the establishment and functioning of the regulatory sandboxes so that the regulatory sandboxes can ensure broad access and keep up with demand for participation without creating disincentivising backlogs or delays;', '(c)that procedures, processes, and bureaucratic requirements for application, selection, participation, and exiting the sandbox are simple, easily intelligible, clearly communicated, and streamlined so as to facilitate the participation of startups with limited legal and bureaucratic capacities;', '(d) that procedures, processes, and bureaucratic requirements for application, selection, participation, and exiting the sandbox are streamlined across the Union and that participation in a regulatory sandbox established by a Member State by virtue of its obligation in paragraph 1 or by the Commission is uniformly recognised and carries the same legal effects across the Union.",
        "title":"Amendment 2334: Article 53 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"5a5eeedd-1525-4c9e-8be0-8ac4d2d8f4e6",
        "text":"6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out by the European Artificial Intelligence Board in close cooperation with the Member States’ and competent authorities. A list of planned and current sandboxes, including the modalities, conditions, eligibility criteria and application, selection, participation procedure shall be made publicly available by the European Artificial intelligence Board.",
        "title":"Amendment 2335: Article 53 – paragraph 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"1497b647-41bc-4e2c-bb36-4f1f76473c79",
        "text":"6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be discussed with all the relevant actors of the AI value chain, such as research institutions and businesses, and set out in implementing acts. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2336: Article 53 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"dd5f35d5-dbe5-4304-8b78-3559ae5370aa",
        "text":"6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out in implementing acts in accordance with the Council’s communication(11\/2020) and in strong cooperation with relevant stakeholders. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",
        "title":"Amendment 2337: Article 53 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"889d9628-b4ae-4a51-8c8c-7caed901bf0f",
        "text":"6 a. The modalities referred to in Article 53(6) shall ensure at least the following: (a) participants in the regulatory sandboxing system, in particular small-scale providers, are granted access to pre-deployment services, such as preliminary registration of AI system, insurance, compliance and R&D support services, and to all the other relevant elements of the Union’s AI ecosystem and other Digital Single Market initiatives such as testing and experimentation facilities, digital hubs, centers of excellence, testing and experimentation facilities, and EU benchmarking capabilities; and to other value-adding services such as standardization and certification, community social platform and contact databases, tenders and grant making portal and lists of potential investors. (b) foreign providers, in particular small-scale providers, are eligible to take part in the regulatory sandboxes to incubate and refine their products in compliance with this Regulation. (c) individuals such as researchers, entrepreneurs, innovators and other pre-market ideas owners are eligible to take part in the regulatory sandboxes to incubate and refine their products in compliance with this Regulation. (d) there be as little fragmentation as possible of the regulatory sandboxes across Member States, notably through development of a single interface and contact point at the EU level to interact with the regulatory sandbox ecosystem and through the Commission facilitating the creation of transnational and EU-wide regulatory sandboxes",
        "title":"Amendment 2338: Article 53 – paragraph 6 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6ee6b264-28ed-44ed-abd4-c118ad778cdc",
        "text":"6 a. Notwithstanding the modalities and conditions outlined in paragraph 6, Member States shall design regulatory sandboxes to provide access to as many providers as possible. There shall be aparticular focus on the use and application of general purpose AI systems. Member States may establish virtual sandboxing environments to ensure that sandboxes can meet the demand.",
        "title":"Amendment 2339: Article 53 – paragraph 6 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b4bbc45a-a941-4520-ae83-2e27bafd5aec",
        "text":"6 a. The Commission shall establish an EU AI Regulatory Sandboxing Programme whose modalities referred to in Article 53(6) shall cover the elements set out in Annex IXa. The Commission shall proactively coordinate with national, regional and also local authorities, as relevant.",
        "title":"Amendment 2340: Article 53 – paragraph 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej"
    },
    {
        "uuid":"8411d8a8-c748-4e8b-9dc2-ae982a42c38f",
        "text":"6 a. The Commission shall draw up guidelines for the proper establishment, development, implementation, functioning, and supervision of regulatory sandboxes.",
        "title":"Amendment 2341: Article 53 – paragraph 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e0a1d9ce-18be-47d8-bb59-ec7dd8396704",
        "text":"6 b. The Commission shall establish an EU AI Regulatory Sandboxing Work Programme whose modalities referred to in Article 53(6) shall cover the elements set out in Annex IXa. The Commission shall proactively coordinate with national and local authorities, where relevant.",
        "title":"Amendment 2342: Article 53 – paragraph 6 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"73f5e27d-d119-470a-b2ab-a54f6a008f5a",
        "text":"deleted",
        "title":"Amendment 2343: Article 54  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8820856a-0601-4265-8b07-4a27e2d0f4c2",
        "text":"deleted",
        "title":"Amendment 2344: Article 54  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"fc2bd70d-976b-4846-8b14-feb1a62c5466",
        "text":"deleted",
        "title":"Amendment 2345: Article 54  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"877ac28c-751d-40eb-90b7-0f5e4ae3c8f6",
        "text":"1. In the AI regulatory sandbox personal data and data protected by intellectual property rights or trade secrets lawfully collected for other purposes shall be processed solely for the purposes of developing and testing certain AI systems in the sandbox under the following conditions:",
        "title":"Amendment 2346: Article 54 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"edc42a47-1389-43f2-b7e0-2ef1650bd711",
        "text":"1. In the AI regulatory sandbox personal data lawfully collected for other purposes shall be processed for the purposes of developing and testing certain innovative AI systems in the sandbox when all of the following conditions are met:",
        "title":"Amendment 2347: Article 54 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"20dddb26-cb51-46d7-b5a3-a0d18f7aeb86",
        "text":"1. In the AI regulatory sandbox personal data lawfully collected for other purposes may be processed for the purposes of developing and testing certain innovative AI systems in the sandbox under the following conditions:",
        "title":"Amendment 2348: Article 54 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"76ca219c-e6dd-43c8-9d88-860a9af2cf73",
        "text":"(a) the AI systems shall be developed for safeguarding substantial public interest in one or more of the following areas:",
        "title":"Amendment 2349: Article 54 – paragraph 1 – point a – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"07cbc748-fff9-4bbe-8b3c-5a9183eb3589",
        "text":"(a) the innovative AI systems shall be developed for safeguarding public interest in one or more of the following areas:",
        "title":"Amendment 2350: Article 54 – paragraph 1 – point a – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"072cf208-cc6f-4d14-9d05-2e8f4f0bf019",
        "text":"deleted",
        "title":"Amendment 2351: Article 54 – paragraph 1 – point a – point i  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e2be5a68-84ba-402e-aaf2-b9aa00460265",
        "text":"(i) the investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against threats to public security, under the control and responsibility of the competent authorities. The processing shall be based on Member State or Union law;",
        "title":"Amendment 2352: Article 54 – paragraph 1 – point a – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Malik Azmani, Svenja Hahn, Alin Mituța"
    },
    {
        "uuid":"bb24c399-517c-465e-a30e-ed6778c75467",
        "text":"(iii) a high level of protection and improvement of the quality of the environment, and to counter and remedy the climate crisis;",
        "title":"Amendment 2353: Article 54 – paragraph 1 – point a – point iii  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b30c61d3-92ca-4b52-af71-5469a35ad4b0",
        "text":"(aa) natural persons whose personal data are used for the development and testing of certain innovative AI systems in the sandbox shall be informed of the collection and use of their data and shall have given their consent thereto;",
        "title":"Amendment 2354: Article 54 – paragraph 1 – point a a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9850bb74-f40b-42cd-98bb-628b1fc1f244",
        "text":"(c) there are effective monitoring mechanisms to identify if any high risks to the rights and freedoms of the data subjects, as referred to in Art 35 Regulation (EU) 2016\/679 and in Article 35 of Regulation (EU) 2018\/1725 may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing;",
        "title":"Amendment 2355: Article 54 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"c9daa212-ce1f-481c-8404-909389c7568b",
        "text":"(c) there are effective monitoring mechanisms to identify if any risks to the fundamental rights of the data subjects and holders of intellectual property rights or trade secrets may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing;",
        "title":"Amendment 2356: Article 54 – paragraph 1 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"381e18b3-638f-47cd-a95b-94599af25150",
        "text":"(d) any personal data or data protected by intellectual property rights or trade secrets to be processed in the context of the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the participants and only authorised persons have access to those data;",
        "title":"Amendment 2357: Article 54 – paragraph 1 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c489153c-12b0-48c4-92c2-336f5b2c44ef",
        "text":"(e) any personal data processed are not be transmitted, transferred or otherwise accessed by other parties that are not participants in the sandbox nor transferred to a third country outside the Union or an international organisation;",
        "title":"Amendment 2358: Article 54 – paragraph 1 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"9cefecff-7f5b-4312-9097-05a911bc4ea1",
        "text":"(e) any personal data or data protected by intellectual property rights or trade secrets processed are not be transmitted, transferred or otherwise accessed by other parties;",
        "title":"Amendment 2359: Article 54 – paragraph 1 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"63feab38-4193-4783-8604-af19f3bf7e2c",
        "text":"(f) any processing of personal data in the context of the sandbox shall not affect the application of the rights of the data subjects as provided for under Union law on the protection of personal data, in particular in Article 22 of Regulation (EU) 2016\/679 and Article 24 of Regulation (EU) 2018\/1725;",
        "title":"Amendment 2360: Article 54 – paragraph 1 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"ed46a210-7a49-48e1-81eb-e2b25e0ba8d0",
        "text":"(g) any personal data processed in the context of the sandbox are protected by means of appropriate technical and organisational measures and deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period;",
        "title":"Amendment 2361: Article 54 – paragraph 1 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"44a29a18-dd8e-492f-8861-3883067adb10",
        "text":"(g) any personal data or data protected by intellectual property rights or trade secrets processed in the context of the sandbox are deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period;",
        "title":"Amendment 2362: Article 54 – paragraph 1 – point g  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6894546f-d4b4-4945-8ba2-1454fa0ceaf8",
        "text":"(h) the logs of the processing of personal data in the context of the sandbox are kept for the duration of the participation in the sandbox;",
        "title":"Amendment 2363: Article 54 – paragraph 1 – point h  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"549b3baf-9923-4b83-9da3-d94400000d19",
        "text":"(h) the logs of the processing of personal data or data protected by intellectual property rights or trade secrets in the context of the sandbox are kept for the duration of the participation in the sandbox and 1 year after its termination, solely for the purpose of and only as long as necessary for fulfilling accountability and documentation obligations under this Article or other applicable Union or Member States legislation;",
        "title":"Amendment 2364: Article 54 – paragraph 1 – point h  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"67ac1b21-e405-4a39-a577-0ef4bfaaee5e",
        "text":"(j) a short summary of the AI project developed in the sandbox, its objectives, hypotheses and expected results, and non-confidential testing results, is published on the website of the competent authorities.",
        "title":"Amendment 2365: Article 54 – paragraph 1 – point j  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"d8eee792-855c-42e2-b59f-e8e545b6c437",
        "text":"(j) a short summary of the AI system developed in the sandbox, its objectives and expected results published on the website of the competent authorities.",
        "title":"Amendment 2366: Article 54 – paragraph 1 – point j  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"8f78bcae-9319-4063-a9c8-eac00390f540",
        "text":"1 a. Provided that the conditions of paragraph 1 are met, personal data processed for developing and testing innovative AI systems in the sandbox shall be considered compatible for the purposes of Article 6(4) GDPR.",
        "title":"Amendment 2367: Article 54 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"64350098-65a4-4ec9-afee-c24c7bb68925",
        "text":"2. Paragraph 1 further specifies Article 89 of Regulation (EU) 2016\/679 and is without prejudice to Union or Member States legislation excluding processing for other purposes than those explicitly mentioned in that legislation or to Union or Member States legislation excluding the use of data protected by intellectual property or trade secrets under the conditions covered by Paragraph 1.",
        "title":"Amendment 2368: Article 54 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"62bc2daf-16f4-4a09-8394-fed81cb5e1bf",
        "text":"Article 54 a', 'Promotion of AI research and development in support of socially and environmentally beneficial outcomes', '1. Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels, including within the sandboxes, for communication with projects to provide guidance and respond to queries about the implementation of this Regulation.', '2. Without prejudice to Article 55 a (new)1(a), Member States shall ensure that relevant projects are led by civil society and social stakeholders that set the project priorities, goals, and outcomes.",
        "title":"Amendment 2369: Article 54 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"5d8e6457-5213-42d0-bfb0-9edbfd394065",
        "text":"Measures for providers and users that are SME’s or start-ups",
        "title":"Amendment 2370: Article 55 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a398d0f0-4112-4df4-8baa-aade94456d68",
        "text":"Measures for small-scale providers and deployers', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)",
        "title":"Amendment 2371: Article 55 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9bb21925-ac8f-49a8-b7bd-83c075cd5f58",
        "text":"Measures for SMEs, start-ups and users",
        "title":"Amendment 2372: Article 55 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"9fb13f8c-9058-435c-9a39-3622e06d47d0",
        "text":"1. The national supervisory authority shall undertake the following actions:",
        "title":"Amendment 2373: Article 55 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"660bc3b9-e155-46b6-8ce2-3de75daca9ae",
        "text":"(a) provide SMEs and start-ups with priority access to and make AI regulatory sandboxes reusable as well as affordable to the extent that SMEs and start-ups fulfil the eligibility conditions;",
        "title":"Amendment 2374: Article 55 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d98a43f5-0070-4d22-8146-ed9e84c73519",
        "text":"(a) provide SMEs and start-ups with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;",
        "title":"Amendment 2375: Article 55 – paragraph 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"b7dc3070-2dcf-4efa-ad98-b9ae4b1b7753",
        "text":"(b) organise specific awareness raising and training activities about the application of this Regulation tailored to the needs of SME’s and start-ups;",
        "title":"Amendment 2376: Article 55 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"444eb6e5-0fc9-4cd2-8761-ebb1a3213bde",
        "text":"(b) organise specific awareness raising activities about the application of this Regulation tailored to the needs of SMEs, sart-ups and users;",
        "title":"Amendment 2377: Article 55 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"cf4fbb4d-9ca2-4cee-be66-bdc5046fe270",
        "text":"(c) where appropriate, establish a dedicated channel for communication with SME’s and start-ups and user and other innovators to provide guidance and respond to queries about the implementation of this Regulation;",
        "title":"Amendment 2378: Article 55 – paragraph 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c7b562d4-b4e4-4a24-8147-e2b8c9b243ba",
        "text":"(c) where appropriate, establish a dedicated channel for communication with SMEs, start-ups, users and other innovators to provide guidance and respond to queries about the implementation of this Regulation.",
        "title":"Amendment 2379: Article 55 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"764c07bc-c7db-4f10-84c6-b471f5154b7d",
        "text":"(c a) consult representative organisations of SMEs and start ups and involve them in the development of relevant standards;",
        "title":"Amendment 2380: Article 55 – paragraph 1 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1203f99c-6ab0-44f2-81dd-203505f54645",
        "text":"(c a) support SME's increased participation in the standardisation development process;",
        "title":"Amendment 2381: Article 55 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"b0920530-9ebb-4f20-b077-76bfb9f438e8",
        "text":"(c b) create development paths and services for SMEs and start ups, ensuring that government support is provided at all stages of their development, in particular by promoting digital tools and developing AI transition plans;",
        "title":"Amendment 2382: Article 55 – paragraph 1 – point c b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c09f4baa-55bb-4e3a-9ccc-67029c486179",
        "text":"(c c) promote industry best practices and responsible approaches toAI development and use self-regulatory commitments as a criterion for public procurement projects or as a factor that allows more opportunities to use andshare data responsibly;",
        "title":"Amendment 2383: Article 55 – paragraph 1 – point c c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3df3ff98-0de0-4e74-bea9-6de67700344e",
        "text":"(c d) offer tax breaks for doing research, better access to computer capacities and datasets, an EU-Visa schema for tech-talents, temporary support in technology scouting or in paying salaries of AI specialists, and state aid exemptions in the area of AI education, training and reskilling of employees;",
        "title":"Amendment 2384: Article 55 – paragraph 1 – point c d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0e6fbd2e-3e38-4f2d-9841-9c35b4f737b1",
        "text":"(c e) reduce extensive reporting, information or documentation obligations, establish a single EU online portal in different languages concerning all necessary procedures and formalities to operate in another EU country, a single point of contact in the home country that can certify the company’s eligibility to provide services in another EU country as well as a standardized EU-wide VAT declaration in the respective native language.",
        "title":"Amendment 2385: Article 55 – paragraph 1 – point c e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1c7764b9-7bb5-42d3-994b-d2c6877dfb2b",
        "text":"2. The specific interests and needs of the SME’s and start-ups shall be taken into account when setting the fees for conformity assessment under Article 43, reducing those fees proportionately to their size and market size, by granting subsidies or even exempting SMEs and start ups from paying.",
        "title":"Amendment 2386: Article 55 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e6b32a38-bc43-4d2a-b9d0-5977a5fdbe6a",
        "text":"2. The specific interests and needs of the SMEs and start-ups shall be taken into account when setting the fees for conformity assessment under Article 43, reducing those fees proportionately to their size and market size.",
        "title":"Amendment 2387: Article 55 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"1ad0cd7c-94bd-41ab-814c-134d62852518",
        "text":"Article 55 a', 'Promoting research and development of AI in support of socially and environmentally beneficial outcomes led by civil society', '1. Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels for communication with projects to provide guidance and respond to queries about the implementation of this Regulation.', '2. Member States shall ensure that when conformity assessment is required under Article 43, cost of such assessment is covered by public, including EU, funds available for AI research and development.', '3. Without prejudice to Article 55 a (new)1(a), Member States shall ensure that relevant projects are led by civil society and social stakeholders that set the project priorities, goals, and outcomes.",
        "title":"Amendment 2388: Article 55 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1cd96434-ad1b-4889-928e-272871fc4fde",
        "text":"Article 55 a', 'Promoting research and development of AI in support of socially and environmentally beneficial outcomes', 'Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels for communication with projects to provide guidance and respond toqueries about the implementation of this Regulation.",
        "title":"Amendment 2389: Article 55 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"8b6ed818-6bfa-4cda-b307-21de1934407a",
        "text":"Article 55 b', 'Right not to be subject to non-compliant AI systems', 'Natural persons shall have the right not to be subject to AI systems that:', '(a) pose an unacceptable risk pursuant to Article 5, or', '(b) otherwise do not comply with the requirements of this Regulation.",
        "title":"Amendment 2390: Article 55 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4f7a8a35-524a-472a-8e5b-92809dbc4e57",
        "text":"Article 55 c', 'Right to information about the use and functioning of AI systems', '1. Natural persons shall have the right to be informed that they have been exposed to high-risk AI systems as defined in Article 6, and other AI systems as defined in Article 52.', '2. Natural persons shall have the right to be provided upon request, with an explanation for decisions producing legal effects or otherwise affecting them or outcomes related to them taken by or with the assistance of systems within the scope of this Regulation, pursuant to Article 52 paragraph (3b).', '3. The information outlined in paragraphs 1 and 2 shall be provided in a clear, easily understandable and intelligible way, in a manner that is accessible for persons with disabilities.",
        "title":"Amendment 2391: Article 55 c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b1e354f1-75da-4e0d-8190-192e79a82a9d",
        "text":"1 European Artificial Intelligence Office",
        "title":"Amendment 2392: Title VI – Chapter 1 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Alin Mituța"
    },
    {
        "uuid":"b33f5a91-0f84-42dc-b656-1014dcc0a942",
        "text":"deleted",
        "title":"Amendment 2393: Article 56  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"0249003b-e16f-4829-851c-04ba27c7d014",
        "text":"Establishment of the European Artificial Intelligence Office",
        "title":"Amendment 2394: Article 56 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ed8bd78e-19f9-4955-8369-687fe80a452a",
        "text":"European Artificial Intelligence Board",
        "title":"Amendment 2395: Article 56 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3f1f9545-d8f4-4071-a48a-d538188e19d7",
        "text":"European Artificial Intelligence Board",
        "title":"Amendment 2396: Article 56 – title  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"dcb2e906-fb00-4499-92cf-e4a50a9652a8",
        "text":"deleted",
        "title":"Amendment 2397: Article 56 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c14fc84e-2cca-4457-a162-5faa90b61034",
        "text":"1. A ‘European Artificial Intelligence Board’ (the ‘Board’) is established as an independent body with its own legal personality. The Board shall have a Secretariat, a strong mandate as well as sufficient resources and skilled personnel at its disposal for the assistance in the performance of its tasks laid down in Article 58.",
        "title":"Amendment 2398: Article 56 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b396d1e4-cd09-4ec9-a4af-87cc54ba6b68",
        "text":"1. An independent ‘European Artificial Intelligence Board’ (the ‘Board’) is hereby established as a body of the Union and shall have legal personality.",
        "title":"Amendment 2399: Article 56 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"dc63ba20-8962-4ffb-8c62-239bcffaa9e3",
        "text":"1. A ‘European Artificial Intelligence Board’ (the ‘Board’) is established as a body of the Union and shall have legal personality.",
        "title":"Amendment 2400: Article 56 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"f02d21c4-ca8f-45ca-a0bc-4ec04d49da52",
        "text":"1 a. The Board shall monitor and ensure the effective and consistent application, and contribute to the effective and consistent enforcement, of this Regulation throughout the Union, including with regard to cases involving two or more Member States as set out in Article 59b.",
        "title":"Amendment 2401: Article 56 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"8031cda6-ae23-47db-9463-c71f22e540fc",
        "text":"1 a. The Board shall be independent in the fulfilment of its task. It shall have legal personality.",
        "title":"Amendment 2402: Article 56 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ae43d794-ee65-457a-8cab-1d26dadff849",
        "text":"1 b. The Board shall ensure the consistent application of this Regulation.",
        "title":"Amendment 2403: Article 56 – paragraph 1 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bec8f097-5b45-46f5-a74f-94526946fd07",
        "text":"deleted",
        "title":"Amendment 2404: Article 56 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"486be956-dfd5-4aba-8572-13bdf7dc7d2d",
        "text":"2. The Board shall provide advice and assistance to the Commission and to the national supervisory authorities in order to:",
        "title":"Amendment 2405: Article 56 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"216dccc1-9cce-43fc-ba4b-8e4fd0e22c78",
        "text":"2. The Board shall provide advice and assistance to the Commission and the national authorities in order to:",
        "title":"Amendment 2406: Article 56 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8f7d9310-c328-4be8-920d-5a9409d2583e",
        "text":"(a) contribute to the effective cooperation of the national supervisory authorities and the Commission with regard to matters covered by this Regulation;",
        "title":"Amendment 2407: Article 56 – paragraph 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"89a8db55-46de-44dc-b60d-3615d6aa3aef",
        "text":"(b) coordinate and provide guidance and analysis by the Commission and the national supervisory authorities and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation;",
        "title":"Amendment 2408: Article 56 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"3bed34d0-b42c-40b1-97aa-ec12ca723056",
        "text":"(c) assist the Commission, national supervisory authorities and other competent authorities in ensuring the consistent application of this Regulation, in particular in line with the consistency mechanism referred to in Article 59a(3);",
        "title":"Amendment 2409: Article 56 – paragraph 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b3213aca-7901-49b5-808e-1924f0237cf8",
        "text":"(c) contribute to the effective and consistent application of this Regulation and assist the national supervisory authorities and the Commission in that regard.",
        "title":"Amendment 2410: Article 56 – paragraph 2 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"411ebea7-2988-4a86-aff3-ccfbe2e8e11e",
        "text":"(c a) carry out annual reviews and analyses of the complaints sent to and findings by national competent authorities, of the serious incidents and malfunctioning reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens and not adequately addressed by this Regulation; to carry out biannual horizon scanning and foresight exercises to extrapolate the impact these trends and emerging issues can have on the Union; and to annually publish recommendations to the Commission, including but not limited to recommendations on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk.",
        "title":"Amendment 2411: Article 56 – paragraph 2 – point c a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ffb5e0be-cf5b-46bb-82b5-e9f98bfc8aa4",
        "text":"(c a) provide particular oversight, monitoring and regular dialogue with the providers of general purpose AI systems about their compliance with the Regulation. Any such meeting shall be open to national supervisory authorities, notified bodies and market surveillance authorities to attend and contribute",
        "title":"Amendment 2412: Article 56 – paragraph 2 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"87d3ee89-1aa9-480e-aa86-41b9990b3c41",
        "text":"(c a) contribute to the effective cooperation with the competent authorities of third countries and with international organisations.",
        "title":"Amendment 2413: Article 56 – paragraph 2 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d3984454-6209-4de6-8518-40e6e8eedae0",
        "text":"(c a) contribute to the effective cooperation with the competent authorities of third countries and with international organisations.",
        "title":"Amendment 2414: Article 56 – paragraph 2 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"66c4f080-abcd-4b9c-bcc1-9f237e1373b9",
        "text":"(c a) propose amendments to Annexes I and III to the Commission.",
        "title":"Amendment 2415: Article 56 – paragraph 2 – point c a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"78fe6f9c-da79-470a-9dc7-0748e21c9c8b",
        "text":"(c b) bring together national metrology and benchmarking authorities to provide guidance to address the technical aspects of how to measure appropiate levels of accuracy and robustness.",
        "title":"Amendment 2416: Article 56 – paragraph 2 – point c b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9db3f86b-fe90-491a-aba8-480ab9bf1fed",
        "text":"(c b) represent and defend the interest of the broad cicil society, including Social Partners.",
        "title":"Amendment 2417: Article 56 – paragraph 2 – point c b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d1dd204a-0a0f-41c3-876f-9d59eafc7854",
        "text":"(c c) launch an evaluation procedure for an AI system",
        "title":"Amendment 2418: Article 56 – paragraph 2 – point c c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a543cd2a-3a3c-41b5-b887-3ce8a62b1ff2",
        "text":"2 a. The Board shall have a sufficient number of competent personnel at their disposal for assistance in the proper performance of their tasks.",
        "title":"Amendment 2419: Article 56 – paragraph 2 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"bb39112e-11db-4c8d-a022-a978de481eba",
        "text":"2 b. The Board shall be organised and operated so as to safeguard the independence, objectivity and impartiality of their activities. The Board shall document and implement a structure and procedures to safeguard impartiality and to promote and apply the principles of impartiality throughout its activities.",
        "title":"Amendment 2420: Article 56 – paragraph 2 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"e70703ec-bb11-48d5-87d6-f6a9ecab1f61",
        "text":"Article 56 a', 'SECTION 1:General provisions', 'An independent ‘European Artificial Intelligence Office’ (the ‘AI Office’) is hereby established. The European Union Artificial Intelligence Office shall bean Office of the Union, shall have legal personality, and shall be adequately funded and staffed. The Office shall enjoy in all the Member States the most extensive legal capacity accorded to legal persons under their laws.",
        "title":"Amendment 2421: Article 56 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"916c850a-5de3-41d4-b495-d22f806fb892",
        "text":"Article 56 b', 'Mandate', '1. The AI Office shall carry out the tasks assigned to it under this Regulation for the purpose of achieving a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU across the Union with regards to artificial intelligence systems, including by actively supporting Member States, Union institutions, bodies, offices and agencies in matters pertaining to this Regulation. The AI Office shall act as a reference point for advice and expertise on artificial intelligence for Union institutions, bodies, offices and agencies, for Member States and their national supervisory authorities, as well as for other relevant Union stakeholders.', '2. The AI Office shall contribute to reducing the fragmentation of the internal market and to increasing the uptake of artificial intelligence throughout the Union by carrying out the tasks assigned to it under this Regulation.', '3. When carrying out its tasks, the AI Office shall act independently while avoiding the duplication of Member State activities and taking into consideration Member State competences.', '4. The AI Office shall organise consultations with stakeholders twice a year to assess the evolution of trends in technology, issues related to the implementation and the effectiveness of this Regulation, regulatory gaps or loopholes observed in practice. Such stakeholders shall include representatives from industry, start-ups and SMEs, civil society organisations, such as NGOs, consumer associations, the social partners and academia.', '5. The AI Office may consult national authorities, such as national equality bodies, where the issues discussed are of relevance for them. The AI Office may also consult, where appropriate, external experts and observers and interested third parties, including stakeholders such as those referred to in paragraph 5, and may hold exchanges with them.', '6. The AI Office shall cooperate with Union institutions, bodies, offices, agencies and advisory groups and shall make the results of that cooperation publicly available.",
        "title":"Amendment 2422: Article 56 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"1778265c-e6f0-47a7-b120-8c89ee9d6473",
        "text":"Article 56 c', 'Accountability, transparency, and independence', '1. The AI Office shall be accountable to the European Parliament and to the Council in accordance with this Regulation.', '2. The AI Office shall develop good administrative practices in order to ensure the highest possible level of transparency concerning its activities. Regulation (EC) No 1049\/2001 shall apply to documents held by the AI Office.', '3. The AI Office shall fulfil its tasks in complete independence.",
        "title":"Amendment 2423: Article 56 c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"46d4495d-eb41-4535-b30e-0929ae9dcdf9",
        "text":"Article 56 d', 'Administrative and management structure', '1. The administrative and management structure of the AI Office shall comprise:', '(a) a management board', '(b) an executive director', '(c) an advisory forum', '(d) where appropriate, other advisory bodies established by the management board to support the AI Office in technical or scientific matters related to this Regulation.",
        "title":"Amendment 2424: Article 56 d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ae7b5ff4-99f7-47af-8d23-a1fbd09dbb79",
        "text":"Article 56 e', 'Objectives', '1. The AI Office shall:', '(a) contribute to the uptake of artificial intelligence in the Union, including through supporting innovation and the development of regulatory sandboxes provided for in this Regulation;', '(b) contribute to a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU with regard to artificial intelligence systems in the Union;', '(c) contribute to the effective cooperation of the national supervisory authorities and the Commission with regard to matters covered by this Regulation;', '(d) provide forecasts, guidance, and analysis to the Commission, Member States, and to the national supervisory authorities and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation and related issues;', '(e) contribute to the effective and consistent application of this Regulation and assist Member States, the national supervisory authorities, and the Commission in this regard;', '(f) contribute to the effective cooperation with the competent authorities of third countries and with international organisations;', '(g) contribute to the development, promotion, and adoption of harmonized standards, common specifications, common benchmarking standards, and voluntary codes of conduct;', '(h) contribute to the effective and consistent enforcement of this Regulation throughout the Union, including by issuing binding decisions with regard to cases involving two or more Member States asset out in Article 59b.",
        "title":"Amendment 2425: Article 56 e (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"dd75e8bd-92e2-41af-9832-1789768b31f5",
        "text":"deleted",
        "title":"Amendment 2426: Article 57  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"b01f3389-cd2e-43e0-bd2c-49c5ba35f726",
        "text":"deleted",
        "title":"Amendment 2427: Article 57  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b27c9bdc-00a5-4ccc-87df-a438edd2cee6",
        "text":"Structure and independence of the Board",
        "title":"Amendment 2428: Article 57 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"9b469bab-790f-4785-8697-b47b4dbfb231",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority. Other national authorities may also be invited to the meetings, where the issues discussed are of relevance for them.', 'The European Data Protection Supervisor, the Chairperson of the EU Agency for Fundamental Rights, the Executive director of the EU Agency for Cybersecurity, the Chair of the High Level Expert Group on AI, the Director-General of the Joint Research Centre, and the presidents of the European Committee for Standardization, the European Committee for Electrotechnical Standardization, and the European Telecommunications Standards Institute shall be invited as permanent observers with the right to speak but without voting rights.",
        "title":"Amendment 2429: Article 57 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cff8f3a2-0739-47cb-b75a-cfa93c0a0646",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head of that authority, and the European Data Protection Supervisor, the Chair of the European Data Protection Board, the Director of the Fundamental Rights Agency, the Executive Director of the European Union Agency for Cybersecurity or their respective representatives. Other national authorities or Union agencies and bodies may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2430: Article 57 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"eae5d300-e00d-479c-aae3-fc60cf7d7d08",
        "text":"1. The Board shall be composed of the national supervisory authorities, the European Data Protection Supervisor as the EU Agency for Fundamental Rights, the EU Agency for Cybersecurity, the Joint Research Centre, the European Committee for Standardization, the European Committee for Electrotechnical Standardization, and the European Telecommunications Standards Institute, each with one representative. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2431: Article 57 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"18a69221-f542-4855-9a5d-10c860a951aa",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor, the EU Agency for Fundamental Rights, ENISA, EIGE and social partners as well representratives of civil society. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2432: Article 57 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"ac7c8be7-3b2f-42af-a9f0-0ba9a3295801",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the national data protection bodies. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2433: Article 57 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"41de3dc1-d5ba-4a66-8e28-0103cf9786b4",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor, AI ethics experts and industry representatives. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2434: Article 57 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"7a2823f7-2c58-42ec-8c4f-ba087bd199b6",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the Fundamental Rights Agency. Other national authorities or EU agencies may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2435: Article 57 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"69afbde5-2094-41fe-8492-d042bc4d6ea4",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor and relevant stakeholders including SMEs. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2436: Article 57 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"da43f26d-f84f-4315-bad3-a465568b59d8",
        "text":"1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the FRA. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.",
        "title":"Amendment 2437: Article 57 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"17a98309-5897-47fb-86e8-b81bd863650a",
        "text":"1 a. The Commission shall have the right to participate in the activities and meetings of the Board without voting right. The Commission shall designate a representative. The Chair of the Board shall communicate to the Commission the activities of the Board.",
        "title":"Amendment 2438: Article 57 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8c6491d7-60fb-4c95-9cf5-6faef7ab4cfa",
        "text":"1 a. The Board shall act independently when performing its tasks or exercising its powers.",
        "title":"Amendment 2439: Article 57 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"655dea38-bbd4-4a50-b8a6-3fa74ac7edf5",
        "text":"1 a. The Board shall be represented by its Chair.",
        "title":"Amendment 2440: Article 57 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b00cbd64-ae92-4682-937d-6fef06caea6d",
        "text":"1 b. The Board shall act independently when performing its tasks or exercising its powers pursuant to Articles 58.",
        "title":"Amendment 2441: Article 57 – paragraph 1 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0952cb56-4a6a-4fe4-a020-8b11264298b0",
        "text":"1 c. The Board shall take decisions by a simple majority of its voting members, unless otherwise provided for in this Regulation. Each national supervisory authority and the EDPS shall have one vote.",
        "title":"Amendment 2442: Article 57 – paragraph 1 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0539fb4a-9e07-4045-8381-83548da931ea",
        "text":"2. The Board shall adopt its rules of procedure by a simple two-thirds majority of its voting members and organise its own operational arrangements.",
        "title":"Amendment 2443: Article 57 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"81a2b88c-1ef4-467b-bc01-e598422db6b2",
        "text":"2. The Board shall adopt its rules of procedure by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.",
        "title":"Amendment 2444: Article 57 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"72977f7f-f465-4255-8962-f848f11f3581",
        "text":"2. The Board shall adopt its rules of procedure by two-thirds majority and shall take decisions by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.",
        "title":"Amendment 2445: Article 57 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"70c27b94-e476-437e-a236-1741eae878f0",
        "text":"2. The Board shall adopt its rules of procedure by a two-thirds majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.",
        "title":"Amendment 2446: Article 57 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"a91b1720-d2fa-4efc-af6b-8530517ef7fc",
        "text":"2. The Board shall adopt its rules of procedure by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish standing or temporary sub-groups as appropriate for the purpose of examining specific questions.",
        "title":"Amendment 2447: Article 57 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0e9eccca-f67c-4bff-948e-6460609ef087",
        "text":"2 a. The Board may establish sub-groups as appropriate for the purpose of examining specific questions. The Board shall establish a permanent sub-group for the purpose of examining the question of the proper governance of general purpose AI systems. The Board shall also establish a permanent sub-group for the purpose of examining the question of the proper governance of research and development activities on the topic of AI and to inform the development of the governance framework.",
        "title":"Amendment 2448: Article 57 – paragraph 2 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6e659d22-7825-437e-82ce-a9b80aae934f",
        "text":"2 a. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.In any case, the Board shall establish the following permanent sub-groups:', 'a) for the purpose of examining the question of the proper governance of AI systems with indeterminate use;', 'b) for the purpose of examining the question of the proper governance of research and development activities on the topic of AI.",
        "title":"Amendment 2449: Article 57 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f5362c2b-bdc0-46be-96d6-ffa024254bb8",
        "text":"2 b. The Board shall elect a Chair and two deputy Chairs from among its voting members by simple majority. The term of office of the Chair and of the deputy Chairs shall be three years, renewable once.",
        "title":"Amendment 2450: Article 57 – paragraph 2 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"30653212-0f51-40a2-9eb0-5530b672006e",
        "text":"3. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.",
        "title":"Amendment 2451: Article 57 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"43646b45-0bbf-431c-b78a-dce400af5865",
        "text":"3. The Board shall be chaired by the national supervisory authority of the Member State holding the Presidency of the Council of the European Union. The latter shall convene the meetings and prepare the agenda in accordance the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.",
        "title":"Amendment 2452: Article 57 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9eabbf0c-b793-4f2e-8e36-c4114f79b499",
        "text":"3. The Board shall be co-chaired by the Commission and a representative chosen from among the delegates of the Member States. The Commission shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.",
        "title":"Amendment 2453: Article 57 – paragraph 3  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"22f22a30-fe47-4fc3-a37b-cc36dae84464",
        "text":"3. The Chair shall have the following tasks:', '- convene the meetings of the Board and prepare its agenda;', '- ensure the timely performance of the tasks of the Board;', '- notify Member States and the Commission of any recommendations adopted by the Board.",
        "title":"Amendment 2454: Article 57 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"97eb340d-51bd-4848-b999-1c81a5cb5396",
        "text":"3. The Board shall be chaired by the Commission. The Board’s Secretariat shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Board’s Secretariat shall also provide administrative and analytical support for the activities of the Board pursuant to this Regulation.",
        "title":"Amendment 2455: Article 57 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0da7c767-8693-459c-902f-b87b47b81840",
        "text":"3. The Board shall elect a chair and two deputy chairs from among its members. Their term of office shall be five years and be renewable once. . The Chair shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure.",
        "title":"Amendment 2456: Article 57 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"cfd3746b-b41d-4fb7-887f-1540fc0c32d8",
        "text":"3 a. The Board shall establish a AI Advisory Council (Advisory Council). The Advisory Council shall be composed of relevant representatives from industry, research, academia, civil society, standardisation organisations, relevant common European data spaces and other relevant stakeholders or third parties appointed by the Board, representing all Member States to maintain geographical balance. The Advisory Council shall support the work of the Board by providing advice relating to the tasks of the Board. The Advisory Council shall nominate a relevant representative, depending on the configuration in which the Board meets, to attend meetings of the Board and to participate in its work. The composition of the Advisory Council and its recommendations to the Board shall be made public.",
        "title":"Amendment 2457: Article 57 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"4286c745-a9a3-4d63-88c4-66039ad26915",
        "text":"3 a. The secretariat of the Board shall have the necessary human and financial resources to be able to perform its tasks pursuant to this Regulation.",
        "title":"Amendment 2458: Article 57 – paragraph 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"01b14ba2-fb94-4280-9bda-dcaf4ec3d452",
        "text":"3 a. The Board shall elect a chair and two deputy chairs from amongst its members by simple majority.",
        "title":"Amendment 2459: Article 57 – paragraph 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"50c3ba69-aae2-41b6-9ca4-d72831b306df",
        "text":"3 b. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.",
        "title":"Amendment 2460: Article 57 – paragraph 3 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c42eb3d5-21fb-490d-9665-08e1367d2bf8",
        "text":"3 b. The term of office of the Chair and of the deputy chairs shall be five years and be renewable once.",
        "title":"Amendment 2461: Article 57 – paragraph 3 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"cdda297f-8de2-4227-8fa3-0f3b9c8d02ba",
        "text":"4. The Board shall regularly invite external experts, in particular from organisations representing the interests of the providers and users of AI systems, SMEs and start-ups, civil society organisations, representatives of affected persons, researchers, standardisation organisations, testing and experimentation facilities, to attend its meetings in order to ensure accountability and appropriate participation of external actors. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups.",
        "title":"Amendment 2462: Article 57 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2e176617-0ed2-4e60-8854-523d643ae877",
        "text":"4. The Board may invite external experts and observers to attend its meetings and may hold exchanges with interested third parties to inform its activities to an appropriate extent. To that end the Chair shall facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups. The Board shall ensure a balanced representation of stakeholders from academia, research, industry and civil society when it invites external experts and observers, and actively stimulate participation from underrepresented categories.",
        "title":"Amendment 2463: Article 57 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ad6b6acf-11be-4948-8fce-38d7f10f74d2",
        "text":"4. The Board may invite external experts and observers to attend its meetings and may hold exchanges with interested third parties to inform its activities to an appropriate extent, and hold consultations with relevant stakeholders and ensure appropriate participation. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups.",
        "title":"Amendment 2464: Article 57 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"63576e35-cc16-46b4-b7fc-a8e0ffcc183d",
        "text":"4. The Board may invite external experts and observers. To that end the Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and specialised bodies. The composition of the specialised body shall ensure fair representation of consumer organisations, civil society organisations and academics specialised on AI. Its meetings and their minutes shall be published online.",
        "title":"Amendment 2465: Article 57 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b91948e8-bab2-4698-a93c-f68910eb1498",
        "text":"4. The Board may invite national authorities, such as national equality bodies, to its meetings, where the issues discussed are of relevance for them. The Board may also invite, where appropriate, external experts, and observers and interested third parties, including stakeholders, such as those referred to in Article 58, paragraph 1c, to attend its meetings and may hold exchanges with them.",
        "title":"Amendment 2466: Article 57 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"960661c0-1f0f-4611-bc74-04824b50508b",
        "text":"4 a. Without prejudice to paragraph 4, the Board’s Secretariat shall organise four additional meetings between the Board and the High Level Expert Group on AI to allow them to share their practical and technical expertise every quarter of the year.",
        "title":"Amendment 2467: Article 57 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c23574c0-8a0b-438e-877d-07e8b4686043",
        "text":"4 a. The Board shall take into consideration advice provided by the EDPB, particularly on new or evolving risks of high-risk AI systems processing personal data.",
        "title":"Amendment 2468: Article 57 – paragraph 4 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"c197932f-7425-46e7-94ef-4df0944e853a",
        "text":"4 a. The Board shall cooperate with Union institutions, bodies, offices, agencies and advisory groups and shall make the results of that cooperation publicly available.",
        "title":"Amendment 2469: Article 57 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"9be0d9d7-9c42-4fb1-831f-f7151ecc4878",
        "text":"Article 57 a', 'Secretariat', '1. The Board shall have a secretariat, which shall be provided by the European Data Protection Supervisor.', '2. The secretariat shall perform its tasks exclusively under the instructions of the Chair of the Board.', '3. The staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation shall be subject to separate reporting lines from the staff involved in carrying out tasks conferred on the European Data Protection Supervisor.', '4. Where appropriate, the Board and the European Data Protection Supervisor shall establish and publish a Memorandum of Understanding implementing this Article, determining the terms of their cooperation, and applicable to the staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation.', '5. The secretariat shall provide analytical, administrative and logistical support to the Board.', '6. The secretariat shall be responsible in particular for:', '(a) the day-to-day business of the Board;', '(b) communication between the members of the Board, its Chair and the Commission;', '(c) communication with other institutions and the public;', '(d) the use of electronic means for the internal and external communication;', '(e) the translation of relevant information;', '(f) the preparation and follow-up of the meetings of the Board;', '(g) the preparation, drafting and publication of opinions, guidelines, and other texts to be adopted by the Board.', '7. For the exercise of point (g) of paragraph 6, the secretariat shall, under the guidance of the Chair and the deputy Chairs, establish a European Centre of Excellence for Artificial Intelligence (ECE-AI, “the Centre”). The Centre shall be provided with sufficient resources and facilities to attract the highest level of expertise on artificial intelligence from technical and humanities sciences. In particular it shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, health and safety risks and environmental risks, and knowledge of existing standards and legal requirements, including competition law.",
        "title":"Amendment 2470: Article 57 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"30ab4cd8-3b99-4210-b34c-5e11566568bc",
        "text":"Article 57 a', 'Composition of the management board', '1. The management board shall be composed of one representative of each Member State, the Commission, and the European Data Protection Supervisor, and the Fundamental Rights Agency. Each Member State and the Commission shall have one vote. The EDPS and the FRA shall not have voting rights.', '2. Each member of the management board shall have an alternate. That alternate shall represent the member in the member’s absence.', '3. The Commission and the Member States shall aim to achieve gender balance on the management board.', '4. The list of the members and alternate members of the management board shall be made public and shall be updated by the AI Office on its web site.', '5. The term of office of the members of the management board and their alternates shall be four years. That term shall be renewable once.",
        "title":"Amendment 2471: Article 57 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"383233bf-0845-48c5-92b2-753fb6b820a0",
        "text":"Article 57 b', 'Functions of the management board', '1. The management board shall be responsible for taking the strategic decisions of the AI Office in accordance with this Regulation. In particular, the management board shall:', '(a) Establish the general direction of the operation of the AI Office and ensure that the AI Office operates in accordance with the rules and principles laid down in this Regulation;', \"(b) Adopt, on the basis of the draft submitted by the Office's executive director and after the Commission has delivered an opinion, the single programming document of the AI Office containing, inter alia, the AI Office’s multiannual programming and its work programme for the following year. The single programming document shall be transmitted to the European Parliament, the Council and the Commission;\", '(c) Appoint the executive director and, where relevant, extend his or her term of office or remove him or her from office;', '(d) Produce, on the basis of a draft drawn up by the executive director, the estimate budget of the AI Office for the following financial year. This estimate, which shall initially include a draft establishment plan by the date of entry into force of this Regulation, shall be transmitted by the management board to the Commission within the first quarter of each year;', '(e)Adopt the AI Office’s annual draft and final budgets;', '(f) Assess and adopt the consolidated annual report on the AI Office activities, including an evaluation based on performance indicators; submit both the annual report and the assessment thereof to the European Parliament, to the Council, to the Commission and to the Court of Auditors, and make the annual report public;', '(g) Adopt the AI Office’s rules of procedure on the basis of the draft submitted by the executive director after the Commission has delivered an opinion;', '(h) Take decisions, based on the executive director’s recommendation, concerning the establishment of the AI Office’s internal structures and, where necessary, the modification of those internal structures, taking into consideration technological developments that may create additional operational needs and having regard to sound budgetary management;",
        "title":"Amendment 2472: Article 57 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"24a37e55-fedb-45f2-8f8b-6acd8b7c0cc4",
        "text":"Article 57 c', 'Meetings of the management board', '1. The meetings of the management board shall be convened by the Chair. The Chair shall prepare the agenda of the meetings in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure.', '2. The meetings of the management board shall be considered to be quorate where at least two-thirds of its members are present.', '3. The management board shall hold at least two ordinary meetings a year. It shall also hold extraordinary meetings at the request of the Chair, at the request of the Commission, or at the request of at least one third of its members.', '4. The executive director shall take part in the meetings of the management board but shall not have the right to vote.', '5. Members of the advisory forum may take part in the meetings of the management board at the invitation of the Chair, but shall not have the right to vote.', '6. The members of the management board and their alternates may be assisted at the meetings of the management board by advisers or experts, subject to the rules of procedure of the management board.', '7. The AI Office shall provide the secretariat of the management board and support the management Board in its operations.",
        "title":"Amendment 2473: Article 57 c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"379f3aab-b50a-4e08-b4c7-30c20f1f2c14",
        "text":"Article 57 c', 'Chair of the management board', '1. The management board shall elect a Chair and a deputy Chair from among its voting members by simple majority. The term of office of the Chair and of the deputy Chair shall be three years. The terms of the Chair and of the deputy Chair may be renewed once. The Deputy Chair shall replace the Chair ex officio if the Chair is unable to attend to his or her duties.",
        "title":"Amendment 2474: Article 57 c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"030e80c1-7aa4-4b9c-a3a6-979e4841a5b4",
        "text":"Article 57 d', 'Voting rules of the management board', '1. The management board shall take its decisions by a majority of its members, unless otherwise provided for in this Regulation.', '2. A majority of two-thirds of the members of the management board shall be required for the adoption of the single programming document and of the annual budget and for the appointment, extension of the term of office or removal of the executive director.', '3. Each member shall have one vote. In the absence of a member, their alternate shall be entitled to exercise the member’s right to vote.', '4. The Chair of the management board shall take part in the voting.', '5. The executive director shall not take part in the voting.', '6. The management board’s rules of procedure shall establish more detailed voting arrangements, in particular the circumstances in which a member may act on behalf of another member.",
        "title":"Amendment 2475: Article 57 d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a05559a9-00ca-4352-a965-167987e2025f",
        "text":"deleted",
        "title":"Amendment 2476: Article 58 – title  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"55de0241-ec58-4072-b654-7f0ee0257421",
        "text":"Tasks",
        "title":"Amendment 2477: Article 58 – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e323259e-1122-4dd0-bd55-65234dd038c6",
        "text":"-1 The Board shall ensure the consistent application of this Regulation and shall the competent supervisory authority to enforce this Regulation where one of the following criteria is met:', '(a) The aggregate worldwide turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 2 500 million;', '(b) in each of at least three Member States, the aggregate turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 100 million;', '(c) in each of at least three Member States included for the purpose of point (b), the aggregate turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 25 million;and', '(d) the aggregate Union-wide turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 100 million, unless each of the undertakings concerned achieves more than two-thirds of its aggregate Community-wide turnover within one and the same Member State.",
        "title":"Amendment 2478: Article 58 – paragraph -1 (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"33cb7e35-cca5-44c1-a1f6-99eb2e7b294e",
        "text":"-1 a In order to ensure consistent application of this Regulation, the Board shall, on its own initiative or, where relevant, at the request of the Commission, in particular:', '(a) monitor and ensure the correct application of Title III of this Regulation without prejudice to the tasks of national supervisory authorities;', '(b) advise the Commission on any issue related to the development and use of artificial intelligence in the in the Union, including on any proposed amendment of this Regulation;', '(c) issue guidelines, recommendations, and best practices on procedures, information and documentation as referred to in Titles III and VIII;', '(d) examine, on its own initiative, on request of one of its members or on request of the Commission, any question covering the application of this Regulation and issue guidelines, recommendations and best practices in order to encourage consistent application of this Regulation;', '(e) draw up guidelines for supervisory authorities concerning the application of this Regulation;', '(f) draw up guidelines for supervisory authorities concerning the setting of administrative fines pursuant to Article 72;', '(g) review the practical application of the guidelines, recommendations and best practices referred to in points (e) and (f);', '(h) encourage the drawing-up of codes of conduct pursuant to Article 69;', '(i) issue opinions on codes of conduct drawn up at Union level pursuant to Article 69(3a);', '(j) issue decisions pursuant to Articles 66 and 67;', '(k) promote the cooperation and the effective bilateral and multilateral exchange of information and best practices between the supervisory authorities;', '(l) promote common training programmes and facilitate personnel exchanges between the supervisory authorities and, where appropriate, with the supervisory authorities of third countries or with international organisations;', '(m) promote the exchange of knowledge and documentation on relevant legislation and practice with supervisory authorities whose scope includes artificial intelligence worldwide;', '(n) maintain a publicly accessible electronic register of decisions taken by supervisory authorities and courts on issues handled pursuant to Chapter 3 of Title VIII.",
        "title":"Amendment 2479: Article 58 – paragraph -1 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e0e1ec48-736e-46ac-8049-270f161c3298",
        "text":"-1 b Where the Commission requests advice from the Board, it may indicate a time limit, taking into account the urgency of the matter.",
        "title":"Amendment 2480: Article 58 – paragraph -1 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese"
    },
    {
        "uuid":"1a6dd5fc-f309-42dd-af23-6796f1181ca2",
        "text":"-1 c The Board shall forward its opinions, guidelines, recommendations, and best practices to the Commission and to the committee referred to in Article 73 and make them public.",
        "title":"Amendment 2481: Article 58 – paragraph -1 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c9f84581-15a8-444a-a8a1-569798f0d8ec",
        "text":"-1 d The Board shall, where appropriate, consult interested parties and give them the opportunity to comment within a reasonable period. The Board shall make the results of the consultation procedure publicly available.",
        "title":"Amendment 2482: Article 58 – paragraph -1 d (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"22000e72-e21d-4b1a-affe-20ba37272ff9",
        "text":"-1 e When providing advice and assistance to the Commission in the context of Article 56(2), the Board shall in particular:', '(a) collect and share expertise and best practices among Member States;', '(b) contribute to uniform administrative practices in the Member States, including for the functioning of regulatory sandboxes referred to in Article 53;', '(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, in particular on', '(i) technical specifications or existing standards regarding the requirements set out in Title III, Chapter 2,', '(ii) the use of harmonised standards or common specifications referred to in Articles 40 and 41,', '(iii) the preparation of guidance documents, including the guidelines concerning the setting of administrative fines referred to in Article 71,', '(iii a) amendments to the Annexes I and III.",
        "title":"Amendment 2483: Article 58 – paragraph -1 e (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"2204eef7-c952-4f1d-a434-005fad3c88e6",
        "text":"When providing advice and assistance to the Commission and to the national supervisory authorities in the context of Article 56(2), the Board shall in particular:",
        "title":"Amendment 2484: Article 58 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"2a3c445f-0cb1-4c0e-aba3-ebe1e9030b9e",
        "text":"When providing advice and assistance to the Commission and the national supervisory authorities in the context of Article 56(2), the Board shall in particular:",
        "title":"Amendment 2485: Article 58 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"efcc30ff-f12c-4a83-81f6-73f49bf8f787",
        "text":"In fulfilling its objectives, the AI Office shall in particular:",
        "title":"Amendment 2486: Article 58 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"9d0f2be2-45da-4cfc-a34d-4c610bb9e989",
        "text":"1. When providing advice and assistance to the Commission in the context of Article 56(2), the Board shall in particular:",
        "title":"Amendment 2487: Article 58 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"cb19cdb8-2d05-40f7-a1f1-42282c20c739",
        "text":"When ensuring the consistent application of this Regulation, the Board shall in particular:",
        "title":"Amendment 2488: Article 58 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"60401e30-dac9-469f-94c7-6894045fe8ca",
        "text":"(-a) issue opinions, recommendations or written contributions with a view to ensuring the consistent implementation of this Regulation;",
        "title":"Amendment 2489: Article 58 – paragraph 1 – point -a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3b21759d-be69-48fd-b536-c68d9062b162",
        "text":"(-a a) examine, on its own initiative or on request of one of its members, any question covering the application of this Regulation and issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;",
        "title":"Amendment 2490: Article 58 – paragraph 1 – point -a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"eed704cc-8583-41fb-9a34-9ed828c7a4d6",
        "text":"(a) collect and share expertise and best practices among Member States, including on the promotion of awareness raising initiatives on Artificial Intelligence and the Regulation;",
        "title":"Amendment 2491: Article 58 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7accce3e-292e-43e6-a1fe-a538b0e0f028",
        "text":"(a) collect and share expertise and best practices in implementation of this Regulation;",
        "title":"Amendment 2492: Article 58 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"800e75e1-a6d1-47ff-865d-4e7b5aafb7e2",
        "text":"(a a) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation;",
        "title":"Amendment 2493: Article 58 – paragraph 1 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"07a4b4d1-a57c-4b6a-8c52-90520e7b99c2",
        "text":"(a b) examine, on its own initiative or on request of its management board, any question covering the application of this Regulation and issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;",
        "title":"Amendment 2494: Article 58 – paragraph 1 – point a b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"4bf8b7b1-83f3-498a-8fbf-789a024a5095",
        "text":"(a c) provide the Commission, in the cases referred to in Article 68a (1)(a) and(1)(b), with all the available information at its disposal, including market studies, impact assessments, and analyses referred to in paragraph (f) of this article, to prepare the decision for triggering the Commission's intervention and opening of proceedings pursuant to Article 68a;",
        "title":"Amendment 2495: Article 58 – paragraph 1 – point a d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"13fe80cf-fd2b-4d77-b37d-9c0bca9c8bf6",
        "text":"(a d) assist Member States in developing the organizational and technical expertise required for the implementation of this Regulation;",
        "title":"Amendment 2496: Article 58 – paragraph 1 – point a d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b7e32de6-3208-4a04-902b-2272110f5619",
        "text":"(b) contribute to uniform practices in the Member States, including by assisting Member States, the Commission, and, where applicable, other authorities in the establishment, development, and functioning of regulatory sandboxes referred to in Article 53, including by providing input and support in drafting the delegated acts referred to in Article 53(6);",
        "title":"Amendment 2497: Article 58 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"fcc5bfd9-74e4-410e-baae-11ee7f70a23b",
        "text":"(b) contribute to uniform administrative practices in the Member States, including for the assessment , establishing, managing with the meaning of fostering cooperation and guaranteeing consistency among regulatory sandboxes, and functioning of regulatory sandboxes referred to in Article 53, Article54 and Annex IXa;",
        "title":"Amendment 2498: Article 58 – paragraph 1 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"ae5997a2-55cf-47aa-8f31-3db6414f01cf",
        "text":"(b) contribute to uniform administrative practices in the Member States, including for the assessment, establishing, managing with the meaning of fostering cooperation and guaranteeing consistency among regulatory sandboxes, and functioning of regulatory sandboxes referred to in Article 53;",
        "title":"Amendment 2499: Article 58 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"882fbfbc-4f90-499d-b867-7fde72e88009",
        "text":"(b) contribute to uniform administrative practices, including for the functioning of the regulatory sandboxes, as referred to in Article 53;",
        "title":"Amendment 2500: Article 58 – paragraph 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"76808283-c06d-4802-84a8-3dadfc5f8c3e",
        "text":"(b a) Support innovation by coordinating the exchange of information and good practices and by facilitating the cooperation among regulatory sandboxes established according to Article 53 and by making available on its website the information referred to in Article 53 (5).",
        "title":"Amendment 2501: Article 58 – paragraph 1 – point b a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"bd6da03a-554f-4f2c-a23c-311b3d3dceab",
        "text":"(c) issue opinions, recommendations, written contributions, or studies on matters related to the technical specifications or existing standards regarding the requirements set out in Title III, Chapter 2 and on the use of harmonised standards or common specifications referred to in Articles 40and 41;",
        "title":"Amendment 2502: Article 58 – paragraph 1 – point c – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"6e3f556f-c4e4-416e-9a7f-46600ade8dea",
        "text":"(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, in consultation with relevant stakeholders, in particular",
        "title":"Amendment 2503: Article 58 – paragraph 1 – point c – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"64f972d5-b498-4f06-9c1d-1f37f71a4f0b",
        "text":"(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, after consulting relevant stakeholders, in particular",
        "title":"Amendment 2504: Article 58 – paragraph 1 – point c – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"23174d26-cca4-4467-be16-98afdc5510c0",
        "text":"deleted",
        "title":"Amendment 2505: Article 58 – paragraph 1 – point c – point i  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8de92dd9-177a-4298-be1b-7e198953d3f1",
        "text":"deleted",
        "title":"Amendment 2506: Article 58 – paragraph 1 – point c – point ii  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a13aafdf-5ce6-4059-a64c-9ea9115d4b3e",
        "text":"deleted",
        "title":"Amendment 2507: Article 58 – paragraph 1 – point c – point iii a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"713f047e-23f3-40d3-b108-441ed45a0be0",
        "text":"(iii a) on the need for the amendment of each of the Annexes as referred to in Article 73 as well as all other provisions in this Regulation that the Commission can amend, in light of the available evidence.",
        "title":"Amendment 2508: Article 58 – paragraph 1 – point c – point iii a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"82958a52-6641-4e86-bd6e-049e60dfdf2b",
        "text":"(iii b) on activities and decisions of Member States regarding post-market monitoring, information sharing, market surveillance referred to in Title VIII;",
        "title":"Amendment 2509: Article 58 – paragraph 1 – point c – point iii b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3d13b5be-5e77-46a1-8c85-3037c1b31384",
        "text":"(iii c) on developing common criteria for market operators and competent authorities having the same understanding of concepts such as the 'generally acknowledged state of the art' referred to in Article 9 (3), 'foreseeable risks' referred to in Articles 9 (2) (a), 'foreseeable misuse' referred to in Article 3 (13), Article 9 (2) (b), Article 9 (4), Article 13 (3)(b)(iii) and Article 14 (2), and the 'type and degree of transparency' referred in Article 13 (1);",
        "title":"Amendment 2510: Article 58 – paragraph 1 – point c – point iii c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"08f36f25-9d6c-4cfa-aa0e-df8101e72bf3",
        "text":"(iii d) verify alignment with the legal acts listed in Annex II, including with the implementation matters related to those acts.",
        "title":"Amendment 2511: Article 58 – paragraph 1 – point c – point iii d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c8ced9bd-b3d7-40dd-bb23-921adb705f79",
        "text":"(c a) carry out annual reviews and analyses of the complaints sent to and findings made by national supervisory authorities, of the serious incidents reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens that are not adequately addressed by this Regulation;",
        "title":"Amendment 2512: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e94d1435-40da-4d5e-92b0-5bd9b26b4d03",
        "text":"(c a) carry out annual reviews and analyses of the complaints sent to and findings made by national competent authorities, of the serious incidents reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens that are not adequately addressed by this Regulation;",
        "title":"Amendment 2513: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"472b25a9-5244-45d1-8ac4-c3d25eed17f9",
        "text":"(c a) encourage, facilitate and support the drawing up of codes of conduct intended to foster the voluntary application to AI systems of those codes of conduct in close cooperation with relevant stakeholders in accordance with Article 69;",
        "title":"Amendment 2514: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"863fbf5f-dc94-4977-bb19-ec4bb08dced5",
        "text":"(c a) advise the Commission on the possible amendment of Article 5, to expand the prohibitions, based on national and cross-border cases that led to withdrawing or recalling AI systems from the market.",
        "title":"Amendment 2515: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"fea11f19-264e-44b3-a56f-d1ac00b26b18",
        "text":"(c a) support the Commission and the Member States in the preparation of guidance documents, including the guidelines concerning the setting of administrative fines referred to in Article 71;",
        "title":"Amendment 2516: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ab7e0c82-f9e7-4f1a-8615-261e2886c587",
        "text":"(c a) provide guidance in relation to governing general-purpose AI systems and their compliance with applicable requirements to meet the objectives of this Regulation.",
        "title":"Amendment 2517: Article 58 – paragraph 1 – point c a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6010561c-c806-4146-b345-0e2367990bac",
        "text":"(c b) cooperate with the European Data Protection Board and with the FRA to receive guidance in relation to the respect of fundamental rights, in particular the right to non-discrimination and to equal treatment, the right to privacy, confidentiality of communications and the protection of personal data;",
        "title":"Amendment 2518: Article 58 – paragraph 1 – point c b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"67a8943b-9d4e-4fbb-8707-62c36650387b",
        "text":"(c b) encourage, facilitate and support the drawing up of risk-commensurate codes of conduct intended to foster the voluntary application to AI systems of those codes of conduct in close cooperation with industry and other relevant stakeholders in accordance with Article 69;",
        "title":"Amendment 2519: Article 58 – paragraph 1 – point c b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0c88e003-f4c2-48aa-ba5c-3255962424e5",
        "text":"(c b) provide guidance in relation to governing research and development activities for creating new or improving existing AI systems, and the alignment of these activities with the objectives of this Regulation.",
        "title":"Amendment 2520: Article 58 – paragraph 1 – point c b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"76ae50db-369c-404d-99cb-0629be0a48f5",
        "text":"(c b) coordinate among national competent authorities; issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;",
        "title":"Amendment 2521: Article 58 – paragraph 1 – point c b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5d9fcfb6-738b-47ce-b7ce-2b897cfa9677",
        "text":"(c b) carry out biannual horizon scanning and foresight exercises to extrapolate the impact the trends and emerging issues can have on the Union;",
        "title":"Amendment 2522: Article 58 – paragraph 1 – point c b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a617bf75-faaf-4a67-a334-05ffe1579365",
        "text":"(c c) carry out periodic in-depth horizon-scanning, foresight, and market monitoring exercises to analyse trends and emerging issues in respect of this Regulation, with a particular focus on emerging technologies and their interaction with artificial intelligence, European global competitiveness in artificial intelligence, the uptake of artificial intelligence technologies, the development of digital skills, and emerging systemic threats related to artificial intelligence, including those referred to in Article 68a (1)(a) and (1)(b);",
        "title":"Amendment 2523: Article 58 – paragraph 1 – point c c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"2aed44ed-0bc7-45b0-b1f4-1273d45e1731",
        "text":"(c c) The Board shall provide statutory guidance in relation to children’s rights, applicable law and minimum standards for the evaluation of automated decision-making systems to meet the objectives of this Regulation pertaining to children and to investigate the design goals, data inputs, model selection, implementation and outcomes of such systems.",
        "title":"Amendment 2524: Article 58 – paragraph 1 – point c c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d8e316ee-4988-4281-88b5-0a7313309477",
        "text":"(c c) annually publish recommendations to the Commission, in particular on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk;",
        "title":"Amendment 2525: Article 58 – paragraph 1 – point c c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"61a3e2df-6a0d-4fa8-9217-8c082e39b0ad",
        "text":"(c c) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;",
        "title":"Amendment 2526: Article 58 – paragraph 1 – point c c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"b8a97f84-2052-42b7-9a46-b176eff73356",
        "text":"(c c) promote public awareness and understanding of the benefits, risks, rules and safeguards and rights in relation to the use of AI systems;",
        "title":"Amendment 2527: Article 58 – paragraph 1 – point c c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"36934108-1821-4330-a97a-8f402cb1ad95",
        "text":"(c d) cooperate with the European Data Protection Board and with the FRA to provide guidance in relation to the respect of fundamental rights, in particular the right to non-discrimination and to equal treatment, the right to privacy and the protection of personal data;",
        "title":"Amendment 2528: Article 58 – paragraph 1 – point c d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"89a08b9c-0294-4198-b7f3-48636a466391",
        "text":"(c d) annually publish recommendations to the Commission, in particular on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk;",
        "title":"Amendment 2529: Article 58 – paragraph 1 – point c d (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"51d9bc43-ff6e-407c-9bec-4be6fafd655e",
        "text":"(c d) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;",
        "title":"Amendment 2530: Article 58 – paragraph 1 – point c d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"763fdf4a-60f8-4404-8751-f9a43a21f1a4",
        "text":"(c d) encourage and facilitate the drawing up of codes of conduct as referred to in Article 69;",
        "title":"Amendment 2531: Article 58 – paragraph 1 – point c d (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0ee93f74-55c2-4162-a0ba-d95726c3d4dc",
        "text":"(c e) promote common training programmes and facilitate personnel exchanges between the national supervisory authorities and, where appropriate, with the national supervisory authorities of third countries or with international organisations;",
        "title":"Amendment 2532: Article 58 – paragraph 1 – point c e (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7fd4cf87-d7a6-4cb0-b710-686794098463",
        "text":"(c e) carry out biannual horizon scanning and foresight exercises to extrapolate the impact the trends and emerging issues can have on the Union;",
        "title":"Amendment 2533: Article 58 – paragraph 1 – point c e (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"1480da32-7846-42ae-8081-2263e14a924c",
        "text":"(c e) promote public awareness and understanding of the benefits, risks, rules and safeguards and rights in relation to the use of AI systems;",
        "title":"Amendment 2534: Article 58 – paragraph 1 – point c e (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8fa32f19-70f7-4710-9dce-7ff39349d36c",
        "text":"(c e) coordinate among national supervisory authorities and make sure that the consistency mechanism in Article 59a(3) is observed;",
        "title":"Amendment 2535: Article 58 – paragraph 1 – point c e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"34deeb60-8d75-4aaa-978f-51d0356ccaa3",
        "text":"(c f) adopt binding decisions for national supervisory authorities in case the consistency mechanism is not able to solve the conflict among national supervisory authorities as it is clarified in Article 59a(6);",
        "title":"Amendment 2536: Article 58 – paragraph 1 – point c f (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"268ff97f-880f-4aac-9065-34b8f5a24c93",
        "text":"(c f) advise the Commission on the possible amendment of the Annexes by means of delegated act in accordance with Article 73, in particular the annex listing high-risk AI systems;",
        "title":"Amendment 2537: Article 58 – paragraph 1 – point c f (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"cf78dfa8-9e96-4d15-a8c5-c14cd07ecfb3",
        "text":"(c f) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;",
        "title":"Amendment 2538: Article 58 – paragraph 1 – point c f (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a5db6016-3953-4d45-90e3-7fb77862773d",
        "text":"(c f) promote public awareness and understanding of the benefits, rules and safeguards and rights in relation to the use of AI systems.",
        "title":"Amendment 2539: Article 58 – paragraph 1 – point c f (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"245783c5-379b-4c46-bac1-23a119809ce0",
        "text":"(c g) facilitate cooperation between the supervisory authorities of Member States and other supervisory authorities that might be responsible for the enforcement of this Regulation;",
        "title":"Amendment 2540: Article 58 – paragraph 1 – point c g (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"fb4e0107-8e7f-4735-85ad-f23972953e85",
        "text":"(c g) issue yearly reports on the implementation of the Regulation, including an assessment of the impact of the Regulation on economic operators.",
        "title":"Amendment 2541: Article 58 – paragraph 1 – point c g (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"67f68ad7-b75a-48eb-a65f-787d2502acb5",
        "text":"(c g) ensure that the national supervisory authorities actively cooperate in the implementation of this Regulation;",
        "title":"Amendment 2542: Article 58 – paragraph 1 – point c g (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"34f8b1ef-c05a-4ecb-8505-88cfe3097a70",
        "text":"(c h) support capacity and expertise building in supervisory authorities that are responsible for the enforcement of this Regulation;",
        "title":"Amendment 2543: Article 58 – paragraph 1 – point c h (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"4bb48956-63a2-4dc2-8f6e-9bc435cc9e1a",
        "text":"(c i) advise the Commission on the possible amendment of the Annexes by means of delegated acts in accordance with Article 73, in particular the annex listing high-risk AI systems;",
        "title":"Amendment 2544: Article 58 – paragraph 1 – point c i (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"17f0ffa3-f707-4a78-9aa9-37852185afcd",
        "text":"(c j) ensure that the national supervisory authorities actively cooperate in the implementation of this Regulation;",
        "title":"Amendment 2545: Article 58 – paragraph 1 – point c j (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c9d2b14d-3ea5-4912-9d86-e469846ea277",
        "text":"(c k) adopt binding decisions for national competent authorities in cases of serious disagreements pursuant to article 59a (5);",
        "title":"Amendment 2546: Article 58 – paragraph 1 – point c k (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b5a8b1b4-c635-41ed-9dd9-1e71b248cf20",
        "text":"(c l) promote the development of a common European approach to benchmarking by cooperating with national metrology and benchmarking authorities and by issuing opinions, recommendations, written contributions, or studies with a view to ensure consistent and harmonised European benchmarking standards;",
        "title":"Amendment 2547: Article 58 – paragraph 1 – point c l (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b3f6dcda-5461-465b-ae5c-f264d28d59f1",
        "text":"(c m) provide guidance in relation to children’s rights, applicable law and minimum standards to meet the objectives of this Regulation that pertain to children;",
        "title":"Amendment 2548: Article 58 – paragraph 1 – point c m (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"14e88af7-41ed-4094-a865-30148c3f94a7",
        "text":"(c n) promote and support the accessible development and use of artificial intelligence systems, in accordance with the provisions of Directive (EU) 2019\/882;",
        "title":"Amendment 2549: Article 58 – paragraph 1 – point c n (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"7be69c2c-7cdc-4a52-99db-3665615677c0",
        "text":"When acting in the context of Article 59c on cases involving two or more Member States, the Board shall adopt binding decisions for national supervisory authorities.",
        "title":"Amendment 2550: Article 58 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"cc55e594-9f8b-4140-a1be-89ec6779c1f8",
        "text":"The Board shall organise consultations with stakeholders twice a year. Such stakeholders shall include representatives from industry, start-ups and SMEs ,organisations from the civil society organisations such as NGOs, consumer associations, the social partners and academia, to assess the evolution of trends in technology, issues related to the implementation and the effectiveness of this Regulation, regulatory gaps or loopholes observed in practice.",
        "title":"Amendment 2551: Article 58 – paragraph 1 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"64863f0e-9a7d-43ed-bfa0-a3799860eae8",
        "text":"Article 58 a', 'SECTION 3:the Executive Director', 'Functions and powers of the executive director', '1. The AI Office shall be managed by its executive director, who shall be completely independent in the performance of his or her duties. Without prejudice to the respective competencies of the Union institutions and the management board, the executive director shall neither seek nor take instructions from any government or from any other body.', \"2. The executive director may be called upon at any time by the European Parliament or by the Council to attend a hearing on any matter linked to the AI Office's activities or to report on the carrying out of his or her tasks. This includes reporting on the activities of the AI Office, the implementation of its annual programming, the annual activity report for the previous year, and any other matter related to the activities of the AO Office. The executive director shall also make a statement before the European Parliament, if requested, and shall answer in writing any question put forward by a Member of the European Parliament within 15 calendar days from receipt of such question. The executive director shall report regularly to the appropriate bodies and committees of the European Parliament.\", '3. Except where specific deadlines are provided for in this Regulation, the executive director shall ensure that reports are transmitted to the European Parliament, to the Council and to the Commission as soon as possible, and in any event within six months of the end of the reporting period, unless the executive director duly justifies a delay in writing.', '4. The executive director shall be responsible for the preparation and implementation of the strategic decisions taken by the management board and for the taking of decisions related to the operational activities of the AI Office in accordance with this Regulation. The executive director shall have the following functions and powers:', '(a) to propose, prepare and implement the strategic decisions and programmes and activities adopted by the management board within the limits set out in this Regulation, its implementing rules and any applicable law;', '(b) to take all necessary steps, including the adoption of internal administrative instructions and the publication of notices, to ensure the day-to-day administration and functioning of the AI Office in accordance with this Regulation;', '(c) to prepare each year the draft single programming document pursuant to Article 57a (b) and to submit it to the management board for endorsement before that draft is sent to the European Parliament, to the Council and to the Commission;', '(d) to draw up a draft statement of estimates of the revenues and expenditure of the AI Office as part of the single programming document pursuant to Article 57a (d) and to implement thebudget of the AI Office;', \"(e) to prepare each year the annual activity report on the Agency's activities and submit it to the management board;\", '(f) to coordinate all staff matters and all matters of day-to-day administration of the AI Office;', '(g) to prepare appropriate draft implementing rules to give effect to the Staff Regulations and the Conditions of Employment of Other Servants in accordance with Article 110 of the Staff Regulations;', '(h) to protect the values and interests of the Union by drawing up, submitting to the management board for approval, and implementing effective internal anti-fraud, anti-corruption, data protection and equal opportunity strategies, procedures, and safeguards;', '(i) to establish and implement effective monitoring and evaluation procedures relating to the performance of the AI Office against its objectives and to report annually to the management board on the results of the monitoring;', '(j) to consult the advisory forum and to facilitate its operations;', '(k) to develop and maintain contact with industry, standardization bodies, academia, and civil society, including organizations protecting fundamental and digital rights, consumers, workers, children, persons with disabilities, and other vulnerable categories, to ensure regular dialogue with relevant stakeholders;', '(l) to cooperate and to exchange views and information regularly with Union institutions, bodies, offices and agencies regarding artificial intelligence and related domains such as data, digital infrastructure, platform and internet governance, and cybersecurity, tonsure coherence in the development and the implementation of Union policy;', '(m) to represent the AI Office in international fora for cooperation on Artificial Intelligence;', '(n) To support the Chair of the management board in preparing and planning the management board meetings;', '(o) to perform other tasks pursuant to this Regulation.', '5. The executive director shall be accountable for his or her activities to the management board. 6. The executive director shall be the legal representative of the AI Office.",
        "title":"Amendment 2552: Article 58 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"1183da82-84ad-43c1-b572-d826f870a44a",
        "text":"Article 58 a', 'Guidelines from the Commission on the implementation of this Regulation', 'Upon the request of the Member States or the Board, or on its own initiative, the Commission shall issue guidelines on the practical implementation of this Regulation and in particular on:', '(i) the application of the requirements referred to in Articles 8 - 15;', '(ii) the prohibited practices referred to in Article 5;', '(iii) the practical implementation of the provisions related to substantial modification;', '(iv) the identification and application of criteria and use cases related to high risk AIsystems referred to in Annex III;', '(v) the practical implementation of transparency obligations laid down in Article 52;', '(vi) the relationship of this Regulation with other relevant Union legislation.', 'When issuing such guidelines, the Commission shall pay particular attention to the needs of SMEs and start-ups as well as sectors most likely to be affected by this Regulation.",
        "title":"Amendment 2553: Article 58 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1f476d45-2fc9-4027-8f67-3e3f0b161412",
        "text":"Article 58 a', 'Independence of the Board', '1. The Board shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '2. The members of the Board shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from anybody.', '3. The members of the Board shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.",
        "title":"Amendment 2554: Article 58 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"36ea1e89-cd46-4cfe-a2a4-65e8d8b2290b",
        "text":"Article 58 b', 'SECTION 4:the Advisory Forum', 'The advisory forum', '1. An advisory forum shall be established by the AI Office to advise it in the fulfilment of its tasks by providing stakeholder input in matters pertaining to this Regulation, in particular on:', '(a) technological developments and trends related to artificial intelligence;', '(b) potential updates of this Regulation, including prohibited practices, high-risk AI systems, AI systems requiring additional transparency obligations, and novel techniques used for the development of artificial intelligence;', '(c) best practices to optimise compliance and to reduce compliance costs and regulatory burden;', '(d) measures in support of innovation, start-ups, and SMEs, including improving participation in regulatory sandboxes;', '(e) the development, promotion, and uptake of harmonised standards, harmonised benchmarking standards, and common specifications;', '(f) emerging threats to health, safety, fundamental rights, or the values of the Union as enshrined in Article2 TEU related to artificial intelligence;', '2. The advisory forum shall have a balanced composition and represent the views of different stakeholders, with a third of its members representing industry, a third of its members representing start-ups, SMEs, and the innovation environment, and a third of its members representing civil society and academia.', '3. Stakeholders established outside the Union shall only participate in the advisory forum if they are established in third countries that are subject to a decision of the Commission adopted in accordance with Article 36 of Directive (EU) 2016\/680 or Article 45 of Regulation 2016\/679(‘adequacy decision’) or that are part of an international agreement concluded between the Union and that third country or international organisation pursuant to Article 218 TFEU adducing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals.', '4. Members of the advisory forum shall be appointed by the management board, based on a recommendation from the executive director, following a transparent call for applications and selection procedure.', '5. When drawing up the call for applications and the selection procedure, the executive director shall ensure that:', '(a) the composition criteria stet out in paragraph 2 are met;', '(b) the representation of industry, start-up, SMEs and the innovation environment is varied and includes stakeholders of different sizes and representing different industries;', '(c) the representation of civil society is varied and includes, at a minimum, organizations for the protection of democracy, fundamental rights, consumer rights, the rights of persons with disabilities, and children’s rights;', '(d) the advisory forum is balanced in terms of geographical distribution and gender.', '6. The term of office of the members of the advisory forum shall be two years. To ensure diversity and balanced representation, the term of office for members of the advisory forum shall not be renewable consecutively.', '7. The advisory forum shall draw up its rules of procedure and elect three co-Chairs from among its members according to there presentation criteria set out in paragraph 2. Their term of office shall be two years, non-renewable.', '8. The advisory forum shall hold regular meetings at least four times a year. The advisory forum can invite experts and other stakeholders to its meetings. The executive director can attend, ex officio, the meetings of the advisory forum.', '9. In fulfilling its role as set out in paragraph 1, the advisory forum can prepare opinions, recommendations or written contributions and forward these to the attention of the executive director.', '10. The advisory forum shall prepare an annual report of its activities. That report shall be made publicly available, including on the AI Office website.', '11. The AI Office shall provide secretarial assistance to the advisory forum to ensure its proper functioning.",
        "title":"Amendment 2555: Article 58 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"16374be5-514f-48c5-9429-56eb53372d3a",
        "text":"2 National competent authorities and national supervisory authorities",
        "title":"Amendment 2556: Title VI – Chapter 2 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"eab1e7fa-34dd-4d94-ac44-621c82eb9679",
        "text":"2 national supervisory authorities",
        "title":"Amendment 2557: Title VI – Chapter 2 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3f32b09e-4610-4297-8601-8aec0a08a1b1",
        "text":"Designation of national supervisory authorities",
        "title":"Amendment 2558: Article 59 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9912df26-4326-440a-b590-4e8d680fa075",
        "text":"1. Each Member State shall establish or designate one national supervisory authority, which shall be organised so as to safeguard the objectivity and impartiality of its activities and tasks.",
        "title":"Amendment 2559: Article 59 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6894e593-2c96-427f-a32b-560940bc1a5e",
        "text":"1. National competent authorities shall be established or designated by each Member State for the purpose of ensuring the application, implementation and enforcement of this Regulation. National competent authorities shall be organised so as to safeguard the objectivity and impartiality of their activities and tasks.",
        "title":"Amendment 2560: Article 59 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"563c0b74-c0c3-45f4-9f4c-82932f983e4b",
        "text":"deleted",
        "title":"Amendment 2561: Article 59 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"bd6e2b3f-1d48-479d-a608-f286d4a5145f",
        "text":"2. The national supervisory authority shall be in charge to ensure the application and implementation of this Regulation. With regard to high-risk AI systems, related to products to which legal acts listed in Annex II apply, the competent authorities designated under those legal acts shall continue to lead the administrative procedures. However, to the extent a case involves aspects covered by this Regulation, the competent authorities shall be bound by measures issued by the national supervisory authority designated under this Regulation. The national supervisory authority shall also act as notifying authority and market surveillance authority.",
        "title":"Amendment 2562: Article 59 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"45093cbc-163f-4b27-a286-fc73454ccf8c",
        "text":"2. Each Member State shall designate a national supervisory authority among the national competent authorities. The national supervisory authority shall act as notifying authority and market surveillance authority.",
        "title":"Amendment 2563: Article 59 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e74cdf79-0478-4921-8900-668fc25e2bd9",
        "text":"2. 2. Each Member State shall designate the national data protection authority as tthe national supervisory authority among the national competent authorities. The national supervisory authority shall act as notifying authority and market surveillance authority unless a Member State has organisational and administrative reasons to designate more than one authority.",
        "title":"Amendment 2564: Article 59 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bc1cd1b6-ee70-4cf2-95f2-9c45a665b6b3",
        "text":"2. Each Member State shall designate one or more national supervisory authorities among the national competent authorities. The national supervisory authority or authorities shall act as notifying authorities and market surveillance authorities.",
        "title":"Amendment 2565: Article 59 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"6bc0f114-5540-4bf1-add1-58ba1997a386",
        "text":"3. The national supervisory authority in each Member State shall be the lead authority, ensure adequate coordination and act as single point of contact for this Regulation. Member States shall inform the Commission of their designations.",
        "title":"Amendment 2566: Article 59 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"768f7970-0411-44e8-8792-a167169afa47",
        "text":"3. Member States shall inform the Commission of their designation or designations",
        "title":"Amendment 2567: Article 59 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b213dbd5-3f72-47ce-862a-dbf5d923e556",
        "text":"3. Member States shall inform the Board and the Commission of their designation or designations and, where applicable, the reasons for designating more than one authority.",
        "title":"Amendment 2568: Article 59 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"99f31e3e-9172-4ecb-878f-3dfaa4375340",
        "text":"4. Member States shall ensure that the national competent authorities are provided with adequate technical, financial and human resources, premises and infrastructure necessary to fulfil their tasks under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, personal data protection, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements. Member States shall assess and update competence and resource requirements referred to in this paragraph on an annual basis.",
        "title":"Amendment 2569: Article 59 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"fdc8e1f3-cb60-447e-80d4-4259fb2e402b",
        "text":"4. Member States shall ensure that national supervisory authority is provided with adequate financial and human resources to fulfil its tasks under this Regulation. In particular, national supervisory authorities shall have a sufficient number of permanently available personnel, whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data, data protection and data computing, cybersecurity, competition law, fundamental rights, health and safety risks as well as knowledge of existing standards and legal requirements.",
        "title":"Amendment 2570: Article 59 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"217d5d47-5600-45db-9791-4b089be80f39",
        "text":"4. Member States shall ensure that national competent authorities are provided with adequate financial and human and technical resources to fulfil their tasks effectively under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, competition law, health and safety risks and knowledge of existing standards and other legal requirements.",
        "title":"Amendment 2571: Article 59 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"08c518d3-20d2-4272-b976-ba4057a3bc19",
        "text":"4. Member States shall ensure that national competent authorities are provided with adequate financial, technical and human resources to fulfil their tasks under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements.",
        "title":"Amendment 2572: Article 59 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"a95d2797-e3d2-43d6-b103-d1691ef884c5",
        "text":"4 a. National supervisory authorities shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive XXXX\/XX on measures for a high common level of cybersecurity across the Union (NIS 2), repealing Directive (EU) 2016\/1148.",
        "title":"Amendment 2573: Article 59 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"43f899cd-5a59-42e9-8d7c-4ddc84adb275",
        "text":"4 a. National competent authorities shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive (…) on measures for a high common level of cybersecurity across the Union, repealing Directive (EU) 2016\/1148.",
        "title":"Amendment 2574: Article 59 – paragraph 4 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"fcf039ee-5d2b-411a-954c-c16b30d9b54a",
        "text":"4 b. Any information and documentation obtained by the national competent authorities pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2575: Article 59 – paragraph 4 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"b937d89e-edea-4a8a-8fb2-065def3c400b",
        "text":"4 b. Any information and documentation obtained by the national supervisory authorities pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2576: Article 59 – paragraph 4 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"46d17fdd-01ac-4f78-8a59-2c7d222f0e87",
        "text":"5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with a qualified assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations and formally accept or reject the assessments. Where an assessment is rejected, a new assessment shall be requested.",
        "title":"Amendment 2577: Article 59 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a7ca5ab4-601b-47d4-873f-03ac726b54b5",
        "text":"5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy.",
        "title":"Amendment 2578: Article 59 – paragraph 5  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jorge Buxadé Villalba"
    },
    {
        "uuid":"dca7278f-72dd-4e60-8965-8eea312ef1b6",
        "text":"5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities. The Commission shall transmit that information to the Board for discussion and possible recommendations.",
        "title":"Amendment 2579: Article 59 – paragraph 5  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"14d6b9c2-d31d-4694-9304-87d6fa356063",
        "text":"5. Member States shall report to the Board and the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations.",
        "title":"Amendment 2580: Article 59 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4ef4fa07-b859-4a90-9e5e-23120c16dc00",
        "text":"5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy. The Commission shall transmit that information to the AI Office for discussion and possible recommendations.",
        "title":"Amendment 2581: Article 59 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"96a745db-3b14-482a-8158-90781f5ea629",
        "text":"5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national supervisory authority with an assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations.",
        "title":"Amendment 2582: Article 59 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e25273d8-7aad-46a1-bfd0-e3bf2d748884",
        "text":"6. The Commission and the Board shall facilitate the exchange of experience between national competent authorities.",
        "title":"Amendment 2583: Article 59 – paragraph 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"bb820907-2314-4e3a-ab81-57073f87b612",
        "text":"6. The Commission and the board shall facilitate the exchange of experience between national competent authorities.",
        "title":"Amendment 2584: Article 59 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"60761937-0784-46b0-b355-b09b92b5dd18",
        "text":"6. The Commission and board shall facilitate the exchange of experience between national supervisory authorities.",
        "title":"Amendment 2585: Article 59 – paragraph 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fc79e461-cf33-42e4-850c-21230fd528cc",
        "text":"6. The Board shall facilitate the exchange of experience between national competent authorities.",
        "title":"Amendment 2586: Article 59 – paragraph 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b0005c2e-0568-4ce7-9972-862808b881ef",
        "text":"7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States shall also establish one central contact point for communication with operators. In addition, the central contact point of each Member State should be contactable through electronic communications means.",
        "title":"Amendment 2587: Article 59 – paragraph 7  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"8f15ba07-4ff5-4411-9aa5-3882e90f0a0c",
        "text":"7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the guidance shall be drafted in consultation with the competent national authorities under that Union legislation, as appropriate.",
        "title":"Amendment 2588: Article 59 – paragraph 7  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"90f834b4-f5c9-41a1-bd3a-2557c79b4328",
        "text":"7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to SMEs and start-ups. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted,as appropriate. Member States shall also establish one central contact point for communication with operators and other stakeholders.",
        "title":"Amendment 2589: Article 59 – paragraph 7  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"f7604b27-c3fb-4e2e-9bd8-2d2268e674f0",
        "text":"7. The Board may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever the Board intends to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States may also establish one central contact point for communication with operators.",
        "title":"Amendment 2590: Article 59 – paragraph 7  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"10301b20-36c3-4851-b37a-bada0f214bc9",
        "text":"7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States shall also establish one central contact point for communication with operators.",
        "title":"Amendment 2591: Article 59 – paragraph 7  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"52238f7e-9f6d-4a8b-98b3-489716a35ca8",
        "text":"7. National supervisory authorities may provide guidance and advice on the implementation of this Regulation, including to SMEs and start-ups, as long as it is not in contradiction with the Board’s or the Commission’s guidance and advice. Whenever national supervisory authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent authorities under that Union legislation shall be consulted, as appropriate.",
        "title":"Amendment 2592: Article 59 – paragraph 7  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"11bddfe8-8af4-41c2-95d9-876235c88b6e",
        "text":"8. When Union institutions, agencies and bodies fall within the scope of this Regulation, the European Data Protection Supervisor shall act as the competent authority for their supervision and coordination.",
        "title":"Amendment 2593: Article 59 – paragraph 8  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"0a9db61d-21b0-42be-b437-86187400383d",
        "text":"8. The European Data Protection Supervisor shall act as the competent authority for the supervision of Union institutions, agencies and bodies.",
        "title":"Amendment 2594: Article 59 – paragraph 8  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"cd531b69-8d42-41ec-b0a9-85e1c07491e2",
        "text":"Article 59 a', 'Independent national superviosry authority', '1. Each Member State shall establish or designate a single national supervisory authority within 3 months after the entering into force of this Regulation.', '2. The national supervisory authority shall act as the lead authority and be responsible for ensuring the effective coordination between the national competent authorities regarding the implementation of this Regulation. It shall represent its Member State on the Board, in accordance with Article 57.', '3. Each national supervisory authority shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '4. The members of each national supervisory authority shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from any other body.', '5. Members of each national supervisory authority shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.', '6. Each Member State shall ensure that each national supervisory authority is provided with the human, technical and financial resources, premises and infrastructure necessary for the effective performance of its tasks and exercise of its powers, including those to be carried out in the context of mutual assistance, cooperation and participation in the Board.', '7. Each Member State shall ensure that each national supervisory authority chooses and has its own staff which shall be subject to the exclusive direction of the member or members of the supervisory authority concerned.', '8. Each Member State shall ensure that each national supervisory authority is subject to financial control which does not affect its independence and that it has separate, public annual budgets, which may be part of the overall state or national budget.', '9. Each member of the national supervisory authority shall have the qualifications, experience and skills, in particular an in-depth understanding of artificial intelligence technologies, data and data computing, personal data protection, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements, to perform their duties and exercise their powers.', '10. The duties of a member of the national supervisory authority shall end in the event of the expiry of the term of office, resignation or compulsory retirement, in accordance with the law of the Member State concerned.', '11. A member of the national supervisory authority shall be dismissed only in cases of serious misconduct or if the member no longer fulfils the conditions required for the performance of the duties.', '12. Member States shall make publicly available and communicate to the Commission and the Board, the national supervisory designation, and information on how it can be contacted, by [three months after the entry into force of this Regulation].', '13. For the purposes of the consistent application of the Regulation and for reasons of necessary cooperation with the market surveillance authorities, each national supervisory authority shall have at least one staff member from the market surveillance authority posted as a liaison officer to the national supervisory authority.",
        "title":"Amendment 2595: Article 59 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"694f7d93-fdd6-4715-afb1-4e6952330baf",
        "text":"Article 59 a', 'Consistency mechanism for cross-border cases', '1. Each national supervisory authority shall perform the tasks assigned to and the exercise of the powers conferred on it in accordance with this Regulation on the territory of its own Member State.', \"2. The national supervisory authority of the Member State where the provider's place of central administration in the Union is present or established shall be competent to act as lead national supervisory authority for a cross-border case that involves an AI-system that falls under this Regulation and that is being placed on the market or put into service in two or more Member States.\", '3. In order to contribute to the consistent application of this Regulation throughout the Union, national supervisory authorities shall cooperate with each other and, where relevant, with the Commission and the Board, through the consistency mechanism as set out in the following paragraphs.', '4. The lead national supervisory authority shall cooperate with the other supervisory authorities in an endeavour to reach consensus. The lead national supervisory authority and the other national supervisory authorities concerned shall exchange all relevant information with each other, provide mutual assistance and execute joint operations.', '5. The lead national supervisory authority shall, without delay, communicate the relevant information on the matter to the other national supervisory authorities concerned. It shall without delay submit a draft decision to the other national supervisory authorities concerned for their opinion and take due account of their views.', '6. In case the Board, after being notified by another national supervisory authority, finds that the lead national supervisory authority did not use its investigative, corrective or authorisation power despite being notified by another national supervisory authority or came to a decision that is clearly incompatible with provisions of this Regulation, other national supervisory authorities may address the case on their own, taking into account the procedure described in paragraph 3 or request that the Board issue a binding decision.",
        "title":"Amendment 2596: Article 59 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ee099a81-c594-4f64-bb34-3045e02817f3",
        "text":"Article 59 a', 'Cooperation mechanism between national supervisory authorities in cases involving two or more Member States', '1. Each national supervisory authority shall perform its tasks and powers conferred on in accordance with this Regulation on the territory of its own Member State.', '2. In the event of a case involving two or more national supervisory authorities, the national supervisory authority of the Member State where the provider or the user of the concerned AI system is established or where the authorised representative is appointed shall be considered to be the lead national supervisory authority.', '3. In the cases referred to in paragraph 2,the relevant national supervisory authorities shall cooperate and exchange all relevant information in due time. National supervisory authorities shall cooperate in order to reach a consensus.', '4. In the case of a serious disagreement between two or more national supervisory authorities, the national supervisory authorities shall notify the AI Office and communicate without delay all relevant information related to the case to the AI Office.', '5. The AI Office shall, within three months of receipt of the notification referred to in paragraph 4, issue a binding decision to the national supervisory authorities.",
        "title":"Amendment 2597: Article 59 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"feb2d48e-029e-41ca-a40d-bb08f0ebbe8c",
        "text":"Article 59 a', 'Independence', '1. Each supervisory authority shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '2. The member or members of each supervisory authority shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from anybody.', '3. The member or members of each supervisory authority shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.', '4. Each Member State shall ensure that each supervisory authority chooses and has its own staff which shall be subject to the exclusive direction of the member or members of the supervisory authority concerned.', '5. Each Member State shall ensure that each supervisory authority is subject to financial control which does not affect its independence and that it has separate, public annual budgets, which may be part of the overall state or national budget.",
        "title":"Amendment 2598: Article 59 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"993f1c6f-659e-48d1-9213-7e55a4057ef7",
        "text":"Article 59 b', 'Powers', '1. Each supervisory authority shall have all of the following investigative powers:', '(a) to order the provider or deployer of an AI system, and, where applicable, their representative, to provide any information it requires for the performance of its tasks;', '(b) to carry out investigations of providers or deployers of AI systems in the form of', '(i) audits;', '(ii) reviews of fundamental rights impact assessments;', '(iii) reviews of certifications of conformity;', '(iv) any other investigation to assess compliance with this Regulation;', '(c) to carry out a review on certifications issued pursuant to Article 44;', '(d) to notify the provider or deployer of an AI system of an alleged infringement of this Regulation;', '(e) to obtain, from the provider or deployer of an AI system, access to all data and to all information necessary for the performance of its tasks;', '(f) to obtain access to any premises of the provider or deployer of an AI system, including to any data processing equipment and means, in accordance with Union or Member State procedural law.', '2. Each supervisory authority shall have all of the following corrective powers:', '(a) to issue warnings to a provider or deployer of an AI system that the use or reasonably foreseeable misuse of that system is likely to infringe provisions of this Regulation;', '(b) to issue reprimands to a provider or deployer of an AI system where they have infringed provisions of this Regulation;', \"(c) to order the provider or deployer of an AI system to comply with a subject's request to exercise his or her rights pursuant to this Regulation;\", '(d) to order the provider or deployer of an AI system to bring operations into compliance with the provisions of this Regulation, where appropriate, in a specified manner and within a specified period;', '(e) to order the controller to communicate an infringement of this Regulation to the affected subject;', '(f) to impose a temporary or definitive limitation including a ban of the operation of an AI system;', '(g) to order the erasure of all data and of the related logic underlying automated processing, which had been generated as part of the development, training, or operation of an AI system that was subsequently found in breach of this Regulation;', '(h) to withdraw a certification or to order the certification body to withdraw a certification issued pursuant to Articles 44, or to order the certification body not to issue certification if the requirements for the certification are not or are no longer met;', '(i) to impose an administrative fine pursuant to Article 71, in addition to, or instead of measures referred to in this paragraph, depending on the circumstances of each individual case;', '(j) to order the suspension of the placing on the market of an AI system or of its export to a third country or to an international organisation.', '3. The exercise of the powers conferred on the supervisory authority pursuant to this Article shall be subject to appropriate safeguards, including effective judicial remedy and due process, set out in Union and Member State law in accordance with the Charter.', '4. Each Member State shall provide by law that its supervisory authority shall have the power to bring infringements of this Regulation to the attention of the judicial authorities and where appropriate, to commence or engage otherwise in legal proceedings, in order to enforce the provisions of this Regulation.', '5. Each Member State may provide by law that its supervisory authority shall have additional powers to those referred to in paragraphs 1, 2 and 3. The exercise of those powers shall not impair the effective operation of this Regulation.",
        "title":"Amendment 2599: Article 59 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e80f62cd-a3b1-44c1-a3ac-0b0f10cbec6d",
        "text":"Article 59 b', 'Tasks of the national supervisory authority', '1. Without prejudice to other tasks set out under this Regulation, each national supervisory authority shall on the territory of its Member State:', '(a) monitor and enforce the application of this Regulation, in particular as to the upholding of the principles of article 4a, fundamental rights of individuals and the Union values, as enshrined in Article 2 TEU;', '(b) promote public awareness and understanding of the risks, rules, safeguards and rights in relation to use of AI systems;', '(c) promote the awareness of operators of their obligations under this Regulation;', '(d) monitor operators’ data governance and management practices, in particular in relation to training, validation and testing datasets;', '(e) upon request, provide information to affected persons concerning the exercise of their rights under this Regulation and, if appropriate, cooperate with the supervisory authorities in other Member States to that end;', '(f) handle complaints lodged by an affected person, organisation or association in accordance with Articles 68a and 68b, and investigate, to the extent appropriate, the subject matter of the complaint and inform the complainant of the progress and the outcome of the investigation within a reasonable period, in particular if further investigation or coordination with another national supervisory authority or national competent authority is necessary;', '(g) assist small-scale providers and users in accordance with Article 55;', '(h) cooperate with, including by sharing information and providing mutual assistance to, other national supervisory authorities and national competent authorities with a view to ensuring the consistency of application and enforcement of this Regulation;', '(i) conduct investigations on the application of this Regulation, including on the basis of information received from another national supervisory authority, national competent authority or other public authority;', '(j) cooperate with other competent authorities in their fields of competence, as necessary;', '(k) monitor relevant developments, insofar as they have an impact on the protection of fundamental rights and the values enshrined in Article 2 TEU, in particular the development of technologies and commercial practices;', '(l) contribute to the activities of the Board;', '2. National supervisory authorities may establish regulatory sandboxes in accordance with Article 53.', '3. Each national supervisory authority shall facilitate the submission of complaints referred to in point (f) of paragraph 1 by measures such as a complaint submission form which can also be completed electronically, without excluding other means of communication.', '4. The performance of the tasks of each national supervisory authority shall be free of charge for the affected person.",
        "title":"Amendment 2600: Article 59 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2fedf4dc-e665-4d33-bf26-95a1fe9e73b8",
        "text":"Article 59 c', 'Cooperation and consistency', 'In order to contribute to the consistent application of this Regulation throughout the Union, the national supervisory authorities shall cooperate with each other and, where relevant, with the market surveillance authorities and the Commission, in order to reach consensus.",
        "title":"Amendment 2601: Article 59 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"cf481289-a747-49e9-b035-f6255ecfdfe5",
        "text":"Article 59 d', 'Cooperation mechanism in cases involving two or more Member States', '1. Each national supervisory authority shall perform its tasks and powers conferred to it in accordance with this Regulation, on the territory of its own Member State.', '2. In the event of a case involving two or more national supervisory authorities, the national supervisory authority of the Member State where the provider or the user of the concerned AI system is established, or where the legal representative resides, shall be considered to be the lead national supervisory authority.', '3. In case it is not clear which national supervisory authority should act as the lead authority pursuant to paragraph 2, the Board shall issue a binding decision according to Article 59e.', '4. In cases referred to in paragraph 2, the relevant national supervisory authorities shall cooperate and exchange all relevant information in due time.', '5. The national supervisory authorities shall, where appropriate, conduct joint operations, including joint investigations, in which members or staff of the national supervisory authorities of other Member States are involved.', '6. In case of a serious disagreement between two or more national supervisory authorities, the national supervisory authorities shall notify the Board and communicate without delay all relevant information related to the case to the Board for a binding decision.",
        "title":"Amendment 2602: Article 59 d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7fc69a61-248a-4662-8660-b48817041fb1",
        "text":"Article 59 e', 'Binding decisions by the Board', '1. In order to ensure the correct and consistent application of this Regulation in individual cases, the Board shall adopt a binding decision in the following cases:', '(a) where there are conflicting views on which of the national supervisory authorities concerned would be the lead authority pursuant to Article 59c;', '(b) where, in a case referred to in Article 59c(4), there is a serious disagreement between national supervisory authorities concerned regarding a matter involving two or more Member States;', '(c) where, in a case referred to in Article 67a, a national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection;', '2. The decisions referred to in paragraph 1, point (a) shall be adopted within one week from the referral of the subject-matter, by a two-thirds majority of the members of the Board.', '3. The decisions referred to in paragraph 1, points (b) and (c) shall be adopted within one month from the referral of the subject-matter, by a two-thirds majority of the members of the Board. That period may be extended by a further month on account of the complexity of the subject-matter. The decision referred to in paragraph 1, points (b) and (c) shall be reasoned and addressed to the lead national supervisory authority and all the national supervisory authorities concerned and be binding on them.', '4. Where the Board has been unable to adopt a decision within the periods referred to in paragraph 3, it shall adopt its decision within two weeks following the expiration of the second month referred to in paragraph 2 by a simple majority of the members of the Board. Where the members of the Board are split, the decision shall by adopted by the vote of its Chair.', '5. The national supervisory authorities concerned shall not adopt a decision on the subject matter submitted to the Board under paragraph 1, points (b) and (c) during the periods referred to in paragraphs 3 and 4.', '6. The Chair of the Board shall notify, without undue delay, the decision referred to in paragraph 1 to the national supervisory authorities concerned. It shall also inform the Commission thereof. The decision shall be published on the website of the Board without delay after the national supervisory authorities have been notified.",
        "title":"Amendment 2603: Article 59 e (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"dda8dfaf-3ab6-4cde-99c3-08e8dc700cf3",
        "text":"2 a Effective remedies', 'Create a comprehensive remedies framework for affected persons, including a right for individuals to bring complaints, a right to bring collective action; and a right to information.",
        "title":"Amendment 2604: Title VI – Chapter 2 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"303fef47-250a-4710-9e66-f445d792f261",
        "text":"2 b The right to object to the use of automated decision-making in high-risk areas', 'Individuals shall have the right not to be subject to a decision based solely on automated processing by high-risk AI systems in Annex III which significantly affects them.",
        "title":"Amendment 2605: Title VI – Chapter 2 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"aa521816-40ea-499f-8a45-0d1a3459ad31",
        "text":"deleted",
        "title":"Amendment 2606: Title VII  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"c622fad4-0918-4c43-ab65-66b30c9f2370",
        "text":"EU DATABASE FOR STAND-ALONE AI SYSTEMS",
        "title":"Amendment 2607: Title VII  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c63ef7e7-1deb-4d33-ac05-53a4a0d87773",
        "text":"EU DATABASE FOR HIGH-RISK AI SYSTEMS",
        "title":"Amendment 2608: Title VII  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f9de7421-7686-47d5-a74c-38ef823acc63",
        "text":"EU DATABASE FOR AI SYSTEMS",
        "title":"Amendment 2609: Title VII  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4dabf65b-f484-41fd-8af7-f090c0b2df0b",
        "text":"60 EU database for stand-alone high-risk, general purpose and certain AI systems, uses thereof, and uses of AI systems by public authorities AI systems",
        "title":"Amendment 2610: Article 60 – title  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b42271e5-bd57-4366-9c5b-bfb7f3e5db9a",
        "text":"EU database for stand-alone AI systems",
        "title":"Amendment 2611: Article 60 – title  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"cf99e345-fb5f-42f9-89e9-38b4bf2e43d5",
        "text":"EU database for high-risk AI systems",
        "title":"Amendment 2612: Article 60 – title  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5c0caf46-b058-401a-b090-c22aac225272",
        "text":"EU database for AI systems",
        "title":"Amendment 2613: Article 60 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1a1fd275-7640-4e39-8a50-dfa8601afada",
        "text":"1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 concerning AI systems which are registered in accordance with Article 51 and general purpose AI systems, in accordance with Article xx:', 'a. high-risk AI systems referred to in Article 6(2) which are registered in accordance with Article 51(1);', 'b. any AI systems referred to in Article 52 paragraphs 1b and 2 which are registered in accordance with Article 51(1);', 'c. any uses of high-risk AI systems referred to in Article 6(2) which are registered in accordance with Article 51(2);', 'd. any uses of AI systems referred to in Article 52 paragraph 1b and 2 which are registered in accordance with Article 51(2);', 'e. any uses of AI systems by or on behalf of public authorities registered in accordance with Article 51(3).",
        "title":"Amendment 2614: Article 60 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0fa24f39-86a3-40fd-92d5-0b8d83224346",
        "text":"1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 concerning high-risk AI systems in one of the areas listed in Annex III which are registered in accordance with Article 51 and their uses by public authorities and Union institutions, bodies, offices or agencies or on their behalf.",
        "title":"Amendment 2615: Article 60 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"4bb446d0-d5ad-40c0-9728-324dfc77f992",
        "text":"1. The Commission shall, in collaboration with the Member States and by building on the existing Business Registries in line with Directive 2012\/17\/EU, set up and maintain a EU database containing information referred to in paragraph 2 concerning high-risk AI systems listed in Annex III which are registered in accordance with Article 51.",
        "title":"Amendment 2616: Article 60 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"57598b24-2aad-469c-b99d-d12074136e20",
        "text":"1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 and 2a concerning AI systems which are registered in accordance with Article 51, as well as users of any AI systems by public authorities and Union institutions, bodies, offices or agencies.",
        "title":"Amendment 2617: Article 60 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1c59f11d-3b52-473e-a369-5a3b402bce52",
        "text":"1. The Commission shall, in collaboration with the Member States, set up and maintain a public EU database containing information referred to in paragraph 2 concerning high-risk AI systems which are registered in accordance with Article 51.",
        "title":"Amendment 2618: Article 60 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9b182dac-1937-4f19-af2b-609edcf49f2d",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.",
        "title":"Amendment 2619: Article 60 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"97a9c0ff-edc6-466e-bbfe-356fe9d11dac",
        "text":"2. The Commission shall provide providers and users entering data into the EU database with technical and administrative support.The following information should be included in the EU database:', '(a) For registrations according to paragraph 1(a) and 1(b), the data listed in Annex VIII point 1 shall be entered into the EU database by the providers.', '(b) For registrations according to paragraph 1(c) , 1(d) and 1(e), the data listed in Annex VIII point 2 shall be entered into the EU database by the users.",
        "title":"Amendment 2620: Article 60 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1ce8cb17-8b4d-4d87-8492-1263ed110ef3",
        "text":"2. The data listed in Annex VIII shall be entered into the EU database by the providers, and, where relevant, deployers. The Commission shall provide them with technical and administrative support.",
        "title":"Amendment 2621: Article 60 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a6053134-49a3-476f-8320-c66f642efe85",
        "text":"2 a. The data listed in Annex VIII, point (2), shall be entered into the EU database by the users, including those who are or who act on behalf of public authorities or Union institutions, bodies, offices or agencies. The Commission shall provide them with technical and administrative support.",
        "title":"Amendment 2622: Article 60 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"511fa446-1be2-4b23-942b-9875a91a02d8",
        "text":"3. Information contained in the EU database shall be freely available and accessible to the public, comply with the accessibility requirements of Annex I to Directive 2019\/882, and be user-friendly, navigable, and machine-readable, containing structured digital data based on a standardised protocol.",
        "title":"Amendment 2623: Article 60 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a13a206e-f945-4145-82ea-05a8a1c7e745",
        "text":"3. The EU database and the information contained in it shall be freely available to the public, comply with the accessibility requirements of Annex I to Directive 2019\/882, and be user-friendly, navigable, and machine-readable, containing structured digital data based on a standardised protocol.",
        "title":"Amendment 2624: Article 60 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6b92fc8d-342b-4a2f-b7ac-73b35d580845",
        "text":"3. Information contained in the EU database shall be accessible to the public, user-friendly and machine-readable.",
        "title":"Amendment 2625: Article 60 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6d9d6a9d-7124-4686-90ca-7bfe1e7fe604",
        "text":"3 a. Users should register deployments of high-risk AI systems into the EU database before putting them into use. The users should include information in the database, not limited to, the identity of the provider and the user, the context of the purpose and of deployment, the designation of impacted persons, and the results of the impact assessment.",
        "title":"Amendment 2626: Article 60 – paragraph 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1f476787-ef96-4728-b2cf-94c639b4822b",
        "text":"4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the user, if the user is a public authority or a Union institution, body, office or agency or a user acting on their behalf.",
        "title":"Amendment 2627: Article 60 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen"
    },
    {
        "uuid":"9b3738f6-092f-45e3-95c1-35afea6ad1b0",
        "text":"4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider, or the user.",
        "title":"Amendment 2628: Article 60 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"587a2da1-3c3d-4b29-8039-48150afad2f6",
        "text":"4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the user.",
        "title":"Amendment 2629: Article 60 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1d289969-0d61-494c-bd6e-1248572ebc44",
        "text":"4 a. The EU database shall not contain any confidential business information or trade secrets of a natural or legal person, including source code.",
        "title":"Amendment 2630: Article 60 – paragraph 4 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"444cb26f-691b-492b-93a2-0cc03893851d",
        "text":"4 a. The EU database shall not contain any confidential business information or trade secrets of a natural or legal person, including source code.",
        "title":"Amendment 2631: Article 60 – paragraph 4 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"422dc8e9-00fe-4f96-9bf2-3a9cbba4e049",
        "text":"5. The Commission shall be the controller of the EU database. It shall also ensure to providers and users adequate technical and administrative support, in particular in relation to registrations according to paragraph 1(e).",
        "title":"Amendment 2632: Article 60 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"83cad224-590c-4f32-959a-11fe4a7a9fbe",
        "text":"5. The Commission shall be the controller of the EU database.",
        "title":"Amendment 2633: Article 60 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"94cd99a2-1ec0-44e8-9823-37128d57ee6b",
        "text":"5. The Commission shall be the controller of the EU database. It shall also ensure to providers and, where relevant, deployers, adequate technical and administrative support.",
        "title":"Amendment 2634: Article 60 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"fd638a03-61a0-4c79-8785-f438ebc194f4",
        "text":"5 a. Any information and documentation obtained by the Commission and Member States pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2635: Article 60 – paragraph 5 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan"
    },
    {
        "uuid":"5a17dd52-cc76-4e42-bafc-7aa7fcd7db5f",
        "text":"5 a. Any information and documentation obtained by the Commission and Member States pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2636: Article 60 – paragraph 5 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ed6b478e-5d6d-4936-af04-e62997e4020c",
        "text":"5 a. The database shall comply with the accessibility requirements of Annex I to Directive 2019\/882.",
        "title":"Amendment 2637: Article 60 – paragraph 5 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3f361d3c-6ac0-4dee-a171-6db1367d463c",
        "text":"Article 60 a', 'Systemic transparency and monitoring of societal implications', '1. The Commission shall, in collaboration with the Member States, set up and maintain a relational database of digital and AI systems that interact with high-risk or general purpose AI systems or with AI systems with transparency obligations. Among others, the relational database shall include digital and AI systems whose input directly or indirectly come from a high-risk or general purpose AI system or whose output directly or indirectly is taken as input by a high-risk or general purpose AI system.', '2. For each entry in the EU database referred to in Article 60, the provider shall enter the upstream and downstream digital and AI systems into the relational database, as well as, to the extent it is possible, the digital and AI systems upstream of the upstream AI systems and the digital and AI systems downstream of the downstream AI systems.', '3. The European AI Board and the Commission shall regularly assess the relational map to facilitate incident response and to identify AI systems (‘Societally Significant AI systems’)whose output is used as input into many downstream digital and AI systems.4. The European AI Board and the Commission shall develop a Code of Conduct for Societally Significant AI Systems.",
        "title":"Amendment 2638: Article 60 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c17f5577-4a61-4a43-b817-d76c74bc7dcd",
        "text":"1. Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the the risks of the high-risk AI system.",
        "title":"Amendment 2639: Article 61 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2c14b08e-03bb-4452-b28e-0b94aec53ef7",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.', 'Post-market monitoring must include continuous analysis of the AI environment, including other devices, software, and other AI systems that will interact with the AI system.",
        "title":"Amendment 2640: Article 61 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"fe40bb6c-d6ee-4a1b-994c-ab2c99374778",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2. Post-market monitoring must include continuous analysis of the AI environment, including other devices, software, and other AI systems that will interact with the AI system.",
        "title":"Amendment 2641: Article 61 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"9187c0b3-cc57-4d7d-a721-33ecbf8b53ac",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by deployers or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2. Post-market monitoring shall include continuous analysis of the AI environment, including other devices, software, and other AI systems that interact with the AI system.",
        "title":"Amendment 2642: Article 61 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"01559cd9-7a2d-44a3-961c-48bb42fbd433",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.",
        "title":"Amendment 2643: Article 61 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"5c594d15-c126-4bb3-a00a-e83bd498778d",
        "text":"2. In order to allow the provider to evaluate the compliance of AI systems with the requirements set out in Title III, Chapter 2 throughout their lifetime, the post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems.",
        "title":"Amendment 2644: Article 61 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d032b131-d69c-46c0-ae88-d1fd81a0da26",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, not including the automated transmission of data, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.",
        "title":"Amendment 2645: Article 61 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"d750bb12-d6cd-448f-8fa2-05358f68b4d6",
        "text":"2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users and end-users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.",
        "title":"Amendment 2646: Article 61 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"d2858d3a-ecff-4303-800d-89bf4c5f3533",
        "text":"3. The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV. The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan. These provisions shall not provide for the automated and systematic transmission of data.",
        "title":"Amendment 2647: Article 61 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"2dcea3c7-04af-4551-bf40-770f084e5f4d",
        "text":"3. The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV. The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan by ... [12 months following the entry into force of this Regulation].",
        "title":"Amendment 2648: Article 61 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"31dd0edb-96b7-478f-9e01-66534400d11c",
        "text":"2 Sharing of information on incidents",
        "title":"Amendment 2649: Title VIII – Chapter 2 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"58d21ff6-9038-4c0c-9e3b-02162a3f0647",
        "text":"Reporting of serious incidents",
        "title":"Amendment 2650: Article 62 – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"90fb6e18-c9f9-4415-9ab3-70820fef3c96",
        "text":"1. Providers and, where users have identified a serious incident or malfunctioning, users of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law to the market surveillance authorities of the Member States where that incident or breach occurred and to the affected persons and, where the incident or breach occurs or is likely to occur in at least two Member States, to the Commission.",
        "title":"Amendment 2651: Article 62 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a96f927a-4425-4b8c-b226-3c02341cec57",
        "text":"1. Providers and, where users have identified a serious incident or malfunctioning, users of AI systems placed on the Union market shall report any serious incident or any malfunctioning, including near misses, of those systems which constitutes a breach of obligations under Union law to the national supervisory authorities and the market surveillance authorities of the Member States where that incident or breach occurred and, where relevant, to the Commission and to the affected persons.",
        "title":"Amendment 2652: Article 62 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"943e2a33-4d5d-4c6f-93bb-71d53558fa4e",
        "text":"1. Providers of high-risk AI systems placed on the Union market shall report any serious incident to the market surveillance authorities of the Member States where that incident occurred.",
        "title":"Amendment 2653: Article 62 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d4496466-c33d-47c2-b60d-dd4c30fac1e8",
        "text":"1. Providers and, where users have identified a serious incident or malfunctioning, including near misses, users of high-risk or general purpose systems which constitutes a breach of obligations under Union law intended to protect fundamental rights, health and safety to the market surveillance authorities of the Member States where that incident or breach occurred, and to the Commission..",
        "title":"Amendment 2654: Article 62 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"a3a35a9f-998e-4ad0-ae12-90cdbf7af128",
        "text":"1. Providers and, where applicable, users of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law intended to protect fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred.",
        "title":"Amendment 2655: Article 62 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"6ccffc41-ef64-4499-aa12-17f88a4e0c24",
        "text":"1. Providers and deployers of AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law or of fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred.",
        "title":"Amendment 2656: Article 62 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c3c336b0-f81f-445e-8853-d211e1a05d07",
        "text":"Such notification shall be made without undue delay after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.",
        "title":"Amendment 2657: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"61c1e653-d984-4e23-bc2f-e405abc2885d",
        "text":"Such notification shall be made immediately after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.",
        "title":"Amendment 2658: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"78b70371-0b8c-43c6-8b6c-dee00c2c8ebd",
        "text":"Such notification shall be made immediately after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.",
        "title":"Amendment 2659: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"b38442fe-759a-4af4-97ec-1fdda1ac0d1d",
        "text":"Such notification shall be made immediately when an AI system is involved in an incident or malfunctioning, including near misses, and, in any event, not later than 72 hours after the providers or, where applicable, the user becomes aware of the serious incident or of the malfunctioning.",
        "title":"Amendment 2660: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"1b22ca2b-ad0a-48f2-90de-4719e38eb6d4",
        "text":"Such notification shall be made immediately when an AI system is involved in the incident or malfunctioning, including near misses, and, in any event, not later than 72 hours after the providers or, where applicable, the user becomes aware of the serious incident or of the malfunctioning.",
        "title":"Amendment 2661: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"cb2a2156-42af-4b1e-98fc-9cbeb7f94eab",
        "text":"Such notification shall be made without undue delay after the provider has established a causal link between the AI system and the serious incident or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident.",
        "title":"Amendment 2662: Article 62 – paragraph 1 – subparagraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d93d1442-8f54-466b-9e91-c393631e964c",
        "text":"No report under this Article is required if the serious incident also leads to reporting requirements under other laws. In that case, the authorities competent under those laws shall forward the received report to the national competent authority.",
        "title":"Amendment 2663: Article 62 – paragraph 1 – subparagraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e1dd2765-37b0-47e4-a1b0-d03cc51f17ad",
        "text":"No report under this Article is required if the serious incident also leads to reporting requirements under other laws. In that case, the authorities competent under those laws shall forward the received report to the national competent authority.",
        "title":"Amendment 2664: Article 62 – paragraph 1 – subparagraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"aeaf929b-1274-4231-a3be-b79f42443fb4",
        "text":"2. Upon receiving a notification related to a serious incident referred to in Article 3(44), the relevant market surveillance authority shall inform the national public authorities or bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to facilitate compliance with the obligations set out in paragraph 1. That guidance shall be issued 12 months after the entry into force of this Regulation, at the latest.",
        "title":"Amendment 2665: Article 62 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"39079b3d-ed4f-4afb-8f2f-6700e7c58a1a",
        "text":"2. Upon receiving a notification related to a breach of obligations under Union law or of fundamental rights, the market surveillance authority shall inform the national public authorities or bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to facilitate compliance with the obligations set out in paragraph 1. That guidance shall be issued 3 months after the entry into force of this Regulation, at the latest.",
        "title":"Amendment 2666: Article 62 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"0547d2c3-a91d-4c49-b1d3-bf7ef8196f59",
        "text":"2 a. The market surveillance authorities shall take appropriate measures within 7 days from the date it received the notification referred to in paragraph 1. Where the infringement takes place or is likely to take place in other Member States, the market surveillance authority shall notify the Commission, the Board and the relevant national competent authorities of these Member States.",
        "title":"Amendment 2667: Article 62 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"b24fb74f-24ce-4006-b19a-9b8e6c39345f",
        "text":"2 a. Upon establishing a causal link between the AI system and the serious incident or malfunctioning or the reasonable likelihood of such a link, providers shall take appropriate corrective actions pursuant to Article 21.",
        "title":"Amendment 2668: Article 62 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"f713a9ec-9e4e-464f-a943-d183a04eb8e6",
        "text":"3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are subject to regulations that require solutions equivalent to those set out in this Regulation, the notification of serious incidents shall be limited to those referred to in Article 3(44).",
        "title":"Amendment 2669: Article 62 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b391e60f-4e61-4d80-b454-9763433a82ba",
        "text":"3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013\/36\/EU and for high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017\/745 and Regulation(EU) 2017\/746, the notification of serious incidents or malfunctioning for the purposes of this Regulation shall be limited to those that that constitute a breach of obligations under Union law intended to protect fundamental rights and the environment.",
        "title":"Amendment 2670: Article 62 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"d0c188a9-69f5-49ba-9cf1-1070c924b1a0",
        "text":"3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013\/36\/EU and for high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017\/745 and Regulation (EU) 2017\/746, the notification of serious incidents or malfunctioning shall be limited to those that that constitute a breach of obligations under Union law or fundamental rights.",
        "title":"Amendment 2671: Article 62 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ec1a4595-6f56-437a-a08d-55fe19f97321",
        "text":"3 a. Requirements in place in existing EU legislation shall be taken into account with regard to reporting of information of incidents, in view of avoiding duplications and harmonizing the provisions on incident and event reporting.",
        "title":"Amendment 2672: Article 62 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"6df3c40f-c545-4168-84ab-c9c41041ac72",
        "text":"3 a. National supervisory authorities shall on an annual basis notify the Board of the serious incidents and malfunctioning reported to them in accordance with this Article.",
        "title":"Amendment 2673: Article 62 – paragraph 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"6456fc5d-7a4c-46a5-b0b6-8c505daddbe4",
        "text":"2. The national supervisory authority shall report annually to the Commission the outcomes of relevant market surveillance activities. The national supervisory authority shall report, without delay, to the Commission and relevant national competition authorities any information identified in the course of market surveillance activities that may be of potential interest for the application of Union law on competition rules.",
        "title":"Amendment 2674: Article 63 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"fe570e2d-049c-44d0-a9f4-1a61fced7d80",
        "text":"3 a. For the purpose of regulating high-risk AI systems, Market surveillance authorities may have the power to:', '(a) carry out unannounced on-site and remote inspections of high-risk AI systems;', '(b) acquire samples related to high-risk AI systems, including through remote inspections, to reverse-engineer the AI systems and to acquire evidence to identify non-compliance.",
        "title":"Amendment 2675: Article 63 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"dee74f66-c3e5-4286-85bc-2c544a328361",
        "text":"3 a. The procedures referred to in Articles 65, 66, 67 and 68 of this Regulation shall not apply to AI systems related to products, to which legal acts listed in Annex II, section A apply, when such legal acts already provide for procedures having the same objective. In such a case, these sectoral procedures shall apply instead.",
        "title":"Amendment 2676: Article 63 – paragraph 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"538ca44f-8070-4d4f-9125-0406b9c283fc",
        "text":"5. For AI systems that are used for law enforcement purposes, Member States shall designate as market surveillance authorities for the purposes of this Regulation the competent data protection supervisory authorities under Directive (EU) 2016\/680, or Regulation 2016\/679.",
        "title":"Amendment 2677: Article 63 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"17c63844-314b-4d01-b509-6a853ba5dfa0",
        "text":"5. For AI systems listed in point 1(a) in so far as the systems are used for law enforcement purposes Member States shall designate as market surveillance authorities for the purposes of this Regulation the competent data protection supervisory authorities under Directive (EU) 2016\/680 or Regulation 2016\/679.",
        "title":"Amendment 2678: Article 63 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"392de6e9-fbdc-43c4-be61-e5a00d75818b",
        "text":"1. Without prejudice to powers provided under Regulation (EU) 2019\/1020, and where relevant and limited to what is necessary to fulfil their tasks, market surveillance authorities may request access to data and documentation in the context of their activities, the market surveillance authorities shall be granted full access to the training, validation and testing datasets used by the provider that are strictly necessary for the purpose of its request., including, where appropriate and subject to security safeguards, through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.",
        "title":"Amendment 2679: Article 64 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"bbca13ec-958d-4374-987c-0fcd14d12de1",
        "text":"1. When appropriate and proportionate, market surveillance authorities may request access to data and documentation in the context of their activities. The market surveillance authorities shall only be granted, access to those training, machine-learning validation and testing datasets used by the provider that are relevant and strictly necessary for the purpose of its request, after it has been clearly demonstrated that the data and documentation provided under paragraph 1 was not sufficient to assess conformity.",
        "title":"Amendment 2680: Article 64 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b5594431-d2d0-40f2-bdbb-32b599c1ab2a",
        "text":"1. Access to data and documentation in the context of their activities, the market surveillance authorities shall be granted sufficient access to the training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access, taking into account the scope of access agreed with the relevant data subjects or data holders.",
        "title":"Amendment 2681: Article 64 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"9f4a8209-03e7-4387-90ae-10694dd3ac4a",
        "text":"1. In the context of their activities, the national supervisory authorities, the market surveillance authorities, or the Commission, shall be granted full access to the training data sets, and where applicable, validation and testing datasets used by the provider or, where relevant, the user, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.",
        "title":"Amendment 2682: Article 64 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"ac4f5c26-2ef4-4c96-9236-c9a57beba70b",
        "text":"1. Upon a reasoned request the market surveillance authorities shall be granted access to the training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.",
        "title":"Amendment 2683: Article 64 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"ab15162e-df9f-489b-808b-bcd7fb258310",
        "text":"1. Access to data and documentation in the context of their activities, the market surveillance authorities shall be granted access to the relevant training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.",
        "title":"Amendment 2684: Article 64 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"ae967496-6a49-44d2-89dd-ffef9b8307d5",
        "text":"1. In the context of their activities, the market surveillance authorities shall be granted full access to the comprehensive training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.",
        "title":"Amendment 2685: Article 64 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"43c44b7f-989a-442d-9c33-d1598fb770ed",
        "text":"1 a. Providers may challenge requests through an appeal procedure made available by Member States.",
        "title":"Amendment 2686: Article 64 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"64169155-281a-433a-a71d-2e26011a8bdb",
        "text":"deleted",
        "title":"Amendment 2687: Article 64 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0e44078c-9be5-4a0d-8516-15c3c333cb86",
        "text":"2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2, after all other reasonable ways to verify conformity have been exhausted and have proven to be insufficient, and upon a reasoned request, the market surveillance authorities or, where applicable, the Commission, shall be granted access to the source code of the AI system. Such access shall be subject to existing Union law on the protection of intellectual property and trade secrets.",
        "title":"Amendment 2688: Article 64 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"3895bf7e-7277-4c86-987e-94ed4e585992",
        "text":"2. Market surveillance authorities shall be granted access to the source code of the high-risk AI system upon a reasoned request and only when the following cumulative conditions are fulfilled:', 'a) Access to source code is necessary to assess the conformity of a high-risk AI system with the requirements set out in Title III, Chapter 2, and', 'b) testing\/auditing procedures and verifications based on the data and documentation provided by the provider have been exhausted or proved insufficient.",
        "title":"Amendment 2689: Article 64 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"fec2a679-36b6-4df5-8bdf-d78b70902722",
        "text":"2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the national supervisory authority, the market surveillance authorities or, where applicable, the Commission shall be granted access to the source code of the AI system.",
        "title":"Amendment 2690: Article 64 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"cc03dca6-93a2-4c49-bc23-e1fd28561361",
        "text":"2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request. AI providers or deployers shall support market surveillance authorities with the necessary facilities to carry out testing to confirm compliance.",
        "title":"Amendment 2691: Article 64 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"34881c6b-42d3-4776-a87e-049daff94858",
        "text":"2. Where necessary to assess the conformity of the high-risk uses of AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall ask for the explainability of the functioning of algorithms and criteria used by an AI system.",
        "title":"Amendment 2692: Article 64 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"0b48e122-d67c-4e62-ab0b-0ad03ecb3984",
        "text":"2. Where necessary to assess the conformity of the high-risk uses of AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall ask for the explainability of the functioning of algorithms and criteria used by an AI system.",
        "title":"Amendment 2693: Article 64 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"eb4411c7-dcf5-4704-a7da-4465e594673e",
        "text":"2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall be granted access to other data if no confidential business information are at risk.",
        "title":"Amendment 2694: Article 64 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"209f3d3f-4d65-408f-a3fc-87cc735e0d37",
        "text":"2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon request, the market surveillance authorities shall be granted access to the source code of the AI system.",
        "title":"Amendment 2695: Article 64 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"9e5b42b2-d0c2-491f-a1c6-bd1498da6628",
        "text":"3. National public authorities or bodies which supervise or enforce the respect of obligations under Union law protecting fundamental rights in relation to the use of high-risk AI systems referred to in Annex III shall have the power to request and access any documentation created or maintained under this Regulation, including data protection impact assessments and human rights impact assessments carried out by the users of such systems, when access to that documentation is necessary for the fulfilment of the competences under their mandate within the limits of their jurisdiction. The relevant public authority or body shall inform the market surveillance authority of the Member State concerned of any such request.",
        "title":"Amendment 2696: Article 64 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"14061920-414c-4d1b-a35e-98bcd196bfb2",
        "text":"3. National public authorities or bodies, which supervise or enforce the respect of obligations under Union law protecting fundamental rights in relation to the use of high-risk AI systems referred to in Annex III shall have the power to request and access any documentation created or maintained under this Regulation when access to that documentation is necessary for the fulfilment of the competences under their mandate within the limits of their jurisdiction.",
        "title":"Amendment 2697: Article 64 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"a0f829d1-99a6-436a-991b-e0c70c6318f2",
        "text":"deleted",
        "title":"Amendment 2698: Article 64 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"fa889b16-bca6-4977-aef2-036875f5bec6",
        "text":"4. By 3 months after the entering into force of this Regulation, each Member State shall identify the public authorities or bodies referred to in paragraph 3 and make a list publicly available on the website of the national supervisory authority. Member States shall notify the list to the Commission and all other Member States and keep the list up to date. The European Commission shall publish in a dedicated website the list of all the Competent authorities designated by the Member States in accordance with this article.",
        "title":"Amendment 2699: Article 64 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"abae4741-559a-4c67-a487-e39147c818a8",
        "text":"5. Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a breach of obligations under Union law intended to protect fundamental rights has occurred, the public authority or body referred to paragraph 3 may make a reasoned request to the national supervisory authority, the market surveillance authority, or where applicable the Commission, to organise testing of the high-risk AI system through technical means. The national supervisory authority, the market surveillance authority or where applicable the Commission shall organise the testing with the close involvement of the requesting public authority or body within reasonable time following the request.",
        "title":"Amendment 2700: Article 64 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"e72609de-d464-4c42-bc67-f1f0ba2bd5f9",
        "text":"5. Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a breach of obligations under Union law or fundamental rights has occurred, the public authority or body referred to paragraph 3 may make a reasoned request to the market surveillance authority to organise testing of the high-risk AI system through technical means. The market surveillance authority shall organise the testing with the close involvement of the requesting public authority or body within reasonable time following the request.",
        "title":"Amendment 2701: Article 64 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c06eebb6-b55f-4107-8272-32a0b22d9571",
        "text":"6. Any information and documentation obtained by the market surveillance authorities or the national public authorities or bodies referred to in paragraph 1, 2 and 3 pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",
        "title":"Amendment 2702: Article 64 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"688958ea-66cc-4790-98c0-0e2871c51ecd",
        "text":"Article 64 a', 'Market surveillance authorities', '1. Market surveillance authorities shall, at a minimum, have the power to', '(a) carry out unannounced on-site and remote inspections of AI systems.', '(b) acquire samples related to AI systems, including through remote inspections, to reverse-engineer the AI systems and to acquire evidence to identify non-compliance.', '2. Member States may authorise their market surveillance authorities to reclaim from the relevant operator the totality of the costs of their activities with respect to instances of non-compliance.', '3. The costs referred to in paragraph 2 of this Article may include the costs of carrying out testing, computation, hardware,storage, and the costs of activities relating to AI systems that are found to be non-compliant and are subject to corrective action prior to their placing on the market.",
        "title":"Amendment 2703: Article 64 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"42675cfc-7e14-4ccb-b86a-bb64bec3d733",
        "text":"Procedure for dealing with AI systems presenting a risk",
        "title":"Amendment 2704: Article 65 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"59514e12-7326-4978-93f4-5984254ff014",
        "text":"1. AI systems presenting a risk means an AI system having the potential to affect adversely fundamental rights, health and safety of persons in general, including in the workplace, protection of consumers, the environment, public security, the values enshrined in Article 2 TEU and other public interests, that are protected by the applicable Union harmonisation legislation, to a degree which goes beyond that considered reasonable and acceptable in relation to its intended purpose or under the normal or reasonably foreseeable conditions of use of the system concerned, including the duration of use and, where applicable, its putting into service, installation and maintenance requirements.",
        "title":"Amendment 2705: Article 65 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"c037fc95-b24c-4947-985c-297738174d1f",
        "text":"1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019\/1020 insofar as risks to the health or safety in general, including safety in the workplace, protection of consumers, the environment, or to the protection of fundamental rights of persons are concerned, including autonomy of choice, access to goods and services, unfair discrimination and economic harm, privacy and data protection, as well as societal risks.",
        "title":"Amendment 2706: Article 65 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a5536f91-287a-4988-811b-d1ebbed6837f",
        "text":"1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019\/1020 insofar as risks to the health or safety or to the protection of fundamental rights of persons, or of public order or the national security of the Member States are concerned.",
        "title":"Amendment 2707: Article 65 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"ba4f2a35-836f-446e-bd6b-f493930da664",
        "text":"1. AI systems presenting a risk shall be understood as AI systems having the potential to affect adversely the fundamental rights of persons, their health or safety, as well as AI systems having the potential to breach the principles defined in Art. 4a or the Union values as enshrined in Article 2 TEU.",
        "title":"Amendment 2708: Article 65 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"74c1d29e-d47c-4e79-b18d-ac4b0571cf20",
        "text":"1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019\/1020 insofar as risks to the health or safety or to fundamental rights of persons are concerned.",
        "title":"Amendment 2709: Article 65 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"a4358fb8-1ac1-4c40-acc5-be54d733a13a",
        "text":"1 a. When AI systems are likely to interact with or impact on children, the precautionary principle shall apply.",
        "title":"Amendment 2710: Article 65 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Milan Brglez, Hilde Vautmans, Catharina Rinzema"
    },
    {
        "uuid":"7b155d72-b4ab-45ae-825c-285ea0a0ab78",
        "text":"1 a. When AI systems are likely to interact with or impact on children, the precautionary principle shall apply.",
        "title":"Amendment 2711: Article 65 – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5b2cfa08-9f9a-4151-9fd1-bc00d75dcc02",
        "text":"2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to the protection of fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities or bodies referred to in Article 64(3). Where there is sufficient reason to consider that that an AI system exploits the vulnerabilities of children or violates their rights intentionally or unintentionally, the market surveillance authority shall have the duty to investigate the design goals, data inputs, model selection, implementation and outcomes of the AI system and the burden of proof shall be on the operator or operators of that system to demonstrate compliance with the provisions of this Regulation. The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3), including by providing access to personnel, documents, internal communications, code, data samples and on platform testing as necessary. Where, in the course of its evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe. The corrective action can also be applied to AI systems in other products or services judged to be similar in their objectives, design or impact.",
        "title":"Amendment 2712: Article 65 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Milan Brglez, Hilde Vautmans, Catharina Rinzema"
    },
    {
        "uuid":"3183dcb9-524a-4288-8e7a-95996ec74b11",
        "text":"2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to the protection of fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities, Board or bodies referred to in Article 64(3). Where there is sufficient reason to consider that that an AI system exploits the vulnerabilities of children or violates their rights intentionally or unintentionally, the market surveillance authority shall have the duty to investigate the design goals, data inputs, model selection, implementation and outcomes of the AI system and the burden of proof shall be on the operator or operators of that system to demonstrate compliance with the provisions of this Regulation. The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3), including by providing access to personnel, documents, internal communications, code, data samples and on platform testing as necessary.",
        "title":"Amendment 2713: Article 65 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1eb15157-cab5-4c6e-8c04-09a013fa1185",
        "text":"2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk to the health and safety of persons, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation.",
        "title":"Amendment 2714: Article 65 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"48726af5-3328-4903-be7e-cf9a8e773cad",
        "text":"2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities or bodies referred to in Article 64(3). The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3).",
        "title":"Amendment 2715: Article 65 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"d314b30b-bdbe-4bae-b573-d84100397e30",
        "text":"Where, in the course of its evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe. The corrective action can also be applied to AI systems in other products or services judged to be similar in their objectives, design or impact.",
        "title":"Amendment 2716: Article 65 – paragraph 2 – subparagraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a18bd844-247f-4b5b-aedd-26e1a359d0da",
        "text":"Where, in the course of that evaluation, the market surveillance authority or, where relevant, the national public authority referred to in Article 64(3) finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe, and in any case no later than 15 working days.",
        "title":"Amendment 2717: Article 65 – paragraph 2 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"22e0537c-b41d-4957-8d6b-de034f9cf213",
        "text":"Where, in the course of that evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions within a reasonable period, commensurate with the nature of the risk, and which it may prescribe, to withdraw the AI system from the market, or to recall it to bring it into compliance.",
        "title":"Amendment 2718: Article 65 – paragraph 2 – subparagraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"4537123b-32f0-4ad5-a797-8663d3776024",
        "text":"2 a. Where the national supervisory authority has sufficient reasons to consider that an AI system presents a risk to the protection of fundamental rights, the principles as defined in Art 4a or the Union values, as enshrined in Article 2 TEU, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation.",
        "title":"Amendment 2719: Article 65 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4bae02c5-8acf-448d-91b0-39164fb9c3a5",
        "text":"2 b. Where, in the course of that evaluation, the market surveillance authority or, where relevant, the national supervisory authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe, and in any case no later than 15 working days.', 'The market surveillance authority shall inform the relevant notified body accordingly. Article 18 of Regulation (EU) 2019\/1020 shall apply to the measures referred to in the first subparagraph.",
        "title":"Amendment 2720: Article 65 – paragraph 2 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0ecc91aa-c40a-480a-b799-cc7b9ba626ca",
        "text":"3. Where the market surveillance authority or, where relevant, the national supervisory authority, considers that non-compliance is not restricted to its national territory, it shall inform the Board, the Commission and the Member States’ competent authorities of the results of the evaluation and of the actions which it has required the operator to take.",
        "title":"Amendment 2721: Article 65 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7a16c343-d722-4c16-b741-8b53013d32a9",
        "text":"3. Where the market surveillance authority considers that non-compliance is not restricted to its national territory, it shall inform the Commission and the other Member States without undue delay of the results of the evaluation and of the actions which it has required the operator to take.",
        "title":"Amendment 2722: Article 65 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5284af87-4f14-4027-b4ad-7f00cd262ef0",
        "text":"3. Where the market surveillance authority considers that non-compliance is not restricted to its national territory, it shall inform the Commission, the AI Office and the other Member States of the results of the evaluation and of the actions which it has required the operator to take.",
        "title":"Amendment 2723: Article 65 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"621bc343-92ba-4951-9d94-476f55663406",
        "text":"5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2b, the market surveillance authority or, where relevant, the national supervisory authority, shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market or put into service, to withdraw the AI system from that market or to recall it. That authority shall immediately inform the Commission, the Board and the Member States’ market surveillance authorities, of those measures.",
        "title":"Amendment 2724: Article 65 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0cdc4d47-7db4-47b5-8560-d036c48bcf93",
        "text":"5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market or put into service, to withdraw the AI system from that market or to recall it. That authority shall immediately inform the Commission, the Board and the other Member States, of those measures.",
        "title":"Amendment 2725: Article 65 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"324cf547-8f24-4be8-ac52-272a837a2d2a",
        "text":"5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market, to withdraw the product from that market or to recall it. That authority shall notify the Commission and the other Member States, without delay, of those measures.",
        "title":"Amendment 2726: Article 65 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5e929ccb-aacb-4629-94bc-895103ccda87",
        "text":"6. The notification referred to in paragraph 5 shall include all available details, in particular the information necessary for the identification of the non-compliant AI system, the origin of the AI system, the nature of the non-compliance alleged and the risk involved, the nature and duration of the national measures taken and the arguments put forward by the relevant operator. In particular, the market surveillance authorities shall indicate whether the non-compliance is due to one or more of the following:",
        "title":"Amendment 2727: Article 65 – paragraph 6 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"a6d3f5f9-d7dc-4217-9edb-3098fb4bf690",
        "text":"(a) a failure of the AI system to meet requirements and obligations set out in this Regulation;",
        "title":"Amendment 2728: Article 65 – paragraph 6 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"2bfc7779-9fe4-4855-832b-2d01d2bfd9bc",
        "text":"(a) a failure of the high-risk AI system to meet requirements set out in Title III, Chapter 2;",
        "title":"Amendment 2729: Article 65 – paragraph 6 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"c5e7789e-a176-4382-a2ae-914f7512f642",
        "text":"(b a) non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5;",
        "title":"Amendment 2730: Article 65 – paragraph 6 – point b a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"394c3009-3b82-4c2d-9e1a-708a0a6c965a",
        "text":"(b b) non-compliance with provisions set out in Article 52;",
        "title":"Amendment 2731: Article 65 – paragraph 6 – point b b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"68aafa19-bb73-463c-a6ce-a93f42c2e188",
        "text":"7. The market surveillance authorities of the Member States other than the market surveillance authority of the Member State initiating the procedure shall without delay inform the Commission and the other Member States of any measures adopted and of any additional information at their disposal relating to the non-compliance of the AI system concerned.",
        "title":"Amendment 2732: Article 65 – paragraph 7  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"4df9e435-7dbe-41e4-af03-13583adfd214",
        "text":"7. The market surveillance authorities or, where applicable, the national supervisory authorities of the other Member States shall without delay inform the Commission, the Board and the authority initiating the procedure of any measures adopted and of any additional information at their disposal relating to the non-compliance of the AI system concerned, and, in the event of disagreement with the notified national measure, of their objections.",
        "title":"Amendment 2733: Article 65 – paragraph 7  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"a2cc5625-e288-4216-bb34-bf5ff38c0bfc",
        "text":"deleted",
        "title":"Amendment 2734: Article 65 – paragraph 8  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"6f8e2618-dc18-4c16-8d81-7dd2b4c379fc",
        "text":"8. Where, within three months of receipt of the notification referred to in paragraph 5, no objection has been raised by either a Member State or the Commission in respect of a provisional measure taken by a Member State, that measure shall be deemed justified. This is without prejudice to the procedural rights of the concerned operator in accordance with Article 18 of Regulation (EU) 2019\/1020. The period referred to in the first sentence of this paragraph shall be reduced to 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5.",
        "title":"Amendment 2735: Article 65 – paragraph 8  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"067a348b-6788-4758-9b6a-21f035376874",
        "text":"8. Where, within three months of receipt of the information referred to in paragraph 5, no objection has been raised by either a market surveillance authority, a national supervisory authority, or the Commission in respect of a provisional measure taken by a market surveillance authority or a national supervisory authority , that measure shall be deemed justified. This is without prejudice to the procedural rights of the concerned operator in accordance with Article 18 of Regulation (EU) 2019\/1020.",
        "title":"Amendment 2736: Article 65 – paragraph 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"82f637a7-a9a7-4c13-a515-5cb96c40e1dc",
        "text":"9. The market surveillance authorities of all Member States shall ensure that appropriate restrictive measures are taken in respect of the AI system concerned, such as withdrawal of the product from their market, without delay.",
        "title":"Amendment 2737: Article 65 – paragraph 9  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"a43915d8-54a8-40c4-b94a-7f00e68434de",
        "text":"deleted",
        "title":"Amendment 2738: Article 66  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"fcf81929-83d8-48f3-b141-4bbd129bc755",
        "text":"1. Where, within three months of receipt of the notification referred to in Article 65(5), or 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, objections are raised by a Member State against a measure taken by another Member State, or where the Commission considers the measure to be contrary to Union law, the Commission shall without delay enter into consultation with the relevant Member State’s market surveillance authority and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within 9 months, or 60 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, starting from the notification referred to in Article 65(5) and notify such decision to the Member State concerned. The Commission shall also inform all other Member States of such decision.",
        "title":"Amendment 2739: Article 66 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"4d52bd8b-89c7-4f52-b061-78b63c5a46df",
        "text":"1. Where, within three months of receipt of the notification referred to in Article 65(5), objections are raised by the European Parliament or a Member State against a measure taken by another Member State, or where the Commission considers the measure to be contrary to Union law, or has sufficient reasons to believe that an AI system presents a risk or affects consumers in more than one Member State the Commission shall without delay enter into consultation with the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within 9 months from the notification referred to in Article 65(5) and notify such decision to the Member State concerned.",
        "title":"Amendment 2740: Article 66 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"12a9aaf3-10c6-47b1-a0f5-c2eff3c4aec2",
        "text":"1. Where, within three months of receipt of the notification referred to in Article 65(5), objections are raised by a Member State against a measure taken by another Member State, or where the Board considers the measure to be contrary to Union law, the Board shall without delay enter into consultation with the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Board shall decide whether the national measure is justified or not within 9 months from the notification referred to in Article 65(5) and notify such decision to the Member State concerned.",
        "title":"Amendment 2741: Article 66 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"6ff64d23-929d-4fb4-b797-7e9647ef803c",
        "text":"2. If the national measure is considered justified, all Member States shall take the measures necessary to ensure that the non-compliant AI system is withdrawn from their market, and shall inform the Board accordingly. If the national measure is considered unjustified, the Member State concerned shall withdraw the measure.",
        "title":"Amendment 2742: Article 66 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"35388d5e-a38b-46ee-81f2-ff2a9ecb3c7c",
        "text":"3. Where the national measure is considered justified and the non-compliance of the AI system is attributed to shortcomings in the harmonised standards or common specifications referred to in Articles 40 and 41 of this Regulation, the Commission shall apply the procedure provided for in Article 11 of Regulation (EU) No 1025\/2012.The Commission shall also have the possibility to suggest alternative measures to the Member State concerned.",
        "title":"Amendment 2743: Article 66 – paragraph 3 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"95883a83-a8be-44f3-a5e6-7719dca6c994",
        "text":"3 a. If the national measure is found to be unjustified, the Member State concerned shall reimburse the operator for the costs and loss of revenue directly attributable to the measure found to be unjustified.",
        "title":"Amendment 2744: Article 66 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"2d9ba39a-1dc5-46a8-9cbc-9059da76956f",
        "text":"Article 66 a', 'Requests for Commission intervention', '1. Where market surveillance authorities have reasons to suspect that the infringement of a provider or of a user of a high-risk AI system to this Regulation is liable to compromise the health or safety or fundamental of affected persons, the environment and the Union values enshrined in Article 2 TEU amount to a widespread infringement or a widespread infringement with a Uniondimension or affects or is likely affect at least 45 million citizens in the Union. The market surveillance authority may request the Commission to take the necessary investigatory and enforcement measures to ensure compliance with this Regulation. Such request shall set out the reasons for the Commission to intervene.', '2. Prior to requesting the Commission to intervene, the market surveillance authority shall notify the Board which shall issue within 7 days a non-binding opinion on the request for the Commission to intervene. The market surveillance authority shall take into account the non-binding opinion of the Board before sending its request to the Commission.",
        "title":"Amendment 2745: Article 66 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"0d181d94-68e0-4bd4-a934-85d0e1b3d1e1",
        "text":"deleted",
        "title":"Amendment 2746: Article 67  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1580c254-d0b6-4f32-ba1d-fd46733a2581",
        "text":"Compliant AI systems which present a risk to the health and safety",
        "title":"Amendment 2747: Article 67 – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"4f16a9dd-5bd9-42af-9905-2ccf241db39e",
        "text":"1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons or to the compliance with obligations under Union or national law intended to protect fundamental rights, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk",
        "title":"Amendment 2748: Article 67 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e9ad67d4-201e-471c-a395-25ae3dcf1cd6",
        "text":"1. Where, having performed an evaluation under Article 65 in full cooperation with the relevant national public authority referred to in Article 64(3),the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights, environment, European values as enshrined in Article 2 TEU or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.",
        "title":"Amendment 2749: Article 67 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"3cc2ef3b-78ca-4205-abf4-173f4a14aa16",
        "text":"1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.",
        "title":"Amendment 2750: Article 67 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"8cbe4c1c-5cdd-4a75-aa8d-84802e9a1bbe",
        "text":"1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons or to fundamental rights, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.",
        "title":"Amendment 2751: Article 67 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"5af80608-83ae-401a-ba04-fd99309347a2",
        "text":"1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds and demonstrates that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.",
        "title":"Amendment 2752: Article 67 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"04191333-a483-43e4-9e35-df77bdae2c1d",
        "text":"2 a. Should the provider or other relevant operators fail to take corrective action as referred to in paragraph 2 and should the AI system continue to present a risk as referred to in paragraph 1, the market surveillance authority may require the relevant operator, as a measure of last resort, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk.",
        "title":"Amendment 2753: Article 67 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"7780e5bd-59cf-477b-940f-339cef5b5c08",
        "text":"3. The market surveillance authority shall immediately inform the Commission, the Board and the other Member States’ market surveillance authorities. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.",
        "title":"Amendment 2754: Article 67 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"536689de-85a7-4b90-8438-a68316add1d9",
        "text":"3. The Member State shall immediately inform the Commission, the AI Office, and the other Member States. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.",
        "title":"Amendment 2755: Article 67 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"94d121c7-d387-4bc8-9cb3-467a4ab43514",
        "text":"3. The Member State shall immediately inform the Board and the other Member States. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.",
        "title":"Amendment 2756: Article 67 – paragraph 3  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"3e4e2aa4-894a-4cd2-bd3c-a2077cab310a",
        "text":"4. The Commission shall without delay enter into consultation with the Member States and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall propose appropriate measures.",
        "title":"Amendment 2757: Article 67 – paragraph 4  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"96dca77b-909e-488b-992f-7f5767bcd137",
        "text":"4. The Commission shall without delay enter into consultation with the Member States concerned and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.",
        "title":"Amendment 2758: Article 67 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"97286cf8-48df-49e1-9b73-d55988b530b7",
        "text":"4. The Commission shall without delay enter into consultation with the market surveillance authorities and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.",
        "title":"Amendment 2759: Article 67 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c6c0f431-190a-43aa-ab87-6d51dce14baf",
        "text":"4. The Board shall without delay enter into consultation with the Member States and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Board shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.",
        "title":"Amendment 2760: Article 67 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5d79ae88-6406-40ee-8e21-eeb74bc04fee",
        "text":"5. The Commission shall address its decision to the market surveillance authorities and communicate it to them and to the relevant operators.",
        "title":"Amendment 2761: Article 67 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"84b4b81b-dc35-4f50-b3bb-abdd4a25b79c",
        "text":"5. The Commission shall address its decision to the Member States concerned, and inform all other Member States.",
        "title":"Amendment 2762: Article 67 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"1decb059-6ac3-4d8f-b79b-9f0b75b14c63",
        "text":"5. The Board shall address its decision to the Member States.",
        "title":"Amendment 2763: Article 67 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"087392a6-8b7b-4f7b-81e1-b149bfa237e0",
        "text":"5 a. The Board shall adopt guidelines to help national competent authorities to identify and rectify, where necessary, similar problems arising in other AI systems.",
        "title":"Amendment 2764: Article 67 – paragraph 5 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f01adb04-38d0-45ae-9510-e41d1d207fa0",
        "text":"Article 67 a', 'Compliant AI systems which present a risk to the fundamental rights', '1. Where, having performed an evaluation under Article 65, the national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.', '2. The provider or other relevant operators shall ensure that corrective action is taken in respect of all the AI systems concerned that they have made available on the market throughout the Union within the timeline prescribed by the national supervisory authority of the Member State referred to in paragraph 1.', '3. The national supervisory authority shall immediately inform the Board, the Commission and the market surveillance authority. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.', '4. The Board shall without delay enter into consultation with the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Board shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.', '5. The Board shall address its decision to the national supervisory authority and to the relevant operators.",
        "title":"Amendment 2765: Article 67 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f6ad2ff2-802e-421d-a315-0950c41b6377",
        "text":"(b) the CE marking has not been affixed;",
        "title":"Amendment 2766: Article 68 – paragraph 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cf58b0a8-4380-4e7a-8e6d-a93d8c348083",
        "text":"2. Where the non-compliance referred to in paragraph 1 persists for longer than one week following receipt of the relevant notice, the Member State concerned shall take all appropriate measures to restrict or prohibit the high-risk AI system being made available on the market or ensure that it is recalled or withdrawn from the market, imposing, where necessary, the penalties laid down in national law.",
        "title":"Amendment 2767: Article 68 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"01065936-25d7-4d85-aedc-b08c481c04e8",
        "text":"2. Where the non-compliance referred to in paragraph 1 persists, the Member State concerned shall take proportionate measures to restrict or prohibit the high-risk AI system being made available on the market.",
        "title":"Amendment 2768: Article 68 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a857ee6a-b849-4f65-bd97-d570f05a4519",
        "text":"2. Where the non-compliance referred to in paragraph 1 persists, the Member State concerned shall take all appropriate and proportionate measures to restrict or prohibit the high-risk AI system being made available on the market or ensure that it is recalled or withdrawn from the market.",
        "title":"Amendment 2769: Article 68 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"00b02545-6536-4440-9b40-b54f8e40f080",
        "text":"Article 68 a', 'Insufficient application or non-application of Union law by the competent authority', '1. Where a competent authority has failed to ensure that an AI system is in compliance with the requirements laid down in this Regulation, or where a competent authority fails to require sufficient corrective action from an operator of an AI system that is incompliance with this Regulation but presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights or to other aspects of public interest protection, the Commission shall act in accordance with the powers set out in the following paragraphs of this Article.', '2. Upon request from one or more competent authorities, the European Parliament, the Council, the European Artificial Intelligence Board, or on its own initiative, including when this is based on well substantiated information from natural or legal persons, and after having informed the competent authority concerned, the Commission shall outline how it intends to proceed with the case and, where appropriate, investigate the alleged insufficient application or non-application of Union law.', 'The competent authority shall, without delay, provide the Commission with all information which the Commission considers necessary for its investigation.', 'The Commission may, after having informed the competent authority concerned, address a duly justified and reasoned request for information directly to other competent authorities whenever requesting information from the competent authority concerned has proven, or is deemed tobe, insufficient to obtain the information that is deemed necessary for the purpose of investigating an alleged insufficient application or non-application of Union law. The addressee of such a request shall provide the Commission with clear, accurate and complete information without undue delay.', 'Before issuing a recommendation as set out in paragraph 4, the Commission shall engage with the competent authority concerned where it considers such engagement appropriate in order to resolve the insufficient application or non-application of Union law, in an attempt to reach agreement on actions necessary for the competent authority to comply with Union law.', '3. Where necessary to issue a recommendation as set out in paragraph 4, the Commission shall have the rights granted to the market surveillance authorities under Article 64.', '4. The Commission may, not later than 2 months from initiating its investigation, address a recommendation to the competent authority concerned setting out the action necessary to comply with Union law. The competent authority shall, within ten working days of receipt of the recommendation, inform the Commission of the steps it has taken or intends to take to ensure compliance with Union law.', '5. Where the competent authority has not complied with Union law within 1 month from receipt of the Commission’s recommendation, the Commission may issue a formal opinion requiring the competent authority to take the action necessary to comply with Union law. The Commission shall issue such a formal opinion no later than 3 months after the adoption of the recommendation set out in paragraph 4. The Commission may extend this period by 1 month.', '6. The competent authority shall, within ten working days of receipt of the formal opinion referred to in paragraph 5,inform the Commission of the steps it has taken or intends to take to comply with that formal opinion.', '7. Without prejudice to the powers of the Commission pursuant to Article 258 TFEU, where a competent authority does not comply with the formal opinion referred to in paragraph 5 of this Article within the period specified therein, the Commission may adopt an individual decision addressed to the operator of an AI system requiring it to take all necessary action to comply with its obligations under Union law.', 'The decision of the Commission shall be in conformity with the formal opinion issued pursuant to paragraph 5.', '8. Decisions adopted in accordance with paragraph 7 shall prevail over any previous decision adopted by the competent authorities on the same matter. When taking action in relation to issues which are subject to a formal opinion pursuant to paragraph 5 or to a decision pursuant to paragraph 7, competent authorities shall comply with the formal opinion or the decision, as the case may be.",
        "title":"Amendment 2770: Article 68 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder"
    },
    {
        "uuid":"6dad4db8-f3d2-4bfa-8c50-93d862423b63",
        "text":"Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Without prejudice to any other administrative or judicial remedy, AI subjects and any natural or legal person affected by an AI system shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the subject considers that the use of a particular AI system, he or she is affected by, infringes this Regulation. Such a complaint may be lodged through a representative action for the protection of the collective interests of consumers as provided under Directive (EU) 2020\/1828.', '2. Complainants shall have a right to be heard in the complaint handling procedure and in the context of any investigations or deliberations conducted by the competent authority as a result of their complaint.', '3. Supervisory authorities shall inform complainants or their representatives about the progress and outcome of their complaints. In particular, supervisory authorities shall take all the necessary actions to follow up on the complaints they receive and, within three months of the reception of a complaint, give the complainants a preliminary response indicating the measures they intend to take and the next steps in the procedure, if any.', '4. The supervisory authority shall take a decision on the complaint, including the possibility of a judicial remedy pursuant to Article 68b, without delay and no later than six months after the date on which the complaint was lodged.",
        "title":"Amendment 2771: Article 68 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5cc215e4-af97-4676-b230-93214b4c9b3e",
        "text":"Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Without prejudice to any other administrative or judicial remedy, every natural or legal person shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the natural or legal person considers that their health, safety, or fundamental rights have been breached by an AI system falling within the scope of this Regulation.', '2. Natural or legal persons shall have a right to be heard in the complaint handling procedure and in the context of any investigations conducted by the national supervisory authority as a result of their complaint.', '3. The national supervisory authority with which the complaint has been lodged shall inform the complainants about the progress and outcome of their complaint. In particular, the national supervisory authority shall take all the necessary actions to follow up on the complaints it receives and, within three months of the reception of a complaint, give the complainant a preliminary response indicating the measures it intends to take and the next steps in the procedure, if any.', '4. The national supervisory authority shall take a decision on the complaint and inform the complainant on the progress and the outcome of the complaint, including the possibility of a judicial remedy pursuant to Article 68b, without delay and no later than six months after the date on which the complaint was lodged.",
        "title":"Amendment 2772: Article 68 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Samira Rafaela, Monica Semedo, Salima Yenbou, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"222e791f-ff50-418c-b003-c655c5f8b9b6",
        "text":"Article 68 a', 'Right to lodge a complaint', '1. Affected persons, affected by an AI system falling within the scope of this Regulation, shall have the right to lodge a complaint against the providers or users of such AI system, with the national supervisory authority of the Member State where they have their habitual place of residence or place of work or where the alleged infringement took place, if they consider that their fundamental rights, health or safety have been breached.', '2. Affected persons shall have a right to be heard in the complaint handling procedure and in the context of any investigations conducted by the national supervisory authority as a result of their complaint.', '3. The national supervisory authority with which the complaint has been lodged shall inform the complainants about the progress and outcome of their complaint. In particular,the national supervisory authority shall take all the necessary actions to follow up on the complaints it receives and, within three months of the reception of a complaint, give the complainant a preliminary response indicating the measures it intends to take and the next steps in the procedure, if any.', '4. The national supervisory authority shall take a decision on the complaint, without delay and no later than six months after the date on which the complaint was lodged.",
        "title":"Amendment 2773: Article 68 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"302c5fbe-28e8-4e3a-938d-996902574372",
        "text":"Article 68 a', 'Representation of affected persons and the right of public interest organisation to lodge complaints', '1. Without prejudice to Directive 2020\/1828\/EC, natural per-sons or groups of natural persons affected by an AI system shall have the right to mandate a body, organisation or association to lodge a complaint referred to in Article 68 on their behalf, to exercise the right to remedy referred to in Article 68 on their behalf, and to exercise on their behalf other rights under this Regulation, in particular the right to receive an explanation referred to in Article 4a', '2. Without prejudice to Directive 2020\/1828\/EC, the bodies, organisations or associations referred to in paragraph 1 shall have the right to lodge a complaint with national supervisory authorities, independently of the mandate of the natural per-son, if they consider that an AI system has been placed on the market, put into service, or used in a way that infringes this Regulation, or is otherwise in violation of fundamental rights or other aspects of public interest protection, pursuant to article 67.', '3. National supervisory authorities have the duty to investigate, in conjunction with relevant market surveillance authority if applicable, and respond within a reasonable period to all com-plaints referred to in paragraph 2.",
        "title":"Amendment 2774: Article 68 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"2ba865ad-3672-4207-b86a-fb5b3bed868e",
        "text":"Article 68 a', 'Commission fees', '1. The Commission shall charge fees to market surveillance authorities when the Commission initiates proceedings in accordance with Article 68a(1)(c).', '2. The overall amount of the fee shall cover the estimated costs the Commission incurs in relation to proceedings carried out under this Regulation, in particular costs related to the investigation and enforcement measures pursuant to Chapter 4 of Title VIII.', '3. The Commission shall lay down in a delegated act, adopted pursuant to Article 73, the detailed methodology and procedures for:(a) the determination of the estimated costs referred to in paragraph 2and the necessary payment modalities.', '4. The fees charged pursuant to paragraph 1 shall constitute external assigned revenue in accordance with Article 21(5) of Regulation (EU, Euratom) No 2018\/1046 of the European Parliament and of the Council.', '5. The Commission shall report annually to the European Parliament and to the Council on the overall amount of the costs incurred for the fulfilment of the tasks under this Regulation and the total amount of the fees charged in the preceding year.",
        "title":"Amendment 2775: Article 68 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9b05e956-69b2-4e69-871b-40c6f55f5b95",
        "text":"Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Citizens have a right not to be subjected to prohibited AI systems.', '2. Citizens have a right not to be subjected to high-risk AI systems that fail to meet the requirements for high-risk systems.', '3. Without prejudice to any other administrative or judicial remedy, every citizen shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the citizen considers that he or she has been subjected to an AI system that infringes this Regulation.', '4. The supervisory authority with which the complaint has been lodged shall inform the complainant on the progress and the outcome of the complaint.', '5. Without prejudice to any other administrative or non-judicial remedy, each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision",
        "title":"Amendment 2776: Article 68 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"11b11282-3484-46d2-b444-0d6019547e50",
        "text":"Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Every citizen who considers that his or her right to protection of personal data has been infringed by the use of a prohibited AI system or a high-risk AI system shall have the right to lodge a complaint with the authority in charge to handle complaints under Article 77 of Regulation (EU) 2016\/679 in the Member State of his or her habitual residence, place of work or place of the alleged infringement.', '2. The supervisory authority with which the complaint has been lodged shall inform the complainant on the progress and the outcome of the complaint.",
        "title":"Amendment 2777: Article 68 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"821e2679-81bc-48d1-bd3b-e26ceec63165",
        "text":"Article 68 b', 'Representation of affected persons', '1. An affected person shall have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of rights and freedoms of affected persons, with regard to the protection of their fundamental rights, to lodge the complaint on their behalf, to exercise the rights referred to in Article 68a on his or her behalf, and to exercise the right to receive compensation referred to in Article 70a and 71 on his or her behalf.', '2. Any body, organisation or association referred to in paragraph 1 of this Article, independently of an affected person’s mandate, has the right to lodge, in that Member State, a complaint with the national supervisory authority which is competent pursuant to Article 68a, if it considers that the rights of a affected persons under this Regulation have been infringed as a result of them being subject to AI systems.",
        "title":"Amendment 2778: Article 68 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ff39770e-0220-44ff-8a12-63621ccc630c",
        "text":"Article 68 b', 'Right to an effective judicial remedy against a national supervisory authority', '1. Without prejudice to any other administrative or non-judicial remedy, each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision of a national supervisory authority concerning them.', '2. Without prejudice to any other administrative or non-judicial remedy, each data subject shall have the right to a an effective judicial remedy where the national supervisory authority does not handle a complaint, does not inform the complainant on the progress or preliminary outcome of the complaint lodged within three months pursuant to Article 68a(3) or does not comply with its obligation to reach a final decision on the complaint within six months pursuant to Article 68a(4) or its obligations under Article 65.', '3. Proceedings against a supervisory authority shall be brought before the courts of the Member State where the national supervisory authority is established.",
        "title":"Amendment 2779: Article 68 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,"
    },
    {
        "uuid":"db6534cd-063b-454c-b647-eeda8e494eba",
        "text":"Article 68 b', 'Right to an effective judicial remedy against an authority', '1. Without prejudice to any other administrative or non-judicial remedy, individuals and their representatives shall have the right to an effective judicial remedy against any legally binding decision concerning them, whether by a market surveillance authority or a supervisory authority.', '2. Without prejudice to any other administrative or non-judicial remedy, individuals shall have the right to a an effective judicial remedy where the authority which is competent does not handle a complaint, does not inform the individual on the progress or preliminary outcome of the complaint lodged within three months pursuant to Article 68a (3), does not comply with its obligation to reach a final decision on the complaint within six months pursuant to Article 68a (3) or its obligations under Article 65.', '3. Proceedings against a market surveillance authority shall be brought before the courts of the Member State where the authority is established.",
        "title":"Amendment 2780: Article 68 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e6c452f5-860b-4206-9f7c-f368b525d733",
        "text":"Article 68 b', 'Representation of affected persons or groups of persons', '1. Without prejudice to Directive 2020\/1828\/EC, the person or groups of persons harmed by AI systems shall have the right to mandate a not-for-profit body, organisation or association which has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of rights and freedoms impacted by AI to lodge the complaint on his, her or their behalf, to exercise the rights referred to in this Regulation on his, her or their behalf.', '2. Without prejudice to Directive 2020\/1828\/EC, the body, organisation or association referred to in paragraph 1 shall have the right to exercise the rights established in this Regulation independently of a mandate by a person or groups of person if it considers that a provider or a user has infringed any of the rights or obligations set out in this Regulation.",
        "title":"Amendment 2781: Article 68 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"0c979433-e3a7-4880-bb49-9ee9088ceb6b",
        "text":"Article 68 c', 'Remedies', '1. Without prejudice to any available administrative or non-judicial remedy and the right to lodge a complaint with a supervisory authority pursuant to Article 68a, any natural person shall have the right to an effective judicial remedy against a provider or deployer where they consider that their rights under this Regulation have been infringed or has been subject to an AI system otherwise in non-compliance with this Regulation.', '2. Any person who has suffered material or non-material harm, as a result of an infringement of this Regulation shall have the right to receive compensation from the provider or deployer for the damage suffered. Individuals and their representatives shall be able to seek judicial and non-judicial remedies against providers or deployers of AI systems, including repair, replacement, price reduction, contract termination, reimbursement of the price paid or compensation for material and immaterial damages, for breaches of the rights and obligations set out in this Regulation.', '3. Providers and deployers of AI systems which may affect individuals, including AI-subjects, or consumers must provide an effective complaint handling system which enables complaints to be lodged electronically and free of charge, and ensure that complaints submitted through this system are dealt with in an efficient and expedient manner.', '4. Providers and deployers of AI systems shall ensure that their internal complaint-handling systems are easy to access, user-friendly and enable and facilitate the submission of sufficiently precise and adequately substantiated complaints.', '5. Where an AI system infringes this Regulation, any natural or legal person affected by said AI system may ask the supervisory authority or judicial authorities to stop the use of this system.', '6. Member States shall ensure that where infringements of an AI system are imminent or likely, any affected natural or legal person may seek a prohibitory injunction under national law.",
        "title":"Amendment 2782: Article 68 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ac70a10b-3cd1-4c97-a028-1870fa1b1b16",
        "text":"Article 68 c', 'Amendment to Directive 2020\/1828\/EC on Representative Actions for the Protection of the Collective Interests of Consumers', 'The following is added to Annex I of Directive 2020\/1828\/EC on Representative actions for the protection of the collective interests of consumers: “Regulation xxxx\/xxxx of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain union legislative acts”.",
        "title":"Amendment 2783: Article 68 d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"725de40a-c005-462c-aeb9-f6472aaee73f",
        "text":"Article 68 d', 'Representation of individuals', '1. Without prejudice to Directive 2020\/1828\/EC, individuals shall have the right to mandate a body, organisation or association to exercise the rights referred to in Articles 68a, 68b and 68c and, where relevant, the rights of AI subjects, on their behalf, provided that the body, organisation or association meets all of the following conditions:', 'a) It operates on a not-for-profit basis;', 'b) It has been constituted in accordance of the law of a Member State;', 'c) Its statutory objectives include a legitimate interest in ensuring that this Regulation is complied with.', '2. Without prejudice to Directive 2020\/1828\/EC, the bodies, organisations or associations referred to in paragraph 1 shall have the right to exercise the rights established in Articles 68a, 68b and 68c independently of an individual’s mandate, if they consider that a provider or user of an AI system has infringed any of the rights or obligations set out in this Regulation.",
        "title":"Amendment 2784: Article 68 d (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"3775ca0b-e7c7-4209-9d70-83bd17969f99",
        "text":"Article 68 d', 'Reporting of breaches and protection of reporting persons', 'Directive (EU) 2019\/1937 of the European Parliament and of the Council shall apply to the reporting of breaches of this Regulation and the protection of persons reporting such breaches.",
        "title":"Amendment 2785: Article 68 d (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"088797d3-940c-4e51-93a5-f92922ac29d8",
        "text":"1. The Commission, AI Office, and the Member States shall encourage and facilitate the drawing up of codes of conduct intended to foster the development and use of safe and trustworthy AI for AI systems other than high-risk AI systems. These codes of conduct should be voluntary and should be based on the requirements set out in Title III, Chapter 2 on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements but be adapted in light of the intended purpose of the systems and of the lower risk involved",
        "title":"Amendment 2786: Article 69 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"9f36916b-1f13-49cf-b994-44c5450e3f1e",
        "text":"1. The Commission and the board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems other than high-risk AI systems of the requirements set out in Title III, Chapter 2 on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements in light of the intended purpose of the systems.",
        "title":"Amendment 2787: Article 69 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"51a7efd6-6a97-43b7-9c3f-7f4c46c00375",
        "text":"1 a. The Commission and the Board shall encourage and facilitate the drawing up of Codes of Conduct intended to foster the voluntary application of the concept of trustworthy AI set out in Article 4(a) to AI systems other than high-risk AI systems on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements in light of the intended purpose of the system.",
        "title":"Amendment 2788: Article 69 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3a29e0ad-f10e-4b98-92b5-d737fe902d9d",
        "text":"2. The Commission and the Board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability and stakeholders’ participation in the design and development of the AI systems on the basis of clear objectives and key performance indicators to measure the achievement of those objectives.",
        "title":"Amendment 2789: Article 69 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"cc706650-9d86-44ae-91d7-90ce1ec6018c",
        "text":"2. The Commission and the AI Office shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability, stakeholders participation in the design and development of the AI systems and diversity of development teams on the basis of clear objectives and key performance indicators to measure the achievement of those objectives.",
        "title":"Amendment 2790: Article 69 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a0c81b26-f662-49a5-8b35-3f72dd921f41",
        "text":"3. Codes of conduct may be drawn up by individual providers of AI systems or by organisations representing them or by the Commission or the AI Office, including with the involvement of users and any interested stakeholders and their representative organisations. Codes of conduct may cover one or more AI systems taking into account the similarity of the intended purpose of the relevant systems.",
        "title":"Amendment 2791: Article 69 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"9e133c70-2824-4bc0-a938-4840cba387e2",
        "text":"4. The Commission and the AI Office shall take into account the specific interests and needs of the small-scale providers and start-ups when encouraging and facilitating the drawing up of codes of conduct.",
        "title":"Amendment 2792: Article 69 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"08f52db4-cb03-4a2c-8ec7-d9f68591916d",
        "text":"4. The Commission and the Board shall take into account the specific interests and needs of SMEs and start-ups when encouraging and facilitating the drawing up of codes of conduct.",
        "title":"Amendment 2793: Article 69 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"db7cb464-45df-4f61-b275-cd23d9df954c",
        "text":"4. The Commission and the Board shall take into account the specific interests and needs of the SMEs and start-ups when encouraging and facilitating the drawing up of codes of conduct.",
        "title":"Amendment 2794: Article 69 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"01898640-d01a-41d4-a0c8-8cda8a94db02",
        "text":"1. National competent authorities, market surveillance authorities and notified bodies involved in the application of this Regulation shall put effective cybersecurity, technical and organisational measures in place to ensure the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:",
        "title":"Amendment 2795: Article 70 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b68c0e73-0070-42d8-ae37-10a2b150f3c7",
        "text":"1. National competent authorities, notified bodies, the Commission, the Board, and any other natural or legal person involved in the application of this Regulation shall, in accordance with Union or national law, put appropriate technical and organisational measures in place to ensure the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:",
        "title":"Amendment 2796: Article 70 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"78dafe83-a1b0-4859-8de8-747c4d8aac2c",
        "text":"1. National supervisory authorities, national competent authorities and notified bodies involved in the application of this Regulation shall respect the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:",
        "title":"Amendment 2797: Article 70 – paragraph 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar"
    },
    {
        "uuid":"ecfbf441-ef75-452a-a603-f1437b5a90cb",
        "text":"1. The Commission, the AI Office, national competent authorities and notified bodies involved in the application of this Regulation shall respect the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:",
        "title":"Amendment 2798: Article 70 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ddbd5396-184b-4f21-a332-b3a4f4bc2818",
        "text":"(a) intellectual property rights, and confidential business information or trade secrets of a natural or legal person in line with the 2016 EU Trade Secrets Directive (Directive 2016\/943) as well as the 2004 Directive on the enforcement of intellectual property rights (Directive 2004\/48\/EC), including source code, except the cases referred to in Article 5 of Directive 2016\/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.",
        "title":"Amendment 2799: Article 70 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"372cc6bd-ec20-4d4f-ad0f-7c8f60179b5a",
        "text":"(a) intellectual property rights, and confidential business information or professional secrecy or trade secrets of a natural or legal person, including source code, except the cases referred to in Article 5 of Directive 2016\/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.",
        "title":"Amendment 2800: Article 70 – paragraph 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"aebf8bda-8acd-4718-9e5b-5286b3a220cb",
        "text":"(a) confidential business information or trade secrets of a natural or legal person, except the cases referred to in Article 5 of Directive 2016\/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.",
        "title":"Amendment 2801: Article 70 – paragraph 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f6d49957-21b9-482f-a2f9-f6563b02fb10",
        "text":"(c a) the principles of purpose limitation and data minimization, meaning that national competent authorities minimize the quantity of data requested for disclosure in line with what is absolutely necessary for the perceived risk and its assessment, and they must not keep the data for any longer than absolutely necessary.",
        "title":"Amendment 2802: Article 70 – paragraph 1 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"da5168e8-7da3-4403-974e-458f951dc7e9",
        "text":"(c a) the principles of purpose limitation and data minimization, meaning that national competent authorities minimize the quantity of data requested for disclosure inline with what is absolutely necessary for the perceived risk and its assessment, and they must not keep the data for any longer than absolutely necessary;",
        "title":"Amendment 2803: Article 70 – paragraph 1 – point c a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"ffa9fc73-a094-4d8b-9bce-68d9a92fe5d7",
        "text":"1 a. In cases where the activity of national competent authorities, market surveillance authorities and notified bodies pursuant to the provisions of this Article results in a breach of intellectual property rights, Member States shall provide for the measures, procedures and remedies necessary to ensure the enforcement of the intellectual property rights in full application of Directive 2004\/48\/EC on the enforcement of intellectual property rights.",
        "title":"Amendment 2804: Article 70 – paragraph 1 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3149e03b-a153-46bb-bcea-62b8ebb53c25",
        "text":"1 a. Where the activities of national competent authorities and bodies notified under the provisions of this Article infringe intellectual property rights, Member States shall provide for the measures, procedures and remedies necessary to ensure the enforcement of intellectual property rights in full application of Directive 2004\/48\/EC on the enforcement of intellectual property rights.",
        "title":"Amendment 2805: Article 70 – paragraph 1 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"da6b4f80-4a1a-428b-af39-a81d08c5860d",
        "text":"1 a. The Commission, the Board, national supervisory authorities, national competent authorities and notified bodies involved in the application of this Regulation shall put in place adequate cybersecurity and organisational measures to protect the security and confidentiality of the information and data obtained in carrying out their tasks and activities.",
        "title":"Amendment 2806: Article 70 – paragraph 1 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"6e3b7d45-880d-4ed9-b9dc-06d3b4e296a8",
        "text":"1 b. Information and data collected by national competent authorities and notified bodies and referred to in Paragraph 1 shall be:', 'a) collected for specified, explicit and legitimate purposes and not further processed in a way incompatible with those purposes;further processing for archiving purposes in the public interest, for scientific or historical research purposes or for statistical purposes shall not be considered incompatible with the original purposes (\"purpose limitation\");', 'b) adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed (‘data minimisation’);",
        "title":"Amendment 2807: Article 70 – paragraph 1 b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"2c6269f3-7b7b-4f32-b583-f4a6e5bbdcda",
        "text":"2. Without prejudice to paragraph 1, information exchanged on a confidential basis between the national competent authorities and between national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating national competent authority and the deployer when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, immigration or asylum authorities, when such disclosure would jeopardise public or national security.",
        "title":"Amendment 2808: Article 70 – paragraph 2 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"b9146b67-e69c-4413-a365-ef81f745c643",
        "text":"2. Without prejudice to paragraphs 1 and 1a, information exchanged on a confidential basis among the national supervisory authorities, national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating authority and the user when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, immigration or asylum authorities, when such disclosure would jeopardise public and national security interests.",
        "title":"Amendment 2809: Article 70 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"9c8a8a0e-d4a7-4c4e-aa36-91e80a528b3c",
        "text":"4. The Commission and Member States may exchange, where necessary and in compliance with trade agreements between the EU and third countries that may apply, confidential information with regulatory authorities of third countries with which they have concluded bilateral or multilateral confidentiality arrangements guaranteeing an adequate level of confidentiality.",
        "title":"Amendment 2810: Article 70 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"3e5ce607-e7d9-47fd-b444-4815592ac688",
        "text":"4. The Commission and Member States may, if consistent with the provisions contained in EU trade agreements with third countries, exchange, where necessary, confidential information with regulatory authorities of third countries with which they have concluded bilateral or multilateral confidentiality arrangements guaranteeing an adequate level of confidentiality.",
        "title":"Amendment 2811: Article 70 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"8cc97426-3632-4316-b02d-7f84a8d17cb0",
        "text":"Article 70 a', 'Administrative fines', '1. Each national supervisory authority shall ensure that the imposition of administrative fines pursuant to this Article in respect of infringements of this Regulation shall in each individual case be effective, proportionate and dissuasive.', '2. When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case due regard shall be given to the following:', '(a) the nature, gravity and duration of the infringement taking into account the nature, scope or purpose of the processing concerned as well as, where appropriate, the number of affected persons and the level of harm suffered by them;', '(b) the intentional or negligent character of the infringement;', '(c) any action taken by the operator to mitigate the harm suffered by the users or the affected persons;', '(d) the degree of responsibility of the operator taking into account the technical and organisational measures implemented by them;', '(e) any relevant previous infringements by the operator;', '(f) the degree of cooperation with the national supervisory authority, in order to remedy the infringement and mitigate the possible adverse effects of the infringement, including compliance with any of the measures previously ordered by the national supervisory authority with regard to the same subject matter', '(g) the manner in which the infringement became known to the national supervisory authority, in particular whether, and if so to what extent, the operator notified the infringement;', '(h) adherence to approved codes of conduct or approved certification mechanisms; and', '(i) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement.', '3. If an operator, intentionally or negligently, infringes several provisions of this Regulation, the total amount of the administrative fine shall not exceed the amount specified for the gravest infringement.', '4. The non-compliance of the AI system with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 50 000 000 or, if the offender is a company, up to 10% of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '5. The non-compliance of the AI system with the requirements laid down in Article10 shall be subject to administrative fines of up to 40 000 000 EUR or, if the offender is company, up to 8 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '6. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '7. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 20 000000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '8. Without prejudice to the corrective powers of national supervisory authorities, each Member State may lay down the rules on whether and to what extent administrative fines may be imposed on public authorities and bodies established in that Member State.', '9. The exercise by the national supervisory authority of its powers under this Article shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process.', '10. Where the legal system of the Member State does not provide for administrative fines, this Article may be applied in such a manner that the fine is initiated by the national supervisory authority and imposed by competent national courts, while ensuring that those legal remedies are effective and have an equivalent effect to the administrative fines imposed by national supervisory authorities. In any event, the fines imposed shall be effective, proportionate and dissuasive. Those Member States shall notify to the Commission the provisions of their laws which they adopt pursuant to this paragraph by [3 months after entry into force] and, without delay, any subsequent amendment law or amendment affecting them.",
        "title":"Amendment 2812: Article 70 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"7f042ed1-0602-4b33-9743-9a2510cf83e2",
        "text":"Article 70 b', 'Right for removal and injunction', '1. If an AI system infringes this Regulation each natural or legal person affected by said AI system may require the user of this system to stop the use and to remove the infringement.', '2. If further infringements of an AI system are to be feared, each affected natural or legal person may seek a prohibitory injunction.",
        "title":"Amendment 2813: Article 70 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"17d6329b-d7ef-4e83-b1f5-672fac543fa5",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of small-scale providers and start-ups and their economic viability, as well as the extent to which the infringement was intentionally committed and the extent of the harm sustained.",
        "title":"Amendment 2814: Article 71 – paragraph 1  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"96c6afcd-1f00-48d2-9bfb-46a4e0557e2b",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented and aligned with the guidelines issued by the Board, as referred to in Article 58 (c) (iii). The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of small-scale providers and start-up and their economic viability.",
        "title":"Amendment 2815: Article 71 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"384656be-8355-490f-8ed8-4567fb64bb6a",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive.",
        "title":"Amendment 2816: Article 71 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"3c2a76d2-8cb3-463a-8e90-3470a3dabadb",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, the Commission in consultation with Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and in cooperation with Member States shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the size and the interests of SME providers including start-ups and their economic viability.",
        "title":"Amendment 2817: Article 71 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"24ae0a35-3fbe-4ccf-9072-3d89beba1d8a",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented and aligned with the guidelines issued by the Board, as referred to in Article 58 (c) (iii). The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of SMEs and start-up and their economic viability.",
        "title":"Amendment 2818: Article 71 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b49178af-ac4d-4184-ac99-7b3b4464744a",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, applicable to infringements of this Regulation, in particular for infringements which are not subject to administrative fines pursuant to Article70a, and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive.",
        "title":"Amendment 2819: Article 71 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"879d2392-7c25-40df-be68-647b3905f6af",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests and size of small-scale providers and start-ups and their economic viability.",
        "title":"Amendment 2820: Article 71 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e324e426-e486-4f84-aff0-0e78d6b5b066",
        "text":"1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the size and interests of SMEs and start-ups and their economic viability",
        "title":"Amendment 2821: Article 71 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"3fee458c-ccab-4391-852a-4f0f25e4a742",
        "text":"1 a. In cases where administrative fines have been imposed under Article 83 of Regulation 2016\/679, no further penalties shall be imposed on operators under the AI Act.",
        "title":"Amendment 2822: Article 71 – paragraph 1 a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"1d692230-ab47-4234-93f7-eec2c9376baa",
        "text":"deleted",
        "title":"Amendment 2823: Article 71 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"c99f2fda-2246-4013-8ed1-8c6f025e6ced",
        "text":"2. The Member States shall notify [by 3 months following the date of entry into force of this Regulation] the Commission and the Board of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.",
        "title":"Amendment 2824: Article 71 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"032fb233-1db3-4531-86f8-99178794d3ec",
        "text":"2. Within [three months following the entry into force of this Regulation], the Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.",
        "title":"Amendment 2825: Article 71 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"57a9aab0-1980-498e-816e-f1efaa1d6401",
        "text":"2. Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.",
        "title":"Amendment 2826: Article 71 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cf1af52c-671e-4db2-a5e4-d8b30614eaeb",
        "text":"2. The Member States shall without delay notify the Commission of those rules and of those measures and of any subsequent amendment affecting them.",
        "title":"Amendment 2827: Article 71 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"d699e957-ea4b-4b05-af83-08425a0786d8",
        "text":"2 a. The non-compliance of the AI system with the prohibition of the practices referred to in Article 5 shall be subject to administrative fines of up to 50 000 000 EUR or, if the offender is a company, up to 10% of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2828: Article 71 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"a3cc8736-2367-4767-98a9-983f6b07e966",
        "text":"deleted",
        "title":"Amendment 2829: Article 71 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"bf97d08b-cefb-4d49-97b4-60b1d8570823",
        "text":"3. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, and in case of SMEs and start-ups, up to 3% of its worldwide annual turnover for the preceding financial year, whichever is higher.', '.",
        "title":"Amendment 2830: Article 71 – paragraph 3 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"7b4946e2-01c8-422c-8796-5196cb02526c",
        "text":"3. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher;",
        "title":"Amendment 2831: Article 71 – paragraph 3 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"78bb73be-ab4d-4c34-b829-3963842b1970",
        "text":"3. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 40 000 000 EUR or, if the offender is a company, up to 8 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2832: Article 71 – paragraph 3 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"3ee57f6c-fc94-404d-b02d-a495875d9a4e",
        "text":"3. Non-compliance with the prohibition of the AI practices referred to in Article 5 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4% of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2833: Article 71 – paragraph 3 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4742267f-5db2-4c93-9dda-f16c6758c096",
        "text":"3. The following infringements shall be subject to administrative fines of up to 1 000 000 000 EUR or, if the offender is a company, up to 10 % of its total worldwide annual turnover for the preceding financial year, whichever is higher:",
        "title":"Amendment 2834: Article 71 – paragraph 3 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"121da762-305a-4fac-9885-75f783db2792",
        "text":"3. The following infringements shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 10 % of its total worldwide annual turnover for the preceding financial year, whichever is higher:",
        "title":"Amendment 2835: Article 71 – paragraph 3 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2c8f7561-0c29-4b8a-9b26-c5b182d78efa",
        "text":"deleted",
        "title":"Amendment 2836: Article 71 – paragraph 3 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"81a15ad6-b26e-4634-82fb-7d0821bb0b24",
        "text":"deleted",
        "title":"Amendment 2837: Article 71 – paragraph 3 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f59e7f1f-358b-45c6-86fb-cdd1d73f24bc",
        "text":"deleted",
        "title":"Amendment 2838: Article 71 – paragraph 3 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"00cbdb0c-42a3-4569-b357-69f868a59c14",
        "text":"deleted",
        "title":"Amendment 2839: Article 71 – paragraph 3 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"4f92facc-74a5-49f6-9731-7c6b10377be0",
        "text":"deleted",
        "title":"Amendment 2840: Article 71 – paragraph 3 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"90182b50-5b06-43ad-8c35-d206959f6037",
        "text":"deleted",
        "title":"Amendment 2841: Article 71 – paragraph 3 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"f9aeb808-b3a5-4863-b1ba-b65782891a9b",
        "text":"deleted",
        "title":"Amendment 2842: Article 71 – paragraph 3 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"d695ffe7-c1cc-4ce0-be4d-2bb8f86c0d41",
        "text":"deleted",
        "title":"Amendment 2843: Article 71 – paragraph 3 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"597d0592-c9b2-40af-afdc-104f9538405a",
        "text":"deleted",
        "title":"Amendment 2844: Article 71 – paragraph 3 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"fc6f68e2-d6aa-4511-9a50-7b340c07d2b6",
        "text":"3 a. Non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2845: Article 71 – paragraph 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"10afe155-8235-4d8c-ba43-df9571c20349",
        "text":"deleted",
        "title":"Amendment 2846: Article 71 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ca38bea2-7b47-4fc1-8245-f9e3dc8ce378",
        "text":"4. The grossly negligent non-compliance by the provider or user of the AI system with the respective requirements or obligations under this Regulation, other than those laid down in Articles 5, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher, and in case of SMEs and start-ups, up to 1% of its worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2847: Article 71 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0e627b2c-a39b-481d-8cfd-5806a219fb36",
        "text":"4. The grossly negligent non-compliance by the provider or the user of the AIs ystem with any requirements or obligations under this Regulation, other than those laid down in Article 5, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2848: Article 71 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"a50cd743-220f-49fb-988e-6a580d9bb185",
        "text":"4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2849: Article 71 – paragraph 4  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4479aa44-9714-47c4-bdd4-edbc99b1510d",
        "text":"4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 7 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2850: Article 71 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5213ad28-c427-4bef-a685-a64ab0d17ffd",
        "text":"4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2851: Article 71 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c5d64df7-a9d9-4b4b-97ae-09d6bdc6a67c",
        "text":"4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 1 000 000 EUR or, if the offender is a company, up to 1 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2852: Article 71 – paragraph 4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"37fb961c-197a-4fe2-9e1d-8c5d2dec350f",
        "text":"4. Non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2853: Article 71 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"10fd4613-f0e6-4340-bf6f-ef85940ffbcf",
        "text":"deleted",
        "title":"Amendment 2854: Article 71 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"24a3287b-0678-4d3a-972e-6e334687bc40",
        "text":"5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher and in case of SMEs and start-ups, up to 1% of its worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2855: Article 71 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0eb00f72-6082-4e79-a67f-a68ec278d283",
        "text":"5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2856: Article 71 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9c274bc9-d403-4fdf-9120-5dd836ac7098",
        "text":"5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2857: Article 71 – paragraph 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"290672fc-3302-4999-a333-a2a65cd841b7",
        "text":"5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2858: Article 71 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"6223ed7e-0a0a-4399-a4b4-fee169398535",
        "text":"5. The supply of incorrect or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 1 000 000 EUR or, if the offender is a company, up to 1 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.",
        "title":"Amendment 2859: Article 71 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"cdf3daa4-b223-432c-a25c-54335a476789",
        "text":"5 a. Where trade secrets, intellectual property rights or data protection rights have been infringed in the development of an AI system, competent authorities may order the definitive deletion of that system and all associated training data and outputs.",
        "title":"Amendment 2860: Article 71 – paragraph 5 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"7f1001d3-59e3-46f2-877b-a80ed6d37624",
        "text":"deleted",
        "title":"Amendment 2861: Article 71 – paragraph 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b9535576-7866-4112-b5d9-27a0ec5b9ad5",
        "text":"6. Fines may be imposed in addition to or instead of non-monetary measures such as orders or warnings. When deciding on whether to impose a fine or on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:",
        "title":"Amendment 2862: Article 71 – paragraph 6 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"443b2bc3-da8b-4309-aacf-fb8a4f4867b0",
        "text":"(a) the nature, gravity and duration of the infringement and of its consequences taking into account the nature, scope or purpose of the AI system concerned, as well as the number of individuals affected, and the level of damage suffered by them;",
        "title":"Amendment 2863: Article 71 – paragraph 6 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2ddf6e92-1022-429e-8476-fb45ecee6fba",
        "text":"(b) whether administrative fines have been already applied by other market surveillance authorities of one or more Member States to the same operator for the same infringement.",
        "title":"Amendment 2864: Article 71 – paragraph 6 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"6c361738-ff05-4f99-a9e3-479c3c34091f",
        "text":"deleted",
        "title":"Amendment 2865: Article 71 – paragraph 6 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"bf47c368-0576-4553-ae46-2c9fdb470805",
        "text":"(c) the size, the annual turnover and market share of the operator committing the infringement;",
        "title":"Amendment 2866: Article 71 – paragraph 6 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"b2ef3ea5-e294-4dbe-8cde-89fd4c70df41",
        "text":"(c) the size, the annual turnover and market share of the operator committing the infringement;",
        "title":"Amendment 2867: Article 71 – paragraph 6 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"c46c961e-17af-466e-8fb4-ade8e0cce1b6",
        "text":"(c a) any action taken by the provider to mitigate the harm or damage suffered by the affected persons;",
        "title":"Amendment 2868: Article 71 – paragraph 6 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f9af9285-d21a-4ff5-9d35-73f44dcd81a8",
        "text":"(c a) the intentional or negligent character of the infringement;",
        "title":"Amendment 2869: Article 71 – paragraph 6 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f4dc4a17-1cda-483f-a073-dadf65640eb6",
        "text":"(c c) the degree of cooperation with the national competent authorities, in order to remedy the infringement and mitigate the possible adverse effects of the infringement;",
        "title":"Amendment 2870: Article 71 – paragraph 6 – point c c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ff9e0298-aca1-44c3-8bdf-53599ce3a91d",
        "text":"(c c) any relevant previous infringements by the provider;",
        "title":"Amendment 2871: Article 71 – paragraph 6 – point c e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"4cbf5057-1ac1-4924-910a-ed359804313b",
        "text":"(c e) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement;",
        "title":"Amendment 2872: Article 71 – paragraph 6 – point c e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9f5c4284-0cc4-49d0-98f0-5fbcc8cd50a8",
        "text":"(c e) the manner in which the infringement became known to the national competent authority, in particular whether, and if so to what extent, the provider notified the infringement;",
        "title":"Amendment 2873: Article 71 – paragraph 6 – point c e (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"cf7a1c8d-17cb-431e-b626-8758ff0ddd11",
        "text":"(c g) in the context of paragraph 5 of this Article, the intentional or unintentional nature of the infringement.",
        "title":"Amendment 2874: Article 71 – paragraph 6 – point c g (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"75d02099-c9ab-4f01-9bae-32f957c107ad",
        "text":"deleted",
        "title":"Amendment 2875: Article 71 – paragraph 7  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e75656ca-3908-480c-9fc7-9310f5066765",
        "text":"7. Each Member State shall lay down rules on administrative fines to be imposed on public authorities and bodies established in that Member State, with a view to ensure compliance with this Regulation.",
        "title":"Amendment 2876: Article 71 – paragraph 7  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0c4dbc27-3ebb-4bb9-8285-3b869a03920d",
        "text":"deleted",
        "title":"Amendment 2877: Article 71 – paragraph 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"ed853019-b174-4115-850e-7b3b2ebf8e17",
        "text":"8. Depending on the legal system of the Member States, the rules on administrative fines may be applied in such a manner that the fines are imposed by competent national courts of other bodies as applicable in those Member States. The application of such rules in those Member States shall have an equivalent effect. In any event, the fines imposed shall be effective, proportionate and dissuasive.",
        "title":"Amendment 2878: Article 71 – paragraph 8  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"e4cf5c21-a1d1-4768-9aec-d203b18ac869",
        "text":"8 a. In respect of adopting administrative fines and of deciding on the amount of the administrative fine the procedure as set out in Article 68a, paragraphs 2 to 6, applies mutatis mutandis.",
        "title":"Amendment 2879: Article 71 – paragraph 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"540e363c-6bd7-455e-8da8-9b26b91992c4",
        "text":"8 a. Administrative fines shall not be applied to a participant in a regulatory sandbox, who was acting in line with the recommendation issued by the supervisory authority.",
        "title":"Amendment 2880: Article 71 – paragraph 8 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ecd19a89-9cf8-43f3-848a-f41571d502ae",
        "text":"8 a. Administrative fines shall not be applied to a participant in a regulatory sandbox, who was acting in line with the recommendation issued by the supervisory authority;",
        "title":"Amendment 2881: Article 71 – paragraph 8 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"f3aab03c-6489-4c37-8be4-f8396da26e16",
        "text":"8 b. The penalties referred to in this article as well as the associated litigation costs and indemnification claims may not be the subject of contractual clauses or other form of burden-sharing agreements between the providers and distributors, importers, users, or any other third-parties.",
        "title":"Amendment 2882: Article 71 – paragraph 8 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"53f258b0-a592-42d6-a36f-b8520665500f",
        "text":"8 c. The exercise by the market surveillance authority of its powers under this Article shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process.",
        "title":"Amendment 2883: Article 71 – paragraph 8 c (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1dff2a69-0227-41ab-926c-1bb1f3fe0526",
        "text":"1. The European Data Protection Supervisor may impose administrative fines on Union institutions, agencies and bodies developing, deploying or operating AI systems. When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:",
        "title":"Amendment 2884: Article 72 – paragraph 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"437382f3-8e07-498d-a042-509b4536530f",
        "text":"(a) the nature, gravity and duration of the infringement and of its consequences, including to affected persons;",
        "title":"Amendment 2885: Article 72 – paragraph 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"88f29967-ddb7-4faa-8861-2cb744e2bdde",
        "text":"(a a) any action taken by the Union institution, agency or body to mitigate the harm;",
        "title":"Amendment 2886: Article 72 – paragraph 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"a6a7110b-2dc5-4373-b74e-bcf55097da6e",
        "text":"(a a) the intentional or negligent character of the infringement;",
        "title":"Amendment 2887: Article 72 – paragraph 1 – point a a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"0d295d14-b109-4941-aeec-51414b783909",
        "text":"(a b) any relevant previous infringement;",
        "title":"Amendment 2888: Article 72 – paragraph 1 – point a b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"1d0d976c-f588-4d14-9e92-3726e1048dde",
        "text":"deleted",
        "title":"Amendment 2889: Article 72 – paragraph 1 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"d34b1f34-4935-4415-902c-91ac1d6971fe",
        "text":"(b a) the degree of cooperation with the supervisory authority, in order to remedy the infringement and mitigate the possible adverse effects of the infringement;",
        "title":"Amendment 2890: Article 72 – paragraph 1 – point b a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"8d83ab71-d2dc-453e-8294-70cc6f3f732e",
        "text":"(b b) any action taken by the provider to mitigate the damage suffered by subjects;",
        "title":"Amendment 2891: Article 72 – paragraph 1 – point b b (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"e52fceac-23bb-41e6-b050-42f2254c4723",
        "text":"(c a) the manner in which the infringement became known to the European Data Protection Supervisor, in particular whether, and if so, to what extent, the Union institution, agency or body notified the infringement.",
        "title":"Amendment 2892: Article 72 – paragraph 1 – point c a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0c0b85d5-9fb2-4117-9aba-0c658974327b",
        "text":"(c a) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement.",
        "title":"Amendment 2893: Article 72 – paragraph 1 – point c a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"aeb61f85-02bf-497d-9b80-39136e24294b",
        "text":"2. The non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1 000 000 EUR;', '2a. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 700 000 EUR.",
        "title":"Amendment 2894: Article 72 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"5eb4abae-31b4-41c5-8580-f302e49be779",
        "text":"2. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1.000 000 EUR;",
        "title":"Amendment 2895: Article 72 – paragraph 2 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c03cd7bc-c209-47c4-aaa9-4ac1e35b078f",
        "text":"2. The non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1 000 000 EUR:",
        "title":"Amendment 2896: Article 72 – paragraph 2 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"27712d35-8916-4c26-a3ac-32a69836ee2a",
        "text":"2. The following infringements shall be subject to administrative fines of up to 30 000 000 EUR:",
        "title":"Amendment 2897: Article 72 – paragraph 2 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"9840379a-d8c6-47f6-86b8-52358a07c7a9",
        "text":"2. The following infringements shall be subject to administrative fines of up to 5 000 000 EUR:",
        "title":"Amendment 2898: Article 72 – paragraph 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"51c6cb36-a4d1-4bf3-a295-639a53bddcdc",
        "text":"deleted",
        "title":"Amendment 2899: Article 72 – paragraph 2 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"beb31bde-99bf-4c6c-aa21-f0b47d9c3776",
        "text":"deleted",
        "title":"Amendment 2900: Article 72 – paragraph 2 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"691696dc-a52f-404a-875e-d2b155a27693",
        "text":"deleted",
        "title":"Amendment 2901: Article 72 – paragraph 2 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"37d4d722-295b-41df-9c3c-e5eb7e4082de",
        "text":"deleted",
        "title":"Amendment 2902: Article 72 – paragraph 2 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3a1e28cf-0f8f-4aa7-89d8-6cf568af0ee4",
        "text":"deleted",
        "title":"Amendment 2903: Article 72 – paragraph 2 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"3548257f-419a-47b7-a9af-220f042d7622",
        "text":"deleted",
        "title":"Amendment 2904: Article 72 – paragraph 2 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0e8fd680-6dd8-4f38-bb88-35c1b20d2643",
        "text":"2 a. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 700 000 EUR.",
        "title":"Amendment 2905: Article 72 – paragraph 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"8050948f-cba1-4847-afe8-6e65533fb6f2",
        "text":"2 a. non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 500 000 EUR.",
        "title":"Amendment 2906: Article 72 – paragraph 2 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"fbb78578-4565-4fe1-bb89-5369bec1aebe",
        "text":"3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR.",
        "title":"Amendment 2907: Article 72 – paragraph 3  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"34a9a6fd-528b-4f6a-8782-7304dccbfec1",
        "text":"3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 2 500 000 EUR.",
        "title":"Amendment 2908: Article 72 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"8ed63c36-6d82-44aa-8150-1544284bd971",
        "text":"3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 500 000 EUR.",
        "title":"Amendment 2909: Article 72 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d682fda6-9317-462b-a074-347ae779aa56",
        "text":"3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 300 000 EUR.",
        "title":"Amendment 2910: Article 72 – paragraph 3  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a6c37148-d431-4c7d-b037-647510d06301",
        "text":"3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 500 000 EUR.",
        "title":"Amendment 2911: Article 72 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"87258b58-58c9-4556-a181-f0a2cf1767bb",
        "text":"5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor’s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data.",
        "title":"Amendment 2912: Article 72 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"329fcf27-c934-4eb0-aae9-f1a961dbfc56",
        "text":"5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor’s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data.",
        "title":"Amendment 2913: Article 72 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"d8eed220-8aec-459c-9d66-b59ac1dfa01b",
        "text":"deleted",
        "title":"Amendment 2914: Article 72 – paragraph 6  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte"
    },
    {
        "uuid":"31c45d27-cb4f-4fcb-bf71-4e0d83caf248",
        "text":"6. Funds collected by imposition of fines in this Article shall contribute to the general budget of the Union.",
        "title":"Amendment 2915: Article 72 – paragraph 6 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3684d74b-eb4b-44e2-9c9e-c4ab10ba8abe",
        "text":"6 a. The European Data Protection Supervisor shall, on an annual basis, notify the Board of the fines it has imposed pursuant to this Article.",
        "title":"Amendment 2916: Article 72 – paragraph 6 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"50772f10-97f3-46a6-b7f7-80e47364ad17",
        "text":"2. The delegation of power referred to in Article 7(1), Article 11(3), Article 43(5), Article 48(5) and Article 68a shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].",
        "title":"Amendment 2917: Article 73 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"9ee67405-3404-46c3-8140-fd5d5bcd981f",
        "text":"2. The delegation of power referred to in Article 4, Article 5a, Article 7(1), Article 11(3), Article 43(5) and (6), Article 48(5) and Article 52a shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].",
        "title":"Amendment 2918: Article 73 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4ae7fda6-db01-4608-b71b-feff15b1299f",
        "text":"2. The delegation of power referred to in Article 4 and Article 48(5) shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].",
        "title":"Amendment 2919: Article 73 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"c3123681-8a04-4d51-b16c-1699ec20669d",
        "text":"2 a. The delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article 43(5) and (6) and Article 48(5) shall undergo due process, be proportionate and be based on a permanent and institutionalised exchange with the relevant stakeholders as well as the Board and the High Level Expert Group on AI.",
        "title":"Amendment 2920: Article 73 – paragraph 2 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"bfe5e4d0-3525-4601-846d-b9f39484eded",
        "text":"3. The delegation of power referred to in Article 7(1), Article 11(3), Article 43(5), Article 48(5) and Article 68a may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.",
        "title":"Amendment 2921: Article 73 – paragraph 3  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"15aaaf88-6bd0-4f33-bc04-c708566c9eda",
        "text":"3. The delegation of power referred to in Article 4, Article 5a, Article 7(1), Article 11(3), Article 43(5) and (6), Article 48(5) and Article 52a may be revoked at any time by a joint decision from the European Parliament and the Council.. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.",
        "title":"Amendment 2922: Article 73 – paragraph 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"dd03694e-48ca-473b-85f6-abaf2ffbf28c",
        "text":"3. The delegation of power referred to in Article 4 and Article 48(5) may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.",
        "title":"Amendment 2923: Article 73 – paragraph 3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"fe2f3a0e-cfab-4313-8026-045d2089affb",
        "text":"3 a. Before adopting a delegated act, the Commission shall consult with the relevant institutions and stakeholders in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making.",
        "title":"Amendment 2924: Article 73 – paragraph 3 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"bf2dfbe6-7de5-477b-b693-98e7932b438c",
        "text":"3 a. Prior to adopting a delegated act pursuant to Article 4, Article 7(1), Article 11(3), Article 43(5) and (6), and Article48(5) the Commission shall consult the AI Office.",
        "title":"Amendment 2925: Article 73 – paragraph 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"61c48a0c-1129-44c6-a533-4aa077b5300d",
        "text":"3 b. Delegated acts that lead to the modification or the addition of obligations on operators shall foresee an adequate transition period of no less than 24 months before their entry into force.",
        "title":"Amendment 2926: Article 73 – paragraph 3 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"144a9b88-5408-4277-a844-28d6bd7ca09b",
        "text":"4. Once the Commission decides to draft a delegated act, it shall notify the European Parliament of this fact. This notification does not place an obligation on the Commission to adopt the said act. I As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.",
        "title":"Amendment 2927: Article 73 – paragraph 4  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"d279a62a-609c-4e34-bb3a-ea70ac43effe",
        "text":"4. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament, the Council, and the AI Office.",
        "title":"Amendment 2928: Article 73 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b6fc26c8-5e88-4d50-8b2c-c1bf7fcef4b3",
        "text":"4. In preparation of a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.",
        "title":"Amendment 2929: Article 73 – paragraph 4  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4c5fc285-17d6-47ac-88ef-e8ea6be9cb25",
        "text":"5. Any delegated act adopted pursuant to Article 4, Article 5a, Article 7(1), Article 11(3), Article43(5) and (6), Article 48(5) and Article 52a shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",
        "title":"Amendment 2930: Article 73 – paragraph 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"8970b633-e02a-463d-b8cf-c8f22973bc2e",
        "text":"5. Any delegated act adopted pursuant to Article 4 and Article 48(5) shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",
        "title":"Amendment 2931: Article 73 – paragraph 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"efcba96b-bcd6-45ab-83b2-6e97e544d2d0",
        "text":"5. Any delegated act adopted pursuant to Article 7(1), Article 11(3), Article 43(5), Article 48(5) and 68d shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",
        "title":"Amendment 2932: Article 73 – paragraph 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"7d4f07d4-6e26-433f-8bdc-9e722421dd8e",
        "text":"In Article 5 of Regulation (EU) 2018\/858 the following paragraphs are added:",
        "title":"Amendment 2933: Article 80 – paragraph 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"dada9997-5948-42e5-9cd0-07ae7e58047a",
        "text":"In Article 5 of Regulation (EU) 2018\/858 the following paragraphs are added:",
        "title":"Amendment 2934: Article 80 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"52422064-6cf9-4736-9bad-aca37f666c01",
        "text":"4 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 4, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automotive sector to determine the existence of potential gaps relating to Artificial Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principles.",
        "title":"Amendment 2935: Article 80 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"84ceeb6b-4039-49e6-8dc2-8adbb1e12540",
        "text":"4 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 4, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automative sector to determine the existence of potential gaps relating to Artifical Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principle.",
        "title":"Amendment 2936: Article 80 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"fb239106-ce15-4246-93c2-758f67821eb5",
        "text":"Article 81 a', 'Amendment to Regulation (EU) 2019\/1020', 'In Article 14.4 of Regulation (EU) 2019\/1020 the following paragraph is added:', '“(l) The power to implement the powers provided for in this Article remotely, where applicable.”",
        "title":"Amendment 2937: Article 81 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"02262c7e-2c96-47b4-bcb5-a86885b7649f",
        "text":"In Article 11 of Regulation (EU) 2019\/2144, the following paragraphs are added:",
        "title":"Amendment 2938: Article 82 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"91e0b554-e825-4300-99b4-039fe688d912",
        "text":"In Article 11 of Regulation(EU) 2019\/2144, the following paragraphs are added:",
        "title":"Amendment 2939: Article 82 – paragraph 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"dd0118f2-73e4-4f61-8fec-d36213a5709a",
        "text":"3 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 3, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automotive sector to determine the existence of potential gaps relating to Artificial Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principles.",
        "title":"Amendment 2940: Article 82 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"958b3ca5-9ed0-470f-9b0b-02880a344707",
        "text":"3 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 3, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automative sector to determine the existence of potential gaps relating to Artifical Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principle.",
        "title":"Amendment 2941: Article 82 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d0fde490-e81b-43d4-8a5a-2954ff2e9203",
        "text":"Article 82 a', 'Sound regulation', 'In taking into account the requirements of this Regulation pursuant to the Amendments in Articles 75, 76, 77, 78, 79, 80, 81, and 82, the Commission shall conduct an analysis and consult relevant stakeholders to determine potential gaps as well as overlaps between existing sectoral legislation and the provisions of this Regulation in order to avoid duplication, overregulation, and the creation of loopholes.",
        "title":"Amendment 2942: Article 82 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"5c1f08f1-decf-489f-a7fd-b25519683c4e",
        "text":"deleted",
        "title":"Amendment 2943: Article 83  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3b3777c7-db7e-44c1-9d99-ccd3942fbd3b",
        "text":"1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [12 months after the date of application of this Regulation referred to in Article 85(2)].",
        "title":"Amendment 2944: Article 83 – paragraph 1 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"43b21c3a-a685-402c-9c0f-528895c8897f",
        "text":"1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before, with a transitional period of two years after the entry into force of this Regulation.",
        "title":"Amendment 2945: Article 83 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"3171e29a-98f2-44e9-bded-2df4c6aab611",
        "text":"1. Operators of the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [the date of application of this Regulation referred to in Article 85(2)] shall take the necessary steps to comply with the requirements of the present Regulation within 4 years of its entry into force.",
        "title":"Amendment 2946: Article 83 – paragraph 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"adf59179-a3b4-4c8b-8f76-c589b43a4685",
        "text":"1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [12 months after the date of application of this Regulation referred to in Article 85(2)] and the requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX.",
        "title":"Amendment 2947: Article 83 – paragraph 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"01cd541a-833d-41b6-a2aa-bd73e4118597",
        "text":"1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX starting [ on the date of application of this Regulation referred to in Article 85(2)], or as soon as there is a significant change in the design or intended purpose of the AI system or AI systems concerned in which case it shall apply from [the date of application of this Regulation]",
        "title":"Amendment 2948: Article 83 – paragraph 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c9b72455-04b8-4865-b9fb-012fe2234b52",
        "text":"1. This Regulation shall not apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [24 months after the date of application of this Regulation referred to in Article 85(2)], unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned.",
        "title":"Amendment 2949: Article 83 – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"02dd8ddd-a755-47c2-943a-2406d7c70a39",
        "text":"deleted",
        "title":"Amendment 2950: Article 83 – paragraph 1 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"8accad48-3845-4749-9ba8-f406ce7a5e5f",
        "text":"deleted",
        "title":"Amendment 2951: Article 83 – paragraph 1 – subparagraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2c0727d3-9203-47d3-920b-5f6420e1628f",
        "text":"The requirements laid down in this Regulation shall be taken into account, where applicable, in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts and whenever those legal acts are replaced or amended.",
        "title":"Amendment 2952: Article 83 – paragraph 1 – subparagraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"0f8035ee-2e64-4c9e-8db8-aa9ec2065406",
        "text":"The requirements laid down in this Regulation shall apply in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts.",
        "title":"Amendment 2953: Article 83 – paragraph 1 – subparagraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"8cb0ef01-3cbb-49ff-8d63-f6d8cf80e648",
        "text":"The requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts.",
        "title":"Amendment 2954: Article 83 – paragraph 1 – subparagraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"5fb93217-1c11-4618-a443-9ae9d60cd0e2",
        "text":"2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], only if, from that date, those systems are subject to significant changes as defined in Article 3(23) in their design or intended purpose, and those changes are not needed to comply with applicable existing or new legislation, or to provide security fixes.",
        "title":"Amendment 2955: Article 83 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"ac87d2bd-290a-4a1f-b157-6253739c8afc",
        "text":"2. This Regulation shall apply to the high-risk AI systems that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].",
        "title":"Amendment 2956: Article 83 – paragraph 2  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a9c47c74-e503-417a-87a3-a444689f0be3",
        "text":"2. Operators of high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)] shall take the necessary steps to comply with the requirements of the present Regulation within 2 years of its entry into force or at the time when such systems are subject to a substantial modification in their design or intended purpose.",
        "title":"Amendment 2957: Article 83 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ef85816c-2965-4742-a13c-790c52e823f0",
        "text":"2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].",
        "title":"Amendment 2958: Article 83 – paragraph 2  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"3e9c444e-baaf-4175-9c04-ea3ef73052b3",
        "text":"2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service from [date of application of this Regulation referred to in Article 85(2)].",
        "title":"Amendment 2959: Article 83 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a9921fe1-cf64-4367-a1f7-ae6d0cf7b8ba",
        "text":"2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].",
        "title":"Amendment 2960: Article 83 – paragraph 2  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"1be87c2a-7275-4a16-8e5d-25263c0027fd",
        "text":"2. This Regulation shall apply to the high-risk AI systems that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], with a transitional period of two years after the application of this Regulation.",
        "title":"Amendment 2961: Article 83 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein"
    },
    {
        "uuid":"436f122d-d3bc-473b-866f-f3ac2707cdcd",
        "text":"2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], only if, from that date, those systems are subject to substantial modification in their design or intended purpose as defined in Article 3(23) .",
        "title":"Amendment 2962: Article 83 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"cfbd1bca-82cb-4d39-a8c7-548d2ed26126",
        "text":"Article 83 a', 'AI systems deployed in the context of employment', \"Member States may, by law or by collective agreements, decide to prohibit or limit the use of certain AI systems in the employment context or provide for more specific rules for AI systems in employment, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, protection of employer's or customer's property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.",
        "title":"Amendment 2963: Article 83 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"3037ddf8-2632-4c00-b69f-56639ba90dfe",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III, including the extension of existing area headings or addition of new area headings; ,Article 5’s list of prohibited AI practices, and Article 52’s list of AI systems requiring additional transparency measures, once a year following the entry into force of this Regulation.",
        "title":"Amendment 2964: Article 84 – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"47071873-417a-45dc-87ef-0b6dec8efcf7",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III, including the extension of existing area headings or addition of new area headings, the list of prohibited practices in Article 5, and the list of AI systems requiring additional transparency measures, once a year following the entry into force of this Regulation.",
        "title":"Amendment 2965: Article 84 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"67908d28-7ad0-4db2-913a-25c16ef2c024",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III every 24 months following the entry into force of this Regulation and until the end of the period of the delegation of power. The findings of that assessment shall be presented to the European Parliament and the Council.",
        "title":"Amendment 2966: Article 84 – paragraph 1  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"11bbcc0b-fb3b-4b92-9f36-2f45a0f083f0",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation, and when necessary, table to the European Parliament and the Council a legislative proposal in this regard.",
        "title":"Amendment 2967: Article 84 – paragraph 1  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"35577b2c-8671-4ed9-a1e6-a8a337f0dfed",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex I once a year following the entry into force of this Regulation. The findings of that assessment shall be presented to the European Parliament and the Council.",
        "title":"Amendment 2968: Article 84 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"62befe60-182b-4288-a09b-eff5b452217d",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III , including the extension of existing area headings or addition of new area headings, once a year following the entry into force of this Regulation.",
        "title":"Amendment 2969: Article 84 – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"c52f95ef-50ed-4091-af6f-6e66397da7db",
        "text":"1. In consultation with the AI Office, the Commissions shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation.",
        "title":"Amendment 2970: Article 84 – paragraph 1  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"d7cc09c8-4852-4578-9582-28f8838b9d6a",
        "text":"1. The Commission shall assess the need for amendment of the list in Annex III annually following the entry into force of this Regulation and following a recommendation of the Board.",
        "title":"Amendment 2971: Article 84 – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"e736e3c1-19ec-4bfb-9424-ee8f75f49f2f",
        "text":"1 a. The Commission shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation. The findings of that assessment shall be presented to the European Parliament and the Council.",
        "title":"Amendment 2972: Article 84 – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5e9ecc69-523c-4a72-a660-e3057677dd6a",
        "text":"2. By [two years after the date of application of this Regulation referred to in Article 85(2)] and every three years thereafter, the Commission shall submit a report on the evaluation and review of this Regulation to the European Parliament and to the Council. The reports shall be made public.",
        "title":"Amendment 2973: Article 84 – paragraph 2  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"d20fab3e-c53d-48d3-9087-b8ba464e9fe8",
        "text":"(a) the status of the financial, technical and human resources of the national competent authorities in order to effectively perform the tasks assigned to them under this Regulation;",
        "title":"Amendment 2974: Article 84 – paragraph 3 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"495a82a3-0f5f-41ee-82fd-0c138707aa80",
        "text":"(b) the state of penalties, and notably administrative fines as referred to in Articles 70a and 71 applied by national supervisory authoritites and Member States to infringements of the provisions of this Regulation.",
        "title":"Amendment 2975: Article 84 – paragraph 3 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"80bf40af-8967-4e3e-8c70-bd1f80ae8f0f",
        "text":"(b) the state of penalties, and notably administrative fines as referred to in Article 71, applied by Member States to infringements of the provisions of this Regulation.",
        "title":"Amendment 2976: Article 84 – paragraph 3 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"2ca52ce5-625f-4af0-b7f8-911988ab98ad",
        "text":"(b a) the state of the development of harmonised standards and common specifications for Artificial Intelligence;",
        "title":"Amendment 2977: Article 84 – paragraph 3 – point b a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"22c23633-f55c-46f8-899d-5fe1363ac474",
        "text":"(b a) the levels of investments in research, development and application of AI systems throughout the Union,",
        "title":"Amendment 2978: Article 84 – paragraph 3 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"e5b0e6e2-e073-47c1-96c4-7e26fe2f1459",
        "text":"(b b) the competitiveness of the aggregated European AI ecosystem compared to AI ecosystems in third countries.",
        "title":"Amendment 2979: Article 84 – paragraph 3 – point b b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"46f56871-5ae3-4a84-a064-69b148b2e304",
        "text":"3 a. Within [two years after the date of application of this Regulation referred to in Article 85(2)] and every two years thereafter, the Commission shall evaluate the impact and effectiveness of the Regulation with regards to the resource and energy use, waste production and other environmental impact of AI systems and evaluate the need for proposing legislation to regulate the resource and energy efficiency of AI systems and related ICT systems in order for the sector to contribute to EU climate strategy and targets.",
        "title":"Amendment 2980: Article 84 – paragraph 3 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"280fa91e-9315-49ca-89c8-20b2954b9781",
        "text":"4. Within [one year after the date of application of this Regulation referred to in Article 85(2)] and every two years thereafter, the Commission shall evaluate the impact and effectiveness of codes of conduct to foster the application of the requirements set out in Title III, Chapter 2 and possibly other additional requirements for AI systems other than high-risk AI systems.",
        "title":"Amendment 2981: Article 84 – paragraph 4  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8c7df225-49bf-4b3c-b158-ca987e799de9",
        "text":"5. For the purpose of paragraphs 1 to 4 the Board, the Member States and national competent authorities shall provide the Commission with information on its request without undue delay.",
        "title":"Amendment 2982: Article 84 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"3d9ca1fc-ab34-4f61-aa1d-9c925e3e6a47",
        "text":"5. For the purpose of paragraphs 1 to 4 the AI Office, the Member States and national competent authorities shall provide the Commission with information on its request.",
        "title":"Amendment 2983: Article 84 – paragraph 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"7a64f78b-4a7d-419f-ac0c-d2d9020270fd",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of equality bodies and other relevant bodies or sources, and shall consult relevant external stakeholders, in particular those potentially affected by the AI system, as well as stakeholders from academia and civil society.",
        "title":"Amendment 2984: Article 84 – paragraph 6  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"48c084b6-1ae3-4221-b80c-06b088701801",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of equality bodies and other relevant bodies or sources, and shall consult relevant external stakeholders, in particular those potentially affected by the AI system, as well as stakeholders from academia and civil society.",
        "title":"Amendment 2985: Article 84 – paragraph 6  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"463acfb4-7ae0-4a02-b27d-26d092e835e3",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, including stakeholders, and in particular civil society.",
        "title":"Amendment 2986: Article 84 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"f9899d2c-9fdc-4348-a253-bcdcdf56527e",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, including from academia and civil society.",
        "title":"Amendment 2987: Article 84 – paragraph 6  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"a83499bd-ee16-4b11-87b3-108b288be8a2",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, which shall be attached to the report.",
        "title":"Amendment 2988: Article 84 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"92e58cb0-c79b-4326-a5f2-6ba99131b2ec",
        "text":"6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the AI Office, of the European Parliament, of the Council, and of other relevant bodies or sources.",
        "title":"Amendment 2989: Article 84 – paragraph 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"ed77f79e-532d-442d-a693-d8a361c43d21",
        "text":"7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology, the effect of AI systems on health and safety, fundamental rights, the environment, equality, and accessibility for persons with disabilities, and in the light of the state of progress in the information society.",
        "title":"Amendment 2990: Article 84 – paragraph 7  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"55b584d8-7d80-4f94-b017-de240f856f4a",
        "text":"7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology, the effect of AI systems on health and safety, fundamental rights, equality, and accessibility for persons with disabilities, and in the light of the state of progress in the information society.",
        "title":"Amendment 2991: Article 84 – paragraph 7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"f00ddfd1-95ba-4aa1-8040-ffb9668b8a15",
        "text":"7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account the effect of AI systems on fundamental rights, equality, and accessibility for persons with disabilities, developments in technology and in the light of the state of progress in the information society.",
        "title":"Amendment 2992: Article 84 – paragraph 7  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"ae73880f-cb52-4bbc-ad58-f3d695c75fd3",
        "text":"7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology and new potential or realised risks to fundamental rights, and in the light of the state of progress in the information society.",
        "title":"Amendment 2993: Article 84 – paragraph 7  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"253bd6d9-476f-4d6b-9286-3364ab17645a",
        "text":"7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account the impact of this Regulation on fundamental rights, developments in technology and in the light of the state of progress in the information society.",
        "title":"Amendment 2994: Article 84 – paragraph 7  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"d1b2e9c5-f169-45f2-b659-afda317c6423",
        "text":"7 a. By three years from the date of application of this Regulation at the latest, the Commission shall carry out an assessment of the enforcement of this Regulation and shall report it to the European Parliament, the Council and the European Economic and Social Committee, taking into account the first years of application of the Regulation. On the basis of the findings that report shall, where appropriate, be accompanied by a proposal for amendment of this Regulation with regard to the structure of enforcement and the need for an EU agency to resolve any identified shortcomings.",
        "title":"Amendment 2995: Article 84 – paragraph 7 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"e55d0f3e-2b72-4827-886a-c07ce605edc4",
        "text":"7 a. To guide the evaluations and reviews referred to in paragraphs 1 to 4, the Board shall undertake to develop an objective and participative methodology for the evaluation of risk level based on the criteria outlined in the relevant articles and inclusion of new systems in: the list in Annex III, including the extension of existing area headings or addition of new area headings; Article 5’s list of prohibited AI practices; and Article 52’s list of AI systems requiring additional transparency measures.",
        "title":"Amendment 2996: Article 84 – paragraph 7 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"77b27116-2d16-4930-b7c7-14422c890fdf",
        "text":"7 a. To guide the evaluations and reviews referred to in paragraphs 1 to 4, the Board shall undertake to develop an objective and participative methodology for the evaluation of risk level based on the criteria outlined in the relevant articles and inclusion of new systems in: the list in Annex III, including the extension of existing area headings or addition of new area headings; the list of prohibited practices in Article 5; and the list of AI systems requiring additional transparency measures.",
        "title":"Amendment 2997: Article 84 – paragraph 7 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"c8ff9546-82c0-4c63-a09d-324919b86112",
        "text":"7 a. Any amendment to this Regulation pursuant to paragraph 7, or relevant future delegated or implementing acts, which concern sectoral legislation listed in annex II section B, shall take into account the regulatory specificities of each sector, and should not interfere with existing governance, conformity assessment and enforcement mechanisms and authorities established therein.",
        "title":"Amendment 2998: Article 84 – paragraph 7 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"83773032-183c-48e4-b560-b84303e89403",
        "text":"Article 84 a', 'New Article 84a', 'Amendments to Directive (EU) 2020\/1828 on Representative Actions for the Protection of the Collective Interests of Consumers', 'The following is added to Annex I:', '\"(X) Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence (AI)",
        "title":"Amendment 2999: Article 84 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"85a7d529-5e8c-4cb4-8e9e-f5aff9e7c5cb",
        "text":"2. This Regulation shall apply from [36 months following the entering into force of the Regulation].",
        "title":"Amendment 3000: Article 85 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Marion Walsmann"
    },
    {
        "uuid":"dd72ec25-5fcd-4d01-8621-0d87adc8f944",
        "text":"2. This Regulation shall apply from [48 months following the entering into force of the Regulation].",
        "title":"Amendment 3001: Article 85 – paragraph 2  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"76889216-ff29-4f05-924c-e832a05042bb",
        "text":"2. This Regulation shall apply from [48 months following the entering into force of the Regulation].",
        "title":"Amendment 3002: Article 85 – paragraph 2  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9a28e618-90c4-4913-bb6c-c62bb23681f4",
        "text":"2. This Regulation shall apply from [6 months following the entering into force of the Regulation].",
        "title":"Amendment 3003: Article 85 – paragraph 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä"
    },
    {
        "uuid":"f3c05af9-7e6d-490a-9a2c-33de1a0657a7",
        "text":"(b) Article 71 shall apply from [24 months following the entry into force of this Regulation].",
        "title":"Amendment 3004: Article 85 – paragraph 3 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"066c3cc3-4642-4b79-90e2-69f3636e923a",
        "text":"(b a) Title II shall apply from [24 months following the entry into force of this Regulation].",
        "title":"Amendment 3005: Article 85 – paragraph 3 – point b a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5205930d-09cc-491e-95ac-ee9bbf9e5957",
        "text":"3 a. Member States shall not until ... [24 months after the date of application of this Regulation] impede the making available of AI systems and products which were placed on the market in conformity with Union harmonisation legislation before [the date of application of this Regulation].",
        "title":"Amendment 3006: Article 85 – paragraph 3 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9fbca478-1068-472b-8f63-db93c475a770",
        "text":"3 a. Member States shall not until... [24 months after the date of application of this Regulation] impede the making available of AI systems and products which were placed on the market inconformity with Union harmonisation legislation before [the date of application of this Regulation].",
        "title":"Amendment 3007: Article 85 – paragraph 3 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"1c3da4e7-8d93-4080-b8da-f63dd14d0af9",
        "text":"3 b. At the latest by six months after entry into force of this Regulation, the European Commission shall submit a standardization request to the European Standardisation Organisations in order to ensure the timely provision of all relevant harmonised standards that cover the essential requirements of this regulation. Any delay in submitting the standardisation request shall add to the transitional period of 24 months as stipulated in paragraph 3a.",
        "title":"Amendment 3008: Article 85 – paragraph 3 b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz"
    },
    {
        "uuid":"43e4fb77-c397-4292-9a9c-c906a123f066",
        "text":"3 b. At the latest by six months after entry into force of this Regulation, the European Commission shall submit a standardization request to the European Standardisation Organisations in order to ensure the timely provision of all relevant harmonised standards that cover the essential requirements of this regulation. Any delay in submitting the standardisation request shall add to the transitional period of 24 months as stipulated in paragraph 4",
        "title":"Amendment 3009: Article 85 – paragraph 3 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"3a53636e-0650-4ae9-9e94-4056f411dba1",
        "text":"deleted",
        "title":"Amendment 3010: Annex I  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"5c67197b-87f7-4388-8a78-32c2b0e74e64",
        "text":"deleted",
        "title":"Amendment 3011: Annex I  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"1359ade9-014b-476c-8f9f-e0121090dda5",
        "text":"deleted",
        "title":"Amendment 3012: Annex I  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"b1f934d6-f31b-441e-8388-340187ae7e7e",
        "text":"deleted",
        "title":"Amendment 3013: Annex I – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Carlo Fidanza"
    },
    {
        "uuid":"b5b756b9-8eff-4a71-9612-1cead75f660c",
        "text":"deleted",
        "title":"Amendment 3014: Annex I – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"a81e8f27-0b59-4789-8c9d-b1b659eb3aa6",
        "text":"deleted",
        "title":"Amendment 3015: Annex I – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"b179af17-764a-4039-af91-ab2252f35144",
        "text":"deleted",
        "title":"Amendment 3016: Annex I – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"37dc274f-4e43-4942-8acc-321b3be7abde",
        "text":"deleted",
        "title":"Amendment 3017: Annex I – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"9bd08db9-df92-4fde-8a45-d21576457fb2",
        "text":"(b) Other data-driven approaches, including search and optimization methods.",
        "title":"Amendment 3018: Annex I – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"97cbec6c-8b2b-480a-b629-041c077a3759",
        "text":"deleted",
        "title":"Amendment 3019: Annex I – point c  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Carlo Fidanza"
    },
    {
        "uuid":"5f6dee8b-e21a-4d4e-9e35-7e38ef7334c3",
        "text":"deleted",
        "title":"Amendment 3020: Annex I – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"c93c11f3-7aea-4f42-b30a-dccac3dcddb8",
        "text":"deleted",
        "title":"Amendment 3021: Annex I – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"585bb2b3-3c56-4ea9-8eb3-0e6ecb2bcb61",
        "text":"deleted",
        "title":"Amendment 3022: Annex I – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Karlo Ressler"
    },
    {
        "uuid":"d0f632b6-e6b2-4684-aa41-b9d25aa0fc7a",
        "text":"deleted",
        "title":"Amendment 3023: Annex I – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"f332be0e-e7ad-4876-9575-996c665bb229",
        "text":"deleted",
        "title":"Amendment 3024: Annex I – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"beeac3a4-2822-45c4-9e13-3732a41127e5",
        "text":"(c) Statistical approaches, Bayesian estimation, if they are used to extract decisions from data in an automated way and search.",
        "title":"Amendment 3025: Annex I – point c a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"47b13dcf-7999-4aaf-ba34-92f129c5d08e",
        "text":"(c a) Approaches based on neural network imitation and neuro-robotic networks;",
        "title":"Amendment 3026: Annex I – point c a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"90657912-0e30-4be6-960e-dde103f5e435",
        "text":"(c b) Machine learning tasks on graphs for repetition tasks or pattern recognition;",
        "title":"Amendment 3027: Annex I – point c b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"a4def666-3ce5-4d3e-8969-c2c6e071666b",
        "text":"(c c) Natural language programming techniques, including emotion detection and recognition systems, using interactions between human language and computer language;",
        "title":"Amendment 3028: Annex I – point c c (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"52e9fa02-1379-4ea8-bcf8-f3041f69ce8e",
        "text":"(c d) Artificial vision for pattern recognition, including graphical analysis or digital signature identification;",
        "title":"Amendment 3029: Annex I – point c d (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"116fbe6c-7845-4550-b593-26ca43079328",
        "text":"(c e) Interactive systems related to mechatronics, robotics and automation systems.",
        "title":"Amendment 3030: Annex I – point c e (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c0effe9f-880f-4ff7-954d-6e63a8afd96a",
        "text":"deleted",
        "title":"Amendment 3031: Annex II – Part A – point 6  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"84804c97-3215-4e49-b6ec-68c2273e4fc1",
        "text":"deleted",
        "title":"Amendment 3032: Annex II – Part A – point 11  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"11800d70-cfee-45fe-9e8c-7e421b9216f4",
        "text":"deleted",
        "title":"Amendment 3033: Annex II – Part A – point 11  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Deirdre Clune, Axel Voss, Andreas Schwab"
    },
    {
        "uuid":"3d07fc18-8aa3-4429-9d51-212eadae2f38",
        "text":"deleted",
        "title":"Amendment 3034: Annex II – Part A – point 12  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b0e493e1-99c9-4fa3-be14-6564f3788d54",
        "text":"12 a. Directive 2014\/35\/EU of the European Parliament and of the Council of 26 February 2014 on the harmonisation of the laws of the Member States relating to the making available on the market of electrical equipment designed for use within certain voltage limits (OJ L96\/357, 29.3.2014).",
        "title":"Amendment 3035: Annex II – Part A – point 12 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9d373763-4811-4dee-9f67-9878e1c04fbc",
        "text":"12a. [REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on a Single Market For Digital Services (Digital Services Act) and amending Directive 2000\/31\/EC]",
        "title":"Amendment 3036: Annex II – Part A – point 12 a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"3cb44562-ad06-4400-b10b-e060254b3b7e",
        "text":"12b. [REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on contestable and fair markets in the digital sector (Digital Markets Act)].",
        "title":"Amendment 3037: Annex II – Part A – point 12 b (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"caef659b-4c39-407c-9b21-457d499f87b6",
        "text":"7 a. Regulation (EU) 2017\/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001\/83\/EC, Regulation (EC) No 178\/2002 and Regulation (EC) No1223\/2009 and repealing Council Directives 90\/385\/EEC and 93\/42\/EEC (OJ L 117,5.5.2017, p. 1;",
        "title":"Amendment 3038: Annex II – Part B – point 7 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Deirdre Clune, Axel Voss, Andreas Schwab"
    },
    {
        "uuid":"d84a3b75-f9e9-4a3a-9a5f-29c4a8175dbf",
        "text":"7 a. Regulation (EU) 2017\/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001\/83\/EC, Regulation (EC) No 178\/2002 and Regulation (EC) No 1223\/2009 and repealing Council Directives 90\/385\/EEC and 93\/42\/EEC (OJ L 117, 5.5.2017, p. 1;",
        "title":"Amendment 3039: Annex II – Part B – point 7 a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"dd7f6224-07b7-4bd2-a063-a2269bb0162a",
        "text":"7 a. Directive 2009\/125\/EC of the European Parliament and of the Council of 21 October 2009 establishing a framework for the setting of ecodesign requirements for energy-related products.",
        "title":"Amendment 3040: Annex II – Part B – point 7 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f3f9cb3f-40c8-41fd-b1bd-db0de3d0e39c",
        "text":"7 b. Regulation (EU) 2017\/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98\/79\/EC and Commission Decision 2010\/227\/EU (OJ L 117, 5.5.2017, p. 176).",
        "title":"Amendment 3041: Annex II – Part B – point 7 b (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"99f77316-301e-4dfc-a9b0-4a407b862fac",
        "text":"INDICATIVE LIST OF HIGH-RISK AI SYSTEMS REFERRED TO IN ARTICLE 6(2)",
        "title":"Amendment 3042: Annex III – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"23fc8206-d6d2-4b65-9f6d-875bf7c82a7c",
        "text":"HIGH-RISK USES OF AI SYSTEMS REFERRED TO IN ARTICLE 6(2)",
        "title":"Amendment 3043: Annex III – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Geoffroy Didier"
    },
    {
        "uuid":"039d3044-a200-4133-bd8d-826b8fcbf00b",
        "text":"CRITICAL USE CASES REFERRED TO IN ARTICLE 6(2)",
        "title":"Amendment 3044: Annex III – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"85db1706-1679-401f-bcfa-b24918369132",
        "text":"CRITICAL AREAS REFERRED TO IN ARTICLE 6(2)",
        "title":"Amendment 3045: Annex III – title  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"4ea4519d-f991-4186-8266-8a741577cbd1",
        "text":"The AI systems specifically mentioned under points 1-8 stand for critical use cases and are each considered to be high-risk AI systems pursuant to Article 6(2), when - according to their instructions to use - their intended purpose and specific use pose a significant risk of harm to the health and safety or a risk of adverse impact on fundamental rights:",
        "title":"Amendment 3046: Annex III – paragraph 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"479df62e-9c4f-4ac0-b82b-6eb37589a73b",
        "text":"1. 1.Biometric and biometrics-based systems:', '(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons;', '(b) AI systems intended to be used for the remote biometric categorisation of natural persons in publicly-accessible spaces;', '(c) AI systems intended to be used for emotion recognition in natural persons;",
        "title":"Amendment 3047: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"f5df42e8-e928-4c79-ac0f-d8d5338442ad",
        "text":"1. Biometric identification systems, excluding biometric authentication or verification, intended to be used for the ‘real-time’ and ‘post’ remote biometric identification or categorisation of natural persons (i.e., revealing their identity or tracking their behaviour) without their expressed or implied consent and causing legal effects or discrimination against the affected person;",
        "title":"Amendment 3048: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"64d4a40c-4f79-4c97-aeb2-36bd40b9170f",
        "text":"1. Biometric or biometrics-based profiling, including identification and categorisation of natural persons:",
        "title":"Amendment 3049: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"602dea6f-9b5b-4107-8254-c92672357d3c",
        "text":"1. Biometric identification, biometrics-based data and categorisation of natural persons:",
        "title":"Amendment 3050: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"8cb36281-f9a4-46c0-bbda-430014988cf6",
        "text":"1. Biometrics systems identification and categorisation of natural persons",
        "title":"Amendment 3051: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Eugen Jurzyca, Adam Bielan"
    },
    {
        "uuid":"91012795-1a6e-4eec-8df0-e13c7a0bfaed",
        "text":"1. AI systems which use biometric or biometrics-based data:",
        "title":"Amendment 3052: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a35b78bf-b6da-4238-a270-f8dd0227b99b",
        "text":"1. AI systems which use biometric or biometrics-based data:",
        "title":"Amendment 3053: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"64ab4ada-6fb9-49bb-aae0-ca6c001c3594",
        "text":"1. Biometric identification of natural persons:",
        "title":"Amendment 3054: Annex III – paragraph 1 – point 1 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"79ba0b8a-e564-417f-b463-4206e1588459",
        "text":"deleted",
        "title":"Amendment 3055: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"762c8a68-4753-45cb-8ecb-2d85a1cddc1e",
        "text":"deleted",
        "title":"Amendment 3056: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache"
    },
    {
        "uuid":"c19ce18a-527c-468a-b9e5-d326176c2a4c",
        "text":"deleted",
        "title":"Amendment 3057: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"d6a97c5b-94c4-48a2-8c95-9417a8978c08",
        "text":"deleted",
        "title":"Amendment 3058: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"89ac87cd-1fb3-40b0-a288-869055181edb",
        "text":"(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons, excluding verification\/authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;",
        "title":"Amendment 3059: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,"
    },
    {
        "uuid":"ced0d1a8-49bc-45ea-bc5a-0540f122f12c",
        "text":"(a) AI systems that are or may be used for the biometric identification of natural persons, including in workplaces, in educational settings and in border surveillance, or for the provision of public or essential services;",
        "title":"Amendment 3060: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"29fe182d-d940-49a4-acae-3d06a080d985",
        "text":"(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons, within the strict limits of the exemption from the general prohibition on their use laid down in Article 5;",
        "title":"Amendment 3061: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"a1dd15e3-c9ea-4a7f-9d64-468c5c2836e8",
        "text":"(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons without their agreement, including remote biometric identification;",
        "title":"Amendment 3062: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"b26bdd55-1048-493f-b89c-a37045f845b5",
        "text":"(a) AI biometric identification systems intended to be used for the ‘real time’ and ‘post’ remote biometric identification of natural persons without their agreement;",
        "title":"Amendment 3063: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Eugen Jurzyca"
    },
    {
        "uuid":"4b605e6e-0eca-4d25-b744-840c9b52a977",
        "text":"(a) AI systems that are or may be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons;",
        "title":"Amendment 3064: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"be73eb6e-78a9-498b-a1a5-0424a94d0cc9",
        "text":"(a) AI systems used for the ‘real-time’ and ‘post’ biometric identification of natural persons;",
        "title":"Amendment 3065: Annex III – paragraph 1 – point 1 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"04b4b1e1-c8cd-4677-8c0d-92846e28b01a",
        "text":"(a a) AI systems intended to be used to make inferences on the basis of biometric data, including emotion recognition systems, or biometrics-based data, including speech patterns, tone of voice, lip-reading and body language analysis, that produces legal effects or affects the rights and freedoms of natural persons.",
        "title":"Amendment 3066: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Vlad-Marius Botoş, Abir Al-Sahlani, Moritz"
    },
    {
        "uuid":"e6edf2d0-d17f-4c1a-a639-3da7c7d10313",
        "text":"(a a) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual \/ online version of these spaces, on the basis of their biometric or biometrics-based data;",
        "title":"Amendment 3067: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"2ab1d9b4-d34c-4276-8ba4-2d02a9ea070b",
        "text":"(a a) AI systems that are or may be used for the biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance, or in the provision of public or essential services;",
        "title":"Amendment 3068: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"69d7569f-671c-4889-b587-4b4e995ab714",
        "text":"(a a) AI systems that may be or are intended to be used for the ‘real-time’ and ‘post’ non-remote biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance;",
        "title":"Amendment 3069: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9d42641d-f0c1-45c5-b8a8-2ad09227d509",
        "text":"(a a) AI systems intended to be used by autonomous devices, drones or vehicles to transport or collect natural persons;",
        "title":"Amendment 3070: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"31a6efad-75bd-425c-90dc-6d3e4c32ce18",
        "text":"(a a) AI systems that are or may be used for biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;",
        "title":"Amendment 3071: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1cee0ac2-e924-4dd8-8d9f-3719c409c1e4",
        "text":"(a a) AI categorisation systems using biometric or biometrics-based data;",
        "title":"Amendment 3072: Annex III – paragraph 1 – point 1 – point a a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Rob Rooken"
    },
    {
        "uuid":"f339c325-3b6d-44aa-ab48-04cdca51860b",
        "text":"(a b) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual \/ online version of these spaces, on the basis of their biometric or biometrics-based data;",
        "title":"Amendment 3073: Annex III – paragraph 1 – point 1 – point a b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"238df226-051d-4532-9b8d-bfce10b969b7",
        "text":"(a b) AI systems that may be or are intended to be used for the ‘real-time’ and ‘post’ non-remote biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance;",
        "title":"Amendment 3074: Annex III – paragraph 1 – point 1 – point a b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7ea7c2d5-7cee-4f9c-a7b4-202b921b4660",
        "text":"(a b) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness \/attentiveness for safety purposes, on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3075: Annex III – paragraph 1 – point 1 – point a b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"827f4f7d-466b-4e3e-8549-ae17f05e6c3d",
        "text":"(a b) AI systems that are or may be used for biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;",
        "title":"Amendment 3076: Annex III – paragraph 1 – point 1 – point a b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"08bce85a-57b1-4281-9a68-335ca99a88b5",
        "text":"(a b) AI systems that are or may be used for categorisation on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3077: Annex III – paragraph 1 – point 1 – point a b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"aab468c1-01ee-4818-948c-0751659260fd",
        "text":"(a c) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness \/ attentiveness for safety purposes, on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3078: Annex III – paragraph 1 – point 1 – point a c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"229934de-9863-4747-b133-a4b5f099fb18",
        "text":"(a c) AI systems that are or may be used for ‘real-time’ and ‘post’ biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;",
        "title":"Amendment 3079: Annex III – paragraph 1 – point 1 – point a c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"b46630be-fcc9-4268-975f-a0b0d52db58d",
        "text":"(a c) AI systems that are or may be used to diagnose or support diagnosis of medical conditions or medical emergencies on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3080: Annex III – paragraph 1 – point 1 – point a c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"f721f694-754c-489b-958d-e31abb3513a9",
        "text":"(a c) AI systems that are or may be used to diagnose or support diagnosis of medical conditions or medical emergencies on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3081: Annex III – paragraph 1 – point 1 – point a c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7de621e7-eb14-43eb-8358-cfd72b7269fc",
        "text":"(a c) AI systems that are or may be used for categorisation on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3082: Annex III – paragraph 1 – point 1 – point a c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2b93bc38-088a-4873-8355-19201e305219",
        "text":"(a d) AI systems that are or may be used for the ‘real-time’ and ‘post’ detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual or online version of these spaces, on the basis of their physical, physiological or behavioural data, including biometric data;",
        "title":"Amendment 3083: Annex III – paragraph 1 – point 1 – point a d (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"c118c45b-db49-4ce3-836a-94d1758369a3",
        "text":"(a d) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual \/ online version of these spaces, on the basis of their biometric or biometrics-based data;",
        "title":"Amendment 3084: Annex III – paragraph 1 – point 1 – point a d (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d6c91f76-9b10-480a-9011-e4d40124f34b",
        "text":"(a e) AI systems intended to be used by or on behalf of competent authorities in ‘real-time’ and ‘post’ migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings.",
        "title":"Amendment 3085: Annex III – paragraph 1 – point 1 – point a e (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4890ee40-51f2-4360-a231-bbb713798033",
        "text":"(a e) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness \/ attentiveness for safety purposes, on the basis of biometric or biometrics-based data;",
        "title":"Amendment 3086: Annex III – paragraph 1 – point 1 – point a e (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"082ab355-abfa-412e-ad2e-87eec8ab5064",
        "text":"2. Management, operation, generation and supply of critical infrastructure, technology and energy:",
        "title":"Amendment 3087: Annex III – paragraph 1 – point 2 – introductory part  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1a5a9e86-1501-401f-b3c4-43d9a90932af",
        "text":"2. Critical infrastructure and protection of environment:",
        "title":"Amendment 3088: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"d99b0b7f-edc2-406f-8354-021abe9481c1",
        "text":"(a) AI systems intended to be used as a component, the failure or malfunctioning of which endangers the health, safety or fundamental rights of persons or the safety of property, in the management, operation, generation and\/or supply of the telecom, internet, and financial infrastructure, road, rail, air and water traffic, and the operation, management an\/or supply of water, gas, heating, and electricity and energy (including nuclear power).",
        "title":"Amendment 3089: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"b6a3f3d8-aeb7-4693-a86c-6f0189909d5e",
        "text":"(a) AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, whose failure or malfunctioning would directly cause significant harm to the health, natural environment or safety of natural persons.",
        "title":"Amendment 3090: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo"
    },
    {
        "uuid":"ce658547-0ac6-48c6-85af-aec279ab4f60",
        "text":"(a) AI systems that may be or are intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity and entities falling under [Directive XXXX\/XXX\/EU (‘NIS 2 Directive’)].",
        "title":"Amendment 3091: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"a9c69022-1e7a-424d-ba05-029bc61304f8",
        "text":"(a) AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, unless these are regulated in harmonisation legislation or sectorial regulation.",
        "title":"Amendment 3092: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"a40285a7-11bb-4e60-95d7-47091e3d8291",
        "text":"(a) AI systems intended to be used as safety components in the management and operation of road traffic, digital infrastructure and the supply of water, gas, heating and electricity.",
        "title":"Amendment 3093: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"265625d5-f15c-41ff-9b8f-3e4beca33f9f",
        "text":"(a) AI systems used as safety or security components in the management and operation of road traffic to the extent that they are not embedded in a vehicle;",
        "title":"Amendment 3094: Annex III – paragraph 1 – point 2 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"1f16fdd2-4848-4e94-b98c-61259d4be7e5",
        "text":"(a a) AI systems intended to be used as safety or security components in the management and operation of the supply of water, gas, heating and electricity, provided the failure of the AI system is highly likely to lead to an imminent threat to such supply.",
        "title":"Amendment 3095: Annex III – paragraph 1 – point 2 – point a a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d221b702-1692-4c95-9e1d-e58ba9164649",
        "text":"2 a. Vulnerable groups:', 'a) AI systems intended to be used by children in a way that may seriously affect a child’s personal development, such as by educating the child in a broad range of areas not limited to areas which parents or guardians can reasonably foresee at the time of the purchase;', 'b) AI systems, such as virtual assistants, intended to be used by natural persons for taking decisions with regard to their private lives that have legal effects or similarly significantly affect the natural persons;",
        "title":"Amendment 3096: Annex III – paragraph 1 – point 2 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão- Marques"
    },
    {
        "uuid":"aed4d4d7-84f0-45eb-ab76-5931a2485f0c",
        "text":"(a) AI systems intended to be used for the purpose of determining or materially influence decision on the admission of natural persons to educational and vocational training institutions;",
        "title":"Amendment 3097: Annex III – paragraph 1 – point 3 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6f2a8e15-8ddb-47c2-aaaa-229dbac2bea0",
        "text":"(a) AI systems that may be or are intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;",
        "title":"Amendment 3098: Annex III – paragraph 1 – point 3 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"66351ce4-4407-4bff-aa6e-7f8422d331cb",
        "text":"(b) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to educational institutions or monitoring of students during exams, for determining learning objectives, and for allocating personalised learning tasks to students;",
        "title":"Amendment 3099: Annex III – paragraph 1 – point 3 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"4388624a-782d-4a02-8b80-300d2f4dace6",
        "text":"(b) AI systems that may be or are intended to be used for the purpose of assessing students in educational and vocational training institutions or for assessing participants in tests commonly required for admission to educational institutions.",
        "title":"Amendment 3100: Annex III – paragraph 1 – point 3 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"6a1caba9-160a-4372-b447-c728499124e0",
        "text":"(b) AI systems intended to be used for the purpose of assessing the learning outcome of students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to these institutions.",
        "title":"Amendment 3101: Annex III – paragraph 1 – point 3 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"6ccc2047-a08a-4ae8-ad92-c98e2e17db7e",
        "text":"(b) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to those institutions.",
        "title":"Amendment 3102: Annex III – paragraph 1 – point 3 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"1475795c-0e61-42a6-a0fb-5b017e4b1d13",
        "text":"(b a) AI systems that may be or are intended to be used for the purpose of assessing the appropriate level of education for an individual with potential effects for the methods or level of education that individual will recieve or will be able to access.",
        "title":"Amendment 3103: Annex III – paragraph 1 – point 3 – point b a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"0e392532-90fb-488e-b1f6-d36baa515c2d",
        "text":"(b a) AI systems intended to be used for the optimization of individual learning processes based on a student's learning data.",
        "title":"Amendment 3104: Annex III – paragraph 1 – point 3 – point b a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"4daaca9e-3d68-488a-95c4-b68a69a89b5e",
        "text":"4. Employment and work-related contractual relationships', 'AI systems intended to be used to make or materially influence decisions on:', '(i) recruitment or selection of natural persons, specifically for screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(ii) promotion and termination of work-related contractual relationships;', '(iii) task allocation based on individual behaviour or personal traits or characteristics;or', '(iv) monitoring and evaluating the performance and behaviour of persons.', 'where those decisions are likely to pose a significant risk of adversely impacting fundamental rights or threatening harm to health and safety.",
        "title":"Amendment 3105: Annex III – paragraph 1 – point 4 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7187666a-2389-4cbd-8dc8-8815ba85016e",
        "text":"deleted",
        "title":"Amendment 3106: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a97b57b4-4f75-4814-a152-d87faa57fc32",
        "text":"(a) AI systems intended to be used to make final decisions for recruitment or selection of natural persons.",
        "title":"Amendment 3107: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"a5ab4555-8638-47ca-89d5-39f3f3191c89",
        "text":"(a) AI systems intended to make autonomous decisions or materially influence decisions about recruitment or selection of natural persons, notably for screening or filtering applications, evaluating candidates in the course of interviews or tests;",
        "title":"Amendment 3108: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"ac4e162e-ee57-49c2-90f4-769c0481c105",
        "text":"(a) AI systems that may be or are intended intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;",
        "title":"Amendment 3109: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"484de73d-0c51-4ee6-a206-b148b6347b7d",
        "text":"(a) AI systems intended to be used in recruitment for advertising vacancies, screening or filtering applications, or evaluating candidates in the course of interviews or tests;",
        "title":"Amendment 3110: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c0d9e666-cfe1-4729-9952-35a91c2728fd",
        "text":"(a) AI systems intended to be used for recruitment or selection of natural persons, screening or filtering applications, evaluating candidates in the course of interviews or tests;",
        "title":"Amendment 3111: Annex III – paragraph 1 – point 4 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"de1c247c-48fd-4bca-9ddf-4d63aa20ea82",
        "text":"deleted",
        "title":"Amendment 3112: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"48cc929c-2c76-48e9-ae9b-aea8b5c3fd4f",
        "text":"(b) AI systems intended to be used to make decisions on promotion and termination of work-related contractual relationships, based on individual behaviour or personal traits or characteristics, and for monitoring and evaluating performance and behaviour of persons in such relationships that have a likelihood of causing harm to the physical health and safety or adversely impact on the fundamental rights or have given rise to significant concerns in relation to the materialisation of such harm or adverse impact.",
        "title":"Amendment 3113: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki, Adam Bielan, Vincenzo Sofo"
    },
    {
        "uuid":"91ac0303-ea11-4774-a9c9-60cdc2c05bd5",
        "text":"(b) AI that may be or are intended to be used to assist decision-making affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly work-related relationships, for task allocation and for monitoring, measuring and evaluating performance and behavior of persons in such relationships.",
        "title":"Amendment 3114: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"b91434f6-5d51-4ffd-ac00-f5b22d3ab6af",
        "text":"(b) AI intended to be used for making decisions affecting the initiation, establishment, implementation, promotion and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly for task allocation and for monitoring and evaluating performance and behavior of persons or in matters of training or further education in such relationships.",
        "title":"Amendment 3115: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"7e02c9ab-6787-4ca8-95df-357962686b80",
        "text":"(b) AI intended to be used for making decisions affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly for task allocation and for monitoring and evaluating performance and behavior of persons in such relationships",
        "title":"Amendment 3116: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"1e7d28c2-4189-40b6-ba19-d5a17e6b8f72",
        "text":"(b) AI systems intended to be used for making decisions or to assist in making decisions on promotion and termination of work-related contractual relationships; for personalized task allocation based on biometrics, biometrics-based, or personal data; and for monitoring and evaluating performance and behaviour of natural persons in such relationships.",
        "title":"Amendment 3117: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"f8489518-29fd-4e39-bb86-29c71c62e781",
        "text":"(b) AI intended to make autonomous decisions or materially influence decisions on promotion and termination of work-related contractual relationships, for monitoring and evaluating performance and behavior of persons in such relationships.",
        "title":"Amendment 3118: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen"
    },
    {
        "uuid":"e0a7442f-ad9c-4b21-9b9d-05a0f8f197a4",
        "text":"(b) AI intended to be used for making decisions on promotion and termination of work-related contractual relationships, and for monitoring and evaluating performance and behavior of persons in such relationships.",
        "title":"Amendment 3119: Annex III – paragraph 1 – point 4 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Nathalie Colin-Oesterlé"
    },
    {
        "uuid":"c7ef642f-b135-40fa-8c1c-4bb75d46630d",
        "text":"5. Access to and enjoyment of essential private services and public services and benefits, including access to products:",
        "title":"Amendment 3120: Annex III – paragraph 1 – point 5 – introductory part  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"8003a18a-ea6b-4098-a00e-04360626571e",
        "text":"deleted",
        "title":"Amendment 3121: Annex III – paragraph 1 – point 5 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"c606aad0-2e00-432b-9266-b80bda1ab9d4",
        "text":"(a) AI systems intended to be used by or on behalf of (semi-)public authorities or private parties to evaluate or predict the lawful use by, or the eligibility of, natural persons, including the self employed and micro-enterprises, for public assistance, benefits and services and essential private services including but not limited to housing, electricity, heating\/cooling, finance, insurance and internet, as well as to grant reduce, revoke, or reclaim such benefits and services or set payment obligations related to these services;",
        "title":"Amendment 3122: Annex III – paragraph 1 – point 5 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"85ff7c44-19f9-49d8-8879-c4a31a97d0cb",
        "text":"(a) AI systems that may be or are intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;",
        "title":"Amendment 3123: Annex III – paragraph 1 – point 5 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f48f4769-e1c6-4c3a-9bbe-1deb1856a928",
        "text":"(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate and decide on the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;",
        "title":"Amendment 3124: Annex III – paragraph 1 – point 5 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f080a754-8c50-4e6a-b6af-be7ffb259c24",
        "text":"(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, increase, or reclaim such benefits and services;",
        "title":"Amendment 3125: Annex III – paragraph 1 – point 5 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b3455645-763f-4ca7-8753-915d21f0fd7f",
        "text":"deleted",
        "title":"Amendment 3126: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0d884666-2167-4fe7-ad7f-bee9fbae1b01",
        "text":"deleted",
        "title":"Amendment 3127: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2c7797b4-2f60-4f42-9775-c1ddde27c962",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score in order to determine their access to credit or to other essential services. Ancillary applications such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals are not included in those systems;",
        "title":"Amendment 3128: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Andrea Caroppo, Salvatore De Meo"
    },
    {
        "uuid":"8dfa15be-1c15-43f2-b0a9-386929dff4fd",
        "text":"(b) AI systems intended to be used",
        "title":"Amendment 3129: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"345b4eb5-26f0-40ee-b75f-2d4387f206e9",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or assessment of insurance risk, with the exception of AI systems put into service by small scale providers for their own use or AI systems related to low-value credits for the purchase of moveables;",
        "title":"Amendment 3130: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki"
    },
    {
        "uuid":"32d8452d-8d2a-4126-ab57-4ca81565fb93",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use; or AI systems related to low-value credits for the purchase of movables;",
        "title":"Amendment 3131: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"57db17e0-f8bf-4072-bd14-d52b15e41719",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score;",
        "title":"Amendment 3132: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d85cc96a-8880-452a-a36a-2ccdf89d5beb",
        "text":"(b) AI systems that may be or are intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;",
        "title":"Amendment 3133: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"befe19f0-1da5-4f1e-be89-1f6f0b504534",
        "text":"(b) AI systems that may be or are intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;",
        "title":"Amendment 3134: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"90a33f52-ab70-425a-bd61-7ffe470d62b7",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons, establish their credit score, or predict human medical conditions and health-related outcomes",
        "title":"Amendment 3135: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Maria-Manuel Leitão-Marques, Eva Kaili"
    },
    {
        "uuid":"8db4c1b8-9435-43fb-ad2b-9be927aa248a",
        "text":"(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by SMEs and start-ups for their own use;",
        "title":"Amendment 3136: Annex III – paragraph 1 – point 5 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,"
    },
    {
        "uuid":"37741535-ca1a-4df8-949e-1944b2140678",
        "text":"i) to evaluate the creditworthiness of natural persons or establish their credit score,",
        "title":"Amendment 3137: Annex III – paragraph 1 – point 5 – point b – point i (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"7fbc5b64-ecf9-4b90-b916-3d62b05447b1",
        "text":"ii) to evaluate the behaviour of natural persons such as with regard to complaints or the exercise of statutory or contractual rights in order to draw conclusions for their future access to private or public services,",
        "title":"Amendment 3138: Annex III – paragraph 1 – point 5 – point b – point ii (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"b0b54669-32d6-4af4-9401-e5f79a33cfa4",
        "text":"iii) for making individual risk assessments of natural persons in the context of access to essential private and public services, including insurance contracts, or",
        "title":"Amendment 3139: Annex III – paragraph 1 – point 5 – point b – point iii (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"53efef74-b946-4166-8a56-c7c177a9912c",
        "text":"iv) for personalized pricing within the meaning of Article 6 (1) (ea) of Directive 2011\/83\/EU, with the exception of AI systems put into service by small scale providers of AI systems for their own use;",
        "title":"Amendment 3140: Annex III – paragraph 1 – point 5 – point b – point iv (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques"
    },
    {
        "uuid":"0348e218-6242-41a7-9e24-20f98e0420aa",
        "text":"(c) AI systems intended to be used, without taking any decisions on the matter, to dispatch, or to establish priority in the dispatching of emergency first response services, including by firefighters and medical aid.",
        "title":"Amendment 3141: Annex III – paragraph 1 – point 5 – point c  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"98c54b35-3824-4476-9469-0abb18660f04",
        "text":"(c) AI systems that may be or are intended to be used to dispatch, or to establish priority in the dispatching of emergency first response services, including by firefighters and medical aid.",
        "title":"Amendment 3142: Annex III – paragraph 1 – point 5 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"a84c3aee-10c9-4836-ae6f-9b7fce1a3210",
        "text":"(c a) AI systems that may be used or are intended to be used for making individual risk assessments of natural persons in the context of access to private and public services, including determining the amounts of insurance premiums.",
        "title":"Amendment 3143: Annex III – paragraph 1 – point 5 – point c a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"cbc760bd-048b-4a71-a93b-b9d8217f4564",
        "text":"(c a) AI systems intended to be used for insurance premium setting, underwritings and claims assessments, with the exception of AI systems related to low-value property insurance.",
        "title":"Amendment 3144: Annex III – paragraph 1 – point 5 – point c a (new)  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Patryk Jaki"
    },
    {
        "uuid":"074fe035-a3f7-417d-b652-1236db2f4925",
        "text":"(c a) AI systems intended to be used for insurance premium setting, underwritings and claims assessments, with the exception of AI systems related to low-value property insurance.",
        "title":"Amendment 3145: Annex III – paragraph 1 – point 5 – point c a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,"
    },
    {
        "uuid":"8647b4e9-c96a-4a52-b0e2-d937ec239714",
        "text":"(c b) AI systems that may be used or are intended to be used in the context of payment and debt collection services.",
        "title":"Amendment 3146: Annex III – paragraph 1 – point 5 – point c b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"19f38e8f-dd15-4012-b5e7-f879b3086fe1",
        "text":"5 a. Use by vulnerable groups or in situations that imply vulnerability', '(a) AI systems intended to be used by children in a way that may seriously affect a child’s personal development, such as by educating the child in a broad range of areas not limited to areas which parents or guardians can reasonably foresee at the time of the purchase;', '(b) AI systems, such as virtual assistants, intended to be used by natural persons for taking decisions with regard to their private lives that have legal effects or similarly significantly affect the natural persons;', '(c) AI systems intended to be used for personalised pricing within the meaning of Article 6 (1) (ea) of Directive 2011\/83\/EU.",
        "title":"Amendment 3147: Annex III – paragraph 1 – point 5 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"75426ea4-2c24-43a6-91d7-48237ac9b979",
        "text":"deleted",
        "title":"Amendment 3148: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"afae3578-4a0b-4b8c-a78a-c3494b3c5e11",
        "text":"deleted",
        "title":"Amendment 3149: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"c871c885-b357-4f0a-867d-dc7b355d437a",
        "text":"deleted",
        "title":"Amendment 3150: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7429bc5c-68fd-43c4-bfee-b0cc138a2905",
        "text":"deleted",
        "title":"Amendment 3151: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"17e58d3e-edb8-4d4d-a4a7-5060f3bf856c",
        "text":"deleted",
        "title":"Amendment 3152: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a5cb1ec6-6f48-49b9-a75c-db5aeb1f6bd3",
        "text":"(a) AI systems intended to be used by law enforcement authorities or on their behalf for making individual risk assessments of natural persons in order to assess the risk for a natural person for offending or reoffending or the risk for a natural person to become a potential victim of criminal offences;",
        "title":"Amendment 3153: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"2655cc2a-c9e7-49dc-a352-d65da7c3a9a8",
        "text":"(a) AI systems intended to be used by law enforcement authorities or on their behalf for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or the risk for potential victims of criminal offences;",
        "title":"Amendment 3154: Annex III – paragraph 1 – point 6 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Abir"
    },
    {
        "uuid":"e0b97bcc-375e-4b54-a6f4-43eb2f91f139",
        "text":"(a a) AI systems designed for real-time remote biometric identification in publicly accessible locations for law enforcement purposes.",
        "title":"Amendment 3155: Annex III – paragraph 1 – point 6 – point a a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jörgen Warborn, Arba Kokalari, Tomas Tobé"
    },
    {
        "uuid":"aae04e93-069f-412e-a442-e09d762a1a9c",
        "text":"deleted",
        "title":"Amendment 3156: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e2b101f4-45cc-4fd9-8f1a-fd5038456610",
        "text":"deleted",
        "title":"Amendment 3157: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"f7c078cf-8485-4e63-bc14-3c17cc89ef69",
        "text":"deleted",
        "title":"Amendment 3158: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"a9512d21-48e8-41e1-9c98-9d8c34f758f1",
        "text":"deleted",
        "title":"Amendment 3159: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"63281abb-d414-4bce-939c-0cae1f748a5a",
        "text":"deleted",
        "title":"Amendment 3160: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"fab3340e-2ae6-402a-a73a-1182dceec396",
        "text":"deleted",
        "title":"Amendment 3161: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"22fe2d65-8dfb-44c3-943e-583addf70851",
        "text":"deleted",
        "title":"Amendment 3162: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"89dc5bd8-31b2-41b4-a529-66ad9c070be5",
        "text":"(b) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 3163: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"6873529e-59b8-41c9-8227-e2f0b598536c",
        "text":"(b) AI systems intended to be used by law enforcement authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 3164: Annex III – paragraph 1 – point 6 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"98df2fee-5cca-4332-9b28-7ab12c888953",
        "text":"(c) AI systems intended to be used by law enforcement authorities or on their behalf to detect deep fakes as referred to in article 52(3) and in point 8a(a) and (b) of this Annex;",
        "title":"Amendment 3165: Annex III – paragraph 1 – point 6 – point c  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"57f56c44-5a7e-40e3-a812-ee14b4ebf19c",
        "text":"(c) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities to detect deep fakes as referred to in article 52(3);",
        "title":"Amendment 3166: Annex III – paragraph 1 – point 6 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"28af76e6-58e1-4ab4-ba3b-76a7df246ff1",
        "text":"(c) AI systems that may be or are intended to be used by law enforcement authorities to detect deep fakes as referred to in article 52(3);",
        "title":"Amendment 3167: Annex III – paragraph 1 – point 6 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9368b466-8a07-455b-b669-183b6d121104",
        "text":"(c) AI systems intended to be used by law enforcement authorities or on their behalf to detect deep fakes as referred to in article 52(3);",
        "title":"Amendment 3168: Annex III – paragraph 1 – point 6 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"ba0acfb3-bd63-4b8f-8b4d-ab3d6bf4fb7a",
        "text":"(d) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;",
        "title":"Amendment 3169: Annex III – paragraph 1 – point 6 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"913fca9d-964a-4fb5-bb86-d82f6c8e1f50",
        "text":"(d) AI systems intended to be used by law enforcement authorities or on their behalf for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;",
        "title":"Amendment 3170: Annex III – paragraph 1 – point 6 – point d  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"7c22e737-f899-4b81-8238-f3836a480fd9",
        "text":"(d) AI systems that may be or are intended to be used by law enforcement authorities for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;",
        "title":"Amendment 3171: Annex III – paragraph 1 – point 6 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7bfbfb8b-43f1-417c-95a5-2b17dc086faa",
        "text":"(d) AI systems intended to be used by law enforcement authorities or on their behalf for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;",
        "title":"Amendment 3172: Annex III – paragraph 1 – point 6 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"c381d0ad-cf98-4f29-b8f7-14c71d1dd121",
        "text":"deleted",
        "title":"Amendment 3173: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"eef01b16-df2d-4abb-a18d-33ad1502e613",
        "text":"deleted",
        "title":"Amendment 3174: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"eff12f1e-e322-412f-adae-0b26a1385327",
        "text":"deleted",
        "title":"Amendment 3175: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"d5fdb0e8-48c5-4e6d-8071-0e7c5f356014",
        "text":"deleted",
        "title":"Amendment 3176: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"9d07b4f6-69f7-4c57-8117-61fb10cb54bd",
        "text":"deleted",
        "title":"Amendment 3177: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,"
    },
    {
        "uuid":"e78de82e-4631-47ea-b784-69e9dd359934",
        "text":"deleted",
        "title":"Amendment 3178: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"900a373e-dbf7-4058-af2c-25346f0fa077",
        "text":"(e) AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016\/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, with the exception of AI systems used for compliance with applicable counterterrorism and anti-money laundering legislation;",
        "title":"Amendment 3179: Annex III – paragraph 1 – point 6 – point e  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"43d9cbfd-19fe-401c-a8e7-995e23379378",
        "text":"deleted",
        "title":"Amendment 3180: Annex III – paragraph 1 – point 6 – point f  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"6413f890-d983-49ad-8e2b-4d10d1d9e742",
        "text":"deleted",
        "title":"Amendment 3181: Annex III – paragraph 1 – point 6 – point f  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"17848fd0-2d91-4358-b7ab-ca0cb2468e3d",
        "text":"(f) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU)2016\/680 in the course of detection, investigation or prosecution of criminal offences;",
        "title":"Amendment 3182: Annex III – paragraph 1 – point 6 – point f  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"f49d629e-1151-4f0f-a2c4-4514c411e400",
        "text":"(f) AI systems that may be or are intended to be used by law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016\/680 in the course of detection, investigation or prosecution of criminal offences;",
        "title":"Amendment 3183: Annex III – paragraph 1 – point 6 – point f  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"a676d2cd-8940-4691-8eee-92a67adccdf1",
        "text":"(f) AI systems intended to be used by law enforcement authorities or on their behalf for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016\/680 in the course of detection, investigation or prosecution of criminal offences;",
        "title":"Amendment 3184: Annex III – paragraph 1 – point 6 – point f  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"0565f8dc-ac57-4d1c-884a-893457afc6bd",
        "text":"deleted",
        "title":"Amendment 3185: Annex III – paragraph 1 – point 6 – point g  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"acc29bb5-efd9-4886-83d5-8e3264309cab",
        "text":"deleted",
        "title":"Amendment 3186: Annex III – paragraph 1 – point 6 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7181e4db-dce6-4f53-ba8d-234d252bd743",
        "text":"deleted",
        "title":"Amendment 3187: Annex III – paragraph 1 – point 6 – point g  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"697772af-ed11-4dd1-9845-1ec5e0f5f528",
        "text":"(g) AI systems intended to be used by law enforcement authorities or on their behalf for crime analytics regarding natural persons, allowing to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.",
        "title":"Amendment 3188: Annex III – paragraph 1 – point 6 – point g  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"9e9b43ee-ec53-4572-a01d-8f520b4230b9",
        "text":"deleted",
        "title":"Amendment 3189: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4b6927cb-108e-431b-91f7-15bfc00f68f0",
        "text":"deleted",
        "title":"Amendment 3190: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"e6482567-2ba6-430b-b691-ff34e9ed566f",
        "text":"deleted",
        "title":"Amendment 3191: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b718af55-6b6d-4127-b671-563615e015a7",
        "text":"deleted",
        "title":"Amendment 3192: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"39fd08ad-79db-4f66-be9a-640ae3aadd10",
        "text":"deleted",
        "title":"Amendment 3193: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"02f40437-bdff-4c9f-8508-5de286a45963",
        "text":"deleted",
        "title":"Amendment 3194: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"3f66b28a-0583-443e-baaa-a18298f6b2d4",
        "text":"(a) AI systems intended to be used by competent public authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 3195: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"af8c6e9a-aaf5-4d31-99be-d0783267d37f",
        "text":"(a) AI systems intended to be used by competent public authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;",
        "title":"Amendment 3196: Annex III – paragraph 1 – point 7 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"94ec7267-41ce-4ac7-873e-b9a96f892dc8",
        "text":"deleted",
        "title":"Amendment 3197: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"da2d14c2-8b78-41b3-94e6-cda33697f245",
        "text":"deleted",
        "title":"Amendment 3198: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9ae38a74-0d2a-41ac-a4f9-288e2b4bb356",
        "text":"deleted",
        "title":"Amendment 3199: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"01ed1f3e-791c-48c7-9b20-1c96b6153f78",
        "text":"deleted",
        "title":"Amendment 3200: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"e0ab592f-91be-4894-86b8-e881a8068afb",
        "text":"(b) AI systems that may be or are intended to be used by competent public authorities, or third parties on their behalf, to assess a risk, including, but not limited to, a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;",
        "title":"Amendment 3201: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"fd0d59be-392b-4bed-a965-559ca5658b30",
        "text":"(b) AI systems intended to be used by competent public authorities, or by third parties acting on their behalf, to assess a risk, including but not limited to a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;",
        "title":"Amendment 3202: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"a4e230b7-7165-460e-afe7-10311da162e2",
        "text":"(b) AI systems intended to be used by competent public authorities or by third parties acting on their behalf to assess a risk, including but not limited to a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;",
        "title":"Amendment 3203: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"6cc21c7a-95cb-4902-94b3-ec87a8244821",
        "text":"(b) AI systems intended to be used by competent public authorities or on their behalf to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;",
        "title":"Amendment 3204: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"bb4b8cec-223a-4001-8302-5aaf7d90f97e",
        "text":"(b) AI systems intended to be used by competent public authorities or on their behalf to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;",
        "title":"Amendment 3205: Annex III – paragraph 1 – point 7 – point b  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"78e2078c-b084-4c9e-a8a1-388eb71a0703",
        "text":"(c) AI systems that may be or are intended to be used by competent public authorities for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;",
        "title":"Amendment 3206: Annex III – paragraph 1 – point 7 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"5082f593-3569-4b30-9609-66401449863a",
        "text":"(c) AI systems intended to be used by competent public authorities or on their behalf for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;",
        "title":"Amendment 3207: Annex III – paragraph 1 – point 7 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"44d34c6c-e2a0-4a93-b523-854d9ddbe3e1",
        "text":"(c) AI systems intended to be used by competent public authorities or on their behalf for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;",
        "title":"Amendment 3208: Annex III – paragraph 1 – point 7 – point c  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"949f28f5-f0ee-4f12-ae8c-683dc79e15dd",
        "text":"deleted",
        "title":"Amendment 3209: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina"
    },
    {
        "uuid":"5decb161-c1b3-4832-9de0-ecdfdd2a6375",
        "text":"deleted",
        "title":"Amendment 3210: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"d3d69ab2-0438-45d7-b88d-7e37aa11df98",
        "text":"(d) AI systems intended to assist competent public authorities for the examination and assessment of the veracity of evidence and claims in relation to applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3211: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"ae36f108-50d0-4961-959d-c458bc863d6d",
        "text":"(d) AI systems intended to assist competent public authorities for the examination and assessment of the veracity of evidence and claims in relation to applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3212: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c807382e-3198-4aaa-b7bd-d7f94cb49997",
        "text":"(d) AI systems intended to be used by competent public authorities or on their behalf or to assist competent public authorities in the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3213: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"20c6bc5c-417e-4509-b6e5-9154820cbe3f",
        "text":"(d) AI systems intended to assist competent public authorities or on their behalf for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3214: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"4670bd1b-f8f7-433a-b808-5a9b45a4129c",
        "text":"(d) AI systems that may be or are intended to assist competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3215: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"044381c9-5ac0-4d2c-a135-74fb6f44f256",
        "text":"(d) AI systems intended to be used by competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.",
        "title":"Amendment 3216: Annex III – paragraph 1 – point 7 – point d  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Abir"
    },
    {
        "uuid":"64d0d2de-5462-4aad-8b6b-a4f56274bde4",
        "text":"(d a) AI systems that may be or are intended to be used by competent public authorities for border management and immigration authorities to monitor, surveil or process data for the purpose of detecting, verifying or identifying natural persons.",
        "title":"Amendment 3217: Annex III – paragraph 1 – point 7 – point d a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"667bfd67-b5da-462e-b2fb-eaae9396cec3",
        "text":"(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;",
        "title":"Amendment 3218: Annex III – paragraph 1 – point 7 – point d a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"8682c75d-5f99-4b3b-8d6a-c47d45bdac25",
        "text":"(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;",
        "title":"Amendment 3219: Annex III – paragraph 1 – point 7 – point d a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"660b33fe-902f-4bd8-930e-d47bbb2147d5",
        "text":"(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;",
        "title":"Amendment 3220: Annex III – paragraph 1 – point 7 – point d a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"ed72ac99-7245-4845-942e-b6115f7be2fd",
        "text":"(d a) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;",
        "title":"Amendment 3221: Annex III – paragraph 1 – point 7 – point d a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"da8583d5-1996-425b-9bfc-dc0f1c470026",
        "text":"(d b) AI systems that may be or are intended to be used for migration analytics regarding natural persons or groups, allowing immigration authorities or related entities to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.",
        "title":"Amendment 3222: Annex III – paragraph 1 – point 7 – point d b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"76f7b59f-9f3d-4b7f-909b-65344767cccd",
        "text":"(d b) AI systems intended to be used by, or on behalf of, competent authorities in migration, asylum and border control management to monitor, surveil, or process data in the context of border management activities for the purpose of recognizing or detecting objects and natural persons;",
        "title":"Amendment 3223: Annex III – paragraph 1 – point 7 – point d b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"7f605174-fc03-40ae-a51c-59fa23c7c6c9",
        "text":"(d b) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;",
        "title":"Amendment 3224: Annex III – paragraph 1 – point 7 – point d b (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"f08fc82e-cdb5-45a0-b118-52eed7886d05",
        "text":"(d b) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;",
        "title":"Amendment 3225: Annex III – paragraph 1 – point 7 – point d b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6ad6d17c-5c89-4c97-9f3b-cf269baa7529",
        "text":"(d c) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management to monitor, surveil or process data in the context of border management activities for the purpose of recognising or detecting objects and natural persons;",
        "title":"Amendment 3226: Annex III – paragraph 1 – point 7 – point d c (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák"
    },
    {
        "uuid":"18caf4d5-6fe0-48a0-a4af-4847ddce39a2",
        "text":"(d c) AI systems intended to be used by, or on behalf of, competent authorities in migration, asylum and border control management to monitor, surveil or process data in the context of border management activities for the purpose of recognizing or detecting objects and natural persons;",
        "title":"Amendment 3227: Annex III – paragraph 1 – point 7 – point d c (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9b7429a0-dfb3-476c-affa-b677491854b0",
        "text":"deleted",
        "title":"Amendment 3228: Annex III – paragraph 1 – point 8 – introductory part  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"e53221ae-e2b1-4bc3-ba27-9af3cd614315",
        "text":"8. Administration of justice:",
        "title":"Amendment 3229: Annex III – paragraph 1 – point 8 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune"
    },
    {
        "uuid":"d1660d42-0e5a-44de-b6c3-e94ff723005e",
        "text":"(a) AI systems intended to be used by a judicial authority or administrative body or on their behalf or to assist a judicial authority or administrative body in researching and interpreting facts or the law and in applying the law to a concrete set of facts.",
        "title":"Amendment 3230: Annex III – paragraph 1 – point 8 – point a  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"a62fb266-7e84-4570-94a4-3626496b3acb",
        "text":"(a) AI systems which may be or are intended to assist a judicial authority in researching and interpreting facts and the law and in applying the law or used in a similar way in alternative dispute resolution.",
        "title":"Amendment 3231: Annex III – paragraph 1 – point 8 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"e3fd4eb9-7dc4-457f-8a39-0f31154ca190",
        "text":"(a) AI systems intended to be used by a judicial authority, administrative body or on their behalf for in researching and interpreting facts and the law and for applying the law to a concrete set of facts.",
        "title":"Amendment 3232: Annex III – paragraph 1 – point 8 – point a  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0b5f2a72-8cc3-466e-bbf5-a86531505d04",
        "text":"(a) AI systems intended to be used by judicial authorities or on their behalf in interpreting facts or the law for applying the law to a concrete set of facts.",
        "title":"Amendment 3233: Annex III – paragraph 1 – point 8 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"ce4cc866-e264-46ea-b382-31c2ecd9cdc0",
        "text":"(a a) AI systems intended to be used by electoral constituencies for the purpose of protecting democracy and predicting the risk of a candidate for political office, in particular the position of head of government, being homophobic, sexist, dictatorial, kleptocratic and\/or having other toxic personality traits;",
        "title":"Amendment 3234: Annex III – paragraph 1 – point 8 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld"
    },
    {
        "uuid":"37dc256f-7616-457c-9bb8-435124534b32",
        "text":"(a a) AI systems used by political parties, political candidates, public authorities, or on their behalf for influencing natural persons in the exercise of their vote in local, national, or European Parliament elections;",
        "title":"Amendment 3235: Annex III – paragraph 1 – point 8 – point a a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"b2c34ef8-8607-4336-84c9-61231104a6db",
        "text":"(a a) AI systems that may or are intended to assist in democratic processes, the casting or counting of votes, such as in elections.",
        "title":"Amendment 3236: Annex III – paragraph 1 – point 8 – point a a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7a7c9069-625d-4296-a35d-ffefe4d904cc",
        "text":"8 a. Other applications:', '(a) AI systems intended to be used to generate, on the basis of limited human input, complex text content that would falsely appear to a person to be human generated and authentic, such as news articles, opinion articles, novels, scripts, and scientific articles, with the exception of AI systems used exclusively for content that undergoes human review and for the publication of which a natural or legal person established in the Union is liable or holds editorial responsibility;', '(b) AI systems intended to be used to generate or manipulate audio or video content that features existing natural persons appearing to say or do something they have never said or done, with the exception of AI systems used exclusively for content that forms part of an evidently artistic, creative or fictional cinematographic and analogous work;', '(c)AI systems that deploy subliminal techniques for scientific research and for therapeutical purposes;",
        "title":"Amendment 3237: Annex III – paragraph 1 – point 8 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"d1325a4a-0698-46b0-b71e-cd11692b601f",
        "text":"8 a. Other applications:', '(a) AI systems intended to be used to generate, on the basis of limited human input, complex text content that would falsely appear to a person to be human-generated and authentic, such as news articles, opinion articles, novels, scripts, and scientific articles, except where the content forms part of an evidently artistic, creative or fictional and analogous work;', '(b) AI systems intended to be used to generate or manipulate audio or video content that appreciably resembles existing natural persons, in a manner that significantly distorts or fabricates the original situation, meaning, content, or context and would falsely appear to a person to be authentic, except where the content forms part of an evidently artistic, creative or fictional cinematographic and analogous work.",
        "title":"Amendment 3238: Annex III – paragraph 1 – point 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"c35bcd58-d7bf-4574-9fd1-f6e897be1fb5",
        "text":"8 a. Use in online platforms such as social media and search engines:', 'a) AI systems intended to recommend content to users of online intermediaries such as social media platforms and search engines', 'b) AI systems intended to assist the moderation of content produced by users of online intermediaries such as social media platforms.",
        "title":"Amendment 3239: Annex III – paragraph 1 – point 8 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Cornelia Ernst"
    },
    {
        "uuid":"46a9c4ab-82f2-4f92-a1fc-897b34e84191",
        "text":"8 a. Media', '(a). Recommender systems, meaning AI systems used by an online platform to suggest in its online interface specific information to recipients of the service, including as a result of a search initiated by the recipient or otherwise determining the relative order or prominence of information displayed.",
        "title":"Amendment 3240: Annex III – paragraph 1 – point 8 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"0de00e62-f9a4-4e0e-94c4-c1db79bf3fe4",
        "text":"8 a. Others', 'a) AI systems intended to be used for the delivery of online advertising to internet users",
        "title":"Amendment 3241: Annex III – paragraph 1 – point 8 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Maria-Manuel Leitão-Marques, Paul Tang, Tiemo Wölken, Biljana Borzan, Lina Gálvez Muñoz, Birgit Sippel, Martin Schirdewan, Christel Schaldemose, Alex Agius Saliba, Karen Melchior, René Repasi, Eva Kaili, Sylvie Guillaume"
    },
    {
        "uuid":"26ff6fbd-dfc6-4ece-b6d2-78060482df3e",
        "text":"8 b. Health and Healthcare', '(a) AI systems intended to be used inside or outside of the national healthcare system the outputs of which can influence individuals’ health, for example through impacting health diagnostics, treatments or medical prescriptions.', '(b) AI systems intended to be used to facilitate administrative, planning, and health insurance processes within the healthcare system which could influence the distribution of healthcare resources, health insurance or access to healthcare.', '(c) AI systems intended to be used by pharmaceutical companies and medical technology companies to facilitate research and development, as well as for pharmacovigilance, market optimisation and pharmaceutical marketing.",
        "title":"Amendment 3242: Annex III – paragraph 1 – point 8 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"eecace41-e9c8-405d-8ee1-67d390a6267e",
        "text":"(a) its intended purpose, the person\/s developing the system the date and the version of the system, reflecting its relation to previous and, where applicable, more recent, versions in the succession of revisions;",
        "title":"Amendment 3243: Annex IV – paragraph 1 – point 1 – point a  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"4c725f26-3395-4bc3-900f-4f460d0a490f",
        "text":"(a) its intended purpose or reasonably foreseeable use, the person\/s developing the system, the date and the version of the system;",
        "title":"Amendment 3244: Annex IV – paragraph 1 – point 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"b618fb6f-6935-4ac9-8982-4f720634ae6b",
        "text":"(a) its intended purpose or reasonably foreseeable use , the person\/s developing the system the date and the version of the system;",
        "title":"Amendment 3245: Annex IV – paragraph 1 – point 1 – point a  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"b10fe77e-4035-4c48-9919-93322b960d08",
        "text":"(a) its intended purpose or reasonably foreseeable use, the person\/s developing the system the date and the version of the system;",
        "title":"Amendment 3246: Annex IV – paragraph 1 – point 1 – point a  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e044db6c-5e9f-476d-8a20-36efcc7a33ce",
        "text":"(a) its intended purpose, the name of the provider and the version of the system;",
        "title":"Amendment 3247: Annex IV – paragraph 1 – point 1 – point a a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"b55ed8b4-1e49-440a-b5f2-f7db97d3d658",
        "text":"(a a) the categories of natural persons and groups likely or foreseen to be affected;",
        "title":"Amendment 3248: Annex IV – paragraph 1 – point 1 – point a a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"43ec4c71-646f-4d2d-b56b-11e658968fb4",
        "text":"(a b) the categories and nature of data likely or foreseen to be processed;",
        "title":"Amendment 3249: Annex IV – paragraph 1 – point 1 – point a b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"117647cf-afa6-4e77-84bf-b72d70ec2bca",
        "text":"(b) how the AI system interacts or can be used to interact with hardware or software, including other AI systems that are not part of the AI system itself, where applicable;",
        "title":"Amendment 3250: Annex IV – paragraph 1 – point 1 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"53bce7aa-0770-444b-8ee0-628f7b7e2bb0",
        "text":"(b) how the AI system interacts or can be used to interact with hardware or software, including other AI systems, that are not part of the AI system itself, where applicable;",
        "title":"Amendment 3251: Annex IV – paragraph 1 – point 1 – point b  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"0f171e31-d464-4046-8f8a-23b181386935",
        "text":"(b) how the AI system is intended to be used with hardware or software that is not part of the AI system itself, where applicable;",
        "title":"Amendment 3252: Annex IV – paragraph 1 – point 1 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"14357379-d946-4964-a1fa-d43fb991a582",
        "text":"(c) the versions of relevant software or firmware and any requirement related to development, maintenance and version update;",
        "title":"Amendment 3253: Annex IV – paragraph 1 – point 1 – point c  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"fdcd9efe-6f1a-4810-af75-202207518724",
        "text":"(c) the versions of relevant software or firmware and version update information for the user, where applicable;",
        "title":"Amendment 3254: Annex IV – paragraph 1 – point 1 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"e0860c04-1b5e-4bbd-ad6c-34c6a422f6d7",
        "text":"(d) the description or list of the various configurations and variants of the AI system which are intended to be made available on the market or put into service;",
        "title":"Amendment 3255: Annex IV – paragraph 1 – point 1 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"f6f5594e-34ac-4853-8912-232615f1442a",
        "text":"(f) descriptions and, if applicable, photographs or illustrations of the user interface;",
        "title":"Amendment 3256: Annex IV – paragraph 1 – point 1 – point f  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"247c49f8-9667-4e09-8b77-d55d98825950",
        "text":"(g) instructions of use for the deployer and, where applicable installation instructions;",
        "title":"Amendment 3257: Annex IV – paragraph 1 – point 1 – point g  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3f6c75b4-7be3-47fb-bbf6-bd1d2b67451a",
        "text":"(g a) instructions on the intervention in case of emergency, interrupting the system through a “stop” button or a similar procedure that allows the system to come to a halt in a safe state;",
        "title":"Amendment 3258: Annex IV – paragraph 1 – point 1 – point g a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"06bee8d1-9a8d-4f21-b018-093cb71e4f95",
        "text":"2. Provided that no confidential information or trade secrets are disclosed, a detailed description of the AI system and of the process for its development, including:",
        "title":"Amendment 3259: Annex IV – paragraph 1 – point 2 – introductory part  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9f10ceea-1285-41a6-aa2c-f2f5d1cb8d83",
        "text":"(a) provided that no confidential information or trade secrets are disclosed, the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or tools provided by third parties and how these have been used, integrated or modified by the provider;",
        "title":"Amendment 3260: Annex IV – paragraph 1 – point 2 – point a  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"3963450f-17d9-497e-85b7-d32c68fc34a0",
        "text":"(b) the architecture and design specifications: a description of the AI system architecture, with a decomposition of its components and interfaces, how they relate to one another and how they provide for the overall processing or logic of the AI system; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;",
        "title":"Amendment 3261: Annex IV – paragraph 1 – point 2 – point b  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9bce9604-3c81-40f5-bd24-ceaf84ad2d55",
        "text":"(b) provided that no confidential information or trade secrets are disclosed, the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;",
        "title":"Amendment 3262: Annex IV – paragraph 1 – point 2 – point b  ",
        "author":"ECR",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan"
    },
    {
        "uuid":"f21cb467-173f-48de-9b76-a90ad16ec4cb",
        "text":"(b) the design specifications of the system, namely the general logic of the AI system, of the algorithms and of data structures; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;",
        "title":"Amendment 3263: Annex IV – paragraph 1 – point 2 – point b  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f0d42b12-78f0-4c7e-b879-bf181f5503cc",
        "text":"deleted",
        "title":"Amendment 3264: Annex IV – paragraph 1 – point 2 – point c  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"5b32ad15-8ffc-4b73-89e8-868d2d789d19",
        "text":"deleted",
        "title":"Amendment 3265: Annex IV – paragraph 1 – point 2 – point d  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"7a659054-8d5e-4560-81a2-c41c6c3dc57c",
        "text":"(d) where relevant, the data requirements in terms of datasheets describing the training methodologies and techniques and the training data sets used, including information about the provenance of those data sets, their scope and main characteristics; how the data was obtained, selected and prepared; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection), and methods applied to prevent bias;",
        "title":"Amendment 3266: Annex IV – paragraph 1 – point 2 – point d  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"75e4af4d-16dc-4385-bfb5-db761b14faea",
        "text":"(e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the technical measures needed to facilitate the interpretation of the outputs of AI systems by the deployers, in accordance with Articles 13(3)(d);",
        "title":"Amendment 3267: Annex IV – paragraph 1 – point 2 – point e  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"0a0520ba-ee94-4c26-a18e-9c139c7e5369",
        "text":"(g) the validation and testing procedures used, including information about the machine-learning validation and testing data used and their main characteristics; information used to measure accuracy, robustness, and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f);",
        "title":"Amendment 3268: Annex IV – paragraph 1 – point 2 – point g  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"d9d4a3e2-0edb-4b04-84ae-3514fa29241b",
        "text":"(g) the validation and testing procedures used, including information about the validation and testing data used and their main characteristics; metrics used to measure performance, robustness, cybersecurity and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f).",
        "title":"Amendment 3269: Annex IV – paragraph 1 – point 2 – point g  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"89098ed8-8875-402c-bef5-4894109a8d36",
        "text":"(g) the validation and testing procedures used, including information about the validation and testing data used and their main characteristics; metrics used to measure performance, robustness, cybersecurity and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f).",
        "title":"Amendment 3270: Annex IV – paragraph 1 – point 2 – point g  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5f754122-02b0-4b55-98cc-2d910404f790",
        "text":"(g a) cybersecurity measures put in place.",
        "title":"Amendment 3271: Annex IV – paragraph 1 – point 2 – point g a (new)  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"392d02d9-53ef-486e-8260-f6eac2ee6c48",
        "text":"3. Detailed information about the monitoring, functioning and control of the AI system, in particular with regard to: its capabilities and limitations in performance, including the degrees of accuracy for specific persons or groups of persons on which the system is intended to be used and the overall expected level of accuracy in relation to its intended purpose or reasonably foreseeable use ; the foreseeable unintended outcomes and sources of risks to health and safety, fundamental rights and discrimination in view of the intended purpose or reasonably foreseeable use of the AI system; the human oversight measures needed in accordance with Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the users; specifications on input data, as appropriate;",
        "title":"Amendment 3272: Annex IV – paragraph 1 – point 3  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"9bf70a6a-d051-4d38-90f5-ec35a1cc971d",
        "text":"3 a. A description of the appropriateness of the performance metrics for the specific AI system;",
        "title":"Amendment 3273: Annex IV – paragraph 1 – point 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"1bbc7f1d-db29-43de-9cf5-f9ee14b539b6",
        "text":"3 a. A description of the appropriateness of the performance metrics for the specific AI system.",
        "title":"Amendment 3274: Annex IV – paragraph 1 – point 3 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"e84591b1-edd2-422d-aa5f-fe95dc98a3c8",
        "text":"3 b. Detailed information about the carbon footprint and the energy efficiency of the AI system, in particular with regard to the development of hardware, computational resources, as well as algorithm design and training processes;",
        "title":"Amendment 3275: Annex IV – paragraph 1 – point 3 b (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel"
    },
    {
        "uuid":"46abfa75-ba73-4289-9d68-c347207afc50",
        "text":"3 c. Information about the computational resources required for the functioning of the AI system and its expected energy consumption during its use;",
        "title":"Amendment 3276: Annex IV – paragraph 1 – point 3 c (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina"
    },
    {
        "uuid":"de7ac3a5-bd07-4534-909d-8cc9f3b9cbf9",
        "text":"4 a. A detailed description of the system’s environmental impact in accordance with Article 10a.",
        "title":"Amendment 3277: Annex IV – paragraph 1 – point 4 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"8a65f825-fbf4-4951-82fb-f06719e644f8",
        "text":"deleted",
        "title":"Amendment 3278: Annex IV – paragraph 1 – point 5  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0ec2b340-4905-44c7-9530-fba27f8e9901",
        "text":"5. A description of relevant changes made by providers to the system through its lifecycle;",
        "title":"Amendment 3279: Annex IV – paragraph 1 – point 5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,"
    },
    {
        "uuid":"1f7372aa-f2dd-4de7-ad10-bc849837e393",
        "text":"5. A description of any relevant change made to the system through its lifecycle;",
        "title":"Amendment 3280: Annex IV – paragraph 1 – point 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"e34e8501-915a-453e-9b99-0dd9c957ac1f",
        "text":"6. A list of the harmonised standards applied in full or in part the references of which have been published in the Official Journal of the European Union; where no such harmonised standards have been applied, a detailed description of the solutions adopted to meet the requirements set out in Title III, Chapter 2, including a list of common specifications or other relevant standards and technical specifications applied;",
        "title":"Amendment 3281: Annex IV – paragraph 1 – point 6  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-"
    },
    {
        "uuid":"5ded47ff-2b0b-4cd4-ae58-b664321708e5",
        "text":"8 a. Without prejudice to Article 9(2), a detailed description of the economic and social implications and potential risks for health, and in particular mental health, safety and fundamental rights arising from the hypothetical widespread usage of the AI system or of similar systems in society, with reference to past incidents that occurred using similar systems and associated mitigating measures.",
        "title":"Amendment 3282: Annex IV – paragraph 1 – point 8 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"31326bc0-661e-44d4-9183-c573a4717fa8",
        "text":"deleted",
        "title":"Amendment 3283: Annex VI  ",
        "author":"ID",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul"
    },
    {
        "uuid":"c73dfeb6-a45c-4924-97b3-402b8d0ef84c",
        "text":"4.3. The technical documentation shall be examined by the notified body. To this purpose, the notified body shall be granted full access to the testing datasets used by the provider, including through application programming interfaces (API) or other appropriate means and tools enabling remote access.",
        "title":"Amendment 3284: Annex VII – point 4 – point 4.3  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"a32aa369-c681-4068-be97-5d321d0042c8",
        "text":"4.4. In examining the technical documentation, the notified body may require that the provider supplies further evidence or carries out further tests so as to enable a proper assessment of conformity of the AI system with the requirements set out in Title III, Chapter 2.",
        "title":"Amendment 3285: Annex VII – point 4 – point 4.4  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"9e55bea8-56db-446c-8920-0348180eca9b",
        "text":"4.5. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2, after all other reasonable ways to verify conformity have been exhausted and have proven to be insufficient, and upon a reasoned request, the notified body shall also be granted access to the source code of the AI system. Such access shall be subject to existing Union law on the protection of intellectual property and trade secrets.",
        "title":"Amendment 3286: Annex VII – point 4 – point 4.5  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"c5764893-1643-4ef7-9ce0-46c84c40d027",
        "text":"4.7. Any change to the AI system that could affect the compliance of the AI system with the requirements or its intended purpose or reasonably foreseeable use shall be approved by the notified body which issued the EU technical documentation assessment certificate. The provider shall inform such notified body of its intention to introduce any of the above-mentioned changes or if it becomes otherwise aware of the occurrence of such changes. The intended changes shall be assessed by the notified body which shall decide whether those changes require a new conformity assessment in accordance with Article 43(4) or whether they could be addressed by means of a supplement to the EU technical documentation assessment certificate. In the latter case, the notified body shall assess the changes, notify the provider of its decision and, where the changes are approved, issue to the provider a supplement to the EU technical documentation assessment certificate.",
        "title":"Amendment 3287: Annex VII – point 4 – point 4.7  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"c14f7bd0-27c2-414a-ba40-a4fd5452d73d",
        "text":"INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF HIGH-RISK AI SYSTEMS AND OF CERTAIN AI SYSTEMS, USES THEREOF, AND USES OF AI SYSTEMS BY PUBLIC AUTHORITIES IN ACCORDANCE WITH ARTICLE 51",
        "title":"Amendment 3288: Annex VIII – title  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"3d1c36ff-eecc-4e35-9ad8-4194d4f6c887",
        "text":"INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF AI SYSTEMS IN ACCORDANCE WITH ARTICLE 60",
        "title":"Amendment 3289: Annex VIII – title  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"8daedc51-a16c-410b-8b02-cbbba7191c1c",
        "text":"The following information shall be provided and thereafter kept up to date by the provider with regard to high-risk AI systems referred to in Article 6(2) and to any AI system referred to in Article 52 1(b) and (2) to be registered in accordance with Article 51(1).",
        "title":"Amendment 3290: Annex VIII – paragraph 1  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"5e232bbd-3d83-4284-a090-8c21fd2ba415",
        "text":"The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 51.",
        "title":"Amendment 3291: Annex VIII – paragraph 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"d6e24e16-00a2-469a-b8d0-d77e42a5c8da",
        "text":"The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 60.",
        "title":"Amendment 3292: Annex VIII – paragraph 1  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"501aea0c-0eb1-481b-9f2a-f7742e0c8d14",
        "text":"The following information shall be provided and thereafter kept up to date by the user with regard to uses of high-risk AI systems referred to in Article 6(2) and any AI system referred to in Article 52 1(b) and (2) to be registered in accordance with Article 51(2).', '(a) Name, address and contact details of the user;', '(b) Where submission of information is carried out by another person on behalf of the user, the name, address and contact details of that person;', '(c) Name, address and contact details of the authorised representative, where applicable;', '(d) URL of the entry of the AI system in the EU database by its provider, or, where unavailable, AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system;', '(e) Description of the intended purpose of the intended use of the AI system;', '(f) Description of the context and the geographical and temporal scope of application, geographic and temporal, of the intended use of the AI system;', '(g) Basic explanation of design specifications of the system, namely the general logic of the AI system and of the algorithms;the key design choices including the rationale and assumptions made, also with regard to categories persons or groups of persons on which the system is intended to be used;the main classification choices;and what the system is designed to optimise for and the relevance of the different parameters.', '(h) For high-risk AI systems and for systems referred to in Article 52 1(b) and (2), designation of persons foreseeably impacted by the intended use of the AI system as required by Article X;', '(i) For high-risk AI systems, results of the impact assessment on the use of the AI system that is conducted under obligations imposed by Article XX of this Regulation.Where full public disclosure of these results cannot be granted for reasons of privacy and data protection, disclosure must be granted to the national supervisory authority, which in turn must be indicated in the EU database.', '(j) A description of how the relevant accessibility requirements set out in Annex I to Directive 2019\/882 are met by the use of the AI system.",
        "title":"Amendment 3293: Annex VIII – paragraph 1 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"436bb68d-9cc2-48cb-9da1-4a2a10ebb4b3",
        "text":"1a.The following information shall be provided and updated with regard to high risk AI systems to be registered in accordance with Article 51(2) by users who are or act on behalf of public authorities or Union institutions, bodies, offices or agencies:', '1. the name, address and contact details of the user;', '2. the name, address and contact details of any person submitting information on behalf of the user;', '3. the high-risk AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system used;', '4. description of the intended use of the AI system, including the specific outcomes sought through the use of the system;', '5. a summary of the findings of the fundamental rights impact assessment conducted in accordance with the obligation of public authorities or Union institutions, agencies, offices or bodies set out in this Regulation;', '6. a summary of the data protection impact assessment carried out in accordance with Article 35 of Regulation (EU) 2016\/679 or Article 27 of Directive (EU) 2016\/680 as specified in paragraph 6 of Article 29 of this Regulation, where applicable; 6. a declaration of conformity with the applicable data protection rules.",
        "title":"Amendment 3294: Annex VIII – paragraph 1 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona"
    },
    {
        "uuid":"8344a898-6274-4767-835a-41378e2ecb57",
        "text":"The following information shall be provided and thereafter kept up to date by the user with regard to uses of AI systems by public authorities to be registered in accordance with Article 51(3).', '(a) Name, address and contact details of the user;(b) Where submission of information is carried out by another person on behalf of the user, the name, address and contact details of that person;', '(c) Name, address and contact details of the authorised representative, where applicable;', '(d) For high-risk AI systems, URL of the entry of the AI system in the EU database by its provider, or, for non-high risk systems, AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system;', '(e) Description of the intended purpose of the intended use of the AI system;', '(f) Description of the context and the geographical and temporal scope of application, geographic and temporal, of the intended use of the AI system;', '(g) Basic explanation of design specifications of the system, namely the general logic of the AI system and of the algorithms;the key design choices including the rationale and assumptions made, also with regard to categories persons or groups of persons on which the system is intended to be used;the main classification choices;and what the system is designed to optimise for and the relevance of the different parameters.', '(h) Designation of persons foreseeably impacted by the intended use of the AI system;', '(i) If available, results of any impact assessment or due diligence process regarding the use of the AI system that the user has conducted;', '(j) Assessment of the foreseeable impact on the environment, including but not limited to energy consumption, resulting from the use of the AI system over its entire lifecycle, and of the methods to reduce such impact;', '(k) A description of how the relevant accessibility requirements set out in Annex I to Directive 2019\/882 are met by the use of the AI system.",
        "title":"Amendment 3295: Annex VIII – paragraph 1 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"11dd5717-d7b6-42c5-8a03-8e15573cf5cc",
        "text":"1. Name, address and contact details of the provider or deployer;",
        "title":"Amendment 3296: Annex VIII – point 1  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"7f498907-dc64-455b-9e82-b55b8fe4b026",
        "text":"2. Where submission of information is carried out by another person on behalf of the provider or deployer, the name, address and contact details of that person;",
        "title":"Amendment 3297: Annex VIII – point 2  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"051ebbba-a34a-4d95-8798-afed5b733c5e",
        "text":"3. Name, address and contact details of the legal representative, where applicable;",
        "title":"Amendment 3298: Annex VIII – point 5  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,"
    },
    {
        "uuid":"70f43889-de5d-4e52-9d6d-04d39176a8f8",
        "text":"5. Descriptions of:', '(a) the intended purpose of the AI system;', '(b) the components and functions supported through AI;', '(c) the main parameters the AI system takes into account;', '(d) arrangements for human oversight and responsible natural persons for decisions made or influenced by the AI system;",
        "title":"Amendment 3299: Annex VIII – point 5  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"90d8be5d-e969-4833-9149-64f8c3ff26dd",
        "text":"5. Description of the intended purpose or reasonably foreseeable use of the AI system;",
        "title":"Amendment 3300: Annex VIII – point 5  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0a1a701d-672f-40a5-8bae-60a66965a1b5",
        "text":"5 a. Where applicable, the categories of natural persons and groups likely or foreseen to be affected;",
        "title":"Amendment 3301: Annex VIII – point 5 a (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"2b7c897c-10c7-418e-8772-3ae23a6ea564",
        "text":"5 b. Where applicable, the categories and nature of data likely or foreseen to be processed by the AI system;",
        "title":"Amendment 3302: Annex VIII – point 5 b (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"3f358692-89f8-4263-b219-12f08971ae1b",
        "text":"5 c. For each deployment, the deployer’s assessments of the assessment of the systems’ impact in the context of use throughout the entire lifecycle as conducted by the deployer under Article 9a;",
        "title":"Amendment 3303: Annex VIII – point 5 c (new)  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"f39028f7-f297-43f8-b168-b15d6a9ffb8c",
        "text":"6 a. where the user is obliged to register an AI system under Article 29, the human rights impact assessment must also be registered and publicly available;",
        "title":"Amendment 3304: Annex VIII – point 6 a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Sophia in t Veld, Michal Šimečka"
    },
    {
        "uuid":"4b600b10-4ac7-4c3a-a5c7-e9558c7e070b",
        "text":"deleted",
        "title":"Amendment 3305: Annex VIII – point 11  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"748f8e25-d8a6-4b1e-ba28-a7da4811cef5",
        "text":"11. Electronic instructions for use.",
        "title":"Amendment 3306: Annex VIII – point 11  ",
        "author":"Greens\/EFA",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kim Van Sparrentak, Sergey Lagodinsky"
    },
    {
        "uuid":"571c2822-99ba-4fc7-9889-24cef4f4b85b",
        "text":"11. Electronic instructions for use as listed in Article 13(3) and basic explanation of the general logic and key design as listed in Annex IV point 2(b) and of optimization choices as listed in Annex IV point (3).",
        "title":"Amendment 3307: Annex VIII – point 11  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"0ebda024-6e05-47b1-b35c-41578253e347",
        "text":"11 a. Assessment of the environmental impact, including but not limited to resource consumption, resulting from the design, data management and training, and underlying infrastructures of the AI system, and of the methods to reduce such impact;",
        "title":"Amendment 3308: Annex VIII – point 11 a (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"6ea105cf-c206-4bc8-83a8-009ea43313a1",
        "text":"11 b. A description of how the system meets the relevant accessibility requirements of Annex I to Directive 2019\/882.",
        "title":"Amendment 3309: Annex VIII – point 11 b (new)  ",
        "author":"GUE\/NGL",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura"
    },
    {
        "uuid":"2f6a091b-f880-45b8-bb81-62b84e2d2ed4",
        "text":"12 a. The list of users of the AI systems",
        "title":"Amendment 3310: Annex VIII – point 12 a (new)  ",
        "author":"S&D",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López"
    },
    {
        "uuid":"5e4b3725-3faa-47cd-bddf-16a499b4a2a4",
        "text":"4. The sandboxing programme shall, in a later development phase, look at helping Member States develop and manage two types of regulatory sandboxes: Physical Regulatory Sandboxes for AI systems embedded in physical products or services and Cyber Regulatory Sandboxes for AI systems operated and used on a stand-alone basis, not embedded in physical products or services.",
        "title":"Amendment 3311: Annex IX – title  ",
        "author":"EPP",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Axel Voss, Deirdre Clune, Eva Maydell"
    },
    {
        "uuid":"0a42e67a-3e6c-4f29-b0bb-951bf4f4a312",
        "text":"ANNEX IXa: MODALITIES FOR AN EU AI REGULATORY SANDBOXING PROGRAMME', '1.The European Commission shall establish the EU AI Regulatory Sandboxing Programme (‘sandboxing programme’) in collaboration with Member States and other competent entities such as regions or universities.', '2.The Commission shall play a complementary role, allowing those entities with demonstrated experience with sandboxing to build on their expertise and, on the other hand, assisting and providing technical understanding and resources to those Member States and regions that seek guidance on the set-up of these regulatory sandboxes.', '3.Participants in the sandboxing programme, in particular start-ups and SMEs, are granted access to pre-deployment services, such as preliminary registration of their AI system, compliance R&D support services, and to all the other relevant elements of the Union’s AI ecosystem and other Digital Single Market initiatives such as Testing &Experimentation Facilities, Digital Hubs, Centres of Excellence, and EU benchmarking capabilities;and to other value-adding services such as standardisation documents and certification, an online social platform for the community, contact databases, existing portal for tenders and grant making and lists of EU investors.', '4.Foreign providers, in particular start-ups and SMEs, are eligible to take part in the sandboxes to incubate and refine their products incompliance with this Regulation.', '5.Individuals such as researchers, entrepreneurs, innovators and other pre-market ideas owners are eligible to pre-register into the sandboxing programme to incubate and refine their products in compliance with this Regulation.', '6.The sandboxing programme and its benefits shall be available from a single portal established by the European Commission.', '7.The sandboxing programme shall develop and manage two types of regulatory sandboxes:Physical Regulatory Sandboxes for AI systems embedded in physical products or services and Cyber Regulatory Sandboxes for AI systems operated and used on a stand-alone basis, not embedded in physical products or services.', '8.The sandboxing programme shall work with the already established Digital Innovation Hubs in Member States to provide a dedicated point of contact for entrepreneurs to raise enquiries with competent authorities and to seek non-binding guidance on the conformity of innovative products, services or business models embedding AI technologies.', '9.One of the objectives of the sandboxing programme is to enable firms’ compliance with this Regulation at the design stage of the AI system (‘compliance-by-design’).To do so, the programme shall facilitate the development of software tools and infrastructure for testing, benchmarking, assessing and explaining dimensions of AI systems relevant to sandboxes, such as accuracy, robustness and cybersecurity.', '10.The sandboxing programme shall include a Reg Tech lab, to help authorities experiment and develop enforcement tools and protocols for enforcing this Regulation.', '11. The sandboxing programme shall be rolled out in a phased fashion, with the various phases launched by the Commission upon success of the previous phase. The sandboxing programme will have a built-in impact assessment procedure to facilitate the review of cost-effectiveness against the agreed-upon objectives. This assessment shall be drafted with input from Member States based on their experiences and shall be included as part of the Annual Report submitted by the Commission to the European Artificial Intelligence Board.",
        "title":"Amendment 3312: Annex IX a (new)  ",
        "author":"Renew",
        "section":"amendments",
        "content_type":"amendment",
        "proposers":"Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej"
    }
]